{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":""},{"location":"#gemseo-umdo","title":"gemseo-umdo","text":"<p><code>gemseo-umdo</code> is a plugin of the library GEMSEO, dedicated to multidisciplinary optimization (MDO) under uncertainty. This package is open-source, under the LGPL v3 license.</p>"},{"location":"#overview","title":"Overview","text":""},{"location":"#mdo-under-uncertainty","title":"MDO under uncertainty","text":"<p>The main goal of <code>gemseo-umdo</code> is to extend GEMSEO to MDO under uncertainty.</p> <p>Given a collection of disciplines, we are interested in solving a problem like</p> \\[ \\begin{align} &amp;\\underset{x\\in\\mathcal{X}}{\\operatorname{minimize}}&amp; &amp; \\mathbb{E}[f(x,U)]+\\kappa\\times\\mathbb{S}[f(x,U)] \\\\ &amp;\\operatorname{subject\\;to} &amp; &amp;\\mathbb{P}[g(x,U)\\geq 0] \\leq \\varepsilon \\end{align} \\] <p>by selecting an MDO formulation to handle the multidisciplinary coupling and an estimation technique to approximate the statistics.</p>"},{"location":"#statistics","title":"Statistics","text":"<p><code>gemseo-umdo</code> also proposes advanced techniques for uncertainty quantification and management (UQ&amp;M). In presence of multilevel simulators, multilevel Monte Carlo (MLMC) sampling can reduce the variance of the statistics estimators. Another variance reduction technique consists of using the outputs of surrogate models as control variates, even moderately correlated with the original models.</p>"},{"location":"#visualization","title":"Visualization","text":"<p>A third facet of <code>gemseo-umdo</code> is the visualization toolbox to display the propagation of the uncertainties through a multidisciplinary system as well as the interaction between the uncertain input variables.</p>"},{"location":"#installation","title":"Installation","text":"<p>Install the latest stable version with <code>pip install gemseo-umdo</code>.</p> <p>Install the development version with <code>pip install gemseo-umdo@git+https://gitlab.com/gemseo/dev/gemseo-umdo.git@develop</code>.</p> <p>See pip for more information.</p>"},{"location":"#bugs-and-questions","title":"Bugs and questions","text":"<p>Please use the gitlab issue tracker to submit bugs or questions.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>See the contributing section of GEMSEO.</p>"},{"location":"#contributors","title":"Contributors","text":"<ul> <li>Antoine Dechaume</li> <li>Matthias De Lozzo</li> </ul>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#changelog","title":"Changelog","text":"<p>All notable changes of this project will be documented here.</p> <p>The format is based on Keep a Changelog and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#develop","title":"Develop","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>The U-MDO formulation PCE creates a polynomial chaos expansion (PCE)   over the uncertain space at each iteration of the optimization loop and uses the coefficients of the PCE   to estimate the following statistics: <code>Mean</code>, <code>StandardDeviation</code>, <code>Margin</code> and <code>Variance</code>.</li> <li>The U-MDO formulations   Sampling and   SequentialSampling   have an option <code>samples_directory_path</code>   to save the samples at each iteration of the algorithm chosen for the execution of the   UDOEScenario   or UMDOScenario.</li> <li>The U-MDO formulation SequentialSampling   has an option <code>estimate_statistics_iteratively</code> (default: <code>True</code>)   to compute the statistics iteratively   and so do not store the samples in a <code>Database</code>.</li> <li>The dictionary argument <code>uncertain_design_variables</code> of   UDOEScenario   and UMDOScenario   can now accept values such as <code>(\"+\", \"u\")</code> and <code>(\"*\", \"u\")</code>   to noise the corresponding key <code>x</code> as <code>x = dv_x + u</code> and <code>x = dv_x * (1 + u)</code>   where <code>x</code> is a discipline input made uncertain by the random variable <code>u</code>.</li> <li>AdditiveNoiser   and   MultiplicativeNoiser   are disciplines to noise a design variable \\(x\\) as \\(X=x+U\\) and \\(X=x(1+U)\\) respectively   where \\(U\\) is a random variable.   BaseNoiser   can be used to create other noising disciplines   and a specific   NoiserFactory   is available.</li> <li>ControlVariate,   a new BaseUMDOFormulation   estimating the statistics with a control variate technique based on Taylor polynomials.</li> </ul>"},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li><code>gemseo_umdo.scenarios._uscenario._UScenario</code> renamed to <code>gemseo_umdo.scenarios.base_u_scenario.BaseUScenario</code>.</li> <li>API CHANGE: <code>gemseo_umdo.statistics.mlmc.pilots.pilot.MLMCPilot</code> renamed to <code>gemseo_umdo.statistics.mlmc.pilots.base_mlmc_pilot.BaseMLMCPilot</code>.</li> <li>API CHANGE: <code>gemseo_umdo.statistics.mlmc_mlcv.pilots.pilot.MLMCMLCVPilot</code> renamed to <code>gemseo_umdo.statistics.mlmc_mlcv.pilots.base_mlmc_mlcv_pilot.BaseMLMCMLCVPilot</code>.</li> <li>API CHANGE: <code>gemseo_umdo.statistics.pilot.Pilot</code> renamed to <code>gemseo_umdo.statistics.base_pilot.BasePilot</code>.</li> <li>API CHANGE: <code>gemseo_umdo.formulations.formulation.UMDOFormulation</code> renamed to <code>gemseo_umdo.formulations.base_umdo_formulation.BaseUMDOFormulation</code>.</li> <li>API CHANGE: <code>gemseo_umdo.formulations.statistics</code> is now a protected package.</li> <li>API CHANGE: <code>gemseo_umdo.formulations.functions</code> is now a protected package.</li> <li>The BeamConstraints discipline   computed outputs of the form <code>a/(b+eps)</code> where <code>eps</code> was used to avoid division by zero.   Now,   this discipline computes outputs of the form <code>b/a</code>   as <code>a</code> is never zero.</li> </ul>"},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>The U-MDO formulation Sampling   works properly when the option <code>estimate_statistics_iteratively</code>  is <code>True</code>   and the DOE option <code>n_processes</code> is greater than 1.</li> <li>The docstring of the <code>uncertain_design_variables</code> argument of   UDOEScenario   and UMDOScenario   explains that specifying a value such as <code>\"{} + u\"</code> at key <code>\"x\"</code>   assumes that both the uncertain design variable <code>\"x\"</code>   and the uncertain variable <code>\"u\"</code> are scalar variables.</li> <li>The discipline transforming the design variables into uncertain design variables   is placed before the user's disciplines;   by doing so,   the uncertain design variables can be propagated   through the multidisciplinary process   even with MDO formulations that do not ensure the satisfaction of couplings,   such as DisciplinaryOpt.</li> </ul>"},{"location":"changelog/#version-201-january-2024","title":"Version 2.0.1 (January 2024)","text":""},{"location":"changelog/#fixed_1","title":"Fixed","text":"<ul> <li>The U-MDO formulations handle the finite-difference approximation of derivatives.</li> </ul>"},{"location":"changelog/#version-200-december-2023","title":"Version 2.0.0 (December 2023)","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>Support for Python 3.11.</li> <li>A web documentation.</li> <li>The heat equation problem (   HeatEquationConfiguration,   HeatEquationDiscipline,   HeatEquationModel   and HeatEquationUncertainSpace)   to illustrate the algorithms MLMC   and MLMCMLCV.</li> <li>The MLMC and   the MLMCMLCV   algorithms to estimate a statistic of the output of a function   whose input is random.</li> <li>The MonteCarloSampler   to sample vectorized functions.</li> <li>UncertainCouplingGraph   has a new option <code>save</code> (default: <code>True</code>).</li> <li>The U-MDO formulation Sampling   has an option <code>estimate_statistics_iteratively</code> (default: <code>True</code>)   to compute the statistics iteratively   and so do not store the samples in a <code>Database</code>.</li> <li>The package <code>gemseo_umdo.formulations.functions</code> contains the <code>MDOFunction</code>s   used by a UMDOFormulation   to compute the statistics of the objective, constraints and observables.</li> <li>The logs of the UDOEScenario   and UMDOScenario   include the uncertain space.</li> </ul>"},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>Setting the argument <code>n_samples</code>   of the U-MDO formulation Sampling   is mandatory for many DOE algorithms   but optional in the case where   the DOE algorithm does not consider a <code>n_samples</code> argument to generate the samples.</li> <li>The estimator of the Variance   used by the U-MDO formulation Sampling   with <code>estimate_statistics_iteratively=False</code> is now unbiased.</li> <li>API changes:</li> <li>The options of the statistics estimators     are now set at instantiation instead of execution.</li> <li><code>gemseo_umdo.estimators</code> has been renamed to <code>gemseo_umdo.formulations.statistics</code>.</li> <li>The log of the statistics no longer includes design variables and uncertain inputs   (e.g. <code>E[y(x; u)]</code>),   but only uncertain output  (e.g. <code>E[y]</code>) to avoid display problems in large dimensions.</li> </ul>"},{"location":"changelog/#fixed_2","title":"Fixed","text":"<ul> <li>The UDOEScenario   and UMDOScenario   maximize the statistic of the objective   when the argument <code>maximize_objective</code> is set to <code>True</code>.</li> <li>The log of the objective and constraint is now consistent   with the arguments <code>maximize_objective</code> and <code>constraint_name</code>.</li> </ul>"},{"location":"changelog/#removed","title":"Removed","text":"<ul> <li>Support for Python 3.8.</li> </ul>"},{"location":"changelog/#version-111-october-2023","title":"Version 1.1.1 (October 2023)","text":""},{"location":"changelog/#fixed_3","title":"Fixed","text":"<ul> <li>One test was not compatible with GEMSEO 5.1+.</li> </ul>"},{"location":"changelog/#version-110-june-2023","title":"Version 1.1.0 (June 2023)","text":""},{"location":"changelog/#added_2","title":"Added","text":"<ul> <li>The beam problem (Beam,   BeamConstraints,   BeamUncertainSpace   and BeamDesignSpace   to benchmark robust optimization algorithms.</li> <li>TaylorPolynomial,   a new UMDOFormulation   estimating the statistics with Taylor polynomials.</li> <li>SequentialSampling,   a new UMDOFormulation   estimating the statistics with sequential sampling.</li> <li>UncertainCouplingGraph   to visualize the dispersion of the coupling variables.</li> <li>SobolGraph   to visualize the first-, second- and total-order Sobol' indices.</li> <li>The set of SpringMassModel,   SpringMassDiscipline   and SpringMassUncertainSpace   is a use case based on a spring-mass system.</li> </ul>"},{"location":"changelog/#fixed_4","title":"Fixed","text":"<ul> <li>The <code>_UScenario</code> no longer changes the list of disciplines passed by the user.</li> </ul>"},{"location":"changelog/#version-101-january-2023","title":"Version 1.0.1 (January 2023)","text":""},{"location":"changelog/#changed_2","title":"Changed","text":"<ul> <li>API change: the argument <code>statistic_estimation_options</code>   of UMDOFormulation   has been renamed to <code>statistic_estimation_parameters</code>.</li> <li>API change: <code>UMDOFormulation._processed_functions</code> replaces <code>Sampling.processed_functions</code>.</li> </ul>"},{"location":"changelog/#version-100-july-2022","title":"Version 1.0.0 (July 2022)","text":"<p>First release.</p>"},{"location":"credits/","title":"Credits","text":""},{"location":"credits/#credits","title":"Credits","text":"<p>The developers thank all the open source libraries making <code>gemseo-umdo</code> possible.</p>"},{"location":"credits/#external-dependencies","title":"External Dependencies","text":"<p><code>gemseo-umdo</code> depends on software with compatible licenses that are listed below.</p> <p>GEMSEO : GNU LGPL v3.0</p> <p>Python : Python Software License</p>"},{"location":"credits/#internal-dependencies","title":"Internal Dependencies","text":"<p><code>gemseo-umdo</code> source code includes software with compatible licenses that are listed below.</p>"},{"location":"credits/#external-application","title":"External application","text":"<p>Some external applications are used by <code>gemseo-umdo</code>, but not linked with the application, for documentation generation, training or example purposes.</p> <p>commitizen : MIT</p> <p>pre-commit : MIT</p> <p>pygrep-hooks : MIT</p> <p>pytest : MIT</p> <p>pytest-cov : MIT</p> <p>pytest-xdist : MIT</p> <p>ruff : MIT</p> <p>setuptools : MIT</p> <p>setuptools_scm : MIT</p>"},{"location":"credits/#resources","title":"Resources","text":"<p>Some icons and fonts are used by <code>gemseo-umdo</code> or its documentation.</p>"},{"location":"licenses/","title":"Licenses","text":""},{"location":"licenses/#licenses","title":"Licenses","text":""},{"location":"licenses/#gnu-lgpl-v30","title":"GNU LGPL v3.0","text":"<p>The <code>gemseo-mlearning</code> source code is distributed under the GNU LGPL v3.0 license. <pre><code>Copyright 2021 IRT Saint Exup\u00e9ry, https://www.irt-saintexupery.com\n\nThis program is free software; you can redistribute it and/or\nmodify it under the terms of the GNU Lesser General Public\nLicense version 3 as published by the Free Software Foundation.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\nLesser General Public License for more details.\n\nYou should have received a copy of the GNU Lesser General Public License\nalong with this program; if not, write to the Free Software Foundation,\nInc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.\n</code></pre></p>"},{"location":"licenses/#bsd-0-clause","title":"BSD 0-Clause","text":"<p>The <code>gemseo-mlearning</code> examples are distributed under the BSD 0-Clause <pre><code>Copyright 2021 IRT Saint Exup\u00e9ry, https://www.irt-saintexupery.com\n\nThis work is licensed under a BSD 0-Clause License.\n\nPermission to use, copy, modify, and/or distribute this software\nfor any purpose with or without fee is hereby granted.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL\nWARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL\nTHE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\nOR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING\nFROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT,\nNEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION\nWITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n</code></pre></p>"},{"location":"licenses/#cc-by-sa-40","title":"CC BY-SA 4.0","text":"<p>The <code>gemseo-mlearning</code> documentation is distributed under the CC BY-SA 4.0 license. <pre><code>Copyright 2021 IRT Saint Exup\u00e9ry, https://www.irt-saintexupery.com\n\nThis work is licensed under the Creative Commons Attribution-ShareAlike 4.0\nInternational License. To view a copy of this license, visit\nhttp://creativecommons.org/licenses/by-sa/4.0/ or send a letter to Creative\nCommons, PO Box 1866, Mountain View, CA 94042, USA.\n</code></pre></p>"},{"location":"generated/examples/","title":"Index","text":""},{"location":"generated/examples/#examples","title":"Examples","text":""},{"location":"generated/examples/problems/","title":"Problems","text":""},{"location":"generated/examples/problems/#problems","title":"Problems","text":""},{"location":"generated/examples/problems/#the-beam-problem","title":"The beam problem","text":"<p> Optimization problem. </p> <p> Sobol' sensitivity analysis. </p> <p> Robust optimization problem. </p> <p> Large DOE study. </p> <p> Download all examples in Python source code: problems_python.zip</p> <p> Download all examples in Jupyter notebooks: problems_jupyter.zip</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/problems/beam_model/mg_execution_times/","title":"Computation times","text":"<p>00:30.733 total execution time for generated_examples_problems_beam_model files:</p> <p>+------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_beam_rob_opt (docs/examples/problems/beam_model/plot_beam_rob_opt.py) | 00:23.655 | 0.0 MB | +------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_beam_doe (docs/examples/problems/beam_model/plot_beam_doe.py)             | 00:02.937 | 0.0 MB | +------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_beam_sa (docs/examples/problems/beam_model/plot_beam_sa.py)                | 00:02.638 | 0.0 MB | +------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_beam_opt (docs/examples/problems/beam_model/plot_beam_opt.py)             | 00:01.503 | 0.0 MB | +------------------------------------------------------------------------------------------------------+-----------+--------+</p>"},{"location":"generated/examples/problems/beam_model/plot_beam_doe/","title":"Large DOE study.","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/problems/beam_model/plot_beam_doe/#large-doe-study","title":"Large DOE study.","text":"<p>Sample the weight \\(w(h,t)\\) and the constraints \\(c_{\\text{stress}}(h,t)\\) and \\(c_{\\text{displacement}}(h,t)\\) w.r.t. the height \\(h\\in[500, 800]\\) and the thickness \\(t\\in[2,10]\\).</p> <p>Out:</p> <pre><code>    INFO - 23:18:10:  \n    INFO - 23:18:10: *** Start DOEScenario execution ***\n    INFO - 23:18:10: DOEScenario\n    INFO - 23:18:10:    Disciplines: Beam BeamConstraints\n    INFO - 23:18:10:    MDO formulation: MDF\n    INFO - 23:18:10: Optimization problem:\n    INFO - 23:18:10:    minimize w(h, t)\n    INFO - 23:18:10:    with respect to h, t\n    INFO - 23:18:10:    subject to constraints:\n    INFO - 23:18:10:       c_stress(h, t) &lt;= 1.0\n    INFO - 23:18:10:       c_displ(h, t) &gt;= 1.0\n    INFO - 23:18:10:    over the design space:\n    INFO - 23:18:10:       +------+-------------+-------+-------------+-------+\n    INFO - 23:18:10:       | Name | Lower bound | Value | Upper bound | Type  |\n    INFO - 23:18:10:       +------+-------------+-------+-------------+-------+\n    INFO - 23:18:10:       | h    |     500     |  800  |     800     | float |\n    INFO - 23:18:10:       | t    |      2      |  2.5  |      10     | float |\n    INFO - 23:18:10:       +------+-------------+-------+-------------+-------+\n    INFO - 23:18:10: Solving optimization problem with algorithm fullfact:\n    INFO - 23:18:10:      1%|          | 1/100 [00:00&lt;00:01, 52.51 it/sec, obj=55.8]\n    INFO - 23:18:10:      2%|\u258f         | 2/100 [00:00&lt;00:01, 92.83 it/sec, obj=57.6]\n    INFO - 23:18:10:      3%|\u258e         | 3/100 [00:00&lt;00:00, 127.19 it/sec, obj=59.5]\n    INFO - 23:18:10:      4%|\u258d         | 4/100 [00:00&lt;00:00, 156.28 it/sec, obj=61.4]\n    INFO - 23:18:10:      5%|\u258c         | 5/100 [00:00&lt;00:00, 180.98 it/sec, obj=63.2]\n    INFO - 23:18:10:      6%|\u258c         | 6/100 [00:00&lt;00:00, 202.02 it/sec, obj=65.1]\n    INFO - 23:18:10:      7%|\u258b         | 7/100 [00:00&lt;00:00, 220.96 it/sec, obj=67]\n    INFO - 23:18:10:      8%|\u258a         | 8/100 [00:00&lt;00:00, 237.22 it/sec, obj=68.8]\n    INFO - 23:18:10:      9%|\u2589         | 9/100 [00:00&lt;00:00, 251.19 it/sec, obj=70.7]\n    INFO - 23:18:10:     10%|\u2588         | 10/100 [00:00&lt;00:00, 264.10 it/sec, obj=72.6]\n    INFO - 23:18:10:     11%|\u2588         | 11/100 [00:00&lt;00:00, 276.10 it/sec, obj=80.4]\n    INFO - 23:18:10:     12%|\u2588\u258f        | 12/100 [00:00&lt;00:00, 286.82 it/sec, obj=83.1]\n    INFO - 23:18:10:     13%|\u2588\u258e        | 13/100 [00:00&lt;00:00, 296.51 it/sec, obj=85.8]\n    INFO - 23:18:10:     14%|\u2588\u258d        | 14/100 [00:00&lt;00:00, 305.50 it/sec, obj=88.5]\n    INFO - 23:18:10:     15%|\u2588\u258c        | 15/100 [00:00&lt;00:00, 313.89 it/sec, obj=91.2]\n    INFO - 23:18:10:     16%|\u2588\u258c        | 16/100 [00:00&lt;00:00, 321.47 it/sec, obj=93.9]\n    INFO - 23:18:10:     17%|\u2588\u258b        | 17/100 [00:00&lt;00:00, 328.42 it/sec, obj=96.6]\n    INFO - 23:18:10:     18%|\u2588\u258a        | 18/100 [00:00&lt;00:00, 334.73 it/sec, obj=99.3]\n    INFO - 23:18:10:     19%|\u2588\u2589        | 19/100 [00:00&lt;00:00, 340.80 it/sec, obj=102]\n    INFO - 23:18:10:     20%|\u2588\u2588        | 20/100 [00:00&lt;00:00, 346.08 it/sec, obj=105]\n    INFO - 23:18:11:     21%|\u2588\u2588        | 21/100 [00:00&lt;00:00, 351.30 it/sec, obj=105]\n    INFO - 23:18:11:     22%|\u2588\u2588\u258f       | 22/100 [00:00&lt;00:00, 355.92 it/sec, obj=109]\n    INFO - 23:18:11:     23%|\u2588\u2588\u258e       | 23/100 [00:00&lt;00:00, 358.99 it/sec, obj=112]\n    INFO - 23:18:11:     24%|\u2588\u2588\u258d       | 24/100 [00:00&lt;00:00, 362.70 it/sec, obj=116]\n    INFO - 23:18:11:     25%|\u2588\u2588\u258c       | 25/100 [00:00&lt;00:00, 366.56 it/sec, obj=119]\n    INFO - 23:18:11:     26%|\u2588\u2588\u258c       | 26/100 [00:00&lt;00:00, 370.50 it/sec, obj=123]\n    INFO - 23:18:11:     27%|\u2588\u2588\u258b       | 27/100 [00:00&lt;00:00, 374.20 it/sec, obj=126]\n    INFO - 23:18:11:     28%|\u2588\u2588\u258a       | 28/100 [00:00&lt;00:00, 377.73 it/sec, obj=130]\n    INFO - 23:18:11:     29%|\u2588\u2588\u2589       | 29/100 [00:00&lt;00:00, 380.82 it/sec, obj=133]\n    INFO - 23:18:11:     30%|\u2588\u2588\u2588       | 30/100 [00:00&lt;00:00, 383.91 it/sec, obj=137]\n    INFO - 23:18:11:     31%|\u2588\u2588\u2588       | 31/100 [00:00&lt;00:00, 386.89 it/sec, obj=129]\n    INFO - 23:18:11:     32%|\u2588\u2588\u2588\u258f      | 32/100 [00:00&lt;00:00, 389.74 it/sec, obj=134]\n    INFO - 23:18:11:     33%|\u2588\u2588\u2588\u258e      | 33/100 [00:00&lt;00:00, 392.30 it/sec, obj=138]\n    INFO - 23:18:11:     34%|\u2588\u2588\u2588\u258d      | 34/100 [00:00&lt;00:00, 394.63 it/sec, obj=143]\n    INFO - 23:18:11:     35%|\u2588\u2588\u2588\u258c      | 35/100 [00:00&lt;00:00, 396.99 it/sec, obj=147]\n    INFO - 23:18:11:     36%|\u2588\u2588\u2588\u258c      | 36/100 [00:00&lt;00:00, 399.34 it/sec, obj=151]\n    INFO - 23:18:11:     37%|\u2588\u2588\u2588\u258b      | 37/100 [00:00&lt;00:00, 401.56 it/sec, obj=156]\n    INFO - 23:18:11:     38%|\u2588\u2588\u2588\u258a      | 38/100 [00:00&lt;00:00, 403.63 it/sec, obj=160]\n    INFO - 23:18:11:     39%|\u2588\u2588\u2588\u2589      | 39/100 [00:00&lt;00:00, 405.48 it/sec, obj=164]\n    INFO - 23:18:11:     40%|\u2588\u2588\u2588\u2588      | 40/100 [00:00&lt;00:00, 407.37 it/sec, obj=169]\n    INFO - 23:18:11:     41%|\u2588\u2588\u2588\u2588      | 41/100 [00:00&lt;00:00, 409.12 it/sec, obj=154]\n    INFO - 23:18:11:     42%|\u2588\u2588\u2588\u2588\u258f     | 42/100 [00:00&lt;00:00, 410.84 it/sec, obj=159]\n    INFO - 23:18:11:     43%|\u2588\u2588\u2588\u2588\u258e     | 43/100 [00:00&lt;00:00, 412.55 it/sec, obj=164]\n    INFO - 23:18:11:     44%|\u2588\u2588\u2588\u2588\u258d     | 44/100 [00:00&lt;00:00, 413.92 it/sec, obj=169]\n    INFO - 23:18:11:     45%|\u2588\u2588\u2588\u2588\u258c     | 45/100 [00:00&lt;00:00, 415.47 it/sec, obj=175]\n    INFO - 23:18:11:     46%|\u2588\u2588\u2588\u2588\u258c     | 46/100 [00:00&lt;00:00, 416.96 it/sec, obj=180]\n    INFO - 23:18:11:     47%|\u2588\u2588\u2588\u2588\u258b     | 47/100 [00:00&lt;00:00, 418.50 it/sec, obj=185]\n    INFO - 23:18:11:     48%|\u2588\u2588\u2588\u2588\u258a     | 48/100 [00:00&lt;00:00, 419.99 it/sec, obj=190]\n    INFO - 23:18:11:     49%|\u2588\u2588\u2588\u2588\u2589     | 49/100 [00:00&lt;00:00, 421.30 it/sec, obj=195]\n    INFO - 23:18:11:     50%|\u2588\u2588\u2588\u2588\u2588     | 50/100 [00:00&lt;00:00, 422.61 it/sec, obj=200]\n    INFO - 23:18:11:     51%|\u2588\u2588\u2588\u2588\u2588     | 51/100 [00:00&lt;00:00, 423.32 it/sec, obj=178]\n    INFO - 23:18:11:     52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 52/100 [00:00&lt;00:00, 423.75 it/sec, obj=184]\n    INFO - 23:18:11:     53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 53/100 [00:00&lt;00:00, 424.60 it/sec, obj=190]\n    INFO - 23:18:11:     54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 54/100 [00:00&lt;00:00, 425.56 it/sec, obj=196]\n    INFO - 23:18:11:     55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 55/100 [00:00&lt;00:00, 426.51 it/sec, obj=202]\n    INFO - 23:18:11:     56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 56/100 [00:00&lt;00:00, 427.45 it/sec, obj=208]\n    INFO - 23:18:11:     57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 57/100 [00:00&lt;00:00, 428.37 it/sec, obj=214]\n    INFO - 23:18:11:     58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 58/100 [00:00&lt;00:00, 429.25 it/sec, obj=220]\n    INFO - 23:18:11:     59%|\u2588\u2588\u2588\u2588\u2588\u2589    | 59/100 [00:00&lt;00:00, 430.13 it/sec, obj=226]\n    INFO - 23:18:11:     60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 60/100 [00:00&lt;00:00, 431.09 it/sec, obj=232]\n    INFO - 23:18:11:     61%|\u2588\u2588\u2588\u2588\u2588\u2588    | 61/100 [00:00&lt;00:00, 432.09 it/sec, obj=202]\n    INFO - 23:18:11:     62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 62/100 [00:00&lt;00:00, 433.00 it/sec, obj=209]\n    INFO - 23:18:11:     63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 63/100 [00:00&lt;00:00, 433.67 it/sec, obj=216]\n    INFO - 23:18:11:     64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 64/100 [00:00&lt;00:00, 434.27 it/sec, obj=223]\n    INFO - 23:18:11:     65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 65/100 [00:00&lt;00:00, 435.11 it/sec, obj=230]\n    INFO - 23:18:11:     66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 66/100 [00:00&lt;00:00, 435.92 it/sec, obj=237]\n    INFO - 23:18:11:     67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 67/100 [00:00&lt;00:00, 436.43 it/sec, obj=243]\n    INFO - 23:18:11:     68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 68/100 [00:00&lt;00:00, 436.93 it/sec, obj=250]\n    INFO - 23:18:11:     69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 69/100 [00:00&lt;00:00, 437.38 it/sec, obj=257]\n    INFO - 23:18:11:     70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 70/100 [00:00&lt;00:00, 437.99 it/sec, obj=264]\n    INFO - 23:18:11:     71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 71/100 [00:00&lt;00:00, 438.65 it/sec, obj=226]\n    INFO - 23:18:11:     72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 72/100 [00:00&lt;00:00, 439.26 it/sec, obj=234]\n    INFO - 23:18:11:     73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 73/100 [00:00&lt;00:00, 439.76 it/sec, obj=242]\n    INFO - 23:18:11:     74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 74/100 [00:00&lt;00:00, 440.27 it/sec, obj=249]\n    INFO - 23:18:11:     75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 75/100 [00:00&lt;00:00, 440.80 it/sec, obj=257]\n    INFO - 23:18:11:     76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 76/100 [00:00&lt;00:00, 441.36 it/sec, obj=265]\n    INFO - 23:18:11:     77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 77/100 [00:00&lt;00:00, 441.94 it/sec, obj=272]\n    INFO - 23:18:11:     78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 78/100 [00:00&lt;00:00, 442.44 it/sec, obj=280]\n    INFO - 23:18:11:     79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 79/100 [00:00&lt;00:00, 443.00 it/sec, obj=288]\n    INFO - 23:18:11:     80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 80/100 [00:00&lt;00:00, 443.57 it/sec, obj=296]\n    INFO - 23:18:11:     81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 81/100 [00:00&lt;00:00, 444.14 it/sec, obj=250]\n    INFO - 23:18:11:     82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 82/100 [00:00&lt;00:00, 444.64 it/sec, obj=259]\n    INFO - 23:18:11:     83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 83/100 [00:00&lt;00:00, 445.05 it/sec, obj=267]\n    INFO - 23:18:11:     84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 84/100 [00:00&lt;00:00, 445.48 it/sec, obj=276]\n    INFO - 23:18:11:     85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 85/100 [00:00&lt;00:00, 445.91 it/sec, obj=284]\n    INFO - 23:18:11:     86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 86/100 [00:00&lt;00:00, 446.36 it/sec, obj=293]\n    INFO - 23:18:11:     87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 87/100 [00:00&lt;00:00, 446.80 it/sec, obj=301]\n    INFO - 23:18:11:     88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 88/100 [00:00&lt;00:00, 447.24 it/sec, obj=310]\n    INFO - 23:18:11:     89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 89/100 [00:00&lt;00:00, 447.66 it/sec, obj=318]\n    INFO - 23:18:11:     90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 90/100 [00:00&lt;00:00, 448.07 it/sec, obj=327]\n    INFO - 23:18:11:     91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 91/100 [00:00&lt;00:00, 448.49 it/sec, obj=274]\n    INFO - 23:18:11:     92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 92/100 [00:00&lt;00:00, 448.88 it/sec, obj=284]\n    INFO - 23:18:11:     93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 93/100 [00:00&lt;00:00, 449.30 it/sec, obj=293]\n    INFO - 23:18:11:     94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 94/100 [00:00&lt;00:00, 449.59 it/sec, obj=302]\n    INFO - 23:18:11:     95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 95/100 [00:00&lt;00:00, 449.92 it/sec, obj=312]\n    INFO - 23:18:11:     96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 96/100 [00:00&lt;00:00, 450.28 it/sec, obj=321]\n    INFO - 23:18:11:     97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 97/100 [00:00&lt;00:00, 450.65 it/sec, obj=330]\n    INFO - 23:18:11:     98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 98/100 [00:00&lt;00:00, 451.01 it/sec, obj=340]\n    INFO - 23:18:11:     99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 99/100 [00:00&lt;00:00, 451.21 it/sec, obj=349]\n    INFO - 23:18:11:    100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:00&lt;00:00, 451.50 it/sec, obj=358]\n    INFO - 23:18:11: Optimization result:\n    INFO - 23:18:11:    Optimizer info:\n    INFO - 23:18:11:       Status: None\n    INFO - 23:18:11:       Message: None\n    INFO - 23:18:11:       Number of calls to the objective function by the optimizer: 100\n    INFO - 23:18:11:    Solution:\n    INFO - 23:18:11:       The solution is feasible.\n    INFO - 23:18:11:       Objective: 257.1326419753086\n    INFO - 23:18:11:       Standardized constraints:\n    INFO - 23:18:11:          -[c_displ-1.0] = [-0.01235799 -0.01235799 -0.01235799 -0.00782042 -0.00782042 -0.00782042\n    INFO - 23:18:11:  -0.01235799 -0.01235799 -0.01235799]\n    INFO - 23:18:11:          [c_stress-1.0] = [-0.05840978 -0.06171919 -0.05840978 -0.8696619  -1.         -0.8696619\n    INFO - 23:18:11:  -0.05840978 -0.06171919 -0.05840978]\n    INFO - 23:18:11:       Design space:\n    INFO - 23:18:11:          +------+-------------+-------------------+-------------+-------+\n    INFO - 23:18:11:          | Name | Lower bound |       Value       | Upper bound | Type  |\n    INFO - 23:18:11:          +------+-------------+-------------------+-------------+-------+\n    INFO - 23:18:11:          | h    |     500     | 633.3333333333333 |     800     | float |\n    INFO - 23:18:11:          | t    |      2      | 8.222222222222221 |      10     | float |\n    INFO - 23:18:11:          +------+-------------+-------------------+-------------+-------+\n    INFO - 23:18:11: *** End DOEScenario execution (time: 0:00:00.231656) ***\n/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/pandas/core/frame.py:706: DeprecationWarning: Passing a BlockManager to OptimizationDataset is deprecated and will raise in a future version. Use public APIs instead.\n  warnings.warn(\n/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/pandas/core/frame.py:706: DeprecationWarning: Passing a BlockManager to OptimizationDataset is deprecated and will raise in a future version. Use public APIs instead.\n  warnings.warn(\n</code></pre> <p></p> <pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.post.dataset.zvsxy import ZvsXY\nfrom gemseo.scenarios.doe_scenario import DOEScenario\n\nfrom gemseo_umdo.use_cases.beam_model.constraints import BeamConstraints\nfrom gemseo_umdo.use_cases.beam_model.design_space import BeamDesignSpace\nfrom gemseo_umdo.use_cases.beam_model.discipline import Beam\n\nconfigure_logger()\n\ndisciplines = [Beam(), BeamConstraints()]\n\ndesign_space = BeamDesignSpace()\n\nscenario = DOEScenario(disciplines, \"MDF\", \"w\", design_space)\nscenario.add_constraint(\"c_stress\", constraint_type=\"ineq\", value=1.0)\nscenario.add_constraint(\"c_displ\", constraint_type=\"ineq\", positive=True, value=1.0)\nscenario.execute({\"algo\": \"fullfact\", \"n_samples\": 10**2})\n\ndataset = scenario.formulation.optimization_problem.to_dataset()\nZvsXY(dataset, \"h\", \"t\", \"w\").execute(save=True, show=False, file_name=\"w\")\nfor constraint_name in [\"-[c_displ-1.0]\", \"[c_stress-1.0]\"]:\n    for z_component in range(9):\n        ZvsXY(dataset, \"h\", \"t\", (constraint_name, z_component)).execute(\n            save=False,\n            show=True,\n        )\n</code></pre> <p>Total running time of the script: ( 0 minutes  2.937 seconds)</p> <p> Download Python source code: plot_beam_doe.py</p> <p> Download Jupyter notebook: plot_beam_doe.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/problems/beam_model/plot_beam_opt/","title":"Optimization problem.","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/problems/beam_model/plot_beam_opt/#optimization-problem","title":"Optimization problem.","text":"<p>Minimize the weight \\(w(h,t)\\) w.r.t. the height \\(h\\in[500, 800]\\) and the thickness \\(t\\in[2,10]\\) while satisfying \\(c_{\\text{stress}}(h,t)\\geq 1.0\\) and \\(c_{\\text{displacement}}(h,t)\\leq 1.0\\).</p> <p>Out:</p> <pre><code>    INFO - 23:17:42:  \n    INFO - 23:17:42: *** Start MDOScenario execution ***\n    INFO - 23:17:42: MDOScenario\n    INFO - 23:17:42:    Disciplines: Beam BeamConstraints\n    INFO - 23:17:42:    MDO formulation: MDF\n    INFO - 23:17:42: Optimization problem:\n    INFO - 23:17:42:    minimize w(h, t)\n    INFO - 23:17:42:    with respect to h, t\n    INFO - 23:17:42:    subject to constraints:\n    INFO - 23:17:42:       c_stress(h, t) &lt;= 1.0\n    INFO - 23:17:42:       c_displ(h, t) &gt;= 1.0\n    INFO - 23:17:42:    over the design space:\n    INFO - 23:17:42:       +------+-------------+-------+-------------+-------+\n    INFO - 23:17:42:       | Name | Lower bound | Value | Upper bound | Type  |\n    INFO - 23:17:42:       +------+-------------+-------+-------------+-------+\n    INFO - 23:17:42:       | h    |     500     |  800  |     800     | float |\n    INFO - 23:17:42:       | t    |      2      |  2.5  |      10     | float |\n    INFO - 23:17:42:       +------+-------------+-------+-------------+-------+\n    INFO - 23:17:42: Solving optimization problem with algorithm NLOPT_COBYLA:\n    INFO - 23:17:42:      1%|          | 6/1000 [00:00&lt;00:05, 179.70 it/sec, obj=182]\n    INFO - 23:17:42:      1%|          | 7/1000 [00:00&lt;00:05, 192.84 it/sec, obj=211]\n    INFO - 23:17:42:      1%|          | 8/1000 [00:00&lt;00:04, 204.56 it/sec, obj=225]\n    INFO - 23:17:42:      1%|          | 9/1000 [00:00&lt;00:04, 214.52 it/sec, obj=222]\n    INFO - 23:17:42:      1%|          | 10/1000 [00:00&lt;00:04, 223.12 it/sec, obj=220]\n    INFO - 23:17:42:      1%|          | 11/1000 [00:00&lt;00:04, 230.42 it/sec, obj=229]\n    INFO - 23:17:42:      1%|          | 12/1000 [00:00&lt;00:04, 237.32 it/sec, obj=228]\n    INFO - 23:17:42:      1%|\u258f         | 13/1000 [00:00&lt;00:04, 243.63 it/sec, obj=229]\n    INFO - 23:17:42:      1%|\u258f         | 14/1000 [00:00&lt;00:03, 248.93 it/sec, obj=229]\n    INFO - 23:17:42:      2%|\u258f         | 15/1000 [00:00&lt;00:03, 253.99 it/sec, obj=229]\n    INFO - 23:17:42:      2%|\u258f         | 16/1000 [00:00&lt;00:03, 258.52 it/sec, obj=229]\n    INFO - 23:17:42:      2%|\u258f         | 17/1000 [00:00&lt;00:03, 262.76 it/sec, obj=229]\n    INFO - 23:17:42:      2%|\u258f         | 18/1000 [00:00&lt;00:03, 264.48 it/sec, obj=229]\n    INFO - 23:17:42:      2%|\u258f         | 19/1000 [00:00&lt;00:03, 267.14 it/sec, obj=229]\n    INFO - 23:17:42:      2%|\u258f         | 20/1000 [00:00&lt;00:03, 270.59 it/sec, obj=229]\n    INFO - 23:17:42:      2%|\u258f         | 21/1000 [00:00&lt;00:03, 273.69 it/sec, obj=229]\n    INFO - 23:17:42:      2%|\u258f         | 22/1000 [00:00&lt;00:03, 276.34 it/sec, obj=229]\n    INFO - 23:17:42:      2%|\u258f         | 23/1000 [00:00&lt;00:03, 279.08 it/sec, obj=229]\n    INFO - 23:17:42:      2%|\u258f         | 24/1000 [00:00&lt;00:03, 281.60 it/sec, obj=229]\n    INFO - 23:17:42:      2%|\u258e         | 25/1000 [00:00&lt;00:03, 283.68 it/sec, obj=229]\n    INFO - 23:17:42:      3%|\u258e         | 26/1000 [00:00&lt;00:03, 284.73 it/sec, obj=229]\n    INFO - 23:17:42:      3%|\u258e         | 27/1000 [00:00&lt;00:03, 285.93 it/sec, obj=229]\n    INFO - 23:17:42:      3%|\u258e         | 28/1000 [00:00&lt;00:03, 287.03 it/sec, obj=229]\n    INFO - 23:17:42:      3%|\u258e         | 29/1000 [00:00&lt;00:03, 287.84 it/sec, obj=229]\n    INFO - 23:17:42:      3%|\u258e         | 30/1000 [00:00&lt;00:03, 288.91 it/sec, obj=229]\n    INFO - 23:17:42:      3%|\u258e         | 31/1000 [00:00&lt;00:03, 289.73 it/sec, obj=229]\n    INFO - 23:17:42:      3%|\u258e         | 32/1000 [00:00&lt;00:03, 290.58 it/sec, obj=229]\n    INFO - 23:17:42:      3%|\u258e         | 33/1000 [00:00&lt;00:03, 291.39 it/sec, obj=229]\n    INFO - 23:17:42:      3%|\u258e         | 34/1000 [00:00&lt;00:03, 291.89 it/sec, obj=229]\n    INFO - 23:17:42:      4%|\u258e         | 35/1000 [00:00&lt;00:03, 292.65 it/sec, obj=229]\n    INFO - 23:17:42:      4%|\u258e         | 36/1000 [00:00&lt;00:03, 293.16 it/sec, obj=229]\n    INFO - 23:17:42:      4%|\u258e         | 37/1000 [00:00&lt;00:03, 293.64 it/sec, obj=229]\n    INFO - 23:17:42:      4%|\u258d         | 38/1000 [00:00&lt;00:03, 293.88 it/sec, obj=229]\n    INFO - 23:17:42:      4%|\u258d         | 39/1000 [00:00&lt;00:03, 294.07 it/sec, obj=229]\n    INFO - 23:17:42:      4%|\u258d         | 40/1000 [00:00&lt;00:03, 294.46 it/sec, obj=229]\n    INFO - 23:17:42:      4%|\u258d         | 41/1000 [00:00&lt;00:03, 294.98 it/sec, obj=229]\n    INFO - 23:17:42: Optimization result:\n    INFO - 23:17:42:    Optimizer info:\n    INFO - 23:17:42:       Status: None\n    INFO - 23:17:42:       Message: Successive iterates of the objective function are closer than ftol_rel or ftol_abs. GEMSEO Stopped the driver\n    INFO - 23:17:42:       Number of calls to the objective function by the optimizer: 42\n    INFO - 23:17:42:    Solution:\n    INFO - 23:17:42:       The solution is feasible.\n    INFO - 23:17:42:       Objective: 229.1109776763463\n    INFO - 23:17:42:       Standardized constraints:\n    INFO - 23:17:42:          -[c_displ-1.0] = [-5.19123398e-03 -5.19123398e-03 -5.19123398e-03 -3.51346551e-05\n    INFO - 23:17:42:  -3.51346551e-05 -3.51346551e-05 -5.19123398e-03 -5.19123398e-03\n    INFO - 23:17:42:  -5.19123398e-03]\n    INFO - 23:17:42:          [c_stress-1.0] = [ 3.02343028e-05 -3.52038986e-03  3.02343028e-05 -8.57307483e-01\n    INFO - 23:17:42:  -1.00000000e+00 -8.57307483e-01  3.02343028e-05 -3.52038986e-03\n    INFO - 23:17:42:   3.02343028e-05]\n    INFO - 23:17:42:       Design space:\n    INFO - 23:17:42:          +------+-------------+-------------------+-------------+-------+\n    INFO - 23:17:42:          | Name | Lower bound |       Value       | Upper bound | Type  |\n    INFO - 23:17:42:          +------+-------------+-------------------+-------------+-------+\n    INFO - 23:17:42:          | h    |     500     | 677.8534696587071 |     800     | float |\n    INFO - 23:17:42:          | t    |      2      | 7.030927890734481 |      10     | float |\n    INFO - 23:17:42:          +------+-------------+-------------------+-------------+-------+\n    INFO - 23:17:42: *** End MDOScenario execution (time: 0:00:00.151844) ***\n\n&lt;gemseo.post.opt_history_view.OptHistoryView object at 0x7b28ae51b850&gt;\n</code></pre> <p></p> <pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.scenarios.mdo_scenario import MDOScenario\n\nfrom gemseo_umdo.use_cases.beam_model.constraints import BeamConstraints\nfrom gemseo_umdo.use_cases.beam_model.design_space import BeamDesignSpace\nfrom gemseo_umdo.use_cases.beam_model.discipline import Beam\n\nconfigure_logger()\n\ndisciplines = [Beam(), BeamConstraints()]\n\ndesign_space = BeamDesignSpace()\n\nscenario = MDOScenario(disciplines, \"MDF\", \"w\", design_space)\nscenario.add_constraint(\"c_stress\", constraint_type=\"ineq\", value=1.0)\nscenario.add_constraint(\"c_displ\", constraint_type=\"ineq\", positive=True, value=1.0)\nscenario.execute({\"algo\": \"NLOPT_COBYLA\", \"max_iter\": 1000})\n\nscenario.post_process(\"OptHistoryView\", save=False, show=True)\n</code></pre> <p>Total running time of the script: ( 0 minutes  1.503 seconds)</p> <p> Download Python source code: plot_beam_opt.py</p> <p> Download Jupyter notebook: plot_beam_opt.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/problems/beam_model/plot_beam_rob_opt/","title":"Robust optimization problem.","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/problems/beam_model/plot_beam_rob_opt/#robust-optimization-problem","title":"Robust optimization problem.","text":"<p>Minimize the expectation of the weight \\(w(h,t)\\) w.r.t. the height \\(h\\in[500, 800]\\) and the thickness \\(t\\in[2,10]\\) while satisfying \\(c_{\\text{stress}}(h,t)\\geq 1.0\\) and \\(c_{\\text{displacement}}(h,t)\\leq 1.0\\) with probability 90\\% where \\(F\\), \\(E\\) and \\(\\sigma_{\\text{all}}\\) are random variables defined by <code>BeamUncertainSpace</code>.</p> <p>Out:</p> <pre><code>    INFO - 23:17:47:  \n    INFO - 23:17:47: *** Start UMDOScenario execution ***\n    INFO - 23:17:47: UMDOScenario\n    INFO - 23:17:47:    Disciplines: Beam BeamConstraints\n    INFO - 23:17:47:    Formulation:\n    INFO - 23:17:47:       MDO formulation: MDF\n    INFO - 23:17:47:       Statistic estimation: Sampling\n    INFO - 23:17:47:    Uncertain space:\n    INFO - 23:17:47:       +-----------+-----------------------------------------------+\n    INFO - 23:17:47:       |    Name   |                  Distribution                 |\n    INFO - 23:17:47:       +-----------+-----------------------------------------------+\n    INFO - 23:17:47:       |     F     | Normal(mu=-200000.0, sigma=6666.666666666667) |\n    INFO - 23:17:47:       |     E     |        Normal(mu=73500.0, sigma=1225.0)       |\n    INFO - 23:17:47:       | sigma_all |          Normal(mu=300.0, sigma=5.0)          |\n    INFO - 23:17:47:       +-----------+-----------------------------------------------+\n    INFO - 23:17:47: Optimization problem:\n    INFO - 23:17:47:    minimize E[w]\n    INFO - 23:17:47:    with respect to h, t\n    INFO - 23:17:47:    subject to constraints:\n    INFO - 23:17:47:       P[c_stress &lt;= 1.0] &gt;= 0.9\n    INFO - 23:17:47:       P[c_displ &gt;= 1.0] &gt;= 0.9\n    INFO - 23:17:47:    over the design space:\n    INFO - 23:17:47:       +------+-------------+-------+-------------+-------+\n    INFO - 23:17:47:       | Name | Lower bound | Value | Upper bound | Type  |\n    INFO - 23:17:47:       +------+-------------+-------+-------------+-------+\n    INFO - 23:17:47:       | h    |     500     |  800  |     800     | float |\n    INFO - 23:17:47:       | t    |      2      |  2.5  |      10     | float |\n    INFO - 23:17:47:       +------+-------------+-------+-------------+-------+\n    INFO - 23:17:47: Solving optimization problem with algorithm NLOPT_COBYLA:\n    INFO - 23:17:47:      3%|\u258e         | 1/30 [00:00&lt;00:11,  2.45 it/sec, obj=90.6]\n    INFO - 23:17:48:      7%|\u258b         | 2/30 [00:01&lt;00:16,  1.71 it/sec, obj=85.4]\n    INFO - 23:17:49:     10%|\u2588         | 3/30 [00:01&lt;00:17,  1.54 it/sec, obj=153]\n    INFO - 23:17:49:     13%|\u2588\u258e        | 4/30 [00:02&lt;00:17,  1.47 it/sec, obj=102]\n    INFO - 23:17:50:     17%|\u2588\u258b        | 5/30 [00:03&lt;00:17,  1.41 it/sec, obj=102]\n    INFO - 23:17:51:     20%|\u2588\u2588        | 6/30 [00:04&lt;00:17,  1.39 it/sec, obj=68.3]\n    INFO - 23:17:52:     23%|\u2588\u2588\u258e       | 7/30 [00:05&lt;00:16,  1.38 it/sec, obj=68.3]\n    INFO - 23:17:52:     27%|\u2588\u2588\u258b       | 8/30 [00:05&lt;00:16,  1.37 it/sec, obj=68.4]\n    INFO - 23:17:53:     30%|\u2588\u2588\u2588       | 9/30 [00:06&lt;00:15,  1.36 it/sec, obj=69]\n    INFO - 23:17:54:     33%|\u2588\u2588\u2588\u258e      | 10/30 [00:07&lt;00:14,  1.36 it/sec, obj=68.4]\n    INFO - 23:17:55:     37%|\u2588\u2588\u2588\u258b      | 11/30 [00:08&lt;00:14,  1.36 it/sec, obj=69.7]\n    INFO - 23:17:55:     40%|\u2588\u2588\u2588\u2588      | 12/30 [00:08&lt;00:13,  1.35 it/sec, obj=68.4]\n    INFO - 23:17:56:     43%|\u2588\u2588\u2588\u2588\u258e     | 13/30 [00:09&lt;00:12,  1.34 it/sec, obj=69.1]\n    INFO - 23:17:57:     47%|\u2588\u2588\u2588\u2588\u258b     | 14/30 [00:10&lt;00:11,  1.34 it/sec, obj=68.4]\n    INFO - 23:17:58:     50%|\u2588\u2588\u2588\u2588\u2588     | 15/30 [00:11&lt;00:11,  1.34 it/sec, obj=70.1]\n    INFO - 23:17:59:     53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 16/30 [00:11&lt;00:10,  1.34 it/sec, obj=68.3]\n    INFO - 23:17:59:     57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 17/30 [00:12&lt;00:09,  1.34 it/sec, obj=72.4]\n    INFO - 23:18:00:     60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 18/30 [00:13&lt;00:08,  1.34 it/sec, obj=68.4]\n    INFO - 23:18:01:     63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 19/30 [00:14&lt;00:08,  1.34 it/sec, obj=69.7]\n    INFO - 23:18:02:     67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 20/30 [00:15&lt;00:07,  1.33 it/sec, obj=68.3]\n    INFO - 23:18:02:     70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 21/30 [00:15&lt;00:06,  1.33 it/sec, obj=75.5]\n    INFO - 23:18:03:     73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 22/30 [00:16&lt;00:06,  1.33 it/sec, obj=68.4]\n    INFO - 23:18:04:     77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 23/30 [00:17&lt;00:05,  1.33 it/sec, obj=69.3]\n    INFO - 23:18:05:     80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 24/30 [00:18&lt;00:04,  1.33 it/sec, obj=68.4]\n    INFO - 23:18:05:     83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 25/30 [00:18&lt;00:03,  1.33 it/sec, obj=68.1]\n    INFO - 23:18:06:     87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 26/30 [00:19&lt;00:03,  1.33 it/sec, obj=68.4]\n    INFO - 23:18:07:     90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 27/30 [00:20&lt;00:02,  1.33 it/sec, obj=68.4]\n    INFO - 23:18:08:     93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 28/30 [00:21&lt;00:01,  1.33 it/sec, obj=68.4]\n    INFO - 23:18:08:     97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 29/30 [00:21&lt;00:00,  1.33 it/sec, obj=68.4]\n    INFO - 23:18:09:    100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:22&lt;00:00,  1.33 it/sec, obj=67.9]\n WARNING - 23:18:10: Optimization found no feasible point !  The least infeasible point is selected.\n    INFO - 23:18:10: Optimization result:\n    INFO - 23:18:10:    Optimizer info:\n    INFO - 23:18:10:       Status: None\n    INFO - 23:18:10:       Message: Maximum number of iterations reached. GEMSEO Stopped the driver\n    INFO - 23:18:10:       Number of calls to the objective function by the optimizer: 32\n    INFO - 23:18:10:    Solution:\n WARNING - 23:18:10:       The solution is not feasible.\n    INFO - 23:18:10:       Objective: 90.6499999999999\n    INFO - 23:18:10:       Standardized constraints:\n    INFO - 23:18:10:          -[P[c_displ &gt;= 1.0]-0.9] = [-0.1 -0.1 -0.1 -0.1 -0.1 -0.1 -0.1 -0.1 -0.1]\n    INFO - 23:18:10:          -[P[c_stress &lt;= 1.0]-0.9] = [ 0.9  0.9  0.9 -0.1 -0.1 -0.1  0.9  0.9  0.9]\n    INFO - 23:18:10:       Design space:\n    INFO - 23:18:10:          +------+-------------+-------+-------------+-------+\n    INFO - 23:18:10:          | Name | Lower bound | Value | Upper bound | Type  |\n    INFO - 23:18:10:          +------+-------------+-------+-------------+-------+\n    INFO - 23:18:10:          | h    |     500     |  800  |     800     | float |\n    INFO - 23:18:10:          | t    |      2      |  2.5  |      10     | float |\n    INFO - 23:18:10:          +------+-------------+-------+-------------+-------+\n    INFO - 23:18:10: *** End UMDOScenario execution (time: 0:00:22.999452) ***\n WARNING - 23:18:10: Optimization found no feasible point !  The least infeasible point is selected.\n\n&lt;gemseo.post.opt_history_view.OptHistoryView object at 0x7b28aba6d610&gt;\n</code></pre> <p></p> <pre><code>from __future__ import annotations\n\nfrom gemseo import configure\nfrom gemseo import configure_logger\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\nfrom gemseo_umdo.use_cases.beam_model.constraints import BeamConstraints\nfrom gemseo_umdo.use_cases.beam_model.design_space import BeamDesignSpace\nfrom gemseo_umdo.use_cases.beam_model.discipline import Beam\nfrom gemseo_umdo.use_cases.beam_model.uncertain_space import BeamUncertainSpace\n\nconfigure()\nconfigure_logger()\n\nscenario = UMDOScenario(\n    [Beam(), BeamConstraints()],\n    \"MDF\",\n    \"w\",\n    BeamDesignSpace(),\n    BeamUncertainSpace(uniform=False),\n    \"Mean\",\n    statistic_estimation=\"Sampling\",\n    statistic_estimation_parameters={\"n_samples\": 200},\n)\nscenario.add_constraint(\n    \"c_stress\", \"Probability\", greater=False, threshold=1.0, positive=True, value=0.9\n)\nscenario.add_constraint(\n    \"c_displ\", \"Probability\", greater=True, threshold=1.0, positive=True, value=0.9\n)\nscenario.execute({\"algo\": \"NLOPT_COBYLA\", \"max_iter\": 30})\n\nscenario.post_process(\"OptHistoryView\", save=False, show=True)\n</code></pre> <p>Total running time of the script: ( 0 minutes  23.655 seconds)</p> <p> Download Python source code: plot_beam_rob_opt.py</p> <p> Download Jupyter notebook: plot_beam_rob_opt.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/problems/beam_model/plot_beam_sa/","title":"Sobol' sensitivity analysis.","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/problems/beam_model/plot_beam_sa/#sobol-sensitivity-analysis","title":"Sobol' sensitivity analysis.","text":"<p>Compute and plot the total Sobol' indices for the field constraints \\(c_{\\text{stress}}\\) and \\(c_{\\text{displacement}}\\) where \\(F\\), \\(E\\) and \\(\\sigma_{\\text{all}}\\) are random variables defined by <code>BeamUncertainSpace</code>.</p> <p>Out:</p> <pre><code>/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib/python3.9/site-packages/gemseo/uncertainty/distributions/openturns/distribution.py:180: DocstringInheritanceWarning: in OTDistribution._pdf: section Args: the docstring for the argument 'value' is missing.\n  def _pdf(self, value: float) -&gt; float:\n/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib/python3.9/site-packages/gemseo/uncertainty/distributions/scipy/joint.py:69: DocstringInheritanceWarning: in SPJointDistribution._create_distribution: section Args: the docstring for the argument '**options' is missing.\n  def _create_distribution(\n/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib/python3.9/site-packages/gemseo/uncertainty/distributions/scipy/joint.py:75: DocstringInheritanceWarning: in SPJointDistribution.compute_cdf: section Args: the docstring for the argument 'vector' is missing.\n  def compute_cdf(  # noqa: D102\n/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib/python3.9/site-packages/gemseo/uncertainty/distributions/scipy/joint.py:84: DocstringInheritanceWarning: in SPJointDistribution.compute_inverse_cdf: section Args: the docstring for the argument 'vector' is missing.\n  def compute_inverse_cdf(  # noqa: D102\n/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib/python3.9/site-packages/gemseo/uncertainty/distributions/scipy/distribution.py:147: DocstringInheritanceWarning: in SPDistribution._pdf: section Args: the docstring for the argument 'value' is missing.\n  def _pdf(\n WARNING - 23:17:44: No coupling in MDA, switching chain_linearize to True.\n    INFO - 23:17:44:  \n    INFO - 23:17:44: *** Start SobolAnalysisSamplingPhase execution ***\n    INFO - 23:17:44: SobolAnalysisSamplingPhase\n    INFO - 23:17:44:    Disciplines: MDOChain\n    INFO - 23:17:44:    MDO formulation: MDF\n    INFO - 23:17:44: Running the algorithm OT_SOBOL_INDICES:\n    INFO - 23:17:44:      1%|          | 3/496 [00:00&lt;00:05, 90.06 it/sec]\n    INFO - 23:17:44:      1%|          | 4/496 [00:00&lt;00:04, 109.20 it/sec]\n    INFO - 23:17:44:      1%|          | 5/496 [00:00&lt;00:03, 125.46 it/sec]\n    INFO - 23:17:44:      1%|          | 6/496 [00:00&lt;00:03, 139.16 it/sec]\n    INFO - 23:17:44:      1%|\u258f         | 7/496 [00:00&lt;00:03, 150.88 it/sec]\n    INFO - 23:17:44:      2%|\u258f         | 8/496 [00:00&lt;00:03, 161.01 it/sec]\n    INFO - 23:17:44:      2%|\u258f         | 9/496 [00:00&lt;00:02, 170.13 it/sec]\n    INFO - 23:17:44:      2%|\u258f         | 10/496 [00:00&lt;00:02, 178.16 it/sec]\n    INFO - 23:17:44:      2%|\u258f         | 11/496 [00:00&lt;00:02, 185.38 it/sec]\n    INFO - 23:17:44:      2%|\u258f         | 12/496 [00:00&lt;00:02, 191.79 it/sec]\n    INFO - 23:17:44:      3%|\u258e         | 13/496 [00:00&lt;00:02, 197.75 it/sec]\n    INFO - 23:17:44:      3%|\u258e         | 14/496 [00:00&lt;00:02, 203.13 it/sec]\n    INFO - 23:17:44:      3%|\u258e         | 15/496 [00:00&lt;00:02, 208.06 it/sec]\n    INFO - 23:17:44:      3%|\u258e         | 16/496 [00:00&lt;00:02, 212.30 it/sec]\n    INFO - 23:17:44:      3%|\u258e         | 17/496 [00:00&lt;00:02, 216.33 it/sec]\n    INFO - 23:17:44:      4%|\u258e         | 18/496 [00:00&lt;00:02, 219.86 it/sec]\n    INFO - 23:17:44:      4%|\u258d         | 19/496 [00:00&lt;00:02, 223.14 it/sec]\n    INFO - 23:17:44:      4%|\u258d         | 20/496 [00:00&lt;00:02, 226.16 it/sec]\n    INFO - 23:17:44:      4%|\u258d         | 21/496 [00:00&lt;00:02, 228.99 it/sec]\n    INFO - 23:17:44:      4%|\u258d         | 22/496 [00:00&lt;00:02, 231.61 it/sec]\n    INFO - 23:17:44:      5%|\u258d         | 23/496 [00:00&lt;00:02, 233.95 it/sec]\n    INFO - 23:17:44:      5%|\u258d         | 24/496 [00:00&lt;00:01, 236.22 it/sec]\n    INFO - 23:17:44:      5%|\u258c         | 25/496 [00:00&lt;00:01, 238.45 it/sec]\n    INFO - 23:17:44:      5%|\u258c         | 26/496 [00:00&lt;00:01, 240.40 it/sec]\n    INFO - 23:17:44:      5%|\u258c         | 27/496 [00:00&lt;00:01, 242.32 it/sec]\n    INFO - 23:17:44:      6%|\u258c         | 28/496 [00:00&lt;00:01, 244.21 it/sec]\n    INFO - 23:17:44:      6%|\u258c         | 29/496 [00:00&lt;00:01, 246.01 it/sec]\n    INFO - 23:17:44:      6%|\u258c         | 30/496 [00:00&lt;00:01, 247.73 it/sec]\n    INFO - 23:17:44:      6%|\u258b         | 31/496 [00:00&lt;00:01, 249.27 it/sec]\n    INFO - 23:17:44:      6%|\u258b         | 32/496 [00:00&lt;00:01, 250.76 it/sec]\n    INFO - 23:17:44:      7%|\u258b         | 33/496 [00:00&lt;00:01, 252.22 it/sec]\n    INFO - 23:17:44:      7%|\u258b         | 34/496 [00:00&lt;00:01, 253.62 it/sec]\n    INFO - 23:17:44:      7%|\u258b         | 35/496 [00:00&lt;00:01, 254.95 it/sec]\n    INFO - 23:17:44:      7%|\u258b         | 36/496 [00:00&lt;00:01, 256.13 it/sec]\n    INFO - 23:17:44:      7%|\u258b         | 37/496 [00:00&lt;00:01, 257.30 it/sec]\n    INFO - 23:17:44:      8%|\u258a         | 38/496 [00:00&lt;00:01, 258.43 it/sec]\n    INFO - 23:17:44:      8%|\u258a         | 39/496 [00:00&lt;00:01, 259.52 it/sec]\n    INFO - 23:17:44:      8%|\u258a         | 40/496 [00:00&lt;00:01, 260.53 it/sec]\n    INFO - 23:17:44:      8%|\u258a         | 41/496 [00:00&lt;00:01, 261.53 it/sec]\n    INFO - 23:17:44:      8%|\u258a         | 42/496 [00:00&lt;00:01, 262.52 it/sec]\n    INFO - 23:17:44:      9%|\u258a         | 43/496 [00:00&lt;00:01, 263.35 it/sec]\n    INFO - 23:17:44:      9%|\u2589         | 44/496 [00:00&lt;00:01, 264.20 it/sec]\n    INFO - 23:17:44:      9%|\u2589         | 45/496 [00:00&lt;00:01, 264.82 it/sec]\n    INFO - 23:17:44:      9%|\u2589         | 46/496 [00:00&lt;00:01, 265.61 it/sec]\n    INFO - 23:17:44:      9%|\u2589         | 47/496 [00:00&lt;00:01, 266.38 it/sec]\n    INFO - 23:17:44:     10%|\u2589         | 48/496 [00:00&lt;00:01, 267.09 it/sec]\n    INFO - 23:17:44:     10%|\u2589         | 49/496 [00:00&lt;00:01, 267.73 it/sec]\n    INFO - 23:17:44:     10%|\u2588         | 50/496 [00:00&lt;00:01, 268.40 it/sec]\n    INFO - 23:17:44:     10%|\u2588         | 51/496 [00:00&lt;00:01, 269.04 it/sec]\n    INFO - 23:17:44:     10%|\u2588         | 52/496 [00:00&lt;00:01, 269.66 it/sec]\n    INFO - 23:17:44:     11%|\u2588         | 53/496 [00:00&lt;00:01, 270.25 it/sec]\n    INFO - 23:17:44:     11%|\u2588         | 54/496 [00:00&lt;00:01, 270.83 it/sec]\n    INFO - 23:17:44:     11%|\u2588         | 55/496 [00:00&lt;00:01, 271.34 it/sec]\n    INFO - 23:17:44:     11%|\u2588\u258f        | 56/496 [00:00&lt;00:01, 271.88 it/sec]\n    INFO - 23:17:44:     11%|\u2588\u258f        | 57/496 [00:00&lt;00:01, 272.38 it/sec]\n    INFO - 23:17:44:     12%|\u2588\u258f        | 58/496 [00:00&lt;00:01, 272.79 it/sec]\n    INFO - 23:17:44:     12%|\u2588\u258f        | 59/496 [00:00&lt;00:01, 273.18 it/sec]\n    INFO - 23:17:44:     12%|\u2588\u258f        | 60/496 [00:00&lt;00:01, 273.51 it/sec]\n    INFO - 23:17:44:     12%|\u2588\u258f        | 61/496 [00:00&lt;00:01, 273.68 it/sec]\n    INFO - 23:17:44:     12%|\u2588\u258e        | 62/496 [00:00&lt;00:01, 273.95 it/sec]\n    INFO - 23:17:44:     13%|\u2588\u258e        | 63/496 [00:00&lt;00:01, 274.08 it/sec]\n    INFO - 23:17:44:     13%|\u2588\u258e        | 64/496 [00:00&lt;00:01, 274.40 it/sec]\n    INFO - 23:17:44:     13%|\u2588\u258e        | 65/496 [00:00&lt;00:01, 274.72 it/sec]\n    INFO - 23:17:44:     13%|\u2588\u258e        | 66/496 [00:00&lt;00:01, 275.03 it/sec]\n    INFO - 23:17:44:     14%|\u2588\u258e        | 67/496 [00:00&lt;00:01, 275.10 it/sec]\n    INFO - 23:17:44:     14%|\u2588\u258e        | 68/496 [00:00&lt;00:01, 275.45 it/sec]\n    INFO - 23:17:44:     14%|\u2588\u258d        | 69/496 [00:00&lt;00:01, 275.82 it/sec]\n    INFO - 23:17:44:     14%|\u2588\u258d        | 70/496 [00:00&lt;00:01, 276.12 it/sec]\n    INFO - 23:17:44:     14%|\u2588\u258d        | 71/496 [00:00&lt;00:01, 276.42 it/sec]\n    INFO - 23:17:44:     15%|\u2588\u258d        | 72/496 [00:00&lt;00:01, 276.81 it/sec]\n    INFO - 23:17:44:     15%|\u2588\u258d        | 73/496 [00:00&lt;00:01, 277.08 it/sec]\n    INFO - 23:17:44:     15%|\u2588\u258d        | 74/496 [00:00&lt;00:01, 277.39 it/sec]\n    INFO - 23:17:44:     15%|\u2588\u258c        | 75/496 [00:00&lt;00:01, 277.77 it/sec]\n    INFO - 23:17:44:     15%|\u2588\u258c        | 76/496 [00:00&lt;00:01, 278.14 it/sec]\n    INFO - 23:17:44:     16%|\u2588\u258c        | 77/496 [00:00&lt;00:01, 278.46 it/sec]\n    INFO - 23:17:44:     16%|\u2588\u258c        | 78/496 [00:00&lt;00:01, 278.86 it/sec]\n    INFO - 23:17:44:     16%|\u2588\u258c        | 79/496 [00:00&lt;00:01, 279.18 it/sec]\n    INFO - 23:17:44:     16%|\u2588\u258c        | 80/496 [00:00&lt;00:01, 279.47 it/sec]\n    INFO - 23:17:44:     16%|\u2588\u258b        | 81/496 [00:00&lt;00:01, 279.73 it/sec]\n    INFO - 23:17:44:     17%|\u2588\u258b        | 82/496 [00:00&lt;00:01, 280.00 it/sec]\n    INFO - 23:17:44:     17%|\u2588\u258b        | 83/496 [00:00&lt;00:01, 280.28 it/sec]\n    INFO - 23:17:44:     17%|\u2588\u258b        | 84/496 [00:00&lt;00:01, 280.56 it/sec]\n    INFO - 23:17:44:     17%|\u2588\u258b        | 85/496 [00:00&lt;00:01, 280.85 it/sec]\n    INFO - 23:17:44:     17%|\u2588\u258b        | 86/496 [00:00&lt;00:01, 281.16 it/sec]\n    INFO - 23:17:44:     18%|\u2588\u258a        | 87/496 [00:00&lt;00:01, 281.43 it/sec]\n    INFO - 23:17:44:     18%|\u2588\u258a        | 88/496 [00:00&lt;00:01, 281.67 it/sec]\n    INFO - 23:17:44:     18%|\u2588\u258a        | 89/496 [00:00&lt;00:01, 281.91 it/sec]\n    INFO - 23:17:44:     18%|\u2588\u258a        | 90/496 [00:00&lt;00:01, 282.13 it/sec]\n    INFO - 23:17:44:     18%|\u2588\u258a        | 91/496 [00:00&lt;00:01, 282.34 it/sec]\n    INFO - 23:17:44:     19%|\u2588\u258a        | 92/496 [00:00&lt;00:01, 282.56 it/sec]\n    INFO - 23:17:44:     19%|\u2588\u2589        | 93/496 [00:00&lt;00:01, 282.76 it/sec]\n    INFO - 23:17:44:     19%|\u2588\u2589        | 94/496 [00:00&lt;00:01, 282.97 it/sec]\n    INFO - 23:17:44:     19%|\u2588\u2589        | 95/496 [00:00&lt;00:01, 283.16 it/sec]\n    INFO - 23:17:44:     19%|\u2588\u2589        | 96/496 [00:00&lt;00:01, 283.36 it/sec]\n    INFO - 23:17:44:     20%|\u2588\u2589        | 97/496 [00:00&lt;00:01, 283.46 it/sec]\n    INFO - 23:17:44:     20%|\u2588\u2589        | 98/496 [00:00&lt;00:01, 283.29 it/sec]\n    INFO - 23:17:44:     20%|\u2588\u2589        | 99/496 [00:00&lt;00:01, 283.09 it/sec]\n    INFO - 23:17:44:     20%|\u2588\u2588        | 100/496 [00:00&lt;00:01, 283.10 it/sec]\n    INFO - 23:17:44:     20%|\u2588\u2588        | 101/496 [00:00&lt;00:01, 283.12 it/sec]\n    INFO - 23:17:44:     21%|\u2588\u2588        | 102/496 [00:00&lt;00:01, 283.13 it/sec]\n    INFO - 23:17:44:     21%|\u2588\u2588        | 103/496 [00:00&lt;00:01, 283.15 it/sec]\n    INFO - 23:17:44:     21%|\u2588\u2588        | 104/496 [00:00&lt;00:01, 283.23 it/sec]\n    INFO - 23:17:44:     21%|\u2588\u2588        | 105/496 [00:00&lt;00:01, 283.31 it/sec]\n    INFO - 23:17:44:     21%|\u2588\u2588\u258f       | 106/496 [00:00&lt;00:01, 283.41 it/sec]\n    INFO - 23:17:44:     22%|\u2588\u2588\u258f       | 107/496 [00:00&lt;00:01, 283.47 it/sec]\n    INFO - 23:17:44:     22%|\u2588\u2588\u258f       | 108/496 [00:00&lt;00:01, 283.60 it/sec]\n    INFO - 23:17:44:     22%|\u2588\u2588\u258f       | 109/496 [00:00&lt;00:01, 283.72 it/sec]\n    INFO - 23:17:44:     22%|\u2588\u2588\u258f       | 110/496 [00:00&lt;00:01, 283.84 it/sec]\n    INFO - 23:17:44:     22%|\u2588\u2588\u258f       | 111/496 [00:00&lt;00:01, 283.97 it/sec]\n    INFO - 23:17:44:     23%|\u2588\u2588\u258e       | 112/496 [00:00&lt;00:01, 284.11 it/sec]\n    INFO - 23:17:44:     23%|\u2588\u2588\u258e       | 113/496 [00:00&lt;00:01, 284.20 it/sec]\n    INFO - 23:17:44:     23%|\u2588\u2588\u258e       | 114/496 [00:00&lt;00:01, 284.31 it/sec]\n    INFO - 23:17:44:     23%|\u2588\u2588\u258e       | 115/496 [00:00&lt;00:01, 284.40 it/sec]\n    INFO - 23:17:44:     23%|\u2588\u2588\u258e       | 116/496 [00:00&lt;00:01, 284.52 it/sec]\n    INFO - 23:17:44:     24%|\u2588\u2588\u258e       | 117/496 [00:00&lt;00:01, 284.66 it/sec]\n    INFO - 23:17:44:     24%|\u2588\u2588\u258d       | 118/496 [00:00&lt;00:01, 284.75 it/sec]\n    INFO - 23:17:44:     24%|\u2588\u2588\u258d       | 119/496 [00:00&lt;00:01, 284.83 it/sec]\n    INFO - 23:17:44:     24%|\u2588\u2588\u258d       | 120/496 [00:00&lt;00:01, 284.84 it/sec]\n    INFO - 23:17:44:     24%|\u2588\u2588\u258d       | 121/496 [00:00&lt;00:01, 284.93 it/sec]\n    INFO - 23:17:44:     25%|\u2588\u2588\u258d       | 122/496 [00:00&lt;00:01, 285.06 it/sec]\n    INFO - 23:17:44:     25%|\u2588\u2588\u258d       | 123/496 [00:00&lt;00:01, 285.21 it/sec]\n    INFO - 23:17:44:     25%|\u2588\u2588\u258c       | 124/496 [00:00&lt;00:01, 285.33 it/sec]\n    INFO - 23:17:44:     25%|\u2588\u2588\u258c       | 125/496 [00:00&lt;00:01, 285.46 it/sec]\n    INFO - 23:17:44:     25%|\u2588\u2588\u258c       | 126/496 [00:00&lt;00:01, 285.57 it/sec]\n    INFO - 23:17:44:     26%|\u2588\u2588\u258c       | 127/496 [00:00&lt;00:01, 285.67 it/sec]\n    INFO - 23:17:44:     26%|\u2588\u2588\u258c       | 128/496 [00:00&lt;00:01, 285.78 it/sec]\n    INFO - 23:17:44:     26%|\u2588\u2588\u258c       | 129/496 [00:00&lt;00:01, 285.85 it/sec]\n    INFO - 23:17:44:     26%|\u2588\u2588\u258c       | 130/496 [00:00&lt;00:01, 285.85 it/sec]\n    INFO - 23:17:44:     26%|\u2588\u2588\u258b       | 131/496 [00:00&lt;00:01, 285.89 it/sec]\n    INFO - 23:17:44:     27%|\u2588\u2588\u258b       | 132/496 [00:00&lt;00:01, 285.94 it/sec]\n    INFO - 23:17:44:     27%|\u2588\u2588\u258b       | 133/496 [00:00&lt;00:01, 286.02 it/sec]\n    INFO - 23:17:44:     27%|\u2588\u2588\u258b       | 134/496 [00:00&lt;00:01, 286.10 it/sec]\n    INFO - 23:17:44:     27%|\u2588\u2588\u258b       | 135/496 [00:00&lt;00:01, 286.17 it/sec]\n    INFO - 23:17:44:     27%|\u2588\u2588\u258b       | 136/496 [00:00&lt;00:01, 286.28 it/sec]\n    INFO - 23:17:44:     28%|\u2588\u2588\u258a       | 137/496 [00:00&lt;00:01, 286.37 it/sec]\n    INFO - 23:17:44:     28%|\u2588\u2588\u258a       | 138/496 [00:00&lt;00:01, 286.48 it/sec]\n    INFO - 23:17:44:     28%|\u2588\u2588\u258a       | 139/496 [00:00&lt;00:01, 286.54 it/sec]\n    INFO - 23:17:44:     28%|\u2588\u2588\u258a       | 140/496 [00:00&lt;00:01, 286.61 it/sec]\n    INFO - 23:17:44:     28%|\u2588\u2588\u258a       | 141/496 [00:00&lt;00:01, 286.73 it/sec]\n    INFO - 23:17:44:     29%|\u2588\u2588\u258a       | 142/496 [00:00&lt;00:01, 286.85 it/sec]\n    INFO - 23:17:44:     29%|\u2588\u2588\u2589       | 143/496 [00:00&lt;00:01, 286.94 it/sec]\n    INFO - 23:17:44:     29%|\u2588\u2588\u2589       | 144/496 [00:00&lt;00:01, 287.04 it/sec]\n    INFO - 23:17:44:     29%|\u2588\u2588\u2589       | 145/496 [00:00&lt;00:01, 287.14 it/sec]\n    INFO - 23:17:44:     29%|\u2588\u2588\u2589       | 146/496 [00:00&lt;00:01, 287.20 it/sec]\n    INFO - 23:17:44:     30%|\u2588\u2588\u2589       | 147/496 [00:00&lt;00:01, 287.27 it/sec]\n    INFO - 23:17:44:     30%|\u2588\u2588\u2589       | 148/496 [00:00&lt;00:01, 287.25 it/sec]\n    INFO - 23:17:44:     30%|\u2588\u2588\u2588       | 149/496 [00:00&lt;00:01, 287.22 it/sec]\n    INFO - 23:17:44:     30%|\u2588\u2588\u2588       | 150/496 [00:00&lt;00:01, 287.17 it/sec]\n    INFO - 23:17:44:     30%|\u2588\u2588\u2588       | 151/496 [00:00&lt;00:01, 287.18 it/sec]\n    INFO - 23:17:44:     31%|\u2588\u2588\u2588       | 152/496 [00:00&lt;00:01, 287.20 it/sec]\n    INFO - 23:17:44:     31%|\u2588\u2588\u2588       | 153/496 [00:00&lt;00:01, 287.24 it/sec]\n    INFO - 23:17:44:     31%|\u2588\u2588\u2588       | 154/496 [00:00&lt;00:01, 287.31 it/sec]\n    INFO - 23:17:44:     31%|\u2588\u2588\u2588\u258f      | 155/496 [00:00&lt;00:01, 287.36 it/sec]\n    INFO - 23:17:44:     31%|\u2588\u2588\u2588\u258f      | 156/496 [00:00&lt;00:01, 287.42 it/sec]\n    INFO - 23:17:44:     32%|\u2588\u2588\u2588\u258f      | 157/496 [00:00&lt;00:01, 287.49 it/sec]\n    INFO - 23:17:44:     32%|\u2588\u2588\u2588\u258f      | 158/496 [00:00&lt;00:01, 287.53 it/sec]\n    INFO - 23:17:44:     32%|\u2588\u2588\u2588\u258f      | 159/496 [00:00&lt;00:01, 287.62 it/sec]\n    INFO - 23:17:44:     32%|\u2588\u2588\u2588\u258f      | 160/496 [00:00&lt;00:01, 287.61 it/sec]\n    INFO - 23:17:44:     32%|\u2588\u2588\u2588\u258f      | 161/496 [00:00&lt;00:01, 287.65 it/sec]\n    INFO - 23:17:44:     33%|\u2588\u2588\u2588\u258e      | 162/496 [00:00&lt;00:01, 287.71 it/sec]\n    INFO - 23:17:44:     33%|\u2588\u2588\u2588\u258e      | 163/496 [00:00&lt;00:01, 287.75 it/sec]\n    INFO - 23:17:44:     33%|\u2588\u2588\u2588\u258e      | 164/496 [00:00&lt;00:01, 287.81 it/sec]\n    INFO - 23:17:44:     33%|\u2588\u2588\u2588\u258e      | 165/496 [00:00&lt;00:01, 287.82 it/sec]\n    INFO - 23:17:44:     33%|\u2588\u2588\u2588\u258e      | 166/496 [00:00&lt;00:01, 287.87 it/sec]\n    INFO - 23:17:44:     34%|\u2588\u2588\u2588\u258e      | 167/496 [00:00&lt;00:01, 287.88 it/sec]\n    INFO - 23:17:44:     34%|\u2588\u2588\u2588\u258d      | 168/496 [00:00&lt;00:01, 287.89 it/sec]\n    INFO - 23:17:44:     34%|\u2588\u2588\u2588\u258d      | 169/496 [00:00&lt;00:01, 287.74 it/sec]\n    INFO - 23:17:44:     34%|\u2588\u2588\u2588\u258d      | 170/496 [00:00&lt;00:01, 287.71 it/sec]\n    INFO - 23:17:44:     34%|\u2588\u2588\u2588\u258d      | 171/496 [00:00&lt;00:01, 287.79 it/sec]\n    INFO - 23:17:44:     35%|\u2588\u2588\u2588\u258d      | 172/496 [00:00&lt;00:01, 287.82 it/sec]\n    INFO - 23:17:44:     35%|\u2588\u2588\u2588\u258d      | 173/496 [00:00&lt;00:01, 287.91 it/sec]\n    INFO - 23:17:44:     35%|\u2588\u2588\u2588\u258c      | 174/496 [00:00&lt;00:01, 287.98 it/sec]\n    INFO - 23:17:44:     35%|\u2588\u2588\u2588\u258c      | 175/496 [00:00&lt;00:01, 288.00 it/sec]\n    INFO - 23:17:44:     35%|\u2588\u2588\u2588\u258c      | 176/496 [00:00&lt;00:01, 288.07 it/sec]\n    INFO - 23:17:44:     36%|\u2588\u2588\u2588\u258c      | 177/496 [00:00&lt;00:01, 288.12 it/sec]\n    INFO - 23:17:44:     36%|\u2588\u2588\u2588\u258c      | 178/496 [00:00&lt;00:01, 288.16 it/sec]\n    INFO - 23:17:44:     36%|\u2588\u2588\u2588\u258c      | 179/496 [00:00&lt;00:01, 288.24 it/sec]\n    INFO - 23:17:44:     36%|\u2588\u2588\u2588\u258b      | 180/496 [00:00&lt;00:01, 288.27 it/sec]\n    INFO - 23:17:44:     36%|\u2588\u2588\u2588\u258b      | 181/496 [00:00&lt;00:01, 288.33 it/sec]\n    INFO - 23:17:44:     37%|\u2588\u2588\u2588\u258b      | 182/496 [00:00&lt;00:01, 288.37 it/sec]\n    INFO - 23:17:44:     37%|\u2588\u2588\u2588\u258b      | 183/496 [00:00&lt;00:01, 288.43 it/sec]\n    INFO - 23:17:45:     37%|\u2588\u2588\u2588\u258b      | 184/496 [00:00&lt;00:01, 288.50 it/sec]\n    INFO - 23:17:45:     37%|\u2588\u2588\u2588\u258b      | 185/496 [00:00&lt;00:01, 288.56 it/sec]\n    INFO - 23:17:45:     38%|\u2588\u2588\u2588\u258a      | 186/496 [00:00&lt;00:01, 288.59 it/sec]\n    INFO - 23:17:45:     38%|\u2588\u2588\u2588\u258a      | 187/496 [00:00&lt;00:01, 288.66 it/sec]\n    INFO - 23:17:45:     38%|\u2588\u2588\u2588\u258a      | 188/496 [00:00&lt;00:01, 288.72 it/sec]\n    INFO - 23:17:45:     38%|\u2588\u2588\u2588\u258a      | 189/496 [00:00&lt;00:01, 288.76 it/sec]\n    INFO - 23:17:45:     38%|\u2588\u2588\u2588\u258a      | 190/496 [00:00&lt;00:01, 288.83 it/sec]\n    INFO - 23:17:45:     39%|\u2588\u2588\u2588\u258a      | 191/496 [00:00&lt;00:01, 288.91 it/sec]\n    INFO - 23:17:45:     39%|\u2588\u2588\u2588\u258a      | 192/496 [00:00&lt;00:01, 288.97 it/sec]\n    INFO - 23:17:45:     39%|\u2588\u2588\u2588\u2589      | 193/496 [00:00&lt;00:01, 289.05 it/sec]\n    INFO - 23:17:45:     39%|\u2588\u2588\u2588\u2589      | 194/496 [00:00&lt;00:01, 289.12 it/sec]\n    INFO - 23:17:45:     39%|\u2588\u2588\u2588\u2589      | 195/496 [00:00&lt;00:01, 289.14 it/sec]\n    INFO - 23:17:45:     40%|\u2588\u2588\u2588\u2589      | 196/496 [00:00&lt;00:01, 289.20 it/sec]\n    INFO - 23:17:45:     40%|\u2588\u2588\u2588\u2589      | 197/496 [00:00&lt;00:01, 289.26 it/sec]\n    INFO - 23:17:45:     40%|\u2588\u2588\u2588\u2589      | 198/496 [00:00&lt;00:01, 289.30 it/sec]\n    INFO - 23:17:45:     40%|\u2588\u2588\u2588\u2588      | 199/496 [00:00&lt;00:01, 289.34 it/sec]\n    INFO - 23:17:45:     40%|\u2588\u2588\u2588\u2588      | 200/496 [00:00&lt;00:01, 289.40 it/sec]\n    INFO - 23:17:45:     41%|\u2588\u2588\u2588\u2588      | 201/496 [00:00&lt;00:01, 289.43 it/sec]\n    INFO - 23:17:45:     41%|\u2588\u2588\u2588\u2588      | 202/496 [00:00&lt;00:01, 289.50 it/sec]\n    INFO - 23:17:45:     41%|\u2588\u2588\u2588\u2588      | 203/496 [00:00&lt;00:01, 289.55 it/sec]\n    INFO - 23:17:45:     41%|\u2588\u2588\u2588\u2588      | 204/496 [00:00&lt;00:01, 289.60 it/sec]\n    INFO - 23:17:45:     41%|\u2588\u2588\u2588\u2588\u258f     | 205/496 [00:00&lt;00:01, 289.66 it/sec]\n    INFO - 23:17:45:     42%|\u2588\u2588\u2588\u2588\u258f     | 206/496 [00:00&lt;00:01, 289.70 it/sec]\n    INFO - 23:17:45:     42%|\u2588\u2588\u2588\u2588\u258f     | 207/496 [00:00&lt;00:00, 289.72 it/sec]\n    INFO - 23:17:45:     42%|\u2588\u2588\u2588\u2588\u258f     | 208/496 [00:00&lt;00:00, 289.77 it/sec]\n    INFO - 23:17:45:     42%|\u2588\u2588\u2588\u2588\u258f     | 209/496 [00:00&lt;00:00, 289.83 it/sec]\n    INFO - 23:17:45:     42%|\u2588\u2588\u2588\u2588\u258f     | 210/496 [00:00&lt;00:00, 289.85 it/sec]\n    INFO - 23:17:45:     43%|\u2588\u2588\u2588\u2588\u258e     | 211/496 [00:00&lt;00:00, 289.89 it/sec]\n    INFO - 23:17:45:     43%|\u2588\u2588\u2588\u2588\u258e     | 212/496 [00:00&lt;00:00, 289.94 it/sec]\n    INFO - 23:17:45:     43%|\u2588\u2588\u2588\u2588\u258e     | 213/496 [00:00&lt;00:00, 289.97 it/sec]\n    INFO - 23:17:45:     43%|\u2588\u2588\u2588\u2588\u258e     | 214/496 [00:00&lt;00:00, 290.01 it/sec]\n    INFO - 23:17:45:     43%|\u2588\u2588\u2588\u2588\u258e     | 215/496 [00:00&lt;00:00, 290.05 it/sec]\n    INFO - 23:17:45:     44%|\u2588\u2588\u2588\u2588\u258e     | 216/496 [00:00&lt;00:00, 290.07 it/sec]\n    INFO - 23:17:45:     44%|\u2588\u2588\u2588\u2588\u258d     | 217/496 [00:00&lt;00:00, 290.10 it/sec]\n    INFO - 23:17:45:     44%|\u2588\u2588\u2588\u2588\u258d     | 218/496 [00:00&lt;00:00, 290.14 it/sec]\n    INFO - 23:17:45:     44%|\u2588\u2588\u2588\u2588\u258d     | 219/496 [00:00&lt;00:00, 290.17 it/sec]\n    INFO - 23:17:45:     44%|\u2588\u2588\u2588\u2588\u258d     | 220/496 [00:00&lt;00:00, 290.17 it/sec]\n    INFO - 23:17:45:     45%|\u2588\u2588\u2588\u2588\u258d     | 221/496 [00:00&lt;00:00, 290.18 it/sec]\n    INFO - 23:17:45:     45%|\u2588\u2588\u2588\u2588\u258d     | 222/496 [00:00&lt;00:00, 290.21 it/sec]\n    INFO - 23:17:45:     45%|\u2588\u2588\u2588\u2588\u258d     | 223/496 [00:00&lt;00:00, 290.25 it/sec]\n    INFO - 23:17:45:     45%|\u2588\u2588\u2588\u2588\u258c     | 224/496 [00:00&lt;00:00, 290.26 it/sec]\n    INFO - 23:17:45:     45%|\u2588\u2588\u2588\u2588\u258c     | 225/496 [00:00&lt;00:00, 290.30 it/sec]\n    INFO - 23:17:45:     46%|\u2588\u2588\u2588\u2588\u258c     | 226/496 [00:00&lt;00:00, 290.32 it/sec]\n    INFO - 23:17:45:     46%|\u2588\u2588\u2588\u2588\u258c     | 227/496 [00:00&lt;00:00, 290.36 it/sec]\n    INFO - 23:17:45:     46%|\u2588\u2588\u2588\u2588\u258c     | 228/496 [00:00&lt;00:00, 290.40 it/sec]\n    INFO - 23:17:45:     46%|\u2588\u2588\u2588\u2588\u258c     | 229/496 [00:00&lt;00:00, 290.44 it/sec]\n    INFO - 23:17:45:     46%|\u2588\u2588\u2588\u2588\u258b     | 230/496 [00:00&lt;00:00, 290.46 it/sec]\n    INFO - 23:17:45:     47%|\u2588\u2588\u2588\u2588\u258b     | 231/496 [00:00&lt;00:00, 290.50 it/sec]\n    INFO - 23:17:45:     47%|\u2588\u2588\u2588\u2588\u258b     | 232/496 [00:00&lt;00:00, 290.29 it/sec]\n    INFO - 23:17:45:     47%|\u2588\u2588\u2588\u2588\u258b     | 233/496 [00:00&lt;00:00, 290.32 it/sec]\n    INFO - 23:17:45:     47%|\u2588\u2588\u2588\u2588\u258b     | 234/496 [00:00&lt;00:00, 290.34 it/sec]\n    INFO - 23:17:45:     47%|\u2588\u2588\u2588\u2588\u258b     | 235/496 [00:00&lt;00:00, 290.31 it/sec]\n    INFO - 23:17:45:     48%|\u2588\u2588\u2588\u2588\u258a     | 236/496 [00:00&lt;00:00, 290.33 it/sec]\n    INFO - 23:17:45:     48%|\u2588\u2588\u2588\u2588\u258a     | 237/496 [00:00&lt;00:00, 290.36 it/sec]\n    INFO - 23:17:45:     48%|\u2588\u2588\u2588\u2588\u258a     | 238/496 [00:00&lt;00:00, 290.34 it/sec]\n    INFO - 23:17:45:     48%|\u2588\u2588\u2588\u2588\u258a     | 239/496 [00:00&lt;00:00, 290.31 it/sec]\n    INFO - 23:17:45:     48%|\u2588\u2588\u2588\u2588\u258a     | 240/496 [00:00&lt;00:00, 290.30 it/sec]\n    INFO - 23:17:45:     49%|\u2588\u2588\u2588\u2588\u258a     | 241/496 [00:00&lt;00:00, 290.33 it/sec]\n    INFO - 23:17:45:     49%|\u2588\u2588\u2588\u2588\u2589     | 242/496 [00:00&lt;00:00, 290.34 it/sec]\n    INFO - 23:17:45:     49%|\u2588\u2588\u2588\u2588\u2589     | 243/496 [00:00&lt;00:00, 290.37 it/sec]\n    INFO - 23:17:45:     49%|\u2588\u2588\u2588\u2588\u2589     | 244/496 [00:00&lt;00:00, 290.41 it/sec]\n    INFO - 23:17:45:     49%|\u2588\u2588\u2588\u2588\u2589     | 245/496 [00:00&lt;00:00, 290.42 it/sec]\n    INFO - 23:17:45:     50%|\u2588\u2588\u2588\u2588\u2589     | 246/496 [00:00&lt;00:00, 290.45 it/sec]\n    INFO - 23:17:45:     50%|\u2588\u2588\u2588\u2588\u2589     | 247/496 [00:00&lt;00:00, 290.47 it/sec]\n    INFO - 23:17:45:     50%|\u2588\u2588\u2588\u2588\u2588     | 248/496 [00:00&lt;00:00, 290.48 it/sec]\n    INFO - 23:17:45:     50%|\u2588\u2588\u2588\u2588\u2588     | 249/496 [00:00&lt;00:00, 290.50 it/sec]\n    INFO - 23:17:45:     50%|\u2588\u2588\u2588\u2588\u2588     | 250/496 [00:00&lt;00:00, 290.53 it/sec]\n    INFO - 23:17:45:     51%|\u2588\u2588\u2588\u2588\u2588     | 251/496 [00:00&lt;00:00, 290.55 it/sec]\n    INFO - 23:17:45:     51%|\u2588\u2588\u2588\u2588\u2588     | 252/496 [00:00&lt;00:00, 290.57 it/sec]\n    INFO - 23:17:45:     51%|\u2588\u2588\u2588\u2588\u2588     | 253/496 [00:00&lt;00:00, 290.60 it/sec]\n    INFO - 23:17:45:     51%|\u2588\u2588\u2588\u2588\u2588     | 254/496 [00:00&lt;00:00, 290.62 it/sec]\n    INFO - 23:17:45:     51%|\u2588\u2588\u2588\u2588\u2588\u258f    | 255/496 [00:00&lt;00:00, 290.64 it/sec]\n    INFO - 23:17:45:     52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 256/496 [00:00&lt;00:00, 290.66 it/sec]\n    INFO - 23:17:45:     52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 257/496 [00:00&lt;00:00, 290.67 it/sec]\n    INFO - 23:17:45:     52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 258/496 [00:00&lt;00:00, 290.67 it/sec]\n    INFO - 23:17:45:     52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 259/496 [00:00&lt;00:00, 290.66 it/sec]\n    INFO - 23:17:45:     52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 260/496 [00:00&lt;00:00, 290.66 it/sec]\n    INFO - 23:17:45:     53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 261/496 [00:00&lt;00:00, 290.66 it/sec]\n    INFO - 23:17:45:     53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 262/496 [00:00&lt;00:00, 290.65 it/sec]\n    INFO - 23:17:45:     53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 263/496 [00:00&lt;00:00, 290.67 it/sec]\n    INFO - 23:17:45:     53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 264/496 [00:00&lt;00:00, 290.41 it/sec]\n    INFO - 23:17:45:     53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 265/496 [00:00&lt;00:00, 290.21 it/sec]\n    INFO - 23:17:45:     54%|\u2588\u2588\u2588\u2588\u2588\u258e    | 266/496 [00:00&lt;00:00, 290.20 it/sec]\n    INFO - 23:17:45:     54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 267/496 [00:00&lt;00:00, 290.22 it/sec]\n    INFO - 23:17:45:     54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 268/496 [00:00&lt;00:00, 290.03 it/sec]\n    INFO - 23:17:45:     54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 269/496 [00:00&lt;00:00, 290.00 it/sec]\n    INFO - 23:17:45:     54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 270/496 [00:00&lt;00:00, 289.89 it/sec]\n    INFO - 23:17:45:     55%|\u2588\u2588\u2588\u2588\u2588\u258d    | 271/496 [00:00&lt;00:00, 289.92 it/sec]\n    INFO - 23:17:45:     55%|\u2588\u2588\u2588\u2588\u2588\u258d    | 272/496 [00:00&lt;00:00, 289.94 it/sec]\n    INFO - 23:17:45:     55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 273/496 [00:00&lt;00:00, 289.90 it/sec]\n    INFO - 23:17:45:     55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 274/496 [00:00&lt;00:00, 289.82 it/sec]\n    INFO - 23:17:45:     55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 275/496 [00:00&lt;00:00, 289.69 it/sec]\n    INFO - 23:17:45:     56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 276/496 [00:00&lt;00:00, 289.48 it/sec]\n    INFO - 23:17:45:     56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 277/496 [00:00&lt;00:00, 289.34 it/sec]\n    INFO - 23:17:45:     56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 278/496 [00:00&lt;00:00, 289.15 it/sec]\n    INFO - 23:17:45:     56%|\u2588\u2588\u2588\u2588\u2588\u258b    | 279/496 [00:00&lt;00:00, 289.11 it/sec]\n    INFO - 23:17:45:     56%|\u2588\u2588\u2588\u2588\u2588\u258b    | 280/496 [00:00&lt;00:00, 289.08 it/sec]\n    INFO - 23:17:45:     57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 281/496 [00:00&lt;00:00, 288.70 it/sec]\n    INFO - 23:17:45:     57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 282/496 [00:00&lt;00:00, 288.43 it/sec]\n    INFO - 23:17:45:     57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 283/496 [00:00&lt;00:00, 288.39 it/sec]\n    INFO - 23:17:45:     57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 284/496 [00:00&lt;00:00, 288.36 it/sec]\n    INFO - 23:17:45:     57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 285/496 [00:00&lt;00:00, 288.31 it/sec]\n    INFO - 23:17:45:     58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 286/496 [00:00&lt;00:00, 288.27 it/sec]\n    INFO - 23:17:45:     58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 287/496 [00:00&lt;00:00, 288.21 it/sec]\n    INFO - 23:17:45:     58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 288/496 [00:00&lt;00:00, 288.15 it/sec]\n    INFO - 23:17:45:     58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 289/496 [00:01&lt;00:00, 288.12 it/sec]\n    INFO - 23:17:45:     58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 290/496 [00:01&lt;00:00, 288.05 it/sec]\n    INFO - 23:17:45:     59%|\u2588\u2588\u2588\u2588\u2588\u258a    | 291/496 [00:01&lt;00:00, 288.01 it/sec]\n    INFO - 23:17:45:     59%|\u2588\u2588\u2588\u2588\u2588\u2589    | 292/496 [00:01&lt;00:00, 287.99 it/sec]\n    INFO - 23:17:45:     59%|\u2588\u2588\u2588\u2588\u2588\u2589    | 293/496 [00:01&lt;00:00, 287.96 it/sec]\n    INFO - 23:17:45:     59%|\u2588\u2588\u2588\u2588\u2588\u2589    | 294/496 [00:01&lt;00:00, 287.96 it/sec]\n    INFO - 23:17:45:     59%|\u2588\u2588\u2588\u2588\u2588\u2589    | 295/496 [00:01&lt;00:00, 287.91 it/sec]\n    INFO - 23:17:45:     60%|\u2588\u2588\u2588\u2588\u2588\u2589    | 296/496 [00:01&lt;00:00, 287.86 it/sec]\n    INFO - 23:17:45:     60%|\u2588\u2588\u2588\u2588\u2588\u2589    | 297/496 [00:01&lt;00:00, 287.82 it/sec]\n    INFO - 23:17:45:     60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 298/496 [00:01&lt;00:00, 287.74 it/sec]\n    INFO - 23:17:45:     60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 299/496 [00:01&lt;00:00, 287.74 it/sec]\n    INFO - 23:17:45:     60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 300/496 [00:01&lt;00:00, 287.71 it/sec]\n    INFO - 23:17:45:     61%|\u2588\u2588\u2588\u2588\u2588\u2588    | 301/496 [00:01&lt;00:00, 287.72 it/sec]\n    INFO - 23:17:45:     61%|\u2588\u2588\u2588\u2588\u2588\u2588    | 302/496 [00:01&lt;00:00, 287.72 it/sec]\n    INFO - 23:17:45:     61%|\u2588\u2588\u2588\u2588\u2588\u2588    | 303/496 [00:01&lt;00:00, 287.73 it/sec]\n    INFO - 23:17:45:     61%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 304/496 [00:01&lt;00:00, 287.74 it/sec]\n    INFO - 23:17:45:     61%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 305/496 [00:01&lt;00:00, 287.77 it/sec]\n    INFO - 23:17:45:     62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 306/496 [00:01&lt;00:00, 287.77 it/sec]\n    INFO - 23:17:45:     62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 307/496 [00:01&lt;00:00, 287.78 it/sec]\n    INFO - 23:17:45:     62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 308/496 [00:01&lt;00:00, 287.78 it/sec]\n    INFO - 23:17:45:     62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 309/496 [00:01&lt;00:00, 287.78 it/sec]\n    INFO - 23:17:45:     62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 310/496 [00:01&lt;00:00, 287.75 it/sec]\n    INFO - 23:17:45:     63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 311/496 [00:01&lt;00:00, 287.75 it/sec]\n    INFO - 23:17:45:     63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 312/496 [00:01&lt;00:00, 287.74 it/sec]\n    INFO - 23:17:45:     63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 313/496 [00:01&lt;00:00, 287.73 it/sec]\n    INFO - 23:17:45:     63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 314/496 [00:01&lt;00:00, 287.74 it/sec]\n    INFO - 23:17:45:     64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 315/496 [00:01&lt;00:00, 287.74 it/sec]\n    INFO - 23:17:45:     64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 316/496 [00:01&lt;00:00, 287.73 it/sec]\n    INFO - 23:17:45:     64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 317/496 [00:01&lt;00:00, 287.73 it/sec]\n    INFO - 23:17:45:     64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 318/496 [00:01&lt;00:00, 287.74 it/sec]\n    INFO - 23:17:45:     64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 319/496 [00:01&lt;00:00, 287.74 it/sec]\n    INFO - 23:17:45:     65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 320/496 [00:01&lt;00:00, 287.72 it/sec]\n    INFO - 23:17:45:     65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 321/496 [00:01&lt;00:00, 287.72 it/sec]\n    INFO - 23:17:45:     65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 322/496 [00:01&lt;00:00, 287.73 it/sec]\n    INFO - 23:17:45:     65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 323/496 [00:01&lt;00:00, 287.74 it/sec]\n    INFO - 23:17:45:     65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 324/496 [00:01&lt;00:00, 287.73 it/sec]\n    INFO - 23:17:45:     66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 325/496 [00:01&lt;00:00, 287.72 it/sec]\n    INFO - 23:17:45:     66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 326/496 [00:01&lt;00:00, 287.72 it/sec]\n    INFO - 23:17:45:     66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 327/496 [00:01&lt;00:00, 287.70 it/sec]\n    INFO - 23:17:45:     66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 328/496 [00:01&lt;00:00, 287.70 it/sec]\n    INFO - 23:17:45:     66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 329/496 [00:01&lt;00:00, 287.70 it/sec]\n    INFO - 23:17:45:     67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 330/496 [00:01&lt;00:00, 287.71 it/sec]\n    INFO - 23:17:45:     67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 331/496 [00:01&lt;00:00, 287.71 it/sec]\n    INFO - 23:17:45:     67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 332/496 [00:01&lt;00:00, 287.72 it/sec]\n    INFO - 23:17:45:     67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 333/496 [00:01&lt;00:00, 287.73 it/sec]\n    INFO - 23:17:45:     67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 334/496 [00:01&lt;00:00, 287.73 it/sec]\n    INFO - 23:17:45:     68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 335/496 [00:01&lt;00:00, 287.71 it/sec]\n    INFO - 23:17:45:     68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 336/496 [00:01&lt;00:00, 287.72 it/sec]\n    INFO - 23:17:45:     68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 337/496 [00:01&lt;00:00, 287.73 it/sec]\n    INFO - 23:17:45:     68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 338/496 [00:01&lt;00:00, 287.73 it/sec]\n    INFO - 23:17:45:     68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 339/496 [00:01&lt;00:00, 287.73 it/sec]\n    INFO - 23:17:45:     69%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 340/496 [00:01&lt;00:00, 287.72 it/sec]\n    INFO - 23:17:45:     69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 341/496 [00:01&lt;00:00, 287.73 it/sec]\n    INFO - 23:17:45:     69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 342/496 [00:01&lt;00:00, 287.72 it/sec]\n    INFO - 23:17:45:     69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 343/496 [00:01&lt;00:00, 287.71 it/sec]\n    INFO - 23:17:45:     69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 344/496 [00:01&lt;00:00, 287.70 it/sec]\n    INFO - 23:17:45:     70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 345/496 [00:01&lt;00:00, 287.68 it/sec]\n    INFO - 23:17:45:     70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 346/496 [00:01&lt;00:00, 287.68 it/sec]\n    INFO - 23:17:45:     70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 347/496 [00:01&lt;00:00, 287.67 it/sec]\n    INFO - 23:17:45:     70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 348/496 [00:01&lt;00:00, 287.67 it/sec]\n    INFO - 23:17:45:     70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 349/496 [00:01&lt;00:00, 287.65 it/sec]\n    INFO - 23:17:45:     71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 350/496 [00:01&lt;00:00, 287.63 it/sec]\n    INFO - 23:17:45:     71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 351/496 [00:01&lt;00:00, 287.61 it/sec]\n    INFO - 23:17:45:     71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 352/496 [00:01&lt;00:00, 287.60 it/sec]\n    INFO - 23:17:45:     71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 353/496 [00:01&lt;00:00, 287.56 it/sec]\n    INFO - 23:17:45:     71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 354/496 [00:01&lt;00:00, 287.54 it/sec]\n    INFO - 23:17:45:     72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 355/496 [00:01&lt;00:00, 287.53 it/sec]\n    INFO - 23:17:45:     72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 356/496 [00:01&lt;00:00, 287.52 it/sec]\n    INFO - 23:17:45:     72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 357/496 [00:01&lt;00:00, 287.51 it/sec]\n    INFO - 23:17:45:     72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 358/496 [00:01&lt;00:00, 287.50 it/sec]\n    INFO - 23:17:45:     72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 359/496 [00:01&lt;00:00, 287.46 it/sec]\n    INFO - 23:17:45:     73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 360/496 [00:01&lt;00:00, 287.41 it/sec]\n    INFO - 23:17:45:     73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 361/496 [00:01&lt;00:00, 287.38 it/sec]\n    INFO - 23:17:45:     73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 362/496 [00:01&lt;00:00, 287.38 it/sec]\n    INFO - 23:17:45:     73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 363/496 [00:01&lt;00:00, 287.37 it/sec]\n    INFO - 23:17:45:     73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 364/496 [00:01&lt;00:00, 287.35 it/sec]\n    INFO - 23:17:45:     74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 365/496 [00:01&lt;00:00, 287.33 it/sec]\n    INFO - 23:17:45:     74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 366/496 [00:01&lt;00:00, 287.31 it/sec]\n    INFO - 23:17:45:     74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 367/496 [00:01&lt;00:00, 287.30 it/sec]\n    INFO - 23:17:45:     74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 368/496 [00:01&lt;00:00, 287.30 it/sec]\n    INFO - 23:17:45:     74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 369/496 [00:01&lt;00:00, 287.29 it/sec]\n    INFO - 23:17:45:     75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 370/496 [00:01&lt;00:00, 287.29 it/sec]\n    INFO - 23:17:45:     75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 371/496 [00:01&lt;00:00, 287.28 it/sec]\n    INFO - 23:17:45:     75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 372/496 [00:01&lt;00:00, 287.27 it/sec]\n    INFO - 23:17:45:     75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 373/496 [00:01&lt;00:00, 287.27 it/sec]\n    INFO - 23:17:45:     75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 374/496 [00:01&lt;00:00, 287.24 it/sec]\n    INFO - 23:17:45:     76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 375/496 [00:01&lt;00:00, 287.23 it/sec]\n    INFO - 23:17:45:     76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 376/496 [00:01&lt;00:00, 287.23 it/sec]\n    INFO - 23:17:45:     76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 377/496 [00:01&lt;00:00, 287.22 it/sec]\n    INFO - 23:17:45:     76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 378/496 [00:01&lt;00:00, 287.22 it/sec]\n    INFO - 23:17:45:     76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 379/496 [00:01&lt;00:00, 287.21 it/sec]\n    INFO - 23:17:45:     77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 380/496 [00:01&lt;00:00, 287.20 it/sec]\n    INFO - 23:17:45:     77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 381/496 [00:01&lt;00:00, 287.21 it/sec]\n    INFO - 23:17:45:     77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 382/496 [00:01&lt;00:00, 287.20 it/sec]\n    INFO - 23:17:45:     77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 383/496 [00:01&lt;00:00, 287.15 it/sec]\n    INFO - 23:17:45:     77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 384/496 [00:01&lt;00:00, 287.14 it/sec]\n    INFO - 23:17:45:     78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 385/496 [00:01&lt;00:00, 287.12 it/sec]\n    INFO - 23:17:45:     78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 386/496 [00:01&lt;00:00, 287.09 it/sec]\n    INFO - 23:17:45:     78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 387/496 [00:01&lt;00:00, 287.09 it/sec]\n    INFO - 23:17:45:     78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 388/496 [00:01&lt;00:00, 287.06 it/sec]\n    INFO - 23:17:45:     78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 389/496 [00:01&lt;00:00, 287.05 it/sec]\n    INFO - 23:17:45:     79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 390/496 [00:01&lt;00:00, 287.04 it/sec]\n    INFO - 23:17:45:     79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 391/496 [00:01&lt;00:00, 287.03 it/sec]\n    INFO - 23:17:45:     79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 392/496 [00:01&lt;00:00, 287.02 it/sec]\n    INFO - 23:17:45:     79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 393/496 [00:01&lt;00:00, 287.01 it/sec]\n    INFO - 23:17:45:     79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 394/496 [00:01&lt;00:00, 287.01 it/sec]\n    INFO - 23:17:45:     80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 395/496 [00:01&lt;00:00, 287.01 it/sec]\n    INFO - 23:17:45:     80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 396/496 [00:01&lt;00:00, 287.01 it/sec]\n    INFO - 23:17:45:     80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 397/496 [00:01&lt;00:00, 287.00 it/sec]\n    INFO - 23:17:45:     80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 398/496 [00:01&lt;00:00, 286.99 it/sec]\n    INFO - 23:17:45:     80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 399/496 [00:01&lt;00:00, 286.99 it/sec]\n    INFO - 23:17:45:     81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 400/496 [00:01&lt;00:00, 286.99 it/sec]\n    INFO - 23:17:45:     81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 401/496 [00:01&lt;00:00, 286.99 it/sec]\n    INFO - 23:17:45:     81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 402/496 [00:01&lt;00:00, 286.98 it/sec]\n    INFO - 23:17:45:     81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 403/496 [00:01&lt;00:00, 286.97 it/sec]\n    INFO - 23:17:45:     81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 404/496 [00:01&lt;00:00, 286.98 it/sec]\n    INFO - 23:17:45:     82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 405/496 [00:01&lt;00:00, 286.96 it/sec]\n    INFO - 23:17:45:     82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 406/496 [00:01&lt;00:00, 286.93 it/sec]\n    INFO - 23:17:45:     82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 407/496 [00:01&lt;00:00, 286.92 it/sec]\n    INFO - 23:17:45:     82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 408/496 [00:01&lt;00:00, 286.91 it/sec]\n    INFO - 23:17:45:     82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 409/496 [00:01&lt;00:00, 286.91 it/sec]\n    INFO - 23:17:45:     83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 410/496 [00:01&lt;00:00, 286.91 it/sec]\n    INFO - 23:17:45:     83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 411/496 [00:01&lt;00:00, 286.90 it/sec]\n    INFO - 23:17:45:     83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 412/496 [00:01&lt;00:00, 286.89 it/sec]\n    INFO - 23:17:45:     83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 413/496 [00:01&lt;00:00, 286.88 it/sec]\n    INFO - 23:17:45:     83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 414/496 [00:01&lt;00:00, 286.88 it/sec]\n    INFO - 23:17:45:     84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 415/496 [00:01&lt;00:00, 286.87 it/sec]\n    INFO - 23:17:45:     84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 416/496 [00:01&lt;00:00, 286.86 it/sec]\n    INFO - 23:17:45:     84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 417/496 [00:01&lt;00:00, 286.86 it/sec]\n    INFO - 23:17:45:     84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 418/496 [00:01&lt;00:00, 286.86 it/sec]\n    INFO - 23:17:45:     84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 419/496 [00:01&lt;00:00, 286.84 it/sec]\n    INFO - 23:17:45:     85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 420/496 [00:01&lt;00:00, 286.79 it/sec]\n    INFO - 23:17:45:     85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 421/496 [00:01&lt;00:00, 286.78 it/sec]\n    INFO - 23:17:45:     85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 422/496 [00:01&lt;00:00, 286.75 it/sec]\n    INFO - 23:17:45:     85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 423/496 [00:01&lt;00:00, 286.70 it/sec]\n    INFO - 23:17:45:     85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 424/496 [00:01&lt;00:00, 286.66 it/sec]\n    INFO - 23:17:45:     86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 425/496 [00:01&lt;00:00, 286.63 it/sec]\n    INFO - 23:17:45:     86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 426/496 [00:01&lt;00:00, 286.58 it/sec]\n    INFO - 23:17:45:     86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 427/496 [00:01&lt;00:00, 286.57 it/sec]\n    INFO - 23:17:45:     86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 428/496 [00:01&lt;00:00, 286.56 it/sec]\n    INFO - 23:17:45:     86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 429/496 [00:01&lt;00:00, 286.56 it/sec]\n    INFO - 23:17:45:     87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 430/496 [00:01&lt;00:00, 286.56 it/sec]\n    INFO - 23:17:45:     87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 431/496 [00:01&lt;00:00, 286.55 it/sec]\n    INFO - 23:17:45:     87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 432/496 [00:01&lt;00:00, 286.54 it/sec]\n    INFO - 23:17:45:     87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 433/496 [00:01&lt;00:00, 286.52 it/sec]\n    INFO - 23:17:45:     88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 434/496 [00:01&lt;00:00, 286.51 it/sec]\n    INFO - 23:17:45:     88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 435/496 [00:01&lt;00:00, 286.49 it/sec]\n    INFO - 23:17:45:     88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 436/496 [00:01&lt;00:00, 286.46 it/sec]\n    INFO - 23:17:45:     88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 437/496 [00:01&lt;00:00, 286.44 it/sec]\n    INFO - 23:17:45:     88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 438/496 [00:01&lt;00:00, 286.43 it/sec]\n    INFO - 23:17:45:     89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 439/496 [00:01&lt;00:00, 286.41 it/sec]\n    INFO - 23:17:45:     89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 440/496 [00:01&lt;00:00, 286.38 it/sec]\n    INFO - 23:17:45:     89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 441/496 [00:01&lt;00:00, 286.37 it/sec]\n    INFO - 23:17:45:     89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 442/496 [00:01&lt;00:00, 286.32 it/sec]\n    INFO - 23:17:45:     89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 443/496 [00:01&lt;00:00, 286.31 it/sec]\n    INFO - 23:17:45:     90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 444/496 [00:01&lt;00:00, 286.29 it/sec]\n    INFO - 23:17:45:     90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 445/496 [00:01&lt;00:00, 286.29 it/sec]\n    INFO - 23:17:45:     90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 446/496 [00:01&lt;00:00, 286.28 it/sec]\n    INFO - 23:17:45:     90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 447/496 [00:01&lt;00:00, 286.27 it/sec]\n    INFO - 23:17:45:     90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 448/496 [00:01&lt;00:00, 286.25 it/sec]\n    INFO - 23:17:45:     91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 449/496 [00:01&lt;00:00, 286.24 it/sec]\n    INFO - 23:17:45:     91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 450/496 [00:01&lt;00:00, 286.22 it/sec]\n    INFO - 23:17:45:     91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 451/496 [00:01&lt;00:00, 286.22 it/sec]\n    INFO - 23:17:45:     91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 452/496 [00:01&lt;00:00, 286.21 it/sec]\n    INFO - 23:17:45:     91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 453/496 [00:01&lt;00:00, 286.20 it/sec]\n    INFO - 23:17:45:     92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 454/496 [00:01&lt;00:00, 286.17 it/sec]\n    INFO - 23:17:45:     92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 455/496 [00:01&lt;00:00, 286.16 it/sec]\n    INFO - 23:17:45:     92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 456/496 [00:01&lt;00:00, 286.15 it/sec]\n    INFO - 23:17:45:     92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 457/496 [00:01&lt;00:00, 286.14 it/sec]\n    INFO - 23:17:45:     92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 458/496 [00:01&lt;00:00, 285.77 it/sec]\n    INFO - 23:17:45:     93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 459/496 [00:01&lt;00:00, 285.70 it/sec]\n    INFO - 23:17:45:     93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 460/496 [00:01&lt;00:00, 285.69 it/sec]\n    INFO - 23:17:45:     93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 461/496 [00:01&lt;00:00, 285.68 it/sec]\n    INFO - 23:17:45:     93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 462/496 [00:01&lt;00:00, 285.66 it/sec]\n    INFO - 23:17:45:     93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 463/496 [00:01&lt;00:00, 285.63 it/sec]\n    INFO - 23:17:45:     94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 464/496 [00:01&lt;00:00, 285.61 it/sec]\n    INFO - 23:17:45:     94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 465/496 [00:01&lt;00:00, 285.60 it/sec]\n    INFO - 23:17:45:     94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 466/496 [00:01&lt;00:00, 285.58 it/sec]\n    INFO - 23:17:45:     94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 467/496 [00:01&lt;00:00, 285.58 it/sec]\n    INFO - 23:17:46:     94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 468/496 [00:01&lt;00:00, 285.57 it/sec]\n    INFO - 23:17:46:     95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 469/496 [00:01&lt;00:00, 285.54 it/sec]\n    INFO - 23:17:46:     95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 470/496 [00:01&lt;00:00, 285.54 it/sec]\n    INFO - 23:17:46:     95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 471/496 [00:01&lt;00:00, 285.53 it/sec]\n    INFO - 23:17:46:     95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 472/496 [00:01&lt;00:00, 285.54 it/sec]\n    INFO - 23:17:46:     95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 473/496 [00:01&lt;00:00, 285.54 it/sec]\n    INFO - 23:17:46:     96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 474/496 [00:01&lt;00:00, 285.54 it/sec]\n    INFO - 23:17:46:     96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 475/496 [00:01&lt;00:00, 285.52 it/sec]\n    INFO - 23:17:46:     96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 476/496 [00:01&lt;00:00, 285.51 it/sec]\n    INFO - 23:17:46:     96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 477/496 [00:01&lt;00:00, 285.50 it/sec]\n    INFO - 23:17:46:     96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 478/496 [00:01&lt;00:00, 285.50 it/sec]\n    INFO - 23:17:46:     97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 479/496 [00:01&lt;00:00, 285.48 it/sec]\n    INFO - 23:17:46:     97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 480/496 [00:01&lt;00:00, 285.47 it/sec]\n    INFO - 23:17:46:     97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 481/496 [00:01&lt;00:00, 285.47 it/sec]\n    INFO - 23:17:46:     97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 482/496 [00:01&lt;00:00, 285.46 it/sec]\n    INFO - 23:17:46:     97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 483/496 [00:01&lt;00:00, 285.46 it/sec]\n    INFO - 23:17:46:     98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 484/496 [00:01&lt;00:00, 285.44 it/sec]\n    INFO - 23:17:46:     98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 485/496 [00:01&lt;00:00, 285.44 it/sec]\n    INFO - 23:17:46:     98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 486/496 [00:01&lt;00:00, 285.43 it/sec]\n    INFO - 23:17:46:     98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 487/496 [00:01&lt;00:00, 285.43 it/sec]\n    INFO - 23:17:46:     98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 488/496 [00:01&lt;00:00, 285.41 it/sec]\n    INFO - 23:17:46:     99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 489/496 [00:01&lt;00:00, 285.39 it/sec]\n    INFO - 23:17:46:     99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 490/496 [00:01&lt;00:00, 285.39 it/sec]\n    INFO - 23:17:46:     99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 491/496 [00:01&lt;00:00, 285.38 it/sec]\n    INFO - 23:17:46:     99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 492/496 [00:01&lt;00:00, 285.37 it/sec]\n    INFO - 23:17:46:     99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 493/496 [00:01&lt;00:00, 285.33 it/sec]\n    INFO - 23:17:46:    100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 494/496 [00:01&lt;00:00, 285.32 it/sec]\n    INFO - 23:17:46:    100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 495/496 [00:01&lt;00:00, 285.29 it/sec]\n    INFO - 23:17:46:    100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 496/496 [00:01&lt;00:00, 285.28 it/sec]\n    INFO - 23:17:46: *** End SobolAnalysisSamplingPhase execution (time: 0:00:01.758276) ***\n/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/pandas/core/frame.py:706: DeprecationWarning: Passing a BlockManager to IODataset is deprecated and will raise in a future version. Use public APIs instead.\n  warnings.warn(\n/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/pandas/core/frame.py:706: DeprecationWarning: Passing a BlockManager to IODataset is deprecated and will raise in a future version. Use public APIs instead.\n  warnings.warn(\n/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/pandas/core/frame.py:706: DeprecationWarning: Passing a BlockManager to IODataset is deprecated and will raise in a future version. Use public APIs instead.\n  warnings.warn(\n/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/pandas/core/frame.py:706: DeprecationWarning: Passing a BlockManager to Dataset is deprecated and will raise in a future version. Use public APIs instead.\n  warnings.warn(\n/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/pandas/core/frame.py:706: DeprecationWarning: Passing a BlockManager to Dataset is deprecated and will raise in a future version. Use public APIs instead.\n  warnings.warn(\n\n&lt;gemseo.post.dataset.surfaces.Surfaces object at 0x7b28aba82bb0&gt;\n</code></pre> <p></p> <pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.core.chain import MDOChain\nfrom gemseo.uncertainty.sensitivity.sobol_analysis import SobolAnalysis\n\nfrom gemseo_umdo.use_cases.beam_model.constraints import BeamConstraints\nfrom gemseo_umdo.use_cases.beam_model.discipline import Beam\nfrom gemseo_umdo.use_cases.beam_model.uncertain_space import BeamUncertainSpace\n\nconfigure_logger()\n\nuncertain_space = BeamUncertainSpace()\n\nn_y = n_z = 10\n\nmdo_chain = MDOChain([Beam(n_y=n_y, n_z=n_z), BeamConstraints()])\n\nsobol = SobolAnalysis(\n    [mdo_chain], uncertain_space, 500, output_names=[\"c_displ\", \"c_stress\"]\n)\nmesh = mdo_chain.disciplines[0].local_data[\"yz_grid\"].reshape((-1, 2))\nsobol.main_method = \"total\"\nsobol.compute_indices()\nsobol.plot_field(\"c_displ\", mesh=mesh, save=False, show=True)\nsobol.plot_field(\"c_stress\", mesh=mesh, save=False, show=True)\n</code></pre> <p>Total running time of the script: ( 0 minutes  2.638 seconds)</p> <p> Download Python source code: plot_beam_sa.py</p> <p> Download Jupyter notebook: plot_beam_sa.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/udoe/","title":"U-DOE","text":""},{"location":"generated/examples/udoe/#doe-under-uncertainty","title":"DOE under uncertainty","text":""},{"location":"generated/examples/udoe/#doe-under-uncertainty-quadratic","title":"DOE under uncertainty | Quadratic","text":"<p> Robust DOE - Sampling - Quadratic function </p> <p> Download all examples in Python source code: udoe_python.zip</p> <p> Download all examples in Jupyter notebooks: udoe_jupyter.zip</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/udoe/quadratic/quadratic_sampling_doe/","title":"Robust DOE - Sampling - Quadratic function","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/udoe/quadratic/quadratic_sampling_doe/#robust-doe-sampling-quadratic-function","title":"Robust DOE - Sampling - Quadratic function","text":"<pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\n\nfrom gemseo_umdo.scenarios.udoe_scenario import UDOEScenario\n\nconfigure_logger()\n</code></pre> <p>Firstly, we define an AnalyticDiscipline implementing the random function \\(f(x,U)=(x+U)^2\\):</p> <pre><code>discipline = AnalyticDiscipline({\"y\": \"(x+u)**2\"}, name=\"quadratic_function\")\n</code></pre> <p>where \\(x\\) belongs to the interval \\([-1,1]\\):</p> <pre><code>design_space = DesignSpace()\ndesign_space.add_variable(\"x\", l_b=-1, u_b=1.0, value=0.5)\n</code></pre> <p>and \\(U\\) is a standard Gaussian variable:</p> <pre><code>uncertain_space = ParameterSpace()\nuncertain_space.add_random_variable(\"u\", \"OTNormalDistribution\")\n</code></pre> <p>Then, we build a UDOEScenario to minimize a sampling-based estimation of the expectation \\(\\mathbb{E}[Y]\\) where \\(Y=f(x,U)\\):</p> <pre><code>scenario = UDOEScenario(\n    [discipline],\n    \"DisciplinaryOpt\",\n    \"y\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    statistic_estimation=\"Sampling\",\n    statistic_estimation_parameters={\"n_samples\": 100},\n)\n</code></pre> <p>We execute it with a full-factorial design of experiments:</p> <pre><code>scenario.execute({\"algo\": \"fullfact\", \"n_samples\": 100})\n</code></pre> <p>and plot the history:</p> <pre><code>scenario.post_process(\"OptHistoryView\", save=True, show=True)\n</code></pre> <p>Notice that the numerical solution is close to \\((x^*,f^*)=(0,1)\\) as expected from the expression of the statistic: \\(\\mathbb{E}[Y]=\\mathbb{E}[(x+U)^2]=x^2+1\\).</p> <p>Total running time of the script: ( 0 minutes  0.000 seconds)</p> <p> Download Python source code: quadratic_sampling_doe.py</p> <p> Download Jupyter notebook: quadratic_sampling_doe.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/","title":"U-MDO","text":""},{"location":"generated/examples/umdo/#mdo-under-uncertainty","title":"MDO under uncertainty","text":""},{"location":"generated/examples/umdo/#mdo-under-uncertainty-quadratic","title":"MDO under uncertainty | Quadratic","text":"<p> Robust OPT - Taylor polynomial - Quadratic function </p> <p> Robust OPT - PCE - Quadratic function. </p> <p> Robust OPT - Sampling - Quadratic function </p> <p> Robust OPT - Control variate - Quadratic function. </p> <p> Robust OPT - Sequential sampling - Quadratic function </p>"},{"location":"generated/examples/umdo/#mdo-under-uncertainty-rosenbrock","title":"MDO under uncertainty | Rosenbrock","text":"<p> Robust OPT - Sampling - Rosenbrock function </p> <p> Robust OPT - Control variate - Rosenbrock function. </p> <p> Robust OPT - Control variate vs Sampling - Rosenbrock function. </p>"},{"location":"generated/examples/umdo/#mdo-under-uncertainty-sellar","title":"MDO under uncertainty | Sellar","text":"<p> OPT - Deterministic - Sellar problem. </p> <p> Robust OPT - First-order Taylor polynomial - Sellar problem </p> <p> Robust OPT - Control variate - Sellar problem </p> <p> Robust OPT - Second-order Taylor polynomial - Sellar problem </p> <p> Robust OPT - Sampling - Sellar problem </p> <p> Robust OPT - Sampling with repetitions - Sellar problem </p>"},{"location":"generated/examples/umdo/#mdo-under-uncertainty-sobieski","title":"MDO under uncertainty | Sobieski","text":"<p> Robust MDO - First-order Taylor polynomial - Sobieski </p> <p> Robust MDO - Sampling - Sobieski </p> <p> Robust MDO - Second-order Taylor polynomial - Sobieski </p> <p> Download all examples in Python source code: umdo_python.zip</p> <p> Download all examples in Jupyter notebooks: umdo_jupyter.zip</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/quadratic/control_variate/","title":"Robust OPT - Control variate - Quadratic function.","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/quadratic/control_variate/#robust-opt-control-variate-quadratic-function","title":"Robust OPT - Control variate - Quadratic function.","text":"<pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nconfigure_logger()\n</code></pre> <p>Firstly, we define an AnalyticDiscipline implementing the random function \\(f(x,U)=(x+U)^2\\):</p> <pre><code>discipline = AnalyticDiscipline({\"y\": \"(x+u)**2\"}, name=\"quadratic_function\")\n</code></pre> <p>where \\(x\\) belongs to the interval \\([-1,1]\\):</p> <pre><code>design_space = DesignSpace()\ndesign_space.add_variable(\"x\", l_b=-1, u_b=1.0, value=0.5)\n</code></pre> <p>and \\(U\\) is a standard Gaussian variable:</p> <pre><code>uncertain_space = ParameterSpace()\nuncertain_space.add_random_variable(\"u\", \"OTNormalDistribution\")\n</code></pre> <p>Then, we build a UMDOScenario to minimize a control variate-based estimation of the expectation \\(\\mathbb{E}[Y]\\) where \\(Y=f(x,U)\\):</p> <pre><code>scenario = UMDOScenario(\n    [discipline],\n    \"DisciplinaryOpt\",\n    \"y\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    statistic_estimation=\"ControlVariate\",\n    statistic_estimation_parameters={\"n_samples\": 50},\n)\n</code></pre> <p>We execute it with a gradient-free optimizer:</p> <pre><code>scenario.execute({\"algo\": \"NLOPT_COBYLA\", \"max_iter\": 100})\n</code></pre> <p>and plot the history:</p> <pre><code>scenario.post_process(\"OptHistoryView\", save=True, show=True)\n</code></pre> <p>Notice that the numerical solution is equal to \\((x^*,f^*)=(0,1)\\) as expected from the expression of the statistic: \\(\\mathbb{E}[Y]=\\mathbb{E}[(x+U)^2]=x^2+1\\).</p> <p>Total running time of the script: ( 0 minutes  0.000 seconds)</p> <p> Download Python source code: control_variate.py</p> <p> Download Jupyter notebook: control_variate.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/quadratic/pce/","title":"Robust OPT - PCE - Quadratic function.","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/quadratic/pce/#robust-opt-pce-quadratic-function","title":"Robust OPT - PCE - Quadratic function.","text":"<pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nconfigure_logger()\n</code></pre> <p>Firstly, we define an AnalyticDiscipline implementing the random function \\(f(x,U)=(x+U)^2\\):</p> <pre><code>discipline = AnalyticDiscipline({\"y\": \"(x+u)**2\"}, name=\"quadratic_function\")\n</code></pre> <p>where \\(x\\) belongs to the interval \\([-1,1]\\):</p> <pre><code>design_space = DesignSpace()\ndesign_space.add_variable(\"x\", l_b=-1, u_b=1.0, value=0.5)\n</code></pre> <p>and \\(U\\) is a standard Gaussian variable:</p> <pre><code>uncertain_space = ParameterSpace()\nuncertain_space.add_random_variable(\"u\", \"OTNormalDistribution\")\n</code></pre> <p>Then, we build a UMDOScenario to minimize a PCE-based estimation of the expectation \\(\\mathbb{E}[Y]\\) where \\(Y=f(x,U)\\):</p> <pre><code>scenario = UMDOScenario(\n    [discipline],\n    \"DisciplinaryOpt\",\n    \"y\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    statistic_estimation=\"PCE\",\n    statistic_estimation_parameters={\"doe_n_samples\": 20},\n)\n</code></pre> <p>We execute it with a gradient-free optimizer:</p> <pre><code>scenario.execute({\"algo\": \"NLOPT_COBYLA\", \"max_iter\": 100})\n</code></pre> <p>and plot the history:</p> <pre><code>scenario.post_process(\"OptHistoryView\", save=False, show=True)\n</code></pre> <p>Notice that the numerical solution is close to \\((x^*,f^*)=(0,1)\\) as expected from the expression of the statistic: \\(\\mathbb{E}[Y]=\\mathbb{E}[(x+U)^2]=x^2+1\\).</p> <p>Total running time of the script: ( 0 minutes  0.000 seconds)</p> <p> Download Python source code: pce.py</p> <p> Download Jupyter notebook: pce.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/quadratic/quadratic_sampling_opt/","title":"Robust OPT - Sampling - Quadratic function","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/quadratic/quadratic_sampling_opt/#robust-opt-sampling-quadratic-function","title":"Robust OPT - Sampling - Quadratic function","text":"<pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nconfigure_logger()\n</code></pre> <p>Firstly, we define an AnalyticDiscipline implementing the random function \\(f(x,U)=(x+U)^2\\):</p> <pre><code>discipline = AnalyticDiscipline({\"y\": \"(x+u)**2\"}, name=\"quadratic_function\")\n</code></pre> <p>where \\(x\\) belongs to the interval \\([-1,1]\\):</p> <pre><code>design_space = DesignSpace()\ndesign_space.add_variable(\"x\", l_b=-1, u_b=1.0, value=0.5)\n</code></pre> <p>and \\(U\\) is a standard Gaussian variable:</p> <pre><code>uncertain_space = ParameterSpace()\nuncertain_space.add_random_variable(\"u\", \"OTNormalDistribution\")\n</code></pre> <p>Then, we build a UMDOScenario to minimize a sampling-based estimation of the expectation \\(\\mathbb{E}[Y]\\) where \\(Y=f(x,U)\\):</p> <pre><code>scenario = UMDOScenario(\n    [discipline],\n    \"DisciplinaryOpt\",\n    \"y\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    statistic_estimation=\"Sampling\",\n    statistic_estimation_parameters={\"n_samples\": 50},\n)\n</code></pre> <p>We execute it with a gradient-free optimizer:</p> <pre><code>scenario.execute({\"algo\": \"NLOPT_COBYLA\", \"max_iter\": 100})\n</code></pre> <p>and plot the history:</p> <pre><code>scenario.post_process(\"OptHistoryView\", save=True, show=True)\n</code></pre> <p>Notice that the numerical solution is equal to \\((x^*,f^*)=(0,1)\\) as expected from the expression of the statistic: \\(\\mathbb{E}[Y]=\\mathbb{E}[(x+U)^2]=x^2+1\\).</p> <p>Total running time of the script: ( 0 minutes  0.000 seconds)</p> <p> Download Python source code: quadratic_sampling_opt.py</p> <p> Download Jupyter notebook: quadratic_sampling_opt.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/quadratic/sequential_sampling/","title":"Robust OPT - Sequential sampling - Quadratic function","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/quadratic/sequential_sampling/#robust-opt-sequential-sampling-quadratic-function","title":"Robust OPT - Sequential sampling - Quadratic function","text":"<pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nconfigure_logger()\n</code></pre> <p>Firstly, we define an AnalyticDiscipline implementing the random function \\(f(x,U)=(x+U)^2\\):</p> <pre><code>discipline = AnalyticDiscipline({\"y\": \"(x+u)**2\"}, name=\"quadratic_function\")\n</code></pre> <p>where \\(x\\) belongs to the interval \\([-1,1]\\):</p> <pre><code>design_space = DesignSpace()\ndesign_space.add_variable(\"x\", l_b=-1, u_b=1.0, value=0.5)\n</code></pre> <p>and \\(U\\) is a standard Gaussian variable:</p> <pre><code>uncertain_space = ParameterSpace()\nuncertain_space.add_random_variable(\"u\", \"OTNormalDistribution\")\n</code></pre> <p>Then, we build a UMDOScenario to minimize a sequential sampling-based estimation of the expectation \\(\\mathbb{E}[Y]\\) where \\(Y=f(x,U)\\):</p> <pre><code>scenario = UMDOScenario(\n    [discipline],\n    \"DisciplinaryOpt\",\n    \"y\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    statistic_estimation=\"SequentialSampling\",\n    statistic_estimation_parameters={\n        \"n_samples\": 10,\n        \"initial_n_samples\": 2,\n        \"n_samples_increment\": 2,\n    },\n)\n</code></pre> <p>We execute it with a gradient-free optimizer:</p> <pre><code>scenario.execute({\"algo\": \"NLOPT_COBYLA\", \"max_iter\": 100})\n</code></pre> <p>and plot the history:</p> <pre><code>scenario.post_process(\"OptHistoryView\", save=True, show=True)\n</code></pre> <p>Notice that the numerical solution is close to \\((x^*,f^*)=(0,1)\\) as expected from the expression of the statistic: \\(\\mathbb{E}[Y]=\\mathbb{E}[(x+U)^2]=x^2+1\\).</p> <p>Total running time of the script: ( 0 minutes  0.000 seconds)</p> <p> Download Python source code: sequential_sampling.py</p> <p> Download Jupyter notebook: sequential_sampling.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/quadratic/taylor_polynomial/","title":"Robust OPT - Taylor polynomial - Quadratic function","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/quadratic/taylor_polynomial/#robust-opt-taylor-polynomial-quadratic-function","title":"Robust OPT - Taylor polynomial - Quadratic function","text":"<pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nconfigure_logger()\n</code></pre> <p>Firstly, we define an AnalyticDiscipline implementing the random function \\(f(x,U)=(x+U)^2\\):</p> <pre><code>discipline = AnalyticDiscipline({\"y\": \"(x+u)**2\"}, name=\"quadratic_function\")\n</code></pre> <p>where \\(x\\) belongs to the interval \\([-1,1]\\):</p> <pre><code>design_space = DesignSpace()\ndesign_space.add_variable(\"x\", l_b=-1, u_b=1.0, value=0.5)\n</code></pre> <p>and \\(U\\) is a standard Gaussian variable:</p> <pre><code>uncertain_space = ParameterSpace()\nuncertain_space.add_random_variable(\"u\", \"OTNormalDistribution\")\n</code></pre> <p>Then, we build a UMDOScenario to minimize a linearization-based estimation of the expectation \\(\\mathbb{E}[Y]\\) where \\(Y=f(x,U)\\):</p> <pre><code>scenario = UMDOScenario(\n    [discipline],\n    \"DisciplinaryOpt\",\n    \"y\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    statistic_estimation=\"TaylorPolynomial\",\n)\n</code></pre> <p>We execute it with a gradient-free optimizer:</p> <pre><code>scenario.execute({\"algo\": \"NLOPT_COBYLA\", \"max_iter\": 100})\n</code></pre> <p>and plot the history:</p> <pre><code>scenario.post_process(\"OptHistoryView\", save=False, show=True)\n</code></pre> <p>Notice that the numerical solution is close to \\((x^*,f^*)=(0,1)\\) as expected from the expression of the statistic: \\(\\mathbb{E}[Y]=\\mathbb{E}[(x+U)^2]=x^2+1\\).</p> <p>Total running time of the script: ( 0 minutes  0.000 seconds)</p> <p> Download Python source code: taylor_polynomial.py</p> <p> Download Jupyter notebook: taylor_polynomial.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/rosenbrock/comparison/","title":"Robust OPT - Control variate vs Sampling - Rosenbrock function.","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/rosenbrock/comparison/#robust-opt-control-variate-vs-sampling-rosenbrock-function","title":"Robust OPT - Control variate vs Sampling - Rosenbrock function.","text":"<pre><code>from __future__ import annotations\n\nimport numpy as np\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\nfrom gemseo.utils.string_tools import MultiLineString\nfrom matplotlib import pyplot as plt\nfrom numpy import array\nfrom numpy import ndarray\nfrom numpy import quantile\nfrom scipy.spatial.distance import cdist\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n</code></pre> <p>Firstly, we define an AnalyticDiscipline implementing a random version of the Rosenbrock function \\(f(x,y,U)=(U-x)^2+100(y-x^2)^2\\):</p> <pre><code>discipline = AnalyticDiscipline({\"z\": \"(a-x)**2+100*(y-x**2)**2\"}, name=\"Rosenbrock\")\n</code></pre> <p>where \\(x,y\\) belongs to the interval \\([-2,2]\\):</p> <pre><code>design_space = DesignSpace()\ndesign_space.add_variable(\"x\", l_b=-2, u_b=2.0, value=-2.0)\ndesign_space.add_variable(\"y\", l_b=-2, u_b=2.0, value=-2.0)\n</code></pre> <p>and \\(U\\) is a Gaussian variable with unit mean and standard deviation equal to 0.05:</p> <pre><code>uncertain_space = ParameterSpace()\nuncertain_space.add_random_variable(\"a\", \"OTNormalDistribution\", mu=1.0, sigma=0.05)\n</code></pre> <p>Then, we want to build a UMDOScenario to minimize a sampling-based estimation of the expectation \\(\\mathbb{E}[Y]\\) where \\(Y=f(x,y,U)\\): For that, we compare an approach based on crude Monte Carlo and an approach based on a linearized model as control variate and repeat it 20 times to get statistics on the results:</p> <pre><code>method_to_x_opt = {\"Sampling\": [], \"ControlVariate\": []}\nfor i in range(20):\n    for method in [\"Sampling\", \"ControlVariate\"]:\n        scenario = UMDOScenario(\n            [discipline],\n            \"DisciplinaryOpt\",\n            \"z\",\n            design_space,\n            uncertain_space,\n            \"Mean\",\n            statistic_estimation=method,\n            statistic_estimation_parameters={\n                \"algo\": \"OT_MONTE_CARLO\",\n                \"n_samples\": 10,\n                \"seed\": i + 1,\n            },\n        )\n        scenario.set_differentiation_method(\"finite_differences\")\n        scenario.execute({\"algo\": \"NLOPT_SLSQP\", \"max_iter\": 100})\n        method_to_x_opt[method].append(scenario.optimization_result.x_opt.tolist())\n</code></pre> <p>Lastly, we print and plot the comparison in terms of distance to the theoretical solution \\(x^*=(1,1)\\):</p> <pre><code>def ecdf(data: ndarray) -&gt; tuple[ndarray, ndarray]:\n    \"\"\"Empirical cumulative distribution function.\n\n    Args:\n        data: The data.\n\n    Returns:\n        The quantiles and the cumulative probabilities.\n    \"\"\"\n    quantiles, counts = np.unique(data, return_counts=True)\n    return quantiles, np.cumsum(counts).astype(np.double) / data.size\n\n\ncomparison = MultiLineString()\nfor index, method in enumerate([\"Sampling\", \"ControlVariate\"]):\n    distances_to_one = cdist(array(method_to_x_opt[method]), array([[1.0, 1.0]]))\n    x, y = ecdf(abs(distances_to_one))\n    plt.plot(x, y, \"-\" * index, label=method)\n    comparison.add(method)\n    comparison.indent()\n    comparison.add(f\"Mean: {distances_to_one.mean():.2e}\")\n    comparison.add(f\"Standard deviation: {distances_to_one.std():.2e}\")\n    comparison.add(f\"0.05-quantile: {quantile(distances_to_one, 0.05):.2e}\")\n    comparison.add(f\"0.95-quantile: {quantile(distances_to_one, 0.95):.2e}\")\n    comparison.dedent()\n\nprint(comparison)\n\nplt.xlabel(\"Distance to the theoretical solution x=(1,1)\")\nplt.ylabel(\"Cumulative distribution function\")\nplt.legend()\nplt.show()\n</code></pre> <p>Total running time of the script: ( 0 minutes  0.000 seconds)</p> <p> Download Python source code: comparison.py</p> <p> Download Jupyter notebook: comparison.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/rosenbrock/rosenbrock_control_variate/","title":"Robust OPT - Control variate - Rosenbrock function.","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/rosenbrock/rosenbrock_control_variate/#robust-opt-control-variate-rosenbrock-function","title":"Robust OPT - Control variate - Rosenbrock function.","text":"<pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nconfigure_logger()\n</code></pre> <p>Firstly, we define an AnalyticDiscipline implementing a random version of the Rosenbrock function \\(f(x,y,U)=(U-x)^2+100(y-x^2)^2\\):</p> <pre><code>discipline = AnalyticDiscipline({\"z\": \"(u-x)**2+100*(y-x**2)**2\"}, name=\"Rosenbrock\")\n</code></pre> <p>where \\(x,y\\) belongs to the interval \\([-2,2]\\):</p> <pre><code>design_space = DesignSpace()\ndesign_space.add_variable(\"x\", l_b=-2, u_b=2.0, value=-2.0)\ndesign_space.add_variable(\"y\", l_b=-2, u_b=2.0, value=-2.0)\n</code></pre> <p>and \\(U\\) is a Gaussian variable with unit mean and standard deviation equal to 0.05:</p> <pre><code>uncertain_space = ParameterSpace()\nuncertain_space.add_random_variable(\"u\", \"OTNormalDistribution\", mu=1.0, sigma=0.05)\n</code></pre> <p>Then, we build a UMDOScenario to minimize a control variate-based estimation of the expectation \\(\\mathbb{E}[Y]\\) where \\(Y=f(x,y,U)\\):</p> <pre><code>scenario = UMDOScenario(\n    [discipline],\n    \"DisciplinaryOpt\",\n    \"z\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    statistic_estimation=\"ControlVariate\",\n    statistic_estimation_parameters={\"n_samples\": 10},\n)\n</code></pre> <p>and execute it with a gradient-based optimizer:</p> <pre><code>scenario.set_differentiation_method(\"finite_differences\")\n</code></pre> <p>.. note::    The statistics do not allow for the moment to use analytical derivatives.    Please use finite differences or complex step to approximate the gradients.</p> <pre><code>scenario.execute({\"algo\": \"NLOPT_SLSQP\", \"max_iter\": 100})\n</code></pre> <p>Lastly, we can plot the optimization history view:</p> <pre><code>scenario.post_process(\"OptHistoryView\", save=True, show=True)\n</code></pre> <p>Total running time of the script: ( 0 minutes  0.000 seconds)</p> <p> Download Python source code: rosenbrock_control_variate.py</p> <p> Download Jupyter notebook: rosenbrock_control_variate.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/rosenbrock/rosenbrock_sampling_opt/","title":"Robust OPT - Sampling - Rosenbrock function","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/rosenbrock/rosenbrock_sampling_opt/#robust-opt-sampling-rosenbrock-function","title":"Robust OPT - Sampling - Rosenbrock function","text":"<pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nconfigure_logger()\n</code></pre> <p>Firstly, we define an AnalyticDiscipline implementing a random version of the Rosenbrock function \\(f(x,y,U)=(U-x)^2+100(y-x^2)^2\\):</p> <pre><code>discipline = AnalyticDiscipline({\"z\": \"(u-x)**2+100*(y-x**2)**2\"}, name=\"Rosenbrock\")\n</code></pre> <p>where \\(x,y\\) belongs to the interval \\([-2,2]\\):</p> <pre><code>design_space = DesignSpace()\ndesign_space.add_variable(\"x\", l_b=-2, u_b=2.0, value=-2.0)\ndesign_space.add_variable(\"y\", l_b=-2, u_b=2.0, value=-2.0)\n</code></pre> <p>and \\(U\\) is a Gaussian variable with unit mean and standard deviation equal to 0.05:</p> <pre><code>uncertain_space = ParameterSpace()\nuncertain_space.add_random_variable(\"u\", \"OTNormalDistribution\", mu=1.0, sigma=0.05)\n</code></pre> <p>Then, we build a UMDOScenario to minimize a sampling-based estimation of the expectation \\(\\mathbb{E}[Y]\\) where \\(Y=f(x,y,U)\\):</p> <pre><code>scenario = UMDOScenario(\n    [discipline],\n    \"DisciplinaryOpt\",\n    \"z\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    statistic_estimation=\"Sampling\",\n    statistic_estimation_parameters={\"n_samples\": 10},\n)\n</code></pre> <p>and execute it with a gradient-based optimizer:</p> <pre><code>scenario.set_differentiation_method(\"finite_differences\")\n</code></pre> <p>.. note::    The statistics do not allow for the moment to use analytical derivatives.    Please use finite differences or complex step to approximate the gradients.</p> <pre><code>scenario.execute({\"algo\": \"NLOPT_SLSQP\", \"max_iter\": 100})\n</code></pre> <p>Lastly, we can plot the optimization history view:</p> <pre><code>scenario.post_process(\"OptHistoryView\", save=True, show=True)\n</code></pre> <p>Total running time of the script: ( 0 minutes  0.000 seconds)</p> <p> Download Python source code: rosenbrock_sampling_opt.py</p> <p> Download Jupyter notebook: rosenbrock_sampling_opt.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/sellar/sellar_control_variate/","title":"Robust OPT - Control variate - Sellar problem","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/sellar/sellar_control_variate/#robust-opt-control-variate-sellar-problem","title":"Robust OPT - Control variate - Sellar problem","text":"<pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nconfigure_logger()\n</code></pre> <p>Firstly, we instantiate the disciplines of the Sellar problem:</p> <pre><code>system = AnalyticDiscipline({\n    \"obj\": \"x**2 + z2 + y1**2 + exp(-y2)\",\n    \"c1\": \"3.16 - y1 ** 2\",\n    \"c2\": \"y2 - 24.0\",\n})\ndisc1 = AnalyticDiscipline({\"y1\": \"(z1**2 + z2 + x - a*y2)**0.5\"})\ndisc2 = AnalyticDiscipline({\"y2\": \"2/10*log(1+exp(10*y1))-y1-2/10*log(2) + z1 + z2\"})\n</code></pre> <p>as well as the design space:</p> <pre><code>design_space = DesignSpace()\ndesign_space.add_variable(\"x\", 1, l_b=0.0, u_b=10.0, value=1.0)\ndesign_space.add_variable(\"z1\", 1, l_b=-10, u_b=10.0, value=4.0)\ndesign_space.add_variable(\"z2\", 1, l_b=0.0, u_b=10.0, value=3.0)\n</code></pre> <p>Secondly, we define the uncertain space:</p> <pre><code>uncertain_space = ParameterSpace()\n</code></pre> <p>with an uncertainty over the constant <code>\"a\"</code>:</p> <pre><code>uncertain_space.add_random_variable(\n    \"a\", \"OTTriangularDistribution\", minimum=0.1, maximum=0.3, mode=0.2\n)\n</code></pre> <p>Then, we build an UMDOScenario to minimize a control variate-based estimation of the expectation \\(\\mathbb{E}[obj]\\):</p> <pre><code>scenario = UMDOScenario(\n    [system, disc1, disc2],\n    \"MDF\",\n    \"obj\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    statistic_estimation=\"ControlVariate\",\n    statistic_estimation_parameters={\"n_samples\": 100},\n)\n</code></pre> <p>while satisfying margin constraints of the form \\(\\mathbb{E}[c_i]+3\\mathbb{S}[c_i]\\)</p> <pre><code>scenario.add_constraint(\"c1\", \"Margin\", factor=3.0)\nscenario.add_constraint(\"c2\", \"Margin\", factor=3.0)\n</code></pre> <p>and execute it with a gradient-free optimizer:</p> <pre><code>scenario.execute({\"algo\": \"NLOPT_COBYLA\", \"max_iter\": 200})\n</code></pre> <p>Lastly, we can plot the optimization history view:</p> <pre><code>scenario.post_process(\"OptHistoryView\", save=True, show=False)\n</code></pre> <p>Total running time of the script: ( 0 minutes  0.000 seconds)</p> <p> Download Python source code: sellar_control_variate.py</p> <p> Download Jupyter notebook: sellar_control_variate.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/sellar/sellar_first_tp_opt/","title":"Robust OPT - First-order Taylor polynomial - Sellar problem","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/sellar/sellar_first_tp_opt/#robust-opt-first-order-taylor-polynomial-sellar-problem","title":"Robust OPT - First-order Taylor polynomial - Sellar problem","text":"<pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nconfigure_logger()\n</code></pre> <p>Firstly, we instantiate the disciplines of the Sellar problem:</p> <pre><code>system = AnalyticDiscipline({\n    \"obj\": \"x**2 + z2 + y1**2 + exp(-y2)\",\n    \"c1\": \"3.16 - y1 ** 2\",\n    \"c2\": \"y2 - 24.0\",\n})\ndisc1 = AnalyticDiscipline({\"y1\": \"(z1**2 + z2 + x - a*y2)**0.5\"})\ndisc2 = AnalyticDiscipline({\"y2\": \"2/10*log(1+exp(10*y1))-y1-2/10*log(2) + z1 + z2\"})\n</code></pre> <p>as well as the design space:</p> <pre><code>design_space = DesignSpace()\ndesign_space.add_variable(\"x\", 1, l_b=0.0, u_b=10.0, value=1.0)\ndesign_space.add_variable(\"z1\", 1, l_b=-10, u_b=10.0, value=4.0)\ndesign_space.add_variable(\"z2\", 1, l_b=0.0, u_b=10.0, value=3.0)\n</code></pre> <p>Secondly, we define the uncertain space:</p> <pre><code>uncertain_space = ParameterSpace()\n</code></pre> <p>with an uncertainty over the constant <code>\"a\"</code>:</p> <pre><code>uncertain_space.add_random_variable(\n    \"a\", \"OTTriangularDistribution\", minimum=0.1, maximum=0.3, mode=0.2\n)\n</code></pre> <p>Then, we build an UMDOScenario to minimize a first-order approximation-based estimation of the expectation \\(\\mathbb{E}[obj]\\):</p> <pre><code>scenario = UMDOScenario(\n    [system, disc1, disc2],\n    \"MDF\",\n    \"obj\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    statistic_estimation=\"TaylorPolynomial\",\n)\n</code></pre> <p>while satisfying margin constraints of the form \\(\\mathbb{E}[c_i]+3\\mathbb{S}[c_i]\\)</p> <pre><code>scenario.add_constraint(\"c1\", \"Margin\", factor=3.0)\nscenario.add_constraint(\"c2\", \"Margin\", factor=3.0)\n</code></pre> <p>and execute it with a gradient-free optimizer:</p> <pre><code>scenario.execute({\"algo\": \"NLOPT_COBYLA\", \"max_iter\": 200})\n</code></pre> <p>Lastly, we can plot the optimization history view:</p> <pre><code>scenario.post_process(\"OptHistoryView\", save=True, show=False)\n</code></pre> <p>Total running time of the script: ( 0 minutes  0.000 seconds)</p> <p> Download Python source code: sellar_first_tp_opt.py</p> <p> Download Jupyter notebook: sellar_first_tp_opt.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/sellar/sellar_opt/","title":"OPT - Deterministic - Sellar problem.","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/sellar/sellar_opt/#opt-deterministic-sellar-problem","title":"OPT - Deterministic - Sellar problem.","text":"<pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\nfrom gemseo.scenarios.mdo_scenario import MDOScenario\n\nconfigure_logger()\n</code></pre> <p>Firstly, we instantiate the disciplines of the Sellar problem:</p> <pre><code>system = AnalyticDiscipline({\n    \"obj\": \"x**2 + z2 + y1**2 + exp(-y2)\",\n    \"c1\": \"3.16 - y1 ** 2\",\n    \"c2\": \"y2 - 24.0\",\n})\ndisc1 = AnalyticDiscipline({\"y1\": \"(z1**2 + z2 + x - 0.2*y2)**0.5\"})\ndisc2 = AnalyticDiscipline({\"y2\": \"abs(y1) + z1 + z2\"})\n</code></pre> <p>as well as the design space:</p> <pre><code>design_space = DesignSpace()\ndesign_space.add_variable(\"x\", 1, l_b=0.0, u_b=10.0, value=1.0)\ndesign_space.add_variable(\"z1\", 1, l_b=-10, u_b=10.0, value=4.0)\ndesign_space.add_variable(\"z2\", 1, l_b=0.0, u_b=10.0, value=3.0)\n</code></pre> <p>Then, we build an <code>MDOScenario</code> to minimize <code>\"obj\"</code>:</p> <pre><code>scenario = MDOScenario(\n    [system, disc1, disc2],\n    formulation=\"MDF\",\n    objective_name=\"obj\",\n    design_space=design_space,\n)\n</code></pre> <p>while satisfying inequality constraints related to <code>\"c_1\"</code> and <code>\"c_2\"</code>:</p> <pre><code>scenario.add_constraint(\"c1\", \"ineq\")\nscenario.add_constraint(\"c2\", \"ineq\")\n</code></pre> <p>and execute it with a gradient-free optimizer:</p> <pre><code>scenario.execute({\"algo\": \"NLOPT_COBYLA\", \"max_iter\": 200})\n</code></pre> <p>Lastly, we can plot the optimization history view:</p> <pre><code>scenario.post_process(\"OptHistoryView\", save=True, show=False)\n</code></pre> <p>Total running time of the script: ( 0 minutes  0.000 seconds)</p> <p> Download Python source code: sellar_opt.py</p> <p> Download Jupyter notebook: sellar_opt.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/sellar/sellar_sampling_opt/","title":"Robust OPT - Sampling - Sellar problem","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/sellar/sellar_sampling_opt/#robust-opt-sampling-sellar-problem","title":"Robust OPT - Sampling - Sellar problem","text":"<pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nconfigure_logger()\n</code></pre> <p>Firstly, we instantiate the disciplines of the Sellar problem:</p> <pre><code>system = AnalyticDiscipline({\n    \"obj\": \"x**2 + z2 + y1**2 + exp(-y2)\",\n    \"c1\": \"3.16 - y1 ** 2\",\n    \"c2\": \"y2 - 24.0\",\n})\ndisc1 = AnalyticDiscipline({\"y1\": \"(z1**2 + z2 + x - a*y2)**0.5\"})\ndisc2 = AnalyticDiscipline({\"y2\": \"abs(y1) + z1 + z2\"})\n</code></pre> <p>as well as the design space:</p> <pre><code>design_space = DesignSpace()\ndesign_space.add_variable(\"x\", 1, l_b=0.0, u_b=10.0, value=1.0)\ndesign_space.add_variable(\"z1\", 1, l_b=-10, u_b=10.0, value=4.0)\ndesign_space.add_variable(\"z2\", 1, l_b=0.0, u_b=10.0, value=3.0)\n</code></pre> <p>Secondly, we define the uncertain space:</p> <pre><code>uncertain_space = ParameterSpace()\n</code></pre> <p>with an uncertainty over the constant <code>\"a\"</code>:</p> <pre><code>uncertain_space.add_random_variable(\n    \"a\", \"OTTriangularDistribution\", minimum=0.1, maximum=0.3, mode=0.2\n)\n</code></pre> <p>Then, we build an UMDOScenario to minimize a sampling-based estimation of the expectation \\(\\mathbb{E}[obj]\\):</p> <pre><code>scenario = UMDOScenario(\n    [system, disc1, disc2],\n    \"MDF\",\n    \"obj\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    statistic_estimation=\"Sampling\",\n    statistic_estimation_parameters={\"n_samples\": 100},\n)\n</code></pre> <p>while satisfying margin constraints of the form \\(\\mathbb{E}[c_i]+3\\mathbb{S}[c_i]\\)</p> <pre><code>scenario.add_constraint(\"c1\", \"Margin\", factor=3.0)\nscenario.add_constraint(\"c2\", \"Margin\", factor=3.0)\n</code></pre> <p>and execute it with a gradient-free optimizer:</p> <pre><code>scenario.execute({\"algo\": \"NLOPT_COBYLA\", \"max_iter\": 200})\nscenario.post_process(\"OptHistoryView\", save=True, show=False)\nscenario.save_optimization_history(\"history.hdf5\")\n</code></pre> <p>Total running time of the script: ( 0 minutes  0.000 seconds)</p> <p> Download Python source code: sellar_sampling_opt.py</p> <p> Download Jupyter notebook: sellar_sampling_opt.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/sellar/sellar_sampling_opt_repetitions/","title":"Robust OPT - Sampling with repetitions - Sellar problem","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/sellar/sellar_sampling_opt_repetitions/#robust-opt-sampling-with-repetitions-sellar-problem","title":"Robust OPT - Sampling with repetitions - Sellar problem","text":"<pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\nfrom matplotlib import pyplot as plt\nfrom numpy import load\nfrom numpy import save\nfrom numpy import stack\nfrom numpy import vstack\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nconfigure_logger()\n</code></pre> <p>Firstly, we instantiate the disciplines of the Sellar problem:</p> <pre><code>system = AnalyticDiscipline({\n    \"obj\": \"x**2 + z2 + y1**2 + exp(-y2)\",\n    \"c1\": \"3.16 - y1 ** 2\",\n    \"c2\": \"y2 - 24.0\",\n})\ndisc1 = AnalyticDiscipline({\"y1\": \"(z1**2 + z2 + x - a*y2)**0.5\"})\ndisc2 = AnalyticDiscipline({\"y2\": \"2/10*log(1+exp(10*y1))-y1-2/10*log(2) + z1 + z2\"})\n</code></pre> <p>as well as a function to instantiate the design space:</p> <pre><code>def create_design_space() -&gt; DesignSpace:\n    \"\"\"Create the design space for the Sellar problem.\"\"\"\n    design_space = DesignSpace()\n    design_space.add_variable(\"x\", 1, l_b=0.0, u_b=10.0, value=1.0)\n    design_space.add_variable(\"z1\", 1, l_b=-10, u_b=10.0, value=4.0)\n    design_space.add_variable(\"z2\", 1, l_b=0.0, u_b=10.0, value=3.0)\n    return design_space\n</code></pre> <p>Secondly, we define the uncertain space:</p> <pre><code>uncertain_space = ParameterSpace()\n</code></pre> <p>with an uncertainty over the constant <code>\"a\"</code>:</p> <pre><code>uncertain_space.add_random_variable(\n    \"a\", \"OTTriangularDistribution\", minimum=0.1, maximum=0.3, mode=0.2\n)\n</code></pre> <p>Then, we build 10 UMDOScenario to minimize a sampling-based estimation of the expectation \\(\\mathbb{E}[obj]\\) and store the history of the design values:</p> <pre><code>x_hist = []\nfor i in range(10):\n    print(i)\n    scenario = UMDOScenario(\n        [system, disc1, disc2],\n        \"MDF\",\n        \"obj\",\n        create_design_space(),\n        uncertain_space,\n        \"Mean\",\n        statistic_estimation=\"Sampling\",\n        statistic_estimation_parameters={\n            \"algo\": \"OT_LHS\",\n            \"n_samples\": 100,\n            \"seed\": i + 1,\n        },\n    )\n    scenario.add_constraint(\"c1\", \"Margin\", factor=3.0)\n    scenario.add_constraint(\"c2\", \"Margin\", factor=3.0)\n    scenario.execute({\"algo\": \"NLOPT_COBYLA\", \"max_iter\": 100})\n    x_hist.append(\n        vstack(scenario.formulation.optimization_problem.database.get_x_vect_history())\n    )\n</code></pre> <p>Lastly, we plot the variability of the optimization history with boxplots:</p> <pre><code>print(x_hist)\nx_hist = stack(x_hist)\nsave(\"x_hist.npy\", x_hist)\nx_hist = load(\"x_hist.npy\")\nplt.boxplot(x_hist[:, :, 0])\nplt.savefig(\"hist.png\")\n</code></pre> <p>Total running time of the script: ( 0 minutes  0.000 seconds)</p> <p> Download Python source code: sellar_sampling_opt_repetitions.py</p> <p> Download Jupyter notebook: sellar_sampling_opt_repetitions.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/sellar/sellar_second_tp_opt/","title":"Robust OPT - Second-order Taylor polynomial - Sellar problem","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/sellar/sellar_second_tp_opt/#robust-opt-second-order-taylor-polynomial-sellar-problem","title":"Robust OPT - Second-order Taylor polynomial - Sellar problem","text":"<pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nconfigure_logger()\n</code></pre> <p>Firstly, we instantiate the disciplines of the Sellar problem:</p> <pre><code>system = AnalyticDiscipline({\n    \"obj\": \"x**2 + z2 + y1**2 + exp(-y2)\",\n    \"c1\": \"3.16 - y1 ** 2\",\n    \"c2\": \"y2 - 24.0\",\n})\ndisc1 = AnalyticDiscipline({\"y1\": \"(z1**2 + z2 + x - a*y2)**0.5\"})\ndisc2 = AnalyticDiscipline({\"y2\": \"2/10*log(1+exp(10*y1))-y1-2/10*log(2) + z1 + z2\"})\n</code></pre> <p>as well as the design space:</p> <pre><code>design_space = DesignSpace()\ndesign_space.add_variable(\"x\", 1, l_b=0.0, u_b=10.0, value=1.0)\ndesign_space.add_variable(\"z1\", 1, l_b=-10, u_b=10.0, value=4.0)\ndesign_space.add_variable(\"z2\", 1, l_b=0.0, u_b=10.0, value=3.0)\n</code></pre> <p>Secondly, we define the uncertain space:</p> <pre><code>uncertain_space = ParameterSpace()\n</code></pre> <p>with an uncertainty over the constant <code>\"a\"</code>:</p> <pre><code>uncertain_space.add_random_variable(\n    \"a\", \"OTTriangularDistribution\", minimum=0.1, maximum=0.3, mode=0.2\n)\n</code></pre> <p>Then, we build an UMDOScenario to minimize a second-order approximation-based estimation of the expectation \\(\\mathbb{E}[obj]\\):</p> <pre><code>scenario = UMDOScenario(\n    [system, disc1, disc2],\n    \"MDF\",\n    \"obj\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    statistic_estimation=\"TaylorPolynomial\",\n    statistic_estimation_parameters={\"second_order\": True},\n)\n</code></pre> <p>while satisfying margin constraints of the form \\(\\mathbb{E}[c_i]+3\\mathbb{S}[c_i]\\)</p> <pre><code>scenario.add_constraint(\"c1\", \"Margin\", factor=3.0)\nscenario.add_constraint(\"c2\", \"Margin\", factor=3.0)\n</code></pre> <p>and execute it with a gradient-free optimizer:</p> <pre><code>scenario.execute({\"algo\": \"NLOPT_COBYLA\", \"max_iter\": 200})\nscenario.post_process(\"OptHistoryView\", save=True, show=False)\n</code></pre> <p>Total running time of the script: ( 0 minutes  0.000 seconds)</p> <p> Download Python source code: sellar_second_tp_opt.py</p> <p> Download Jupyter notebook: sellar_second_tp_opt.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/sobieski/sobieski_first_tp_opt/","title":"Robust MDO - First-order Taylor polynomial - Sobieski","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/sobieski/sobieski_first_tp_opt/#robust-mdo-first-order-taylor-polynomial-sobieski","title":"Robust MDO - First-order Taylor polynomial - Sobieski","text":"<pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.problems.mdo.sobieski.core.problem import SobieskiProblem\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiAerodynamics\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiMission\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiPropulsion\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiStructure\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nconfigure_logger()\n</code></pre> <p>Firstly, we instantiate the discipline of Sobieski's SSBJ problem:</p> <pre><code>mission = SobieskiMission()\nstructure = SobieskiStructure()\npropulsion = SobieskiPropulsion()\naerodynamics = SobieskiAerodynamics()\n</code></pre> <p>as well as the design space:</p> <pre><code>design_space = SobieskiProblem().design_space\n</code></pre> <p>Secondly, we define the uncertain space:</p> <pre><code>uncertain_space = ParameterSpace()\n</code></pre> <p>with an uncertainty over the constant <code>\"c_4\"</code>:</p> <pre><code>uncertain_space.add_random_variable(\n    \"c_4\", \"OTNormalDistribution\", mu=0.01375, sigma=0.01375 * 0.05\n)\n</code></pre> <p>and an uncertainty over the design variable <code>\"x_2\"</code>, expressed as an additive term <code>\"u_x_2\"</code> defined just after in the UMDOScenario:</p> <pre><code>uncertain_space.add_random_variable(\n    \"u_x_2\", \"OTNormalDistribution\", mu=0.0, sigma=1 * 0.05\n)\n</code></pre> <p>Then, we build an UMDOScenario to maximize a first-order linearization-based estimation (default estimation method) of the expectation \\(\\mathbb{E}[y_4]\\):</p> <pre><code>scenario = UMDOScenario(\n    [mission, structure, propulsion, aerodynamics],\n    \"MDF\",\n    \"y_4\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    statistic_estimation=\"TaylorPolynomial\",\n    maximize_objective=True,\n    uncertain_design_variables={\"x_2\": \"{}+u_x_2\"},\n)\n</code></pre> <p>while satisfying margin constraints of the form \\(\\mathbb{E}[g_i]+3\\mathbb{S}[g_i]\\)</p> <pre><code>scenario.add_constraint(\"g_1\", \"Margin\", factor=3.0)\nscenario.add_constraint(\"g_2\", \"Margin\", factor=3.0)\nscenario.add_constraint(\"g_3\", \"Margin\", factor=3.0)\n</code></pre> <p>and execute it with a gradient-free optimizer:</p> <pre><code>scenario.execute({\"algo\": \"NLOPT_COBYLA\", \"max_iter\": 100})\n</code></pre> <p>Lastly, we can plot the optimization history view:</p> <pre><code>scenario.post_process(\"OptHistoryView\", save=False, show=True)\n</code></pre> <p>Total running time of the script: ( 0 minutes  0.000 seconds)</p> <p> Download Python source code: sobieski_first_tp_opt.py</p> <p> Download Jupyter notebook: sobieski_first_tp_opt.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/sobieski/sobieski_sampling_opt/","title":"Robust MDO - Sampling - Sobieski","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/sobieski/sobieski_sampling_opt/#robust-mdo-sampling-sobieski","title":"Robust MDO - Sampling - Sobieski","text":"<pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.problems.mdo.sobieski.core.problem import SobieskiProblem\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiAerodynamics\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiMission\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiPropulsion\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiStructure\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nconfigure_logger()\n</code></pre> <p>Firstly, we instantiate the discipline of Sobieski's SSBJ problem:</p> <pre><code>mission = SobieskiMission()\nstructure = SobieskiStructure()\npropulsion = SobieskiPropulsion()\naerodynamics = SobieskiAerodynamics()\n</code></pre> <p>as well as the design space:</p> <pre><code>design_space = SobieskiProblem().design_space\n</code></pre> <p>Secondly, we define the uncertain space:</p> <pre><code>uncertain_space = ParameterSpace()\n</code></pre> <p>with an uncertainty over the constant <code>\"c_4\"</code>:</p> <pre><code>uncertain_space.add_random_variable(\n    \"c_4\", \"OTNormalDistribution\", mu=0.01375, sigma=0.01375 * 0.05\n)\n</code></pre> <p>and an uncertainty over the design variable <code>\"x_2\"</code>, expressed as an additive term <code>\"u_x_2\"</code> defined just after in the UMDOScenario:</p> <pre><code>uncertain_space.add_random_variable(\n    \"u_x_2\", \"OTNormalDistribution\", mu=0.0, sigma=1 * 0.05\n)\n</code></pre> <p>Then, we build an UMDOScenario to maximize a sampling-based estimation of the expectation \\(\\mathbb{E}[y_4]\\):</p> <pre><code>scenario = UMDOScenario(\n    [mission, structure, propulsion, aerodynamics],\n    \"MDF\",\n    \"y_4\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    statistic_estimation=\"Sampling\",\n    statistic_estimation_parameters={\"n_samples\": 10},\n    maximize_objective=True,\n    uncertain_design_variables={\"x_2\": \"{}+u_x_2\"},\n)\n</code></pre> <p>while satisfying margin constraints of the form \\(\\mathbb{E}[g_i]+3\\mathbb{S}[g_i]\\)</p> <pre><code>scenario.add_constraint(\"g_1\", \"Margin\", factor=3.0)\nscenario.add_constraint(\"g_2\", \"Margin\", factor=3.0)\nscenario.add_constraint(\"g_3\", \"Margin\", factor=3.0)\n</code></pre> <p>and execute it with a gradient-free optimizer:</p> <pre><code>scenario.execute({\"algo\": \"NLOPT_COBYLA\", \"max_iter\": 100})\n</code></pre> <p>Lastly, we can plot the optimization history view:</p> <pre><code>scenario.post_process(\"OptHistoryView\", save=False, show=True)\n</code></pre> <p>Total running time of the script: ( 0 minutes  0.000 seconds)</p> <p> Download Python source code: sobieski_sampling_opt.py</p> <p> Download Jupyter notebook: sobieski_sampling_opt.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/sobieski/sobieski_second_tp_opt/","title":"Robust MDO - Second-order Taylor polynomial - Sobieski","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/sobieski/sobieski_second_tp_opt/#robust-mdo-second-order-taylor-polynomial-sobieski","title":"Robust MDO - Second-order Taylor polynomial - Sobieski","text":"<pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.problems.mdo.sobieski.core.problem import SobieskiProblem\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiAerodynamics\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiMission\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiPropulsion\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiStructure\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nconfigure_logger()\n</code></pre> <p>Firstly, we instantiate the discipline of Sobieski's SSBJ problem:</p> <pre><code>mission = SobieskiMission()\nstructure = SobieskiStructure()\npropulsion = SobieskiPropulsion()\naerodynamics = SobieskiAerodynamics()\n</code></pre> <p>as well as the design space:</p> <pre><code>design_space = SobieskiProblem().design_space\n</code></pre> <p>Secondly, we define the uncertain space:</p> <pre><code>uncertain_space = ParameterSpace()\n</code></pre> <p>with an uncertainty over the constant <code>\"c_4\"</code>:</p> <pre><code>uncertain_space.add_random_variable(\n    \"c_4\", \"OTNormalDistribution\", mu=0.01375, sigma=0.01375 * 0.05\n)\n</code></pre> <p>and an uncertainty over the design variable <code>\"x_2\"</code>, expressed as an additive term <code>\"u_x_2\"</code> defined just after in the UMDOScenario:</p> <pre><code>uncertain_space.add_random_variable(\n    \"u_x_2\", \"OTNormalDistribution\", mu=0.0, sigma=1 * 0.05\n)\n</code></pre> <p>Then, we build an UMDOScenario to maximize a second-order approximation-based estimation of the expectation \\(\\mathbb{E}[y_4]\\):</p> <pre><code>scenario = UMDOScenario(\n    [mission, structure, propulsion, aerodynamics],\n    \"MDF\",\n    \"y_4\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    statistic_estimation=\"TaylorPolynomial\",\n    statistic_estimation_parameters={\"second_order\": True},\n    maximize_objective=True,\n    uncertain_design_variables={\"x_2\": \"{}+u_x_2\"},\n)\n</code></pre> <p>while satisfying margin constraints of the form \\(\\mathbb{E}[g_i]+3\\mathbb{S}[g_i]\\)</p> <pre><code>scenario.add_constraint(\"g_1\", \"Margin\", factor=3.0)\nscenario.add_constraint(\"g_2\", \"Margin\", factor=3.0)\nscenario.add_constraint(\"g_3\", \"Margin\", factor=3.0)\n</code></pre> <p>and execute it with a gradient-free optimizer:</p> <pre><code>scenario.execute({\"algo\": \"NLOPT_COBYLA\", \"max_iter\": 100})\n</code></pre> <p>Lastly, we can plot the optimization history view:</p> <pre><code>scenario.post_process(\"OptHistoryView\", save=False, show=True)\n</code></pre> <p>Total running time of the script: ( 0 minutes  0.000 seconds)</p> <p> Download Python source code: sobieski_second_tp_opt.py</p> <p> Download Jupyter notebook: sobieski_second_tp_opt.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/visualizations/","title":"Visualization","text":""},{"location":"generated/examples/visualizations/#data-visualization","title":"Data visualization","text":""},{"location":"generated/examples/visualizations/#sobol-graph","title":"Sobol' graph","text":"<p> Sobol' graph for the Sellar use case. </p> <p> Sobol' graph for the Ishigami use case. </p> <p> Sobol' graph for the Sobieski's SSBJ use case. </p>"},{"location":"generated/examples/visualizations/#uncertain-coupling-graph","title":"Uncertain coupling graph","text":"<p> The uncertain coupling graph for the Sobieski's SSBJ use case. </p> <p> Download all examples in Python source code: visualizations_python.zip</p> <p> Download all examples in Jupyter notebooks: visualizations_jupyter.zip</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/visualizations/sobol_graph/mg_execution_times/","title":"Computation times","text":"<p>00:05.241 total execution time for generated_examples_visualizations_sobol_graph files:</p> <p>+-------------------------------------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_sobieski_sobol_graph (docs/examples/visualizations/sobol_graph/plot_sobieski_sobol_graph.py) | 00:04.399 | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_sellar_sobol_graph (docs/examples/visualizations/sobol_graph/plot_sellar_sobol_graph.py)       | 00:00.813 | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_ishigami_sobol_graph (docs/examples/visualizations/sobol_graph/plot_ishigami_sobol_graph.py) | 00:00.030 | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------------+-----------+--------+</p>"},{"location":"generated/examples/visualizations/sobol_graph/plot_ishigami_sobol_graph/","title":"Sobol' graph for the Ishigami use case.","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/visualizations/sobol_graph/plot_ishigami_sobol_graph/#sobol-graph-for-the-ishigami-use-case","title":"Sobol' graph for the Ishigami use case.","text":"<pre><code>from __future__ import annotations\n\nfrom gemseo.problems.uncertainty.ishigami.statistics import SOBOL_1\nfrom gemseo.problems.uncertainty.ishigami.statistics import SOBOL_2\nfrom gemseo.problems.uncertainty.ishigami.statistics import SOBOL_3\nfrom gemseo.problems.uncertainty.ishigami.statistics import SOBOL_12\nfrom gemseo.problems.uncertainty.ishigami.statistics import SOBOL_13\nfrom gemseo.problems.uncertainty.ishigami.statistics import SOBOL_23\nfrom gemseo.problems.uncertainty.ishigami.statistics import TOTAL_SOBOL_1\nfrom gemseo.problems.uncertainty.ishigami.statistics import TOTAL_SOBOL_2\nfrom gemseo.problems.uncertainty.ishigami.statistics import TOTAL_SOBOL_3\n\nfrom gemseo_umdo.visualizations.sobol_graph import SobolGraph\n</code></pre> <p>First, we define the first-, second- and total-order Sobol' indices of the different uncertain variables:</p> <pre><code>first_order_indices = {\"X1\": SOBOL_1, \"X2\": SOBOL_2, \"X3\": SOBOL_3}\ntotal_order_indices = {\"X1\": TOTAL_SOBOL_1, \"X2\": TOTAL_SOBOL_2, \"X3\": TOTAL_SOBOL_3}\nsecond_order_indices = {\n    (\"X1\", \"X2\"): SOBOL_12,\n    (\"X1\", \"X3\"): SOBOL_13,\n    (\"X2\", \"X3\"): SOBOL_23,\n}\n</code></pre> <p>Then, we draw the Sobol' graph:</p> <pre><code>sobol_graph = SobolGraph(\n    first_order_indices,\n    second_order_indices=second_order_indices,\n    total_order_indices=total_order_indices,\n)\nsobol_graph\n</code></pre> X1     (56, 31) X1 (56, 31) X3     (24, 0) X3 (24, 0) X1     (56, 31)-&gt;X3     (24, 0) X2     (44, 44) X2 (44, 44) <p>Sphinx Gallery and Jupyter Notebook can display <code>sobol_graph</code> in the web browser. You can also use <code>sobol_graph.visualize()</code> to save it on the disk or display it with a dedicated program.</p> <p>Total running time of the script: ( 0 minutes  0.030 seconds)</p> <p> Download Python source code: plot_ishigami_sobol_graph.py</p> <p> Download Jupyter notebook: plot_ishigami_sobol_graph.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/visualizations/sobol_graph/plot_sellar_sobol_graph/","title":"Sobol' graph for the Sellar use case.","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/visualizations/sobol_graph/plot_sellar_sobol_graph/#sobol-graph-for-the-sellar-use-case","title":"Sobol' graph for the Sellar use case.","text":"<pre><code>from __future__ import annotations\n\nfrom gemseo.problems.mdo.sellar.sellar_1 import Sellar1\nfrom gemseo.problems.mdo.sellar.sellar_2 import Sellar2\nfrom gemseo.problems.mdo.sellar.sellar_design_space import SellarDesignSpace\nfrom gemseo.problems.mdo.sellar.sellar_system import SellarSystem\nfrom gemseo.uncertainty.sensitivity.sobol_analysis import SobolAnalysis\n\nfrom gemseo_umdo.visualizations.sobol_graph import SobolGraph\n</code></pre> <p>First, we consider the SellarDesignSpace as the uncertain space, which means that the uncertain variables are the design variables uniformly distributed between their lower and upper bounds:</p> <pre><code>design_space = SellarDesignSpace(dtype=\"float64\")\n</code></pre> <p>Then, we define the disciplines:</p> <pre><code>disciplines = [Sellar1(), Sellar2(), SellarSystem()]\n</code></pre> <p>Thirdly, we compute the Sobol' indices for all the outputs of the MDO problem:</p> <pre><code>sobol_analysis = SobolAnalysis(disciplines, design_space, 100)\nsobol_analysis.compute_indices()\n</code></pre> <p>Out:</p> <pre><code>/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/pandas/core/frame.py:706: DeprecationWarning: Passing a BlockManager to IODataset is deprecated and will raise in a future version. Use public APIs instead.\n  warnings.warn(\n/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/pandas/core/frame.py:706: DeprecationWarning: Passing a BlockManager to IODataset is deprecated and will raise in a future version. Use public APIs instead.\n  warnings.warn(\n/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/pandas/core/frame.py:706: DeprecationWarning: Passing a BlockManager to IODataset is deprecated and will raise in a future version. Use public APIs instead.\n  warnings.warn(\n\n{&lt;Method.FIRST: 'first'&gt;: {'c_1': [{'x_1': array([-0.34410788]), 'x_2': array([-0.29843742]), 'x_shared': array([ 1.46093658, -0.3048575 ])}], 'c_2': [{'x_1': array([-0.53113261]), 'x_2': array([-0.38770092]), 'x_shared': array([ 0.16102731, -0.23098271])}], 'obj': [{'x_1': array([0.27800547]), 'x_2': array([0.3810475]), 'x_shared': array([ 0.13907663, -0.22035721])}], 'y_1': [{'x_1': array([-0.37913247]), 'x_2': array([-0.31458256]), 'x_shared': array([ 1.55138976, -0.32269605])}], 'y_2': [{'x_1': array([-0.53113261]), 'x_2': array([-0.38770092]), 'x_shared': array([ 0.16102731, -0.23098271])}]}, 'second': {'c_1': [{'x_1': {'x_1': array([[0.]]), 'x_2': array([[0.56701564]]), 'x_shared': array([[0.6422234, 0.5672484]])}, 'x_2': {'x_1': array([[0.56701564]]), 'x_2': array([[0.]]), 'x_shared': array([[0.53308572, 0.55716927]])}, 'x_shared': {'x_1': array([[0.6422234],\n       [0.5672484]]), 'x_2': array([[0.53308572],\n       [0.55716927]]), 'x_shared': array([[0.        , 0.67760023],\n       [0.67760023, 0.        ]])}}], 'c_2': [{'x_1': {'x_1': array([[0.]]), 'x_2': array([[0.97693343]]), 'x_shared': array([[1.02843552, 0.98166638]])}, 'x_2': {'x_1': array([[0.97693343]]), 'x_2': array([[0.]]), 'x_shared': array([[1.03793989, 0.99780683]])}, 'x_shared': {'x_1': array([[1.02843552],\n       [0.98166638]]), 'x_2': array([[1.03793989],\n       [0.99780683]]), 'x_shared': array([[0.        , 1.17629701],\n       [1.17629701, 0.        ]])}}], 'obj': [{'x_1': {'x_1': array([[0.]]), 'x_2': array([[0.13495232]]), 'x_shared': array([[-0.18981874,  0.01449817]])}, 'x_2': {'x_1': array([[0.13495232]]), 'x_2': array([[0.]]), 'x_shared': array([[-0.21880149,  0.26163493]])}, 'x_shared': {'x_1': array([[-0.18981874],\n       [ 0.01449817]]), 'x_2': array([[-0.21880149],\n       [ 0.26163493]]), 'x_shared': array([[0.       , 0.4477143],\n       [0.4477143, 0.       ]])}}], 'y_1': [{'x_1': {'x_1': array([[0.]]), 'x_2': array([[0.613337]]), 'x_shared': array([[0.80500278, 0.60420383]])}, 'x_2': {'x_1': array([[0.613337]]), 'x_2': array([[0.]]), 'x_shared': array([[0.55482328, 0.59360033]])}, 'x_shared': {'x_1': array([[0.80500278],\n       [0.60420383]]), 'x_2': array([[0.55482328],\n       [0.59360033]]), 'x_shared': array([[0.        , 0.59408376],\n       [0.59408376, 0.        ]])}}], 'y_2': [{'x_1': {'x_1': array([[0.]]), 'x_2': array([[0.97693343]]), 'x_shared': array([[1.02843552, 0.98166638]])}, 'x_2': {'x_1': array([[0.97693343]]), 'x_2': array([[0.]]), 'x_shared': array([[1.03793989, 0.99780683]])}, 'x_shared': {'x_1': array([[1.02843552],\n       [0.98166638]]), 'x_2': array([[1.03793989],\n       [0.99780683]]), 'x_shared': array([[0.        , 1.17629701],\n       [1.17629701, 0.        ]])}}]}, &lt;Method.TOTAL: 'total'&gt;: {'c_1': [{'x_1': array([-0.0624271]), 'x_2': array([-0.02552407]), 'x_shared': array([1.91531725, 0.02619011])}], 'c_2': [{'x_1': array([-0.00958822]), 'x_2': array([0.17352038]), 'x_shared': array([1.1045511 , 0.28830055])}], 'obj': [{'x_1': array([0.14342036]), 'x_2': array([0.38962338]), 'x_shared': array([ 0.59975335, -0.17876139])}], 'y_1': [{'x_1': array([-0.0266588]), 'x_2': array([-0.03806078]), 'x_shared': array([1.93039391, 0.04341188])}], 'y_2': [{'x_1': array([-0.00958822]), 'x_2': array([0.17352038]), 'x_shared': array([1.1045511 , 0.28830055])}]}}\n</code></pre> <p>Lastly, we draw the Sobol' graph :</p> <pre><code>sobol_graph = SobolGraph.from_analysis(sobol_analysis, output_name=\"obj\")\nsobol_graph\n</code></pre> x_1     (14, 28) x_1 (14, 28) x_2     (39, 38) x_2 (39, 38) x_1     (14, 28)-&gt;x_2     (39, 38) x_shared[1]     (0, 0) x_shared[1] (0, 0) x_2     (39, 38)-&gt;x_shared[1]     (0, 0) x_shared[0]     (60, 14) x_shared[0] (60, 14) x_shared[0]     (60, 14)-&gt;x_shared[1]     (0, 0) <p>Sphinx Gallery and Jupyter Notebook can display <code>sobol_graph</code> in the web browser. You can also use <code>sobol_graph.visualize()</code> to save it on the disk or display it with a dedicated program.</p> <p>Total running time of the script: ( 0 minutes  0.813 seconds)</p> <p> Download Python source code: plot_sellar_sobol_graph.py</p> <p> Download Jupyter notebook: plot_sellar_sobol_graph.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/visualizations/sobol_graph/plot_sobieski_sobol_graph/","title":"Sobol' graph for the Sobieski's SSBJ use case.","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/visualizations/sobol_graph/plot_sobieski_sobol_graph/#sobol-graph-for-the-sobieskis-ssbj-use-case","title":"Sobol' graph for the Sobieski's SSBJ use case.","text":"<pre><code>from __future__ import annotations\n\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.problems.mdo.sobieski.core.problem import SobieskiProblem\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiAerodynamics\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiMission\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiPropulsion\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiStructure\nfrom gemseo.uncertainty.sensitivity.sobol_analysis import SobolAnalysis\nfrom gemseo.utils.data_conversion import split_array_to_dict_of_arrays\n\nfrom gemseo_umdo.visualizations.sobol_graph import SobolGraph\n</code></pre> <p>First, we define an uncertain space around the optimum design:</p> <pre><code>design_space = SobieskiProblem().design_space\ndesign_variable_names = [\"x_1\", \"x_2\", \"x_3\", \"x_shared\"]\ndesign_space.filter(design_variable_names)\noptimum_design = split_array_to_dict_of_arrays(\n    SobieskiProblem().optimum_design,\n    design_space.variable_sizes,\n    design_variable_names,\n)\n\nuncertain_space = DesignSpace()\nfor name, value in optimum_design.items():\n    uncertain_space.add_variable(\n        name,\n        size=value.size,\n        l_b=value * 0.95,\n        u_b=value * 1.05,\n        value=value,\n    )\n</code></pre> <p>Then, we define the disciplines:</p> <pre><code>disciplines = [\n    SobieskiAerodynamics(),\n    SobieskiStructure(),\n    SobieskiPropulsion(),\n    SobieskiMission(),\n]\n</code></pre> <p>Thirdly, we compute the Sobol' indices for all the outputs of the MDO problem:</p> <pre><code>sobol_analysis = SobolAnalysis(disciplines, uncertain_space, 100)\nsobol_analysis.compute_indices()\n</code></pre> <p>Out:</p> <pre><code>/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib/python3.9/site-packages/gemseo/problems/mdo/sobieski/core/utils.py:223: DeprecationWarning: Conversion of an array with ndim &gt; 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  ai_coeff[index] = -(f_bound[2] - f_bound[0]) / (2 * mtx_shifted[0, 1])\n/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/pandas/core/frame.py:706: DeprecationWarning: Passing a BlockManager to IODataset is deprecated and will raise in a future version. Use public APIs instead.\n  warnings.warn(\n/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/pandas/core/frame.py:706: DeprecationWarning: Passing a BlockManager to IODataset is deprecated and will raise in a future version. Use public APIs instead.\n  warnings.warn(\n/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/pandas/core/frame.py:706: DeprecationWarning: Passing a BlockManager to IODataset is deprecated and will raise in a future version. Use public APIs instead.\n  warnings.warn(\n\n{&lt;Method.FIRST: 'first'&gt;: {'g_1': [{'x_1': array([ 1.25794269, -0.32644388]), 'x_2': array([-0.05557633]), 'x_3': array([-0.05557633]), 'x_shared': array([12.38277997, -0.05557633, -0.05557633, -1.05536659, -0.05557633,\n        0.69775338])}, {'x_1': array([1.59909832, 0.32261034]), 'x_2': array([0.38144802]), 'x_3': array([0.38144802]), 'x_shared': array([11.47445703,  0.38144802,  0.38144802, -0.97815587,  0.38144802,\n        1.41774286])}, {'x_1': array([1.72521777, 0.59361554]), 'x_2': array([0.55746056]), 'x_3': array([0.55746056]), 'x_shared': array([11.01723805,  0.55746056,  0.55746056, -0.9406981 ,  0.55746056,\n        1.7075232 ])}, {'x_1': array([1.78929737, 0.74015108]), 'x_2': array([0.65100393]), 'x_3': array([0.65100393]), 'x_shared': array([10.75036711,  0.65100393,  0.65100393, -0.91912888,  0.65100393,\n        1.86147795])}, {'x_1': array([1.82775987, 0.83156332]), 'x_2': array([0.70876004]), 'x_3': array([0.70876004]), 'x_shared': array([10.57666774,  0.70876004,  0.70876004, -0.90519019,  0.70876004,\n        1.95651438])}, {'x_1': array([2.14904245, 2.64149302]), 'x_2': array([1.03865101]), 'x_3': array([1.03865101]), 'x_shared': array([ 1.03865101,  1.03865101,  1.03865101, -0.85288882,  1.03865101,\n        2.97117135])}, {'x_1': array([2.14904245, 2.64149302]), 'x_2': array([1.03865101]), 'x_3': array([1.03865101]), 'x_shared': array([ 1.03865101,  1.03865101,  1.03865101, -0.85288882,  1.03865101,\n        2.97117135])}], 'g_2': [{'x_1': array([-1.78397901, -1.78397901]), 'x_2': array([-1.78397901]), 'x_3': array([-1.78397901]), 'x_shared': array([14.06439183, -1.78397901, -1.78397901, -1.78397901, -1.78397901,\n       -1.78397901])}], 'g_3': [{'x_1': array([0.37344871, 0.37341757]), 'x_2': array([0.37074072]), 'x_3': array([0.27642849]), 'x_shared': array([0.43630772, 0.27560326, 0.49427916, 0.37346968, 0.40593032,\n       0.38001693])}, {'x_1': array([0.37344871, 0.37341757]), 'x_2': array([0.37074072]), 'x_3': array([0.27642849]), 'x_shared': array([0.43630772, 0.27560326, 0.49427916, 0.37346968, 0.40593032,\n       0.38001693])}, {'x_1': array([0.15567479, 0.15567479]), 'x_2': array([0.15567479]), 'x_3': array([0.02790736]), 'x_shared': array([0.15567479, 0.22115212, 0.35393535, 0.15567479, 0.15567479,\n       0.15567479])}, {'x_1': array([-0.2723266, -0.2723266]), 'x_2': array([-0.2723266]), 'x_3': array([-0.2723266]), 'x_shared': array([-0.2723266 , -0.2723266 ,  0.36138885, -0.2723266 , -0.2723266 ,\n       -0.2723266 ])}], 'y_1': [{'x_1': array([1.39702353, 1.76018349]), 'x_2': array([1.38644256]), 'x_3': array([1.29818395]), 'x_shared': array([1.88540622, 0.99931364, 1.11362056, 1.33119317, 2.13959142,\n       1.25530515])}, {'x_1': array([-0.32221698, -0.32221698]), 'x_2': array([-0.32221698]), 'x_3': array([-0.32221698]), 'x_shared': array([ 1.02765459, -0.32221698, -0.32221698,  0.29295912, -0.32221698,\n        1.48147708])}, {'x_1': array([2.14904245, 2.64149302]), 'x_2': array([1.03865101]), 'x_3': array([1.03865101]), 'x_shared': array([ 1.03865101,  1.03865101,  1.03865101, -0.85288882,  1.03865101,\n        2.97117135])}], 'y_11': [{'x_1': array([-0.52854927,  0.20318673]), 'x_2': array([-0.54405623]), 'x_3': array([-0.44134379]), 'x_shared': array([-0.63777874, -0.32103453, -1.00368703, -0.30372194,  0.4909991 ,\n        0.34072198])}], 'y_12': [{'x_1': array([1.39702314, 1.76018276]), 'x_2': array([1.38644216]), 'x_3': array([1.29818343]), 'x_shared': array([1.88540552, 0.99931347, 1.1136214 , 1.33119262, 2.13959019,\n       1.25530468])}, {'x_1': array([2.14904245, 2.64149302]), 'x_2': array([1.03865101]), 'x_3': array([1.03865101]), 'x_shared': array([ 1.03865101,  1.03865101,  1.03865101, -0.85288882,  1.03865101,\n        2.97117135])}], 'y_14': [{'x_1': array([1.39702353, 1.76018349]), 'x_2': array([1.38644256]), 'x_3': array([1.29818395]), 'x_shared': array([1.88540622, 0.99931364, 1.11362056, 1.33119317, 2.13959142,\n       1.25530515])}, {'x_1': array([-0.32221698, -0.32221698]), 'x_2': array([-0.32221698]), 'x_3': array([-0.32221698]), 'x_shared': array([ 1.02765459, -0.32221698, -0.32221698,  0.29295912, -0.32221698,\n        1.48147708])}], 'y_2': [{'x_1': array([1.39702465, 1.76018186]), 'x_2': array([1.38644371]), 'x_3': array([1.29818413]), 'x_shared': array([1.88540918, 0.99931423, 1.11362534, 1.33119393, 2.13959124,\n       1.25530753])}, {'x_1': array([0.33948382, 0.33943319]), 'x_2': array([0.33649526]), 'x_3': array([0.33844346]), 'x_shared': array([0.41305532, 0.21372957, 0.46903264, 0.33950848, 0.38374435,\n       0.34981841])}, {'x_1': array([-0.00570706,  0.11370291]), 'x_2': array([-0.00932687]), 'x_3': array([0.03728126]), 'x_shared': array([-0.00510218, -0.02725309,  0.55710848, -0.01538353, -0.06301047,\n        0.01880841])}], 'y_21': [{'x_1': array([1.39702333, 1.76018278]), 'x_2': array([1.38644237]), 'x_3': array([1.29818298]), 'x_shared': array([1.88540617, 0.99931373, 1.11362084, 1.33119278, 2.13959071,\n       1.25530467])}], 'y_23': [{'x_1': array([0.33948376, 0.33943313]), 'x_2': array([0.3364952]), 'x_3': array([0.33844339]), 'x_shared': array([0.41305526, 0.21372952, 0.46903265, 0.33950842, 0.38374428,\n       0.34981835])}], 'y_24': [{'x_1': array([-0.00570706,  0.11370291]), 'x_2': array([-0.00932687]), 'x_3': array([0.03728126]), 'x_shared': array([-0.00510218, -0.02725309,  0.55710848, -0.01538353, -0.06301047,\n        0.01880841])}], 'y_3': [{'x_1': array([0.00932773, 0.00932773]), 'x_2': array([0.00932773]), 'x_3': array([-0.00610765]), 'x_shared': array([0.00932773, 0.03243592, 0.42907723, 0.00932773, 0.00932773,\n       0.00932773])}, {'x_1': array([0.37078896, 0.37076038]), 'x_2': array([0.36813537]), 'x_3': array([0.27521916]), 'x_shared': array([0.43259872, 0.27308948, 0.48715849, 0.37080979, 0.40323311,\n       0.37725532])}, {'x_1': array([0.37344871, 0.37341757]), 'x_2': array([0.37074072]), 'x_3': array([0.27642849]), 'x_shared': array([0.43630772, 0.27560326, 0.49427916, 0.37346968, 0.40593032,\n       0.38001693])}], 'y_31': [{'x_1': array([0.37078884, 0.37076029]), 'x_2': array([0.36813524]), 'x_3': array([0.27521904]), 'x_shared': array([0.43259862, 0.27308959, 0.48715826, 0.37080967, 0.40323297,\n       0.37725517])}], 'y_32': [{'x_1': array([0.37344859, 0.37341748]), 'x_2': array([0.37074059]), 'x_3': array([0.27642836]), 'x_shared': array([0.43630761, 0.27560337, 0.49427892, 0.37346957, 0.40593018,\n       0.38001678])}], 'y_34': [{'x_1': array([0.00932773, 0.00932773]), 'x_2': array([0.00932773]), 'x_3': array([-0.00610765]), 'x_shared': array([0.00932773, 0.03243592, 0.42907723, 0.00932773, 0.00932773,\n       0.00932773])}], 'y_4': [{'x_1': array([0.13474852, 0.1319534 ]), 'x_2': array([0.12802605]), 'x_3': array([0.12367808]), 'x_shared': array([0.07868628, 0.27624258, 0.37441688, 0.1713607 , 0.19931265,\n       0.16968431])}]}, 'second': {'g_1': [{'x_1': {'x_1': array([[ 0.        , -1.33012176],\n       [-1.33012176,  0.        ]]), 'x_2': array([[-1.22440811],\n       [-0.26814783]]), 'x_3': array([[-1.22440811],\n       [-0.26814783]]), 'x_shared': array([[-2.49473229, -1.22440811, -1.22440811, -1.12140412, -1.22440811,\n        -1.30955348],\n       [ 1.2598181 , -0.26814783, -0.26814783, -0.27935095, -0.26814783,\n        -0.34571335]])}, 'x_2': {'x_1': array([[-1.22440811, -0.26814783]]), 'x_2': array([[0.]]), 'x_3': array([[-0.05476005]]), 'x_shared': array([[-0.05476005, -0.05476005, -0.05476005, -0.05476005, -0.05476005,\n        -0.05476005]])}, 'x_3': {'x_1': array([[-1.22440811, -0.26814783]]), 'x_2': array([[-0.05476005]]), 'x_3': array([[0.]]), 'x_shared': array([[-0.05476005, -0.05476005, -0.05476005, -0.05476005, -0.05476005,\n        -0.05476005]])}, 'x_shared': {'x_1': array([[-2.49473229,  1.2598181 ],\n       [-1.22440811, -0.26814783],\n       [-1.22440811, -0.26814783],\n       [-1.12140412, -0.27935095],\n       [-1.22440811, -0.26814783],\n       [-1.30955348, -0.34571335]]), 'x_2': array([[-0.05476005],\n       [-0.05476005],\n       [-0.05476005],\n       [-0.05476005],\n       [-0.05476005],\n       [-0.05476005]]), 'x_3': array([[-0.05476005],\n       [-0.05476005],\n       [-0.05476005],\n       [-0.05476005],\n       [-0.05476005],\n       [-0.05476005]]), 'x_shared': array([[ 0.        , -9.43181956, -9.43181956, -8.71601145, -9.43181956,\n        -9.76851244],\n       [-9.43181956,  0.        , -0.05476005, -0.05476005, -0.05476005,\n        -0.05476005],\n       [-9.43181956, -0.05476005,  0.        , -0.05476005, -0.05476005,\n        -0.05476005],\n       [-8.71601145, -0.05476005, -0.05476005,  0.        ,  1.13335547,\n         1.32157824],\n       [-9.43181956, -0.05476005, -0.05476005,  1.13335547,  0.        ,\n        -0.05476005],\n       [-9.76851244, -0.05476005, -0.05476005,  1.32157824, -0.05476005,\n         0.        ]])}}, {'x_1': {'x_1': array([[ 0.      , -2.030818],\n       [-2.030818,  0.      ]]), 'x_2': array([[-1.92566953],\n       [-1.2777357 ]]), 'x_3': array([[-1.92566953],\n       [-1.2777357 ]]), 'x_shared': array([[-3.02868555, -1.92566953, -1.92566953, -1.79228949, -1.92566953,\n        -2.03486034],\n       [ 0.50399995, -1.2777357 , -1.2777357 , -1.25560654, -1.2777357 ,\n        -1.4343896 ]])}, 'x_2': {'x_1': array([[-1.92566953, -1.2777357 ]]), 'x_2': array([[0.]]), 'x_3': array([[-0.78291844]]), 'x_shared': array([[-0.78291844, -0.78291844, -0.78291844, -0.78291844, -0.78291844,\n        -0.78291844]])}, 'x_3': {'x_1': array([[-1.92566953, -1.2777357 ]]), 'x_2': array([[-0.78291844]]), 'x_3': array([[0.]]), 'x_shared': array([[-0.78291844, -0.78291844, -0.78291844, -0.78291844, -0.78291844,\n        -0.78291844]])}, 'x_shared': {'x_1': array([[-3.02868555,  0.50399995],\n       [-1.92566953, -1.2777357 ],\n       [-1.92566953, -1.2777357 ],\n       [-1.79228949, -1.25560654],\n       [-1.92566953, -1.2777357 ],\n       [-2.03486034, -1.4343896 ]]), 'x_2': array([[-0.78291844],\n       [-0.78291844],\n       [-0.78291844],\n       [-0.78291844],\n       [-0.78291844],\n       [-0.78291844]]), 'x_3': array([[-0.78291844],\n       [-0.78291844],\n       [-0.78291844],\n       [-0.78291844],\n       [-0.78291844],\n       [-0.78291844]]), 'x_shared': array([[ 0.        , -9.54632805, -9.54632805, -8.66167114, -9.54632805,\n        -9.92137233],\n       [-9.54632805,  0.        , -0.78291844, -0.78291844, -0.78291844,\n        -0.78291844],\n       [-9.54632805, -0.78291844,  0.        , -0.78291844, -0.78291844,\n        -0.78291844],\n       [-8.66167114, -0.78291844, -0.78291844,  0.        ,  0.94844799,\n         1.24591169],\n       [-9.54632805, -0.78291844, -0.78291844,  0.94844799,  0.        ,\n        -0.78291844],\n       [-9.92137233, -0.78291844, -0.78291844,  1.24591169, -0.78291844,\n         0.        ]])}}, {'x_1': {'x_1': array([[ 0.        , -2.29911085],\n       [-2.29911085,  0.        ]]), 'x_2': array([[-2.19538963],\n       [-1.68606696]]), 'x_3': array([[-2.19538963],\n       [-1.68606696]]), 'x_shared': array([[-3.22263164, -2.19538963, -2.19538963, -2.05253321, -2.19538963,\n        -2.31207735],\n       [ 0.17791995, -1.68606696, -1.68606696, -1.64637166, -1.68606696,\n        -1.88088338]])}, 'x_2': {'x_1': array([[-2.19538963, -1.68606696]]), 'x_2': array([[0.]]), 'x_3': array([[-1.07617]]), 'x_shared': array([[-1.07617, -1.07617, -1.07617, -1.07617, -1.07617, -1.07617]])}, 'x_3': {'x_1': array([[-2.19538963, -1.68606696]]), 'x_2': array([[-1.07617]]), 'x_3': array([[0.]]), 'x_shared': array([[-1.07617, -1.07617, -1.07617, -1.07617, -1.07617, -1.07617]])}, 'x_shared': {'x_1': array([[-3.22263164,  0.17791995],\n       [-2.19538963, -1.68606696],\n       [-2.19538963, -1.68606696],\n       [-2.05253321, -1.64637166],\n       [-2.19538963, -1.68606696],\n       [-2.31207735, -1.88088338]]), 'x_2': array([[-1.07617],\n       [-1.07617],\n       [-1.07617],\n       [-1.07617],\n       [-1.07617],\n       [-1.07617]]), 'x_3': array([[-1.07617],\n       [-1.07617],\n       [-1.07617],\n       [-1.07617],\n       [-1.07617],\n       [-1.07617]]), 'x_shared': array([[ 0.        , -9.51390592, -9.51390592, -8.57121163, -9.51390592,\n        -9.90197908],\n       [-9.51390592,  0.        , -1.07617   , -1.07617   , -1.07617   ,\n        -1.07617   ],\n       [-9.51390592, -1.07617   ,  0.        , -1.07617   , -1.07617   ,\n        -1.07617   ],\n       [-8.57121163, -1.07617   , -1.07617   ,  0.        ,  0.86589942,\n         1.2118906 ],\n       [-9.51390592, -1.07617   , -1.07617   ,  0.86589942,  0.        ,\n        -1.07617   ],\n       [-9.90197908, -1.07617   , -1.07617   ,  1.2118906 , -1.07617   ,\n         0.        ]])}}, {'x_1': {'x_1': array([[ 0.        , -2.43806194],\n       [-2.43806194,  0.        ]]), 'x_2': array([[-2.33541269],\n       [-1.90352685]]), 'x_3': array([[-2.33541269],\n       [-1.90352685]]), 'x_shared': array([[-3.32019176e+00, -2.33541269e+00, -2.33541269e+00,\n        -2.18824047e+00, -2.33541269e+00, -2.45551318e+00],\n       [-1.04056535e-03, -1.90352685e+00, -1.90352685e+00,\n        -1.85341379e+00, -1.90352685e+00, -2.12027357e+00]])}, 'x_2': {'x_1': array([[-2.33541269, -1.90352685]]), 'x_2': array([[0.]]), 'x_3': array([[-1.23201689]]), 'x_shared': array([[-1.23201689, -1.23201689, -1.23201689, -1.23201689, -1.23201689,\n        -1.23201689]])}, 'x_3': {'x_1': array([[-2.33541269, -1.90352685]]), 'x_2': array([[-1.23201689]]), 'x_3': array([[0.]]), 'x_shared': array([[-1.23201689, -1.23201689, -1.23201689, -1.23201689, -1.23201689,\n        -1.23201689]])}, 'x_shared': {'x_1': array([[-3.32019176e+00, -1.04056535e-03],\n       [-2.33541269e+00, -1.90352685e+00],\n       [-2.33541269e+00, -1.90352685e+00],\n       [-2.18824047e+00, -1.85341379e+00],\n       [-2.33541269e+00, -1.90352685e+00],\n       [-2.45551318e+00, -2.12027357e+00]]), 'x_2': array([[-1.23201689],\n       [-1.23201689],\n       [-1.23201689],\n       [-1.23201689],\n       [-1.23201689],\n       [-1.23201689]]), 'x_3': array([[-1.23201689],\n       [-1.23201689],\n       [-1.23201689],\n       [-1.23201689],\n       [-1.23201689],\n       [-1.23201689]]), 'x_shared': array([[ 0.        , -9.47615409, -9.47615409, -8.50521945, -9.47615409,\n        -9.87051999],\n       [-9.47615409,  0.        , -1.23201689, -1.23201689, -1.23201689,\n        -1.23201689],\n       [-9.47615409, -1.23201689,  0.        , -1.23201689, -1.23201689,\n        -1.23201689],\n       [-8.50521945, -1.23201689, -1.23201689,  0.        ,  0.81991803,\n         1.19288325],\n       [-9.47615409, -1.23201689, -1.23201689,  0.81991803,  0.        ,\n        -1.23201689],\n       [-9.87051999, -1.23201689, -1.23201689,  1.19288325, -1.23201689,\n         0.        ]])}}, {'x_1': {'x_1': array([[ 0.        , -2.52249492],\n       [-2.52249492,  0.        ]]), 'x_2': array([[-2.4206247 ],\n       [-2.03795999]]), 'x_3': array([[-2.4206247 ],\n       [-2.03795999]]), 'x_shared': array([[-3.37836655, -2.4206247 , -2.4206247 , -2.27105715, -2.4206247 ,\n        -2.54261867],\n       [-0.11365226, -2.03795999, -2.03795999, -1.98101023, -2.03795999,\n        -2.26886332]])}, 'x_2': {'x_1': array([[-2.4206247 , -2.03795999]]), 'x_2': array([[0.]]), 'x_3': array([[-1.32823927]]), 'x_shared': array([[-1.32823927, -1.32823927, -1.32823927, -1.32823927, -1.32823927,\n        -1.32823927]])}, 'x_3': {'x_1': array([[-2.4206247 , -2.03795999]]), 'x_2': array([[-1.32823927]]), 'x_3': array([[0.]]), 'x_shared': array([[-1.32823927, -1.32823927, -1.32823927, -1.32823927, -1.32823927,\n        -1.32823927]])}, 'x_shared': {'x_1': array([[-3.37836655, -0.11365226],\n       [-2.4206247 , -2.03795999],\n       [-2.4206247 , -2.03795999],\n       [-2.27105715, -1.98101023],\n       [-2.4206247 , -2.03795999],\n       [-2.54261867, -2.26886332]]), 'x_2': array([[-1.32823927],\n       [-1.32823927],\n       [-1.32823927],\n       [-1.32823927],\n       [-1.32823927],\n       [-1.32823927]]), 'x_3': array([[-1.32823927],\n       [-1.32823927],\n       [-1.32823927],\n       [-1.32823927],\n       [-1.32823927],\n       [-1.32823927]]), 'x_shared': array([[ 0.        , -9.44517383, -9.44517383, -8.45777635, -9.44517383,\n        -9.84318894],\n       [-9.44517383,  0.        , -1.32823927, -1.32823927, -1.32823927,\n        -1.32823927],\n       [-9.44517383, -1.32823927,  0.        , -1.32823927, -1.32823927,\n        -1.32823927],\n       [-8.45777635, -1.32823927, -1.32823927,  0.        ,  0.79073906,\n         1.18080126],\n       [-9.44517383, -1.32823927, -1.32823927,  0.79073906,  0.        ,\n        -1.32823927],\n       [-9.84318894, -1.32823927, -1.32823927,  1.18080126, -1.32823927,\n         0.        ]])}}, {'x_1': {'x_1': array([[ 0.        , -3.68593707],\n       [-3.68593707,  0.        ]]), 'x_2': array([[-3.46975419],\n       [-2.95554582]]), 'x_3': array([[-3.46975419],\n       [-2.95554582]]), 'x_shared': array([[-3.46975419, -3.46975419, -3.46975419, -2.81081562, -3.46975419,\n        -4.01503385],\n       [-2.95554582, -2.95554582, -2.95554582, -2.78524532, -2.95554582,\n        -3.52865329]])}, 'x_2': {'x_1': array([[-3.46975419, -2.95554582]]), 'x_2': array([[0.]]), 'x_3': array([[-1.88378948]]), 'x_shared': array([[-1.88378948, -1.88378948, -1.88378948, -1.88378948, -1.88378948,\n        -1.88378948]])}, 'x_3': {'x_1': array([[-3.46975419, -2.95554582]]), 'x_2': array([[-1.88378948]]), 'x_3': array([[0.]]), 'x_shared': array([[-1.88378948, -1.88378948, -1.88378948, -1.88378948, -1.88378948,\n        -1.88378948]])}, 'x_shared': {'x_1': array([[-3.46975419, -2.95554582],\n       [-3.46975419, -2.95554582],\n       [-3.46975419, -2.95554582],\n       [-2.81081562, -2.78524532],\n       [-3.46975419, -2.95554582],\n       [-4.01503385, -3.52865329]]), 'x_2': array([[-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948]]), 'x_3': array([[-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948]]), 'x_shared': array([[ 0.        , -1.88378948, -1.88378948, -1.88378948, -1.88378948,\n        -1.88378948],\n       [-1.88378948,  0.        , -1.88378948, -1.88378948, -1.88378948,\n        -1.88378948],\n       [-1.88378948, -1.88378948,  0.        , -1.88378948, -1.88378948,\n        -1.88378948],\n       [-1.88378948, -1.88378948, -1.88378948,  0.        ,  1.53465731,\n         3.27890399],\n       [-1.88378948, -1.88378948, -1.88378948,  1.53465731,  0.        ,\n        -1.88378948],\n       [-1.88378948, -1.88378948, -1.88378948,  3.27890399, -1.88378948,\n         0.        ]])}}, {'x_1': {'x_1': array([[ 0.        , -3.68593707],\n       [-3.68593707,  0.        ]]), 'x_2': array([[-3.46975419],\n       [-2.95554582]]), 'x_3': array([[-3.46975419],\n       [-2.95554582]]), 'x_shared': array([[-3.46975419, -3.46975419, -3.46975419, -2.81081562, -3.46975419,\n        -4.01503385],\n       [-2.95554582, -2.95554582, -2.95554582, -2.78524532, -2.95554582,\n        -3.52865329]])}, 'x_2': {'x_1': array([[-3.46975419, -2.95554582]]), 'x_2': array([[0.]]), 'x_3': array([[-1.88378948]]), 'x_shared': array([[-1.88378948, -1.88378948, -1.88378948, -1.88378948, -1.88378948,\n        -1.88378948]])}, 'x_3': {'x_1': array([[-3.46975419, -2.95554582]]), 'x_2': array([[-1.88378948]]), 'x_3': array([[0.]]), 'x_shared': array([[-1.88378948, -1.88378948, -1.88378948, -1.88378948, -1.88378948,\n        -1.88378948]])}, 'x_shared': {'x_1': array([[-3.46975419, -2.95554582],\n       [-3.46975419, -2.95554582],\n       [-3.46975419, -2.95554582],\n       [-2.81081562, -2.78524532],\n       [-3.46975419, -2.95554582],\n       [-4.01503385, -3.52865329]]), 'x_2': array([[-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948]]), 'x_3': array([[-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948]]), 'x_shared': array([[ 0.        , -1.88378948, -1.88378948, -1.88378948, -1.88378948,\n        -1.88378948],\n       [-1.88378948,  0.        , -1.88378948, -1.88378948, -1.88378948,\n        -1.88378948],\n       [-1.88378948, -1.88378948,  0.        , -1.88378948, -1.88378948,\n        -1.88378948],\n       [-1.88378948, -1.88378948, -1.88378948,  0.        ,  1.53465731,\n         3.27890399],\n       [-1.88378948, -1.88378948, -1.88378948,  1.53465731,  0.        ,\n        -1.88378948],\n       [-1.88378948, -1.88378948, -1.88378948,  3.27890399, -1.88378948,\n         0.        ]])}}], 'g_2': [{'x_1': {'x_1': array([[0.        , 2.67431043],\n       [2.67431043, 0.        ]]), 'x_2': array([[2.67431043],\n       [2.67431043]]), 'x_3': array([[2.67431043],\n       [2.67431043]]), 'x_shared': array([[2.67431043, 2.67431043, 2.67431043, 2.67431043, 2.67431043,\n        2.67431043],\n       [2.67431043, 2.67431043, 2.67431043, 2.67431043, 2.67431043,\n        2.67431043]])}, 'x_2': {'x_1': array([[2.67431043, 2.67431043]]), 'x_2': array([[0.]]), 'x_3': array([[2.67431043]]), 'x_shared': array([[2.67431043, 2.67431043, 2.67431043, 2.67431043, 2.67431043,\n        2.67431043]])}, 'x_3': {'x_1': array([[2.67431043, 2.67431043]]), 'x_2': array([[2.67431043]]), 'x_3': array([[0.]]), 'x_shared': array([[2.67431043, 2.67431043, 2.67431043, 2.67431043, 2.67431043,\n        2.67431043]])}, 'x_shared': {'x_1': array([[2.67431043, 2.67431043],\n       [2.67431043, 2.67431043],\n       [2.67431043, 2.67431043],\n       [2.67431043, 2.67431043],\n       [2.67431043, 2.67431043],\n       [2.67431043, 2.67431043]]), 'x_2': array([[2.67431043],\n       [2.67431043],\n       [2.67431043],\n       [2.67431043],\n       [2.67431043],\n       [2.67431043]]), 'x_3': array([[2.67431043],\n       [2.67431043],\n       [2.67431043],\n       [2.67431043],\n       [2.67431043],\n       [2.67431043]]), 'x_shared': array([[ 0.        , -6.21198826, -6.21198826, -6.21198826, -6.21198826,\n        -6.21198826],\n       [-6.21198826,  0.        ,  2.67431043,  2.67431043,  2.67431043,\n         2.67431043],\n       [-6.21198826,  2.67431043,  0.        ,  2.67431043,  2.67431043,\n         2.67431043],\n       [-6.21198826,  2.67431043,  2.67431043,  0.        ,  2.67431043,\n         2.67431043],\n       [-6.21198826,  2.67431043,  2.67431043,  2.67431043,  0.        ,\n         2.67431043],\n       [-6.21198826,  2.67431043,  2.67431043,  2.67431043,  2.67431043,\n         0.        ]])}}], 'g_3': [{'x_1': {'x_1': array([[ 0.        , -0.65446902],\n       [-0.65446902,  0.        ]]), 'x_2': array([[-0.65446943],\n       [-0.6547183 ]]), 'x_3': array([[-0.65447059],\n       [-0.65476368]]), 'x_shared': array([[-0.65446376, -0.65447716, -0.65448766, -0.65446903, -0.65445145,\n        -0.65447479],\n       [-0.65468846, -0.65463623, -0.65450767, -0.6547172 , -0.65475441,\n        -0.65469715]])}, 'x_2': {'x_1': array([[-0.65446943, -0.6547183 ]]), 'x_2': array([[0.]]), 'x_3': array([[-0.65513895]]), 'x_shared': array([[-0.65364071, -0.64957331, -0.65361609, -0.65478425, -0.65281373,\n        -0.65682092]])}, 'x_3': {'x_1': array([[-0.65447059, -0.65476368]]), 'x_2': array([[-0.65513895]]), 'x_3': array([[0.]]), 'x_shared': array([[-0.49581736, -0.52825994, -0.44619693, -0.50999028, -0.51956593,\n        -0.49936174]])}, 'x_shared': {'x_1': array([[-0.65446376, -0.65468846],\n       [-0.65447716, -0.65463623],\n       [-0.65448766, -0.65450767],\n       [-0.65446903, -0.6547172 ],\n       [-0.65445145, -0.65475441],\n       [-0.65447479, -0.65469715]]), 'x_2': array([[-0.65364071],\n       [-0.64957331],\n       [-0.65361609],\n       [-0.65478425],\n       [-0.65281373],\n       [-0.65682092]]), 'x_3': array([[-0.49581736],\n       [-0.52825994],\n       [-0.44619693],\n       [-0.50999028],\n       [-0.51956593],\n       [-0.49936174]]), 'x_shared': array([[ 0.        , -0.73961172, -0.76367661, -0.74081926, -0.75542268,\n        -0.73782941],\n       [-0.73961172,  0.        , -0.21718601, -0.0253624 ,  0.02780088,\n         0.0503513 ],\n       [-0.76367661, -0.21718601,  0.        , -0.54523945, -0.4011258 ,\n        -0.57220677],\n       [-0.74081926, -0.0253624 , -0.54523945,  0.        , -0.65455737,\n        -0.65456072],\n       [-0.75542268,  0.02780088, -0.4011258 , -0.65455737,  0.        ,\n        -0.78337748],\n       [-0.73782941,  0.0503513 , -0.57220677, -0.65456072, -0.78337748,\n         0.        ]])}}, {'x_1': {'x_1': array([[ 0.        , -0.65446902],\n       [-0.65446902,  0.        ]]), 'x_2': array([[-0.65446943],\n       [-0.6547183 ]]), 'x_3': array([[-0.65447059],\n       [-0.65476368]]), 'x_shared': array([[-0.65446376, -0.65447716, -0.65448766, -0.65446903, -0.65445145,\n        -0.65447479],\n       [-0.65468846, -0.65463623, -0.65450767, -0.6547172 , -0.65475441,\n        -0.65469715]])}, 'x_2': {'x_1': array([[-0.65446943, -0.6547183 ]]), 'x_2': array([[0.]]), 'x_3': array([[-0.65513895]]), 'x_shared': array([[-0.65364071, -0.64957331, -0.65361609, -0.65478425, -0.65281373,\n        -0.65682092]])}, 'x_3': {'x_1': array([[-0.65447059, -0.65476368]]), 'x_2': array([[-0.65513895]]), 'x_3': array([[0.]]), 'x_shared': array([[-0.49581736, -0.52825994, -0.44619693, -0.50999028, -0.51956593,\n        -0.49936174]])}, 'x_shared': {'x_1': array([[-0.65446376, -0.65468846],\n       [-0.65447716, -0.65463623],\n       [-0.65448766, -0.65450767],\n       [-0.65446903, -0.6547172 ],\n       [-0.65445145, -0.65475441],\n       [-0.65447479, -0.65469715]]), 'x_2': array([[-0.65364071],\n       [-0.64957331],\n       [-0.65361609],\n       [-0.65478425],\n       [-0.65281373],\n       [-0.65682092]]), 'x_3': array([[-0.49581736],\n       [-0.52825994],\n       [-0.44619693],\n       [-0.50999028],\n       [-0.51956593],\n       [-0.49936174]]), 'x_shared': array([[ 0.        , -0.73961172, -0.76367661, -0.74081926, -0.75542268,\n        -0.73782941],\n       [-0.73961172,  0.        , -0.21718601, -0.0253624 ,  0.02780088,\n         0.0503513 ],\n       [-0.76367661, -0.21718601,  0.        , -0.54523945, -0.4011258 ,\n        -0.57220677],\n       [-0.74081926, -0.0253624 , -0.54523945,  0.        , -0.65455737,\n        -0.65456072],\n       [-0.75542268,  0.02780088, -0.4011258 , -0.65455737,  0.        ,\n        -0.78337748],\n       [-0.73782941,  0.0503513 , -0.57220677, -0.65456072, -0.78337748,\n         0.        ]])}}, {'x_1': {'x_1': array([[ 0.        , -0.27575023],\n       [-0.27575023,  0.        ]]), 'x_2': array([[-0.27575023],\n       [-0.27575023]]), 'x_3': array([[-0.27575023],\n       [-0.27575023]]), 'x_shared': array([[-0.27575023, -0.27575023, -0.27575023, -0.27575023, -0.27575023,\n        -0.27575023],\n       [-0.27575023, -0.27575023, -0.27575023, -0.27575023, -0.27575023,\n        -0.27575023]])}, 'x_2': {'x_1': array([[-0.27575023, -0.27575023]]), 'x_2': array([[0.]]), 'x_3': array([[-0.27575023]]), 'x_shared': array([[-0.27575023, -0.27575023, -0.27575023, -0.27575023, -0.27575023,\n        -0.27575023]])}, 'x_3': {'x_1': array([[-0.27575023, -0.27575023]]), 'x_2': array([[-0.27575023]]), 'x_3': array([[0.]]), 'x_shared': array([[ 0.01305851, -0.06785798,  0.15128947,  0.01305851,  0.01305851,\n         0.01305851]])}, 'x_shared': {'x_1': array([[-0.27575023, -0.27575023],\n       [-0.27575023, -0.27575023],\n       [-0.27575023, -0.27575023],\n       [-0.27575023, -0.27575023],\n       [-0.27575023, -0.27575023],\n       [-0.27575023, -0.27575023]]), 'x_2': array([[-0.27575023],\n       [-0.27575023],\n       [-0.27575023],\n       [-0.27575023],\n       [-0.27575023],\n       [-0.27575023]]), 'x_3': array([[ 0.01305851],\n       [-0.06785798],\n       [ 0.15128947],\n       [ 0.01305851],\n       [ 0.01305851],\n       [ 0.01305851]]), 'x_shared': array([[ 0.        , -0.27575023, -0.27575023, -0.27575023, -0.27575023,\n        -0.27575023],\n       [-0.27575023,  0.        ,  0.09096629,  0.24281157,  0.24281157,\n         0.24281157],\n       [-0.27575023,  0.09096629,  0.        , -0.35422855, -0.35422855,\n        -0.35422855],\n       [-0.27575023,  0.24281157, -0.35422855,  0.        , -0.27575023,\n        -0.27575023],\n       [-0.27575023,  0.24281157, -0.35422855, -0.27575023,  0.        ,\n        -0.27575023],\n       [-0.27575023,  0.24281157, -0.35422855, -0.27575023, -0.27575023,\n         0.        ]])}}, {'x_1': {'x_1': array([[0.        , 0.47537351],\n       [0.47537351, 0.        ]]), 'x_2': array([[0.47537351],\n       [0.47537351]]), 'x_3': array([[0.47537351],\n       [0.47537351]]), 'x_shared': array([[0.47537351, 0.47537351, 0.47537351, 0.47537351, 0.47537351,\n        0.47537351],\n       [0.47537351, 0.47537351, 0.47537351, 0.47537351, 0.47537351,\n        0.47537351]])}, 'x_2': {'x_1': array([[0.47537351, 0.47537351]]), 'x_2': array([[0.]]), 'x_3': array([[0.47537351]]), 'x_shared': array([[0.47537351, 0.47537351, 0.47537351, 0.47537351, 0.47537351,\n        0.47537351]])}, 'x_3': {'x_1': array([[0.47537351, 0.47537351]]), 'x_2': array([[0.47537351]]), 'x_3': array([[0.]]), 'x_shared': array([[0.47537351, 0.47537351, 0.47537351, 0.47537351, 0.47537351,\n        0.47537351]])}, 'x_shared': {'x_1': array([[0.47537351, 0.47537351],\n       [0.47537351, 0.47537351],\n       [0.47537351, 0.47537351],\n       [0.47537351, 0.47537351],\n       [0.47537351, 0.47537351],\n       [0.47537351, 0.47537351]]), 'x_2': array([[0.47537351],\n       [0.47537351],\n       [0.47537351],\n       [0.47537351],\n       [0.47537351],\n       [0.47537351]]), 'x_3': array([[0.47537351],\n       [0.47537351],\n       [0.47537351],\n       [0.47537351],\n       [0.47537351],\n       [0.47537351]]), 'x_shared': array([[0.        , 0.47537351, 0.47537351, 0.47537351, 0.47537351,\n        0.47537351],\n       [0.47537351, 0.        , 0.47537351, 0.47537351, 0.47537351,\n        0.47537351],\n       [0.47537351, 0.47537351, 0.        , 1.12516626, 1.12516626,\n        1.12516626],\n       [0.47537351, 0.47537351, 1.12516626, 0.        , 0.47537351,\n        0.47537351],\n       [0.47537351, 0.47537351, 1.12516626, 0.47537351, 0.        ,\n        0.47537351],\n       [0.47537351, 0.47537351, 1.12516626, 0.47537351, 0.47537351,\n        0.        ]])}}], 'y_1': [{'x_1': {'x_1': array([[ 0.        , -2.44485206],\n       [-2.44485206,  0.        ]]), 'x_2': array([[-2.44403837],\n       [-3.08539846]]), 'x_3': array([[-2.44396447],\n       [-3.15829293]]), 'x_shared': array([[-2.44622939, -2.44366676, -2.44261205, -2.44315753, -2.44861371,\n        -2.44241401],\n       [-2.86119783, -3.0023551 , -2.78685663, -3.0686886 , -3.21566848,\n        -2.94808776]])}, 'x_2': {'x_1': array([[-2.44403837, -3.08539846]]), 'x_2': array([[0.]]), 'x_3': array([[-2.42929176]]), 'x_shared': array([[-2.42514464, -2.4248769 , -2.42796133, -2.43158878, -2.42449199,\n        -2.43383968]])}, 'x_3': {'x_1': array([[-2.44396447, -3.15829293]]), 'x_2': array([[-2.42929176]]), 'x_3': array([[0.]]), 'x_shared': array([[-2.22326259, -2.29489256, -2.23230808, -2.27285658, -2.3013594 ,\n        -2.25511469]])}, 'x_shared': {'x_1': array([[-2.44622939, -2.86119783],\n       [-2.44366676, -3.0023551 ],\n       [-2.44261205, -2.78685663],\n       [-2.44315753, -3.0686886 ],\n       [-2.44861371, -3.21566848],\n       [-2.44241401, -2.94808776]]), 'x_2': array([[-2.42514464],\n       [-2.4248769 ],\n       [-2.42796133],\n       [-2.43158878],\n       [-2.42449199],\n       [-2.43383968]]), 'x_3': array([[-2.22326259],\n       [-2.29489256],\n       [-2.23230808],\n       [-2.27285658],\n       [-2.3013594 ],\n       [-2.25511469]]), 'x_shared': array([[ 0.        , -3.1639932 , -3.24177437, -3.1345741 , -3.41658807,\n        -3.13926219],\n       [-3.1639932 ,  0.        , -1.8310945 , -1.58608821, -1.57547378,\n        -1.49682408],\n       [-3.24177437, -1.8310945 ,  0.        , -2.04574626, -1.72270445,\n        -2.09387193],\n       [-3.1345741 , -1.58608821, -2.04574626,  0.        , -2.25573521,\n        -2.51093886],\n       [-3.41658807, -1.57547378, -1.72270445, -2.25573521,  0.        ,\n        -3.33165943],\n       [-3.13926219, -1.49682408, -2.09387193, -2.51093886, -3.33165943,\n         0.        ]])}}, {'x_1': {'x_1': array([[0.        , 0.50460033],\n       [0.50460033, 0.        ]]), 'x_2': array([[0.50460033],\n       [0.50460033]]), 'x_3': array([[0.50460033],\n       [0.50460033]]), 'x_shared': array([[0.50460033, 0.50460033, 0.50460033, 0.50460033, 0.50460033,\n        0.50460033],\n       [0.50460033, 0.50460033, 0.50460033, 0.50460033, 0.50460033,\n        0.50460033]])}, 'x_2': {'x_1': array([[0.50460033, 0.50460033]]), 'x_2': array([[0.]]), 'x_3': array([[0.50460033]]), 'x_shared': array([[0.50460033, 0.50460033, 0.50460033, 0.50460033, 0.50460033,\n        0.50460033]])}, 'x_3': {'x_1': array([[0.50460033, 0.50460033]]), 'x_2': array([[0.50460033]]), 'x_3': array([[0.]]), 'x_shared': array([[0.50460033, 0.50460033, 0.50460033, 0.50460033, 0.50460033,\n        0.50460033]])}, 'x_shared': {'x_1': array([[0.50460033, 0.50460033],\n       [0.50460033, 0.50460033],\n       [0.50460033, 0.50460033],\n       [0.50460033, 0.50460033],\n       [0.50460033, 0.50460033],\n       [0.50460033, 0.50460033]]), 'x_2': array([[0.50460033],\n       [0.50460033],\n       [0.50460033],\n       [0.50460033],\n       [0.50460033],\n       [0.50460033]]), 'x_3': array([[0.50460033],\n       [0.50460033],\n       [0.50460033],\n       [0.50460033],\n       [0.50460033],\n       [0.50460033]]), 'x_shared': array([[ 0.        , -0.91308686, -0.91308686, -0.59789578, -0.91308686,\n        -0.59862833],\n       [-0.91308686,  0.        ,  0.50460033,  0.50460033,  0.50460033,\n         0.50460033],\n       [-0.91308686,  0.50460033,  0.        ,  0.50460033,  0.50460033,\n         0.50460033],\n       [-0.59789578,  0.50460033,  0.50460033,  0.        ,  0.31013608,\n        -0.62288116],\n       [-0.91308686,  0.50460033,  0.50460033,  0.31013608,  0.        ,\n         0.50460033],\n       [-0.59862833,  0.50460033,  0.50460033, -0.62288116,  0.50460033,\n         0.        ]])}}, {'x_1': {'x_1': array([[ 0.        , -3.68593707],\n       [-3.68593707,  0.        ]]), 'x_2': array([[-3.46975419],\n       [-2.95554582]]), 'x_3': array([[-3.46975419],\n       [-2.95554582]]), 'x_shared': array([[-3.46975419, -3.46975419, -3.46975419, -2.81081562, -3.46975419,\n        -4.01503385],\n       [-2.95554582, -2.95554582, -2.95554582, -2.78524532, -2.95554582,\n        -3.52865329]])}, 'x_2': {'x_1': array([[-3.46975419, -2.95554582]]), 'x_2': array([[0.]]), 'x_3': array([[-1.88378948]]), 'x_shared': array([[-1.88378948, -1.88378948, -1.88378948, -1.88378948, -1.88378948,\n        -1.88378948]])}, 'x_3': {'x_1': array([[-3.46975419, -2.95554582]]), 'x_2': array([[-1.88378948]]), 'x_3': array([[0.]]), 'x_shared': array([[-1.88378948, -1.88378948, -1.88378948, -1.88378948, -1.88378948,\n        -1.88378948]])}, 'x_shared': {'x_1': array([[-3.46975419, -2.95554582],\n       [-3.46975419, -2.95554582],\n       [-3.46975419, -2.95554582],\n       [-2.81081562, -2.78524532],\n       [-3.46975419, -2.95554582],\n       [-4.01503385, -3.52865329]]), 'x_2': array([[-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948]]), 'x_3': array([[-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948]]), 'x_shared': array([[ 0.        , -1.88378948, -1.88378948, -1.88378948, -1.88378948,\n        -1.88378948],\n       [-1.88378948,  0.        , -1.88378948, -1.88378948, -1.88378948,\n        -1.88378948],\n       [-1.88378948, -1.88378948,  0.        , -1.88378948, -1.88378948,\n        -1.88378948],\n       [-1.88378948, -1.88378948, -1.88378948,  0.        ,  1.53465731,\n         3.27890399],\n       [-1.88378948, -1.88378948, -1.88378948,  1.53465731,  0.        ,\n        -1.88378948],\n       [-1.88378948, -1.88378948, -1.88378948,  3.27890399, -1.88378948,\n         0.        ]])}}], 'y_11': [{'x_1': {'x_1': array([[0.        , 0.90414932],\n       [0.90414932, 0.        ]]), 'x_2': array([[0.9048442 ],\n       [0.46377239]]), 'x_3': array([[0.90493352],\n       [0.3632703 ]]), 'x_shared': array([[0.9070786 , 0.90521955, 0.90678747, 0.90370272, 0.89734499,\n        0.90167898],\n       [0.26460961, 0.50769643, 0.82943457, 0.44620276, 0.30817316,\n        0.20775518]])}, 'x_2': {'x_1': array([[0.9048442 , 0.46377239]]), 'x_2': array([[0.]]), 'x_3': array([[0.91605243]]), 'x_shared': array([[0.91257625, 0.92046021, 0.91667264, 0.91894718, 0.92488253,\n        0.92378046]])}, 'x_3': {'x_1': array([[0.90493352, 0.3632703 ]]), 'x_2': array([[0.91605243]]), 'x_3': array([[0.]]), 'x_shared': array([[0.88064573, 0.91322027, 0.99587019, 0.92619968, 0.91124811,\n        0.88953539]])}, 'x_shared': {'x_1': array([[0.9070786 , 0.26460961],\n       [0.90521955, 0.50769643],\n       [0.90678747, 0.82943457],\n       [0.90370272, 0.44620276],\n       [0.89734499, 0.30817316],\n       [0.90167898, 0.20775518]]), 'x_2': array([[0.91257625],\n       [0.92046021],\n       [0.91667264],\n       [0.91894718],\n       [0.92488253],\n       [0.92378046]]), 'x_3': array([[0.88064573],\n       [0.91322027],\n       [0.99587019],\n       [0.92619968],\n       [0.91124811],\n       [0.88953539]]), 'x_shared': array([[ 0.        ,  1.20235787,  1.30361727,  1.27606495,  1.51345505,\n         1.27517444],\n       [ 1.20235787,  0.        ,  0.99732531,  1.06298983,  1.24940003,\n         0.90315836],\n       [ 1.30361727,  0.99732531,  0.        ,  1.26940164,  1.67490698,\n         1.39285027],\n       [ 1.27606495,  1.06298983,  1.26940164,  0.        ,  0.6926423 ,\n         0.69100505],\n       [ 1.51345505,  1.24940003,  1.67490698,  0.6926423 ,  0.        ,\n        -0.48609766],\n       [ 1.27517444,  0.90315836,  1.39285027,  0.69100505, -0.48609766,\n         0.        ]])}}], 'y_12': [{'x_1': {'x_1': array([[ 0.        , -2.44485138],\n       [-2.44485138,  0.        ]]), 'x_2': array([[-2.44403769],\n       [-3.08539791]]), 'x_3': array([[-2.44396378],\n       [-3.15829262]]), 'x_shared': array([[-2.4462287 , -2.44366607, -2.44261137, -2.44315684, -2.44861302,\n        -2.44241333],\n       [-2.86119741, -3.0023544 , -2.78685619, -3.06868815, -3.21566799,\n        -2.94808726]])}, 'x_2': {'x_1': array([[-2.44403769, -3.08539791]]), 'x_2': array([[0.]]), 'x_3': array([[-2.42929099]]), 'x_shared': array([[-2.42514383, -2.42487615, -2.42796058, -2.43158803, -2.42449112,\n        -2.43383894]])}, 'x_3': {'x_1': array([[-2.44396378, -3.15829262]]), 'x_2': array([[-2.42929099]]), 'x_3': array([[0.]]), 'x_shared': array([[-2.22326177, -2.29489177, -2.23230718, -2.27285592, -2.30135872,\n        -2.25511399]])}, 'x_shared': {'x_1': array([[-2.4462287 , -2.86119741],\n       [-2.44366607, -3.0023544 ],\n       [-2.44261137, -2.78685619],\n       [-2.44315684, -3.06868815],\n       [-2.44861302, -3.21566799],\n       [-2.44241333, -2.94808726]]), 'x_2': array([[-2.42514383],\n       [-2.42487615],\n       [-2.42796058],\n       [-2.43158803],\n       [-2.42449112],\n       [-2.43383894]]), 'x_3': array([[-2.22326177],\n       [-2.29489177],\n       [-2.23230718],\n       [-2.27285592],\n       [-2.30135872],\n       [-2.25511399]]), 'x_shared': array([[ 0.        , -3.16399229, -3.24177366, -3.13457308, -3.41658731,\n        -3.13926113],\n       [-3.16399229,  0.        , -1.83109358, -1.58608766, -1.57547338,\n        -1.4968239 ],\n       [-3.24177366, -1.83109358,  0.        , -2.04574694, -1.72270702,\n        -2.0938726 ],\n       [-3.13457308, -1.58608766, -2.04574694,  0.        , -2.25573494,\n        -2.51093824],\n       [-3.41658731, -1.57547338, -1.72270702, -2.25573494,  0.        ,\n        -3.33165784],\n       [-3.13926113, -1.4968239 , -2.0938726 , -2.51093824, -3.33165784,\n         0.        ]])}}, {'x_1': {'x_1': array([[ 0.        , -3.68593707],\n       [-3.68593707,  0.        ]]), 'x_2': array([[-3.46975419],\n       [-2.95554582]]), 'x_3': array([[-3.46975419],\n       [-2.95554582]]), 'x_shared': array([[-3.46975419, -3.46975419, -3.46975419, -2.81081562, -3.46975419,\n        -4.01503385],\n       [-2.95554582, -2.95554582, -2.95554582, -2.78524532, -2.95554582,\n        -3.52865329]])}, 'x_2': {'x_1': array([[-3.46975419, -2.95554582]]), 'x_2': array([[0.]]), 'x_3': array([[-1.88378948]]), 'x_shared': array([[-1.88378948, -1.88378948, -1.88378948, -1.88378948, -1.88378948,\n        -1.88378948]])}, 'x_3': {'x_1': array([[-3.46975419, -2.95554582]]), 'x_2': array([[-1.88378948]]), 'x_3': array([[0.]]), 'x_shared': array([[-1.88378948, -1.88378948, -1.88378948, -1.88378948, -1.88378948,\n        -1.88378948]])}, 'x_shared': {'x_1': array([[-3.46975419, -2.95554582],\n       [-3.46975419, -2.95554582],\n       [-3.46975419, -2.95554582],\n       [-2.81081562, -2.78524532],\n       [-3.46975419, -2.95554582],\n       [-4.01503385, -3.52865329]]), 'x_2': array([[-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948]]), 'x_3': array([[-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948]]), 'x_shared': array([[ 0.        , -1.88378948, -1.88378948, -1.88378948, -1.88378948,\n        -1.88378948],\n       [-1.88378948,  0.        , -1.88378948, -1.88378948, -1.88378948,\n        -1.88378948],\n       [-1.88378948, -1.88378948,  0.        , -1.88378948, -1.88378948,\n        -1.88378948],\n       [-1.88378948, -1.88378948, -1.88378948,  0.        ,  1.53465731,\n         3.27890399],\n       [-1.88378948, -1.88378948, -1.88378948,  1.53465731,  0.        ,\n        -1.88378948],\n       [-1.88378948, -1.88378948, -1.88378948,  3.27890399, -1.88378948,\n         0.        ]])}}], 'y_14': [{'x_1': {'x_1': array([[ 0.        , -2.44485206],\n       [-2.44485206,  0.        ]]), 'x_2': array([[-2.44403837],\n       [-3.08539846]]), 'x_3': array([[-2.44396447],\n       [-3.15829293]]), 'x_shared': array([[-2.44622939, -2.44366676, -2.44261205, -2.44315753, -2.44861371,\n        -2.44241401],\n       [-2.86119783, -3.0023551 , -2.78685663, -3.0686886 , -3.21566848,\n        -2.94808776]])}, 'x_2': {'x_1': array([[-2.44403837, -3.08539846]]), 'x_2': array([[0.]]), 'x_3': array([[-2.42929176]]), 'x_shared': array([[-2.42514464, -2.4248769 , -2.42796133, -2.43158878, -2.42449199,\n        -2.43383968]])}, 'x_3': {'x_1': array([[-2.44396447, -3.15829293]]), 'x_2': array([[-2.42929176]]), 'x_3': array([[0.]]), 'x_shared': array([[-2.22326259, -2.29489256, -2.23230808, -2.27285658, -2.3013594 ,\n        -2.25511469]])}, 'x_shared': {'x_1': array([[-2.44622939, -2.86119783],\n       [-2.44366676, -3.0023551 ],\n       [-2.44261205, -2.78685663],\n       [-2.44315753, -3.0686886 ],\n       [-2.44861371, -3.21566848],\n       [-2.44241401, -2.94808776]]), 'x_2': array([[-2.42514464],\n       [-2.4248769 ],\n       [-2.42796133],\n       [-2.43158878],\n       [-2.42449199],\n       [-2.43383968]]), 'x_3': array([[-2.22326259],\n       [-2.29489256],\n       [-2.23230808],\n       [-2.27285658],\n       [-2.3013594 ],\n       [-2.25511469]]), 'x_shared': array([[ 0.        , -3.1639932 , -3.24177437, -3.1345741 , -3.41658807,\n        -3.13926219],\n       [-3.1639932 ,  0.        , -1.8310945 , -1.58608821, -1.57547378,\n        -1.49682408],\n       [-3.24177437, -1.8310945 ,  0.        , -2.04574626, -1.72270445,\n        -2.09387193],\n       [-3.1345741 , -1.58608821, -2.04574626,  0.        , -2.25573521,\n        -2.51093886],\n       [-3.41658807, -1.57547378, -1.72270445, -2.25573521,  0.        ,\n        -3.33165943],\n       [-3.13926219, -1.49682408, -2.09387193, -2.51093886, -3.33165943,\n         0.        ]])}}, {'x_1': {'x_1': array([[0.        , 0.50460033],\n       [0.50460033, 0.        ]]), 'x_2': array([[0.50460033],\n       [0.50460033]]), 'x_3': array([[0.50460033],\n       [0.50460033]]), 'x_shared': array([[0.50460033, 0.50460033, 0.50460033, 0.50460033, 0.50460033,\n        0.50460033],\n       [0.50460033, 0.50460033, 0.50460033, 0.50460033, 0.50460033,\n        0.50460033]])}, 'x_2': {'x_1': array([[0.50460033, 0.50460033]]), 'x_2': array([[0.]]), 'x_3': array([[0.50460033]]), 'x_shared': array([[0.50460033, 0.50460033, 0.50460033, 0.50460033, 0.50460033,\n        0.50460033]])}, 'x_3': {'x_1': array([[0.50460033, 0.50460033]]), 'x_2': array([[0.50460033]]), 'x_3': array([[0.]]), 'x_shared': array([[0.50460033, 0.50460033, 0.50460033, 0.50460033, 0.50460033,\n        0.50460033]])}, 'x_shared': {'x_1': array([[0.50460033, 0.50460033],\n       [0.50460033, 0.50460033],\n       [0.50460033, 0.50460033],\n       [0.50460033, 0.50460033],\n       [0.50460033, 0.50460033],\n       [0.50460033, 0.50460033]]), 'x_2': array([[0.50460033],\n       [0.50460033],\n       [0.50460033],\n       [0.50460033],\n       [0.50460033],\n       [0.50460033]]), 'x_3': array([[0.50460033],\n       [0.50460033],\n       [0.50460033],\n       [0.50460033],\n       [0.50460033],\n       [0.50460033]]), 'x_shared': array([[ 0.        , -0.91308686, -0.91308686, -0.59789578, -0.91308686,\n        -0.59862833],\n       [-0.91308686,  0.        ,  0.50460033,  0.50460033,  0.50460033,\n         0.50460033],\n       [-0.91308686,  0.50460033,  0.        ,  0.50460033,  0.50460033,\n         0.50460033],\n       [-0.59789578,  0.50460033,  0.50460033,  0.        ,  0.31013608,\n        -0.62288116],\n       [-0.91308686,  0.50460033,  0.50460033,  0.31013608,  0.        ,\n         0.50460033],\n       [-0.59862833,  0.50460033,  0.50460033, -0.62288116,  0.50460033,\n         0.        ]])}}], 'y_2': [{'x_1': {'x_1': array([[ 0.        , -2.44485403],\n       [-2.44485403,  0.        ]]), 'x_2': array([[-2.44404034],\n       [-3.08539828]]), 'x_3': array([[-2.44396644],\n       [-3.15829352]]), 'x_shared': array([[-2.44623135, -2.44366873, -2.44261403, -2.4431595 , -2.44861566,\n        -2.44241599],\n       [-2.86119801, -3.00235583, -2.78685923, -3.06868928, -3.21566773,\n        -2.94808852]])}, 'x_2': {'x_1': array([[-2.44404034, -3.08539828]]), 'x_2': array([[0.]]), 'x_3': array([[-2.42929266]]), 'x_shared': array([[-2.42514449, -2.42487795, -2.42796289, -2.43159011, -2.4244906 ,\n        -2.43384128]])}, 'x_3': {'x_1': array([[-2.44396644, -3.15829352]]), 'x_2': array([[-2.42929266]]), 'x_3': array([[0.]]), 'x_shared': array([[-2.2232616 , -2.29489164, -2.23230806, -2.27285775, -2.30135811,\n        -2.25511652]])}, 'x_shared': {'x_1': array([[-2.44623135, -2.86119801],\n       [-2.44366873, -3.00235583],\n       [-2.44261403, -2.78685923],\n       [-2.4431595 , -3.06868928],\n       [-2.44861566, -3.21566773],\n       [-2.44241599, -2.94808852]]), 'x_2': array([[-2.42514449],\n       [-2.42487795],\n       [-2.42796289],\n       [-2.43159011],\n       [-2.4244906 ],\n       [-2.43384128]]), 'x_3': array([[-2.2232616 ],\n       [-2.29489164],\n       [-2.23230806],\n       [-2.27285775],\n       [-2.30135811],\n       [-2.25511652]]), 'x_shared': array([[ 0.        , -3.16399704, -3.24178025, -3.13457876, -3.41659302,\n        -3.1392678 ],\n       [-3.16399704,  0.        , -1.83110024, -1.58609338, -1.57547896,\n        -1.49683129],\n       [-3.24178025, -1.83110024,  0.        , -2.04575471, -1.72271123,\n        -2.09388363],\n       [-3.13457876, -1.58609338, -2.04575471,  0.        , -2.25573862,\n        -2.51094251],\n       [-3.41659302, -1.57547896, -1.72271123, -2.25573862,  0.        ,\n        -3.33166588],\n       [-3.1392678 , -1.49683129, -2.09388363, -2.51094251, -3.33166588,\n         0.        ]])}}, {'x_1': {'x_1': array([[ 0.        , -0.59639475],\n       [-0.59639475,  0.        ]]), 'x_2': array([[-0.59639517],\n       [-0.59668333]]), 'x_3': array([[-0.59639482],\n       [-0.59668169]]), 'x_shared': array([[-0.59638939, -0.59640338, -0.59641395, -0.59639477, -0.59637678,\n        -0.59640062],\n       [-0.59665062, -0.59659979, -0.59645524, -0.59668216, -0.59672259,\n        -0.59665956]])}, 'x_2': {'x_1': array([[-0.59639517, -0.59668333]]), 'x_2': array([[0.]]), 'x_3': array([[-0.5967372]]), 'x_shared': array([[-0.59557345, -0.59135745, -0.59550886, -0.5967442 , -0.59474013,\n        -0.59883396]])}, 'x_3': {'x_1': array([[-0.59639482, -0.59668169]]), 'x_2': array([[-0.5967372]]), 'x_3': array([[0.]]), 'x_shared': array([[-0.59555047, -0.59397057, -0.59444432, -0.59565703, -0.59600821,\n        -0.59609727]])}, 'x_shared': {'x_1': array([[-0.59638939, -0.59665062],\n       [-0.59640338, -0.59659979],\n       [-0.59641395, -0.59645524],\n       [-0.59639477, -0.59668216],\n       [-0.59637678, -0.59672259],\n       [-0.59640062, -0.59665956]]), 'x_2': array([[-0.59557345],\n       [-0.59135745],\n       [-0.59550886],\n       [-0.5967442 ],\n       [-0.59474013],\n       [-0.59883396]]), 'x_3': array([[-0.59555047],\n       [-0.59397057],\n       [-0.59444432],\n       [-0.59565703],\n       [-0.59600821],\n       [-0.59609727]]), 'x_shared': array([[ 0.        , -0.67987885, -0.70839309, -0.68226503, -0.69665082,\n        -0.67987415],\n       [-0.67987885,  0.        , -0.11655273,  0.07798152,  0.13203774,\n         0.1575433 ],\n       [-0.70839309, -0.11655273,  0.        , -0.39587655, -0.24545434,\n        -0.42665416],\n       [-0.68226503,  0.07798152, -0.39587655,  0.        , -0.59648771,\n        -0.59649148],\n       [-0.69665082,  0.13203774, -0.24545434, -0.59648771,  0.        ,\n        -0.76536888],\n       [-0.67987415,  0.1575433 , -0.42665416, -0.59649148, -0.76536888,\n         0.        ]])}}, {'x_1': {'x_1': array([[0.        , 0.00830483],\n       [0.00830483, 0.        ]]), 'x_2': array([[0.00835221],\n       [0.03064404]]), 'x_3': array([[0.00839738],\n       [0.01713786]]), 'x_shared': array([[ 0.00843468,  0.00823623,  0.00754251,  0.00854558,  0.00901952,\n         0.00819389],\n       [ 0.0309273 ,  0.05231044, -0.16007432,  0.03689827,  0.04683457,\n         0.01248837]])}, 'x_2': {'x_1': array([[0.00835221, 0.03064404]]), 'x_2': array([[0.]]), 'x_3': array([[0.00688567]]), 'x_shared': array([[0.00705944, 0.0128394 , 0.00667395, 0.00817669, 0.00945429,\n        0.00498824]])}, 'x_3': {'x_1': array([[0.00839738, 0.01713786]]), 'x_2': array([[0.00688567]]), 'x_3': array([[0.]]), 'x_shared': array([[-0.03740921, -0.02334002, -0.07776475, -0.03563509, -0.03464889,\n        -0.04125978]])}, 'x_shared': {'x_1': array([[ 0.00843468,  0.0309273 ],\n       [ 0.00823623,  0.05231044],\n       [ 0.00754251, -0.16007432],\n       [ 0.00854558,  0.03689827],\n       [ 0.00901952,  0.04683457],\n       [ 0.00819389,  0.01248837]]), 'x_2': array([[0.00705944],\n       [0.0128394 ],\n       [0.00667395],\n       [0.00817669],\n       [0.00945429],\n       [0.00498824]]), 'x_3': array([[-0.03740921],\n       [-0.02334002],\n       [-0.07776475],\n       [-0.03563509],\n       [-0.03464889],\n       [-0.04125978]]), 'x_shared': array([[ 0.        ,  0.01765645, -0.01113018,  0.01897765,  0.02577819,\n         0.01309297],\n       [ 0.01765645,  0.        ,  0.53426557,  0.585212  ,  0.67270906,\n         0.69904032],\n       [-0.01113018,  0.53426557,  0.        , -0.08595912,  0.06208401,\n        -0.15926893],\n       [ 0.01897765,  0.585212  , -0.08595912,  0.        ,  0.02356047,\n         0.0549929 ],\n       [ 0.02577819,  0.67270906,  0.06208401,  0.02356047,  0.        ,\n        -0.0268143 ],\n       [ 0.01309297,  0.69904032, -0.15926893,  0.0549929 , -0.0268143 ,\n         0.        ]])}}], 'y_21': [{'x_1': {'x_1': array([[ 0.        , -2.44485172],\n       [-2.44485172,  0.        ]]), 'x_2': array([[-2.44403802],\n       [-3.08539752]]), 'x_3': array([[-2.44396412],\n       [-3.1582931 ]]), 'x_shared': array([[-2.44622904, -2.44366641, -2.4426117 , -2.44315718, -2.44861336,\n        -2.44241367],\n       [-2.86119715, -3.00235433, -2.78685605, -3.06868769, -3.21566753,\n        -2.9480869 ]])}, 'x_2': {'x_1': array([[-2.44403802, -3.08539752]]), 'x_2': array([[0.]]), 'x_3': array([[-2.42929133]]), 'x_shared': array([[-2.42514415, -2.42487648, -2.42796093, -2.43158837, -2.42449143,\n        -2.43383928]])}, 'x_3': {'x_1': array([[-2.44396412, -3.1582931 ]]), 'x_2': array([[-2.42929133]]), 'x_3': array([[0.]]), 'x_shared': array([[-2.22326144, -2.29489145, -2.23230692, -2.27285564, -2.30135838,\n        -2.25511371]])}, 'x_shared': {'x_1': array([[-2.44622904, -2.86119715],\n       [-2.44366641, -3.00235433],\n       [-2.4426117 , -2.78685605],\n       [-2.44315718, -3.06868769],\n       [-2.44861336, -3.21566753],\n       [-2.44241367, -2.9480869 ]]), 'x_2': array([[-2.42514415],\n       [-2.42487648],\n       [-2.42796093],\n       [-2.43158837],\n       [-2.42449143],\n       [-2.43383928]]), 'x_3': array([[-2.22326144],\n       [-2.29489145],\n       [-2.23230692],\n       [-2.27285564],\n       [-2.30135838],\n       [-2.25511371]]), 'x_shared': array([[ 0.        , -3.16399448, -3.24177482, -3.13457478, -3.41659233,\n        -3.13926238],\n       [-3.16399448,  0.        , -1.83109458, -1.58608811, -1.57547387,\n        -1.49682434],\n       [-3.24177482, -1.83109458,  0.        , -2.04574667, -1.72270649,\n        -2.09387264],\n       [-3.13457478, -1.58608811, -2.04574667,  0.        , -2.25573512,\n        -2.51093855],\n       [-3.41659233, -1.57547387, -1.72270649, -2.25573512,  0.        ,\n        -3.33165962],\n       [-3.13926238, -1.49682434, -2.09387264, -2.51093855, -3.33165962,\n         0.        ]])}}], 'y_23': [{'x_1': {'x_1': array([[ 0.        , -0.59639465],\n       [-0.59639465,  0.        ]]), 'x_2': array([[-0.59639507],\n       [-0.59668332]]), 'x_3': array([[-0.59639471],\n       [-0.59668168]]), 'x_shared': array([[-0.59638929, -0.59640327, -0.59641384, -0.59639466, -0.59637668,\n        -0.59640052],\n       [-0.59665061, -0.59659974, -0.5964552 , -0.59668215, -0.59672258,\n        -0.59665956]])}, 'x_2': {'x_1': array([[-0.59639507, -0.59668332]]), 'x_2': array([[0.]]), 'x_3': array([[-0.59673709]]), 'x_shared': array([[-0.59557334, -0.59135734, -0.59550875, -0.59674409, -0.59474002,\n        -0.59883385]])}, 'x_3': {'x_1': array([[-0.59639471, -0.59668168]]), 'x_2': array([[-0.59673709]]), 'x_3': array([[0.]]), 'x_shared': array([[-0.5955504 , -0.59397049, -0.59444424, -0.59565696, -0.59600814,\n        -0.59609721]])}, 'x_shared': {'x_1': array([[-0.59638929, -0.59665061],\n       [-0.59640327, -0.59659974],\n       [-0.59641384, -0.5964552 ],\n       [-0.59639466, -0.59668215],\n       [-0.59637668, -0.59672258],\n       [-0.59640052, -0.59665956]]), 'x_2': array([[-0.59557334],\n       [-0.59135734],\n       [-0.59550875],\n       [-0.59674409],\n       [-0.59474002],\n       [-0.59883385]]), 'x_3': array([[-0.5955504 ],\n       [-0.59397049],\n       [-0.59444424],\n       [-0.59565696],\n       [-0.59600814],\n       [-0.59609721]]), 'x_shared': array([[ 0.        , -0.67987874, -0.70839298, -0.68226492, -0.69665071,\n        -0.67987404],\n       [-0.67987874,  0.        , -0.11655262,  0.07798167,  0.13203789,\n         0.15754345],\n       [-0.70839298, -0.11655262,  0.        , -0.39587645, -0.24545424,\n        -0.42665406],\n       [-0.68226492,  0.07798167, -0.39587645,  0.        , -0.59648767,\n        -0.59649143],\n       [-0.69665071,  0.13203789, -0.24545424, -0.59648767,  0.        ,\n        -0.76536872],\n       [-0.67987404,  0.15754345, -0.42665406, -0.59649143, -0.76536872,\n         0.        ]])}}], 'y_24': [{'x_1': {'x_1': array([[0.        , 0.00830483],\n       [0.00830483, 0.        ]]), 'x_2': array([[0.00835221],\n       [0.03064404]]), 'x_3': array([[0.00839738],\n       [0.01713786]]), 'x_shared': array([[ 0.00843468,  0.00823623,  0.00754251,  0.00854558,  0.00901952,\n         0.00819389],\n       [ 0.0309273 ,  0.05231044, -0.16007432,  0.03689827,  0.04683457,\n         0.01248837]])}, 'x_2': {'x_1': array([[0.00835221, 0.03064404]]), 'x_2': array([[0.]]), 'x_3': array([[0.00688567]]), 'x_shared': array([[0.00705944, 0.0128394 , 0.00667395, 0.00817669, 0.00945429,\n        0.00498824]])}, 'x_3': {'x_1': array([[0.00839738, 0.01713786]]), 'x_2': array([[0.00688567]]), 'x_3': array([[0.]]), 'x_shared': array([[-0.03740921, -0.02334002, -0.07776475, -0.03563509, -0.03464889,\n        -0.04125978]])}, 'x_shared': {'x_1': array([[ 0.00843468,  0.0309273 ],\n       [ 0.00823623,  0.05231044],\n       [ 0.00754251, -0.16007432],\n       [ 0.00854558,  0.03689827],\n       [ 0.00901952,  0.04683457],\n       [ 0.00819389,  0.01248837]]), 'x_2': array([[0.00705944],\n       [0.0128394 ],\n       [0.00667395],\n       [0.00817669],\n       [0.00945429],\n       [0.00498824]]), 'x_3': array([[-0.03740921],\n       [-0.02334002],\n       [-0.07776475],\n       [-0.03563509],\n       [-0.03464889],\n       [-0.04125978]]), 'x_shared': array([[ 0.        ,  0.01765645, -0.01113018,  0.01897765,  0.02577819,\n         0.01309297],\n       [ 0.01765645,  0.        ,  0.53426557,  0.585212  ,  0.67270906,\n         0.69904032],\n       [-0.01113018,  0.53426557,  0.        , -0.08595912,  0.06208401,\n        -0.15926893],\n       [ 0.01897765,  0.585212  , -0.08595912,  0.        ,  0.02356047,\n         0.0549929 ],\n       [ 0.02577819,  0.67270906,  0.06208401,  0.02356047,  0.        ,\n        -0.0268143 ],\n       [ 0.01309297,  0.69904032, -0.15926893,  0.0549929 , -0.0268143 ,\n         0.        ]])}}], 'y_3': [{'x_1': {'x_1': array([[ 0.        , -0.01704647],\n       [-0.01704647,  0.        ]]), 'x_2': array([[-0.01704647],\n       [-0.01704647]]), 'x_3': array([[-0.01704647],\n       [-0.01704647]]), 'x_shared': array([[-0.01704647, -0.01704647, -0.01704647, -0.01704647, -0.01704647,\n        -0.01704647],\n       [-0.01704647, -0.01704647, -0.01704647, -0.01704647, -0.01704647,\n        -0.01704647]])}, 'x_2': {'x_1': array([[-0.01704647, -0.01704647]]), 'x_2': array([[0.]]), 'x_3': array([[-0.01704647]]), 'x_shared': array([[-0.01704647, -0.01704647, -0.01704647, -0.01704647, -0.01704647,\n        -0.01704647]])}, 'x_3': {'x_1': array([[-0.01704647, -0.01704647]]), 'x_2': array([[-0.01704647]]), 'x_3': array([[0.]]), 'x_shared': array([[-0.0015891 , -0.00386702,  0.01505761, -0.0015891 , -0.0015891 ,\n        -0.0015891 ]])}, 'x_shared': {'x_1': array([[-0.01704647, -0.01704647],\n       [-0.01704647, -0.01704647],\n       [-0.01704647, -0.01704647],\n       [-0.01704647, -0.01704647],\n       [-0.01704647, -0.01704647],\n       [-0.01704647, -0.01704647]]), 'x_2': array([[-0.01704647],\n       [-0.01704647],\n       [-0.01704647],\n       [-0.01704647],\n       [-0.01704647],\n       [-0.01704647]]), 'x_3': array([[-0.0015891 ],\n       [-0.00386702],\n       [ 0.01505761],\n       [-0.0015891 ],\n       [-0.0015891 ],\n       [-0.0015891 ]]), 'x_shared': array([[ 0.        , -0.01704647, -0.01704647, -0.01704647, -0.01704647,\n        -0.01704647],\n       [-0.01704647,  0.        ,  0.30256195,  0.41417593,  0.41417593,\n         0.41417593],\n       [-0.01704647,  0.30256195,  0.        ,  0.10449216,  0.10449216,\n         0.10449216],\n       [-0.01704647,  0.41417593,  0.10449216,  0.        , -0.01704647,\n        -0.01704647],\n       [-0.01704647,  0.41417593,  0.10449216, -0.01704647,  0.        ,\n        -0.01704647],\n       [-0.01704647,  0.41417593,  0.10449216, -0.01704647, -0.01704647,\n         0.        ]])}}, {'x_1': {'x_1': array([[ 0.        , -0.64983475],\n       [-0.64983475,  0.        ]]), 'x_2': array([[-0.64983515],\n       [-0.65008795]]), 'x_3': array([[-0.6498363 ],\n       [-0.65013203]]), 'x_shared': array([[-0.64982961, -0.64984294, -0.64985322, -0.64983476, -0.64981755,\n        -0.6498404 ],\n       [-0.65005867, -0.65000333, -0.6498799 , -0.65008683, -0.65012373,\n        -0.65006783]])}, 'x_2': {'x_1': array([[-0.64983515, -0.65008795]]), 'x_2': array([[0.]]), 'x_3': array([[-0.6505736]]), 'x_shared': array([[-0.64910071, -0.64502447, -0.64902736, -0.65022444, -0.64831294,\n        -0.6522342 ]])}, 'x_3': {'x_1': array([[-0.6498363 , -0.65013203]]), 'x_2': array([[-0.6505736]]), 'x_3': array([[0.]]), 'x_shared': array([[-0.49387276, -0.52528335, -0.44574003, -0.50767112, -0.51701136,\n        -0.49740548]])}, 'x_shared': {'x_1': array([[-0.64982961, -0.65005867],\n       [-0.64984294, -0.65000333],\n       [-0.64985322, -0.6498799 ],\n       [-0.64983476, -0.65008683],\n       [-0.64981755, -0.65012373],\n       [-0.6498404 , -0.65006783]]), 'x_2': array([[-0.64910071],\n       [-0.64502447],\n       [-0.64902736],\n       [-0.65022444],\n       [-0.64831294],\n       [-0.6522342 ]]), 'x_3': array([[-0.49387276],\n       [-0.52528335],\n       [-0.44574003],\n       [-0.50767112],\n       [-0.51701136],\n       [-0.49740548]]), 'x_shared': array([[ 0.        , -0.73375122, -0.756835  , -0.73458649, -0.74883566,\n        -0.73155137],\n       [-0.73375122,  0.        , -0.21466884, -0.02126292,  0.031749  ,\n         0.05359174],\n       [-0.756835  , -0.21466884,  0.        , -0.53507177, -0.39365149,\n        -0.56084951],\n       [-0.73458649, -0.02126292, -0.53507177,  0.        , -0.64992269,\n        -0.64992595],\n       [-0.74883566,  0.031749  , -0.39365149, -0.64992269,  0.        ,\n        -0.7791001 ],\n       [-0.73155137,  0.05359174, -0.56084951, -0.64992595, -0.7791001 ,\n         0.        ]])}}, {'x_1': {'x_1': array([[ 0.        , -0.65446902],\n       [-0.65446902,  0.        ]]), 'x_2': array([[-0.65446943],\n       [-0.6547183 ]]), 'x_3': array([[-0.65447059],\n       [-0.65476368]]), 'x_shared': array([[-0.65446376, -0.65447716, -0.65448766, -0.65446903, -0.65445145,\n        -0.65447479],\n       [-0.65468846, -0.65463623, -0.65450767, -0.6547172 , -0.65475441,\n        -0.65469715]])}, 'x_2': {'x_1': array([[-0.65446943, -0.6547183 ]]), 'x_2': array([[0.]]), 'x_3': array([[-0.65513895]]), 'x_shared': array([[-0.65364071, -0.64957331, -0.65361609, -0.65478425, -0.65281373,\n        -0.65682092]])}, 'x_3': {'x_1': array([[-0.65447059, -0.65476368]]), 'x_2': array([[-0.65513895]]), 'x_3': array([[0.]]), 'x_shared': array([[-0.49581736, -0.52825994, -0.44619693, -0.50999028, -0.51956593,\n        -0.49936174]])}, 'x_shared': {'x_1': array([[-0.65446376, -0.65468846],\n       [-0.65447716, -0.65463623],\n       [-0.65448766, -0.65450767],\n       [-0.65446903, -0.6547172 ],\n       [-0.65445145, -0.65475441],\n       [-0.65447479, -0.65469715]]), 'x_2': array([[-0.65364071],\n       [-0.64957331],\n       [-0.65361609],\n       [-0.65478425],\n       [-0.65281373],\n       [-0.65682092]]), 'x_3': array([[-0.49581736],\n       [-0.52825994],\n       [-0.44619693],\n       [-0.50999028],\n       [-0.51956593],\n       [-0.49936174]]), 'x_shared': array([[ 0.        , -0.73961172, -0.76367661, -0.74081926, -0.75542268,\n        -0.73782941],\n       [-0.73961172,  0.        , -0.21718601, -0.0253624 ,  0.02780088,\n         0.0503513 ],\n       [-0.76367661, -0.21718601,  0.        , -0.54523945, -0.4011258 ,\n        -0.57220677],\n       [-0.74081926, -0.0253624 , -0.54523945,  0.        , -0.65455737,\n        -0.65456072],\n       [-0.75542268,  0.02780088, -0.4011258 , -0.65455737,  0.        ,\n        -0.78337748],\n       [-0.73782941,  0.0503513 , -0.57220677, -0.65456072, -0.78337748,\n         0.        ]])}}], 'y_31': [{'x_1': {'x_1': array([[ 0.        , -0.64983453],\n       [-0.64983453,  0.        ]]), 'x_2': array([[-0.64983494],\n       [-0.6500878 ]]), 'x_3': array([[-0.64983609],\n       [-0.65013188]]), 'x_shared': array([[-0.6498294 , -0.64984273, -0.649853  , -0.64983455, -0.64981733,\n        -0.64984018],\n       [-0.65005851, -0.65000315, -0.64987973, -0.65008668, -0.65012358,\n        -0.65006768]])}, 'x_2': {'x_1': array([[-0.64983494, -0.6500878 ]]), 'x_2': array([[0.]]), 'x_3': array([[-0.65057339]]), 'x_shared': array([[-0.6491005 , -0.64502424, -0.64902714, -0.65022423, -0.64831274,\n        -0.65223399]])}, 'x_3': {'x_1': array([[-0.64983609, -0.65013188]]), 'x_2': array([[-0.65057339]]), 'x_3': array([[0.]]), 'x_shared': array([[-0.49387245, -0.5252832 , -0.44573987, -0.5076708 , -0.517011  ,\n        -0.49740511]])}, 'x_shared': {'x_1': array([[-0.6498294 , -0.65005851],\n       [-0.64984273, -0.65000315],\n       [-0.649853  , -0.64987973],\n       [-0.64983455, -0.65008668],\n       [-0.64981733, -0.65012358],\n       [-0.64984018, -0.65006768]]), 'x_2': array([[-0.6491005 ],\n       [-0.64502424],\n       [-0.64902714],\n       [-0.65022423],\n       [-0.64831274],\n       [-0.65223399]]), 'x_3': array([[-0.49387245],\n       [-0.5252832 ],\n       [-0.44573987],\n       [-0.5076708 ],\n       [-0.517011  ],\n       [-0.49740511]]), 'x_shared': array([[ 0.        , -0.73375105, -0.75683478, -0.73458627, -0.74883543,\n        -0.73155114],\n       [-0.73375105,  0.        , -0.21466881, -0.02126278,  0.03174916,\n         0.05359191],\n       [-0.75683478, -0.21466881,  0.        , -0.53507107, -0.39365077,\n        -0.56084872],\n       [-0.73458627, -0.02126278, -0.53507107,  0.        , -0.6499225 ,\n        -0.64992575],\n       [-0.74883543,  0.03174916, -0.39365077, -0.6499225 ,  0.        ,\n        -0.77909944],\n       [-0.73155114,  0.05359191, -0.56084872, -0.64992575, -0.77909944,\n         0.        ]])}}], 'y_32': [{'x_1': {'x_1': array([[ 0.       , -0.6544688],\n       [-0.6544688,  0.       ]]), 'x_2': array([[-0.65446922],\n       [-0.65471814]]), 'x_3': array([[-0.65447037],\n       [-0.65476353]]), 'x_shared': array([[-0.65446355, -0.65447695, -0.65448744, -0.65446882, -0.65445123,\n        -0.65447458],\n       [-0.6546883 , -0.65463605, -0.65450749, -0.65471704, -0.65475426,\n        -0.654697  ]])}, 'x_2': {'x_1': array([[-0.65446922, -0.65471814]]), 'x_2': array([[0.]]), 'x_3': array([[-0.65513873]]), 'x_shared': array([[-0.6536405 , -0.64957308, -0.65361587, -0.65478404, -0.65281353,\n        -0.65682071]])}, 'x_3': {'x_1': array([[-0.65447037, -0.65476353]]), 'x_2': array([[-0.65513873]]), 'x_3': array([[0.]]), 'x_shared': array([[-0.49581705, -0.52825979, -0.44619676, -0.50998995, -0.51956557,\n        -0.49936137]])}, 'x_shared': {'x_1': array([[-0.65446355, -0.6546883 ],\n       [-0.65447695, -0.65463605],\n       [-0.65448744, -0.65450749],\n       [-0.65446882, -0.65471704],\n       [-0.65445123, -0.65475426],\n       [-0.65447458, -0.654697  ]]), 'x_2': array([[-0.6536405 ],\n       [-0.64957308],\n       [-0.65361587],\n       [-0.65478404],\n       [-0.65281353],\n       [-0.65682071]]), 'x_3': array([[-0.49581705],\n       [-0.52825979],\n       [-0.44619676],\n       [-0.50998995],\n       [-0.51956557],\n       [-0.49936137]]), 'x_shared': array([[ 0.        , -0.73961155, -0.76367639, -0.74081904, -0.75542245,\n        -0.73782917],\n       [-0.73961155,  0.        , -0.21718598, -0.02536226,  0.02780104,\n         0.05035146],\n       [-0.76367639, -0.21718598,  0.        , -0.54523875, -0.40112508,\n        -0.57220597],\n       [-0.74081904, -0.02536226, -0.54523875,  0.        , -0.65455718,\n        -0.65456052],\n       [-0.75542245,  0.02780104, -0.40112508, -0.65455718,  0.        ,\n        -0.78337682],\n       [-0.73782917,  0.05035146, -0.57220597, -0.65456052, -0.78337682,\n         0.        ]])}}], 'y_34': [{'x_1': {'x_1': array([[ 0.        , -0.01704647],\n       [-0.01704647,  0.        ]]), 'x_2': array([[-0.01704647],\n       [-0.01704647]]), 'x_3': array([[-0.01704647],\n       [-0.01704647]]), 'x_shared': array([[-0.01704647, -0.01704647, -0.01704647, -0.01704647, -0.01704647,\n        -0.01704647],\n       [-0.01704647, -0.01704647, -0.01704647, -0.01704647, -0.01704647,\n        -0.01704647]])}, 'x_2': {'x_1': array([[-0.01704647, -0.01704647]]), 'x_2': array([[0.]]), 'x_3': array([[-0.01704647]]), 'x_shared': array([[-0.01704647, -0.01704647, -0.01704647, -0.01704647, -0.01704647,\n        -0.01704647]])}, 'x_3': {'x_1': array([[-0.01704647, -0.01704647]]), 'x_2': array([[-0.01704647]]), 'x_3': array([[0.]]), 'x_shared': array([[-0.0015891 , -0.00386702,  0.01505761, -0.0015891 , -0.0015891 ,\n        -0.0015891 ]])}, 'x_shared': {'x_1': array([[-0.01704647, -0.01704647],\n       [-0.01704647, -0.01704647],\n       [-0.01704647, -0.01704647],\n       [-0.01704647, -0.01704647],\n       [-0.01704647, -0.01704647],\n       [-0.01704647, -0.01704647]]), 'x_2': array([[-0.01704647],\n       [-0.01704647],\n       [-0.01704647],\n       [-0.01704647],\n       [-0.01704647],\n       [-0.01704647]]), 'x_3': array([[-0.0015891 ],\n       [-0.00386702],\n       [ 0.01505761],\n       [-0.0015891 ],\n       [-0.0015891 ],\n       [-0.0015891 ]]), 'x_shared': array([[ 0.        , -0.01704647, -0.01704647, -0.01704647, -0.01704647,\n        -0.01704647],\n       [-0.01704647,  0.        ,  0.30256195,  0.41417593,  0.41417593,\n         0.41417593],\n       [-0.01704647,  0.30256195,  0.        ,  0.10449216,  0.10449216,\n         0.10449216],\n       [-0.01704647,  0.41417593,  0.10449216,  0.        , -0.01704647,\n        -0.01704647],\n       [-0.01704647,  0.41417593,  0.10449216, -0.01704647,  0.        ,\n        -0.01704647],\n       [-0.01704647,  0.41417593,  0.10449216, -0.01704647, -0.01704647,\n         0.        ]])}}], 'y_4': [{'x_1': {'x_1': array([[ 0.        , -0.23791431],\n       [-0.23791431,  0.        ]]), 'x_2': array([[-0.23790814],\n       [-0.24412889]]), 'x_3': array([[-0.23791155],\n       [-0.24540177]]), 'x_shared': array([[-0.2378734 , -0.23788182, -0.23774544, -0.23795748, -0.2381558 ,\n        -0.23795051],\n       [-0.24854579, -0.25077671, -0.20616009, -0.24576745, -0.24923871,\n        -0.24790108]])}, 'x_2': {'x_1': array([[-0.23790814, -0.24412889]]), 'x_2': array([[0.]]), 'x_3': array([[-0.23406821]]), 'x_shared': array([[-0.23506904, -0.2289948 , -0.23473738, -0.23250282, -0.2293013 ,\n        -0.23267625]])}, 'x_3': {'x_1': array([[-0.23791155, -0.24540177]]), 'x_2': array([[-0.23406821]]), 'x_3': array([[0.]]), 'x_shared': array([[-0.22229855, -0.22311811, -0.20149966, -0.22030924, -0.2218356 ,\n        -0.22086134]])}, 'x_shared': {'x_1': array([[-0.2378734 , -0.24854579],\n       [-0.23788182, -0.25077671],\n       [-0.23774544, -0.20616009],\n       [-0.23795748, -0.24576745],\n       [-0.2381558 , -0.24923871],\n       [-0.23795051, -0.24790108]]), 'x_2': array([[-0.23506904],\n       [-0.2289948 ],\n       [-0.23473738],\n       [-0.23250282],\n       [-0.2293013 ],\n       [-0.23267625]]), 'x_3': array([[-0.22229855],\n       [-0.22311811],\n       [-0.20149966],\n       [-0.22030924],\n       [-0.2218356 ],\n       [-0.22086134]]), 'x_shared': array([[ 0.        , -0.16278664, -0.10909619, -0.13076936, -0.09116954,\n        -0.13516692],\n       [-0.16278664,  0.        ,  0.32110559,  0.29273589,  0.41905013,\n         0.28294732],\n       [-0.10909619,  0.32110559,  0.        , -0.26131115, -0.01032671,\n        -0.25027609],\n       [-0.13076936,  0.29273589, -0.26131115,  0.        , -0.26903019,\n        -0.24009229],\n       [-0.09116954,  0.41905013, -0.01032671, -0.26903019,  0.        ,\n        -0.45492547],\n       [-0.13516692,  0.28294732, -0.25027609, -0.24009229, -0.45492547,\n         0.        ]])}}]}, &lt;Method.TOTAL: 'total'&gt;: {'g_1': [{'x_1': array([-0.06409028, -0.89924381]), 'x_2': array([-0.20023777]), 'x_3': array([-0.20023777]), 'x_shared': array([ 2.70743344, -0.20023777, -0.20023777,  0.01367927, -0.20023777,\n       -0.44385   ])}, {'x_1': array([-0.08062251, -0.82652285]), 'x_2': array([-0.15276836]), 'x_3': array([-0.15276836]), 'x_shared': array([ 2.08528533, -0.15276836, -0.15276836,  0.21524092, -0.15276836,\n       -0.55035268])}, {'x_1': array([-0.0864275, -0.7898062]), 'x_2': array([-0.13356686]), 'x_3': array([-0.13356686]), 'x_shared': array([ 1.82381834, -0.13356686, -0.13356686,  0.30365424, -0.13356686,\n       -0.59635336])}, {'x_1': array([-0.08928965, -0.76835203]), 'x_2': array([-0.12334036]), 'x_3': array([-0.12334036]), 'x_shared': array([ 1.68201275, -0.12334036, -0.12334036,  0.35253231, -0.12334036,\n       -0.62161246])}, {'x_1': array([-0.09097346, -0.75438013]), 'x_2': array([-0.11701813]), 'x_3': array([-0.11701813]), 'x_shared': array([ 1.59339411, -0.11701813, -0.11701813,  0.38341746, -0.11701813,\n       -0.63751151])}, {'x_1': array([-0.56145556,  0.44974742]), 'x_2': array([-0.08702435]), 'x_3': array([-0.08702435]), 'x_shared': array([-0.08702435, -0.08702435, -0.08702435,  1.40229147, -0.08702435,\n       -1.09440129])}, {'x_1': array([-0.56145556,  0.44974742]), 'x_2': array([-0.08702435]), 'x_3': array([-0.08702435]), 'x_shared': array([-0.08702435, -0.08702435, -0.08702435,  1.40229147, -0.08702435,\n       -1.09440129])}], 'g_2': [{'x_1': array([-0.59687045, -0.59687045]), 'x_2': array([-0.59687045]), 'x_3': array([-0.59687045]), 'x_shared': array([ 6.3652017 , -0.59687045, -0.59687045, -0.59687045, -0.59687045,\n       -0.59687045])}], 'g_3': [{'x_1': array([-0.0010972 , -0.00135806]), 'x_2': array([-0.00445962]), 'x_3': array([0.05848542]), 'x_shared': array([-0.02863292,  0.56154848,  0.27492934, -0.00114929, -0.11721704,\n       -0.06833947])}, {'x_1': array([-0.0010972 , -0.00135806]), 'x_2': array([-0.00445962]), 'x_3': array([0.05848542]), 'x_shared': array([-0.02863292,  0.56154848,  0.27492934, -0.00114929, -0.11721704,\n       -0.06833947])}, {'x_1': array([-0.00443377, -0.00443377]), 'x_2': array([-0.00443377]), 'x_3': array([0.14725238]), 'x_shared': array([-0.00443377,  0.60573952,  0.12196367, -0.00443377, -0.00443377,\n       -0.00443377])}, {'x_1': array([-0.00159737, -0.00159737]), 'x_2': array([-0.00159737]), 'x_3': array([-0.00159737]), 'x_shared': array([-0.00159737, -0.00159737,  1.28191082, -0.00159737, -0.00159737,\n       -0.00159737])}], 'y_1': [{'x_1': array([-0.00382801, -0.28779995]), 'x_2': array([-0.00034189]), 'x_3': array([0.06814377]), 'x_shared': array([-0.2566161 ,  0.38996348,  0.19141919, -0.0362913 , -0.35961796,\n       -0.04686076])}, {'x_1': array([-0.07937656, -0.07937656]), 'x_2': array([-0.07937656]), 'x_3': array([-0.07937656]), 'x_shared': array([-0.05676045, -0.07937656, -0.07937656,  0.36940585, -0.07937656,\n        1.42047138])}, {'x_1': array([-0.56145556,  0.44974742]), 'x_2': array([-0.08702435]), 'x_3': array([-0.08702435]), 'x_shared': array([-0.08702435, -0.08702435, -0.08702435,  1.40229147, -0.08702435,\n       -1.09440129])}], 'y_11': [{'x_1': array([-0.03381489,  0.36652651]), 'x_2': array([-0.03715257]), 'x_3': array([0.12704941]), 'x_shared': array([ 0.21045362,  0.47914641, -0.20694598,  0.11033824,  0.06262318,\n        0.52863878])}], 'y_12': [{'x_1': array([-0.00382801, -0.28779976]), 'x_2': array([-0.00034189]), 'x_3': array([0.06814391]), 'x_shared': array([-0.25661594,  0.38996333,  0.19141862, -0.03629122, -0.3596176 ,\n       -0.04686071])}, {'x_1': array([-0.56145556,  0.44974742]), 'x_2': array([-0.08702435]), 'x_3': array([-0.08702435]), 'x_shared': array([-0.08702435, -0.08702435, -0.08702435,  1.40229147, -0.08702435,\n       -1.09440129])}], 'y_14': [{'x_1': array([-0.00382801, -0.28779995]), 'x_2': array([-0.00034189]), 'x_3': array([0.06814377]), 'x_shared': array([-0.2566161 ,  0.38996348,  0.19141919, -0.0362913 , -0.35961796,\n       -0.04686076])}, {'x_1': array([-0.07937656, -0.07937656]), 'x_2': array([-0.07937656]), 'x_3': array([-0.07937656]), 'x_shared': array([-0.05676045, -0.07937656, -0.07937656,  0.36940585, -0.07937656,\n        1.42047138])}], 'y_2': [{'x_1': array([-0.00382801, -0.28779902]), 'x_2': array([-0.00034187]), 'x_3': array([0.06814447]), 'x_shared': array([-0.25661668,  0.38996229,  0.19141728, -0.03629053, -0.35961756,\n       -0.04686028])}, {'x_1': array([-0.00290415, -0.00323088]), 'x_2': array([-0.00646936]), 'x_3': array([-0.00100787]), 'x_shared': array([-0.02162375,  0.57194863,  0.36071446, -0.00295507, -0.14641397,\n       -0.05889873])}, {'x_1': array([-0.00217609,  0.1158459 ]), 'x_2': array([-0.00738895]), 'x_3': array([-0.00272057]), 'x_shared': array([-0.0052864 ,  0.56707225,  0.41557318,  0.02545564, -0.11162603,\n       -0.03523156])}], 'y_21': [{'x_1': array([-0.00382801, -0.2877996 ]), 'x_2': array([-0.00034189]), 'x_3': array([0.06814447]), 'x_shared': array([-0.25661607,  0.38996329,  0.19141892, -0.03629119, -0.35961776,\n       -0.04686054])}], 'y_23': [{'x_1': array([-0.00290415, -0.00323087]), 'x_2': array([-0.00646936]), 'x_3': array([-0.00100787]), 'x_shared': array([-0.02162375,  0.5719486 ,  0.36071444, -0.00295507, -0.14641396,\n       -0.05889873])}], 'y_24': [{'x_1': array([-0.00217609,  0.1158459 ]), 'x_2': array([-0.00738895]), 'x_3': array([-0.00272057]), 'x_shared': array([-0.0052864 ,  0.56707225,  0.41557318,  0.02545564, -0.11162603,\n       -0.03523156])}], 'y_3': [{'x_1': array([-0.0009888, -0.0009888]), 'x_2': array([-0.0009888]), 'x_3': array([0.00088859]), 'x_shared': array([-0.0009888 ,  0.45431126,  0.54123151, -0.0009888 , -0.0009888 ,\n       -0.0009888 ])}, {'x_1': array([-0.00111917, -0.00138512]), 'x_2': array([-0.0045175]), 'x_3': array([0.05800666]), 'x_shared': array([-0.02799224,  0.56261158,  0.27780377, -0.00117139, -0.11677491,\n       -0.06829691])}, {'x_1': array([-0.0010972 , -0.00135806]), 'x_2': array([-0.00445962]), 'x_3': array([0.05848542]), 'x_shared': array([-0.02863292,  0.56154848,  0.27492934, -0.00114929, -0.11721704,\n       -0.06833947])}], 'y_31': [{'x_1': array([-0.00111916, -0.00138523]), 'x_2': array([-0.0045175]), 'x_3': array([0.05800666]), 'x_shared': array([-0.02799226,  0.56261187,  0.27780399, -0.00117141, -0.11677492,\n       -0.06829693])}], 'y_32': [{'x_1': array([-0.0010972 , -0.00135817]), 'x_2': array([-0.00445962]), 'x_3': array([0.05848542]), 'x_shared': array([-0.02863294,  0.56154876,  0.27492956, -0.00114931, -0.11721705,\n       -0.06833949])}], 'y_34': [{'x_1': array([-0.0009888, -0.0009888]), 'x_2': array([-0.0009888]), 'x_3': array([0.00088859]), 'x_shared': array([-0.0009888 ,  0.45431126,  0.54123151, -0.0009888 , -0.0009888 ,\n       -0.0009888 ])}], 'y_4': [{'x_1': array([-0.00277676,  0.00126616]), 'x_2': array([-0.00639952]), 'x_3': array([0.00847911]), 'x_shared': array([ 0.03408707,  0.72505751,  0.11247439,  0.04675498, -0.13660392,\n        0.0485379 ])}]}}\n</code></pre> <p>Lastly, we draw the Sobol' graph:</p> <pre><code>sobol_graph = SobolGraph.from_analysis(sobol_analysis, output_name=\"y_4\")\nsobol_graph\n</code></pre> x_1[0]     (0, 13) x_1[0] (0, 13) x_1[1]     (0, 13) x_1[1] (0, 13) x_2     (0, 13) x_2 (0, 13) x_3     (1, 12) x_3 (1, 12) x_shared[0]     (3, 8) x_shared[0] (3, 8) x_shared[1]     (73, 28) x_shared[1] (73, 28) x_shared[2]     (11, 37) x_shared[2] (11, 37) x_shared[1]     (73, 28)-&gt;x_shared[2]     (11, 37) x_shared[3]     (5, 17) x_shared[3] (5, 17) x_shared[1]     (73, 28)-&gt;x_shared[3]     (5, 17) x_shared[4]     (0, 20) x_shared[4] (0, 20) x_shared[1]     (73, 28)-&gt;x_shared[4]     (0, 20) x_shared[5]     (5, 17) x_shared[5] (5, 17) x_shared[1]     (73, 28)-&gt;x_shared[5]     (5, 17) <p>Sphinx Gallery and Jupyter Notebook can display <code>sobol_graph</code> in the web browser. You can also use <code>sobol_graph.visualize()</code> to save it on the disk or display it with a dedicated program.</p> <p>Total running time of the script: ( 0 minutes  4.399 seconds)</p> <p> Download Python source code: plot_sobieski_sobol_graph.py</p> <p> Download Jupyter notebook: plot_sobieski_sobol_graph.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/visualizations/uncertain_coupling_graph/mg_execution_times/","title":"Computation times","text":"<p>00:04.891 total execution time for generated_examples_visualizations_uncertain_coupling_graph files:</p> <p>+-----------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_sobieski_coupling_graph (docs/examples/visualizations/uncertain_coupling_graph/plot_sobieski_coupling_graph.py) | 00:04.891 | 0.0 MB | +-----------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+--------+</p>"},{"location":"generated/examples/visualizations/uncertain_coupling_graph/plot_sobieski_coupling_graph/","title":"The uncertain coupling graph for the Sobieski's SSBJ use case.","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/visualizations/uncertain_coupling_graph/plot_sobieski_coupling_graph/#the-uncertain-coupling-graph-for-the-sobieskis-ssbj-use-case","title":"The uncertain coupling graph for the Sobieski's SSBJ use case.","text":"<pre><code>from __future__ import annotations\n\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.problems.mdo.sobieski.core.problem import SobieskiProblem\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiAerodynamics\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiMission\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiPropulsion\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiStructure\nfrom gemseo.utils.data_conversion import split_array_to_dict_of_arrays\n\nfrom gemseo_umdo.visualizations.uncertain_coupling_graph import UncertainCouplingGraph\n</code></pre> <p>First, we define an uncertain space around the optimum design:</p> <pre><code>design_space = SobieskiProblem().design_space\ndesign_variable_names = [\"x_1\", \"x_2\", \"x_3\", \"x_shared\"]\ndesign_space.filter(design_variable_names)\noptimum_design = split_array_to_dict_of_arrays(\n    SobieskiProblem().optimum_design,\n    design_space.variable_sizes,\n    design_variable_names,\n)\n\nuncertain_space = DesignSpace()\nfor name, value in optimum_design.items():\n    uncertain_space.add_variable(\n        name,\n        size=value.size,\n        l_b=value * 0.95,\n        u_b=value * 1.05,\n        value=value,\n    )\n</code></pre> <p>Then, we define the disciplines:</p> <pre><code>disciplines = [\n    SobieskiAerodynamics(),\n    SobieskiStructure(),\n    SobieskiPropulsion(),\n    SobieskiMission(),\n]\n</code></pre> <p>Thirdly, we instantiate an uncertain coupling graph:</p> <pre><code>uncertain_coupling_graph = UncertainCouplingGraph(disciplines, uncertain_space)\n</code></pre> <p>and sample the multidisciplinary system with 100 evaluations:</p> <pre><code>uncertain_coupling_graph.sample(100)\n</code></pre> <p>Out:</p> <pre><code>/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib/python3.9/site-packages/gemseo/problems/mdo/sobieski/core/utils.py:223: DeprecationWarning: Conversion of an array with ndim &gt; 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  ai_coeff[index] = -(f_bound[2] - f_bound[0]) / (2 * mtx_shifted[0, 1])\n</code></pre> <p>Lastly, we visualize it:</p> <pre><code>uncertain_coupling_graph.visualize(save=False, show=True)\n</code></pre> SobieskiAerodynamics SobieskiAerodynamics SobieskiStructure SobieskiStructure SobieskiAerodynamics-&gt;SobieskiStructure y_21 SobieskiPropulsion SobieskiPropulsion SobieskiAerodynamics-&gt;SobieskiPropulsion y_23 SobieskiMission SobieskiMission SobieskiAerodynamics-&gt;SobieskiMission y_24 SobieskiStructure-&gt;SobieskiAerodynamics y_12[0] SobieskiStructure-&gt;SobieskiAerodynamics y_12[1] SobieskiStructure-&gt;SobieskiMission y_14[0] SobieskiStructure-&gt;SobieskiMission y_14[1] SobieskiPropulsion-&gt;SobieskiAerodynamics y_32 SobieskiPropulsion-&gt;SobieskiStructure y_31 SobieskiPropulsion-&gt;SobieskiMission y_34 <p>In this example designed for Sphinx Gallery and Jupyter Notebook, we do not save the graph on the disk (<code>save=False</code>) or display it with a dedicated program (<code>save=True</code>) but display it in the web browser.</p> <p>Total running time of the script: ( 0 minutes  4.891 seconds)</p> <p> Download Python source code: plot_sobieski_coupling_graph.py</p> <p> Download Jupyter notebook: plot_sobieski_coupling_graph.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>gemseo_umdo<ul> <li>_utils<ul> <li>compatibility<ul> <li>openturns</li> </ul> </li> </ul> </li> <li>disciplines<ul> <li>additive_noiser</li> <li>base_noiser</li> <li>multiplicative_noiser</li> <li>noiser_factory</li> </ul> </li> <li>formulations<ul> <li>_functions<ul> <li>base_statistic_function</li> <li>base_statistic_function_for_sampling</li> <li>hessian_function</li> <li>iterative_estimation</li> <li>statistic_function_for_control_variate</li> <li>statistic_function_for_iterative_sampling</li> <li>statistic_function_for_pce</li> <li>statistic_function_for_standard_sampling</li> <li>statistic_function_for_taylor_polynomial</li> </ul> </li> <li>_statistics<ul> <li>base_statistic_estimator</li> <li>control_variate<ul> <li>base_control_variate_estimator</li> <li>factory</li> <li>margin</li> <li>mean</li> <li>probability</li> <li>standard_deviation</li> <li>variance</li> </ul> </li> <li>iterative_sampling<ul> <li>base_central_moment</li> <li>base_sampling_estimator</li> <li>factory</li> <li>margin</li> <li>mean</li> <li>probability</li> <li>standard_deviation</li> <li>variance</li> </ul> </li> <li>pce<ul> <li>base_pce_estimator</li> <li>factory</li> <li>margin</li> <li>mean</li> <li>standard_deviation</li> <li>variance</li> </ul> </li> <li>sampling<ul> <li>base_sampling_estimator</li> <li>factory</li> <li>margin</li> <li>mean</li> <li>probability</li> <li>standard_deviation</li> <li>variance</li> </ul> </li> <li>taylor_polynomial<ul> <li>base_taylor_polynomial_estimator</li> <li>factory</li> <li>margin</li> <li>mean</li> <li>standard_deviation</li> <li>variance</li> </ul> </li> </ul> </li> <li>base_umdo_formulation</li> <li>control_variate</li> <li>factory</li> <li>pce</li> <li>sampling</li> <li>sequential_sampling</li> <li>taylor_polynomial</li> </ul> </li> <li>monte_carlo_sampler</li> <li>scenarios<ul> <li>base_u_scenario</li> <li>udoe_scenario</li> <li>umdo_scenario</li> </ul> </li> <li>statistics<ul> <li>multilevel<ul> <li>base_pilot</li> <li>mlmc<ul> <li>level</li> <li>mlmc</li> <li>pilots<ul> <li>base_mlmc_pilot</li> <li>factory</li> <li>mean</li> <li>variance</li> </ul> </li> </ul> </li> <li>mlmc_mlcv<ul> <li>level</li> <li>mlmc_mlcv</li> <li>pilots<ul> <li>base_mlmc_mlcv_pilot</li> <li>factory</li> <li>mean</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> <li>use_cases<ul> <li>beam_model<ul> <li>advanced_uncertain_space</li> <li>constraints</li> <li>core<ul> <li>design_space</li> <li>model</li> <li>output_data</li> <li>variables</li> </ul> </li> <li>design_space</li> <li>discipline</li> <li>uncertain_space</li> </ul> </li> <li>heat_equation<ul> <li>configuration</li> <li>discipline</li> <li>model</li> <li>uncertain_space</li> </ul> </li> <li>spring_mass_model<ul> <li>discipline</li> <li>model</li> <li>uncertain_space</li> </ul> </li> </ul> </li> <li>visualizations<ul> <li>sobol_graph</li> <li>uncertain_coupling_graph</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/gemseo_umdo/","title":"API documentation","text":""},{"location":"reference/gemseo_umdo/#gemseo_umdo","title":"gemseo_umdo","text":"<p>A plug-in for multidisciplinary design under uncertainty.</p>"},{"location":"reference/gemseo_umdo/monte_carlo_sampler/","title":"Monte carlo sampler","text":""},{"location":"reference/gemseo_umdo/monte_carlo_sampler/#gemseo_umdo.monte_carlo_sampler","title":"monte_carlo_sampler","text":"<p>A Monte Carlo sampler.</p>"},{"location":"reference/gemseo_umdo/monte_carlo_sampler/#gemseo_umdo.monte_carlo_sampler-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/monte_carlo_sampler/#gemseo_umdo.monte_carlo_sampler.MonteCarloSampler","title":"MonteCarloSampler","text":"<pre><code>MonteCarloSampler(input_space: DesignSpace)\n</code></pre> <p>A Monte Carlo sampler taking advantage of the vectorized functions.</p> <p>Parameters:</p> <ul> <li> <code>input_space</code>               (<code>DesignSpace</code>)           \u2013            <p>The input space on which to sample the functions.</p> </li> </ul> Source code in <code>src/gemseo_umdo/monte_carlo_sampler.py</code> <pre><code>def __init__(self, input_space: DesignSpace) -&gt; None:\n    \"\"\"\n    Args:\n        input_space: The input space on which to sample the functions.\n    \"\"\"  # noqa:D205 D212 D415\n    self.__algo = OpenTURNS()\n    self.__algo.algo_name = \"OT_MONTE_CARLO\"\n    self.__functions = []\n    self.__input_space = input_space\n    self.__input_histories = []\n    self.__output_histories = []\n    self.__all_functions_are_vectorized = True\n</code></pre>"},{"location":"reference/gemseo_umdo/monte_carlo_sampler/#gemseo_umdo.monte_carlo_sampler.MonteCarloSampler-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/monte_carlo_sampler/#gemseo_umdo.monte_carlo_sampler.MonteCarloSampler.input_history","title":"input_history  <code>property</code>","text":"<pre><code>input_history: NDArray[float]\n</code></pre> <p>The history of the function inputs.</p>"},{"location":"reference/gemseo_umdo/monte_carlo_sampler/#gemseo_umdo.monte_carlo_sampler.MonteCarloSampler.output_history","title":"output_history  <code>property</code>","text":"<pre><code>output_history: NDArray[float]\n</code></pre> <p>The history of the function outputs.</p>"},{"location":"reference/gemseo_umdo/monte_carlo_sampler/#gemseo_umdo.monte_carlo_sampler.MonteCarloSampler-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/monte_carlo_sampler/#gemseo_umdo.monte_carlo_sampler.MonteCarloSampler.add_function","title":"add_function","text":"<pre><code>add_function(\n    function: FunctionType, is_vectorized: bool = True\n) -&gt; None\n</code></pre> <p>Add a function to sample.</p> <p>Parameters:</p> <ul> <li> <code>function</code>               (<code>FunctionType</code>)           \u2013            <p>A function to sample.</p> </li> <li> <code>is_vectorized</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether the function is vectorized.</p> </li> </ul> Source code in <code>src/gemseo_umdo/monte_carlo_sampler.py</code> <pre><code>def add_function(self, function: FunctionType, is_vectorized: bool = True) -&gt; None:\n    \"\"\"Add a function to sample.\n\n    Args:\n        function: A function to sample.\n        is_vectorized: Whether the function is vectorized.\n    \"\"\"\n    self.__all_functions_are_vectorized &amp;= is_vectorized\n    self.__functions.append(function)\n</code></pre>"},{"location":"reference/gemseo_umdo/_utils/","title":"utils","text":""},{"location":"reference/gemseo_umdo/_utils/#gemseo_umdo._utils","title":"_utils","text":"<p>Utilities.</p>"},{"location":"reference/gemseo_umdo/_utils/compatibility/","title":"Compatibility","text":""},{"location":"reference/gemseo_umdo/_utils/compatibility/#gemseo_umdo._utils.compatibility","title":"compatibility","text":"<p>Compatibility between different versions of packages.</p>"},{"location":"reference/gemseo_umdo/_utils/compatibility/openturns/","title":"Openturns","text":""},{"location":"reference/gemseo_umdo/_utils/compatibility/openturns/#gemseo_umdo._utils.compatibility.openturns","title":"openturns","text":"<p>Compatibility between different versions of openturns.</p>"},{"location":"reference/gemseo_umdo/disciplines/","title":"Disciplines","text":""},{"location":"reference/gemseo_umdo/disciplines/#gemseo_umdo.disciplines","title":"disciplines","text":"<p>Some disciplines.</p>"},{"location":"reference/gemseo_umdo/disciplines/additive_noiser/","title":"Additive noiser","text":""},{"location":"reference/gemseo_umdo/disciplines/additive_noiser/#gemseo_umdo.disciplines.additive_noiser","title":"additive_noiser","text":"<p>A discipline adding a random variable to a variable.</p>"},{"location":"reference/gemseo_umdo/disciplines/additive_noiser/#gemseo_umdo.disciplines.additive_noiser-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/disciplines/additive_noiser/#gemseo_umdo.disciplines.additive_noiser.AdditiveNoiser","title":"AdditiveNoiser","text":"<pre><code>AdditiveNoiser(\n    variable_name: str,\n    noised_variable_name: str,\n    uncertain_variable_name: str,\n)\n</code></pre> <p>               Bases: <code>BaseNoiser</code></p> <p>A discipline adding a random variable to a variable.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>variable_name</code>               (<code>str</code>)           \u2013            <p>The name of the variable to be noised.</p> </li> <li> <code>noised_variable_name</code>               (<code>str</code>)           \u2013            <p>The name of the variable once noised.</p> </li> <li> <code>uncertain_variable_name</code>               (<code>str</code>)           \u2013            <p>The name of the uncertain variable.</p> </li> </ul> Source code in <code>src/gemseo_umdo/disciplines/base_noiser.py</code> <pre><code>def __init__(\n    self,\n    variable_name: str,\n    noised_variable_name: str,\n    uncertain_variable_name: str,\n) -&gt; None:\n    \"\"\"\n    Args:\n        variable_name: The name of the variable to be noised.\n        noised_variable_name: The name of the variable once noised.\n        uncertain_variable_name: The name of the uncertain variable.\n    \"\"\"  # noqa: D205 D212 D415\n    self._noised_variable_name = noised_variable_name\n    self._variable_name = variable_name\n    self._uncertain_variable_name = uncertain_variable_name\n    super().__init__()\n    self.input_grammar.update_from_names([variable_name, uncertain_variable_name])\n    self.output_grammar.update_from_names([noised_variable_name])\n</code></pre>"},{"location":"reference/gemseo_umdo/disciplines/additive_noiser/#gemseo_umdo.disciplines.additive_noiser.AdditiveNoiser-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/disciplines/additive_noiser/#gemseo_umdo.disciplines.additive_noiser.AdditiveNoiser.SHORT_NAME","title":"SHORT_NAME  <code>class-attribute</code>","text":"<pre><code>SHORT_NAME: str = '+'\n</code></pre> <p>A short name of the noising discipline to instantiate it more easily.</p> <p>For example, <code>\"*\"</code> would be a good short name for a <code>\"MultiplicativeNoiser\"</code>, i.e. clear and concise.</p> <p>In particular, this short name can be used to set the <code>uncertain_design_variables</code> argument of UDOEScenario and UMDOScenario.</p>"},{"location":"reference/gemseo_umdo/disciplines/base_noiser/","title":"Base noiser","text":""},{"location":"reference/gemseo_umdo/disciplines/base_noiser/#gemseo_umdo.disciplines.base_noiser","title":"base_noiser","text":"<p>A noising discipline.</p>"},{"location":"reference/gemseo_umdo/disciplines/base_noiser/#gemseo_umdo.disciplines.base_noiser-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/disciplines/base_noiser/#gemseo_umdo.disciplines.base_noiser.BaseNoiser","title":"BaseNoiser","text":"<pre><code>BaseNoiser(\n    variable_name: str,\n    noised_variable_name: str,\n    uncertain_variable_name: str,\n)\n</code></pre> <p>               Bases: <code>MDODiscipline</code></p> <p>A discipline noising a variable.</p> <p>UDOEScenario and UMDOScenario create this kind of discipline when using their argument <code>uncertain_design_variables</code> in order to define the link between design and uncertain variables in an intuitive way.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>variable_name</code>               (<code>str</code>)           \u2013            <p>The name of the variable to be noised.</p> </li> <li> <code>noised_variable_name</code>               (<code>str</code>)           \u2013            <p>The name of the variable once noised.</p> </li> <li> <code>uncertain_variable_name</code>               (<code>str</code>)           \u2013            <p>The name of the uncertain variable.</p> </li> </ul> Source code in <code>src/gemseo_umdo/disciplines/base_noiser.py</code> <pre><code>def __init__(\n    self,\n    variable_name: str,\n    noised_variable_name: str,\n    uncertain_variable_name: str,\n) -&gt; None:\n    \"\"\"\n    Args:\n        variable_name: The name of the variable to be noised.\n        noised_variable_name: The name of the variable once noised.\n        uncertain_variable_name: The name of the uncertain variable.\n    \"\"\"  # noqa: D205 D212 D415\n    self._noised_variable_name = noised_variable_name\n    self._variable_name = variable_name\n    self._uncertain_variable_name = uncertain_variable_name\n    super().__init__()\n    self.input_grammar.update_from_names([variable_name, uncertain_variable_name])\n    self.output_grammar.update_from_names([noised_variable_name])\n</code></pre>"},{"location":"reference/gemseo_umdo/disciplines/base_noiser/#gemseo_umdo.disciplines.base_noiser.BaseNoiser-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/disciplines/base_noiser/#gemseo_umdo.disciplines.base_noiser.BaseNoiser.SHORT_NAME","title":"SHORT_NAME  <code>class-attribute</code>","text":"<pre><code>SHORT_NAME: str = ''\n</code></pre> <p>A short name of the noising discipline to instantiate it more easily.</p> <p>For example, <code>\"*\"</code> would be a good short name for a <code>\"MultiplicativeNoiser\"</code>, i.e. clear and concise.</p> <p>In particular, this short name can be used to set the <code>uncertain_design_variables</code> argument of UDOEScenario and UMDOScenario.</p>"},{"location":"reference/gemseo_umdo/disciplines/multiplicative_noiser/","title":"Multiplicative noiser","text":""},{"location":"reference/gemseo_umdo/disciplines/multiplicative_noiser/#gemseo_umdo.disciplines.multiplicative_noiser","title":"multiplicative_noiser","text":"<p>A discipline multiplying a variable by a random variable plus one.</p>"},{"location":"reference/gemseo_umdo/disciplines/multiplicative_noiser/#gemseo_umdo.disciplines.multiplicative_noiser-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/disciplines/multiplicative_noiser/#gemseo_umdo.disciplines.multiplicative_noiser.MultiplicativeNoiser","title":"MultiplicativeNoiser","text":"<pre><code>MultiplicativeNoiser(\n    variable_name: str,\n    noised_variable_name: str,\n    uncertain_variable_name: str,\n)\n</code></pre> <p>               Bases: <code>BaseNoiser</code></p> <p>A discipline multiplying a variable by a random variable plus one.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>variable_name</code>               (<code>str</code>)           \u2013            <p>The name of the variable to be noised.</p> </li> <li> <code>noised_variable_name</code>               (<code>str</code>)           \u2013            <p>The name of the variable once noised.</p> </li> <li> <code>uncertain_variable_name</code>               (<code>str</code>)           \u2013            <p>The name of the uncertain variable.</p> </li> </ul> Source code in <code>src/gemseo_umdo/disciplines/base_noiser.py</code> <pre><code>def __init__(\n    self,\n    variable_name: str,\n    noised_variable_name: str,\n    uncertain_variable_name: str,\n) -&gt; None:\n    \"\"\"\n    Args:\n        variable_name: The name of the variable to be noised.\n        noised_variable_name: The name of the variable once noised.\n        uncertain_variable_name: The name of the uncertain variable.\n    \"\"\"  # noqa: D205 D212 D415\n    self._noised_variable_name = noised_variable_name\n    self._variable_name = variable_name\n    self._uncertain_variable_name = uncertain_variable_name\n    super().__init__()\n    self.input_grammar.update_from_names([variable_name, uncertain_variable_name])\n    self.output_grammar.update_from_names([noised_variable_name])\n</code></pre>"},{"location":"reference/gemseo_umdo/disciplines/multiplicative_noiser/#gemseo_umdo.disciplines.multiplicative_noiser.MultiplicativeNoiser-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/disciplines/multiplicative_noiser/#gemseo_umdo.disciplines.multiplicative_noiser.MultiplicativeNoiser.SHORT_NAME","title":"SHORT_NAME  <code>class-attribute</code>","text":"<pre><code>SHORT_NAME: str = '*'\n</code></pre> <p>A short name of the noising discipline to instantiate it more easily.</p> <p>For example, <code>\"*\"</code> would be a good short name for a <code>\"MultiplicativeNoiser\"</code>, i.e. clear and concise.</p> <p>In particular, this short name can be used to set the <code>uncertain_design_variables</code> argument of UDOEScenario and UMDOScenario.</p>"},{"location":"reference/gemseo_umdo/disciplines/noiser_factory/","title":"Noiser factory","text":""},{"location":"reference/gemseo_umdo/disciplines/noiser_factory/#gemseo_umdo.disciplines.noiser_factory","title":"noiser_factory","text":"<p>A factory of noising disciplines.</p>"},{"location":"reference/gemseo_umdo/disciplines/noiser_factory/#gemseo_umdo.disciplines.noiser_factory-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/disciplines/noiser_factory/#gemseo_umdo.disciplines.noiser_factory.NoiserFactory","title":"NoiserFactory","text":"<pre><code>NoiserFactory()\n</code></pre> <p>               Bases: <code>MDODisciplineFactory</code></p> <p>A factory of noising disciplines.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> Source code in <code>src/gemseo_umdo/disciplines/noiser_factory.py</code> <pre><code>def __init__(self):  # noqa: D107\n    super().__init__()\n    self.__short_names_to_class_names = {\n        self.get_class(class_name).SHORT_NAME: class_name\n        for class_name in self.class_names\n    }\n</code></pre>"},{"location":"reference/gemseo_umdo/disciplines/noiser_factory/#gemseo_umdo.disciplines.noiser_factory.NoiserFactory-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/disciplines/noiser_factory/#gemseo_umdo.disciplines.noiser_factory.NoiserFactory.create","title":"create","text":"<pre><code>create(\n    noiser_name: str,\n    variable_name: str,\n    noised_variable_name: str,\n    uncertain_variable_name: str,\n) -&gt; BaseNoiser\n</code></pre> <p>Create an :class:<code>.MDODiscipline</code> from its name.</p> <p>Parameters:</p> <ul> <li> <code>noiser_name</code>               (<code>str</code>)           \u2013            <p>Either the class name or the short name of the noising discipline.</p> </li> <li> <code>variable_name</code>               (<code>str</code>)           \u2013            <p>The name of the variable to be noised.</p> </li> <li> <code>noised_variable_name</code>               (<code>str</code>)           \u2013            <p>The name of the variable once noised.</p> </li> <li> <code>uncertain_variable_name</code>               (<code>str</code>)           \u2013            <p>The name of the uncertain variable.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>BaseNoiser</code>           \u2013            <p>The discipline.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>TypeError</code>             \u2013            <p>If the class cannot be instantiated.</p> </li> </ul> Source code in <code>src/gemseo_umdo/disciplines/noiser_factory.py</code> <pre><code>def create(\n    self,\n    noiser_name: str,\n    variable_name: str,\n    noised_variable_name: str,\n    uncertain_variable_name: str,\n) -&gt; BaseNoiser:\n    \"\"\"\n    Args:\n        noiser_name: Either the class name or the short name\n            of the noising discipline.\n        variable_name: The name of the variable to be noised.\n        noised_variable_name: The name of the variable once noised.\n        uncertain_variable_name: The name of the uncertain variable.\n    \"\"\"  # noqa: D205 D212 D415\n    class_names = self.class_names\n    if noiser_name in class_names:\n        class_name = noiser_name\n    else:\n        class_name = self.__short_names_to_class_names[noiser_name]\n\n    return super().create(\n        class_name,\n        variable_name=variable_name,\n        noised_variable_name=noised_variable_name,\n        uncertain_variable_name=uncertain_variable_name,\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/","title":"Formulations","text":""},{"location":"reference/gemseo_umdo/formulations/#gemseo_umdo.formulations","title":"formulations","text":"<p>Formulations for multidisciplinary design problems under uncertainty.</p> <p>An MDOFormulation defines an OptimizationProblem from one or several MDODisciplines, a DesignSpace, an objective and constraints. The objective can be either minimized (default) or maximized.</p> <p>In the context of deterministic MDO, the OptimizationProblem is handled by a driver (see DriverLibrary), typically an optimizer (see OptimizationLibrary), or a design of experiments (DOE, see DOELibrary).</p> <p>In the frame of U-MDO, the BaseUMDOFormulation uses an MDOFormulation with a ParameterSpace defining the uncertain variables and executes the corresponding OptimizationProblem with a particular DOE. Then, it post-processed the associated Database to estimate the statistics applied to the objective and constraints.</p> <p>The most common BaseUMDOFormulation is Sampling, consisting in estimating the statistics with (quasi) Monte Carlo techniques.</p>"},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation/","title":"Base umdo formulation","text":""},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation/#gemseo_umdo.formulations.base_umdo_formulation","title":"base_umdo_formulation","text":"<p>Base class for U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation/#gemseo_umdo.formulations.base_umdo_formulation-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation/#gemseo_umdo.formulations.base_umdo_formulation.BaseUMDOFormulation","title":"BaseUMDOFormulation","text":"<pre><code>BaseUMDOFormulation(\n    disciplines: Sequence[MDODiscipline],\n    objective_name: str,\n    design_space: DesignSpace,\n    mdo_formulation: MDOFormulation,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    objective_statistic_parameters: Mapping[\n        str, Any\n    ] = READ_ONLY_EMPTY_DICT,\n    maximize_objective: bool = False,\n    grammar_type: GrammarType = MDODiscipline.GrammarType.JSON,\n    **options: Any\n)\n</code></pre> <p>               Bases: <code>BaseFormulation</code></p> <p>Base class for U-MDO formulations.</p> <p>A U-MDO formulation rewrites a multidisciplinary optimization problem under uncertainty, a.k.a. U-MDO problem, as a standard optimization problem without uncertainty.</p> <p>Parameters:</p> <ul> <li> <code>disciplines</code>               (<code>Sequence[MDODiscipline]</code>)           \u2013            <p>The disciplines.</p> </li> <li> <code>objective_name</code>               (<code>str</code>)           \u2013            <p>The name(s) of the discipline output(s) used as objective. If multiple names are passed, the objective will be a vector.</p> </li> <li> <code>design_space</code>               (<code>DesignSpace</code>)           \u2013            <p>The design space.</p> </li> <li> <code>mdo_formulation</code>               (<code>MDOFormulation</code>)           \u2013            <p>The class name of the MDO formulation, e.g. \"MDF\".</p> </li> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain variables with their probability distributions.</p> </li> <li> <code>objective_statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the objective.</p> </li> <li> <code>objective_statistic_parameters</code>               (<code>Mapping[str, Any]</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The values of the parameters of the statistic to be applied to the objective, if any.</p> </li> <li> <code>maximize_objective</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to maximize the objective.</p> </li> <li> <code>grammar_type</code>               (<code>GrammarType</code>, default:                   <code>JSON</code> )           \u2013            <p>The type of the input and output grammars.</p> </li> <li> <code>**options</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The options of the formulation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def __init__(\n    self,\n    disciplines: Sequence[MDODiscipline],\n    objective_name: str,\n    design_space: DesignSpace,\n    mdo_formulation: MDOFormulation,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    objective_statistic_parameters: Mapping[str, Any] = READ_ONLY_EMPTY_DICT,\n    maximize_objective: bool = False,\n    grammar_type: MDODiscipline.GrammarType = MDODiscipline.GrammarType.JSON,\n    **options: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        mdo_formulation: The class name of the MDO formulation, e.g. \"MDF\".\n        uncertain_space: The uncertain variables\n            with their probability distributions.\n        objective_statistic_name: The name of the statistic\n            to be applied to the objective.\n        objective_statistic_parameters: The values of the parameters\n            of the statistic to be applied to the objective, if any.\n    \"\"\"  # noqa: D205 D212 D415\n    objective_name = self.__compute_name(\n        objective_name,\n        objective_statistic_name,\n        **objective_statistic_parameters,\n    )\n    self._uncertain_space = uncertain_space\n    self._mdo_formulation = mdo_formulation\n    super().__init__(\n        disciplines,\n        objective_name,\n        design_space,\n        grammar_type=grammar_type,\n        **options,\n    )\n    self.__available_statistics = self._statistic_factory.class_names\n    sub_opt_problem = self._mdo_formulation.optimization_problem\n    objective = self._statistic_function_class(\n        self,\n        sub_opt_problem.objective,\n        MDOFunction.FunctionType.OBJ,\n        objective_statistic_name,\n        sub_opt_problem,\n        **objective_statistic_parameters,\n    )\n    objective.name = objective_name\n    self.optimization_problem.objective = objective\n    self.optimization_problem.minimize_objective = not maximize_objective\n    self.name = f\"{self.__class__.__name__}[{mdo_formulation.__class__.__name__}]\"\n    self.input_data_to_output_data = {}\n    self.optimization_problem.add_callback(self._clear_input_data_to_output_data)\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation/#gemseo_umdo.formulations.base_umdo_formulation.BaseUMDOFormulation-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation/#gemseo_umdo.formulations.base_umdo_formulation.BaseUMDOFormulation.available_statistics","title":"available_statistics  <code>property</code>","text":"<pre><code>available_statistics: list[str]\n</code></pre> <p>The names of the statistics to quantify the output uncertainties.</p>"},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation/#gemseo_umdo.formulations.base_umdo_formulation.BaseUMDOFormulation.input_data_to_output_data","title":"input_data_to_output_data  <code>instance-attribute</code>","text":"<pre><code>input_data_to_output_data: dict[\n    HashableNdarray, dict[str, Any]\n] = {}\n</code></pre> <p>The output samples or output statistics associated with the input data.</p>"},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation/#gemseo_umdo.formulations.base_umdo_formulation.BaseUMDOFormulation.mdo_formulation","title":"mdo_formulation  <code>property</code>","text":"<pre><code>mdo_formulation: MDOFormulation\n</code></pre> <p>The MDO formulation.</p>"},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation/#gemseo_umdo.formulations.base_umdo_formulation.BaseUMDOFormulation.uncertain_space","title":"uncertain_space  <code>property</code>","text":"<pre><code>uncertain_space: ParameterSpace\n</code></pre> <p>The uncertain variable space.</p>"},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation/#gemseo_umdo.formulations.base_umdo_formulation.BaseUMDOFormulation-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation/#gemseo_umdo.formulations.base_umdo_formulation.BaseUMDOFormulation.add_constraint","title":"add_constraint","text":"<pre><code>add_constraint(\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: ConstraintType = MDOFunction.ConstraintType.INEQ,\n    constraint_name: str | None = None,\n    value: float | None = None,\n    positive: bool = False,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Add an equality or inequality constraint to the optimization problem.</p> <p>An equality constraint is written as :math:<code>c(x)=a</code>, a positive inequality constraint is written as :math:<code>c(x)\\geq a</code> and a negative inequality constraint is written as :math:<code>c(x)\\leq a</code>.</p> <p>This constraint is in addition to those created by the formulation, e.g. consistency constraints in IDF.</p> <p>The strategy of repartition of the constraints is defined by the formulation.</p> <p>Parameters:</p> <ul> <li> <code>output_name</code>               (<code>str | Sequence[str]</code>)           \u2013            <p>The name(s) of the outputs computed by :math:<code>c(x)</code>. If several names are given, a single discipline must provide all outputs.</p> </li> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the constraint.</p> </li> <li> <code>constraint_type</code>               (<code>ConstraintType</code>, default:                   <code>INEQ</code> )           \u2013            <p>The type of constraint.</p> </li> <li> <code>constraint_name</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>The name of the constraint to be stored. If empty, the name of the constraint is generated from <code>output_name</code>, <code>constraint_type</code>, <code>value</code> and <code>positive</code>.</p> </li> <li> <code>value</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>The value :math:<code>a</code>.</p> </li> <li> <code>positive</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether the inequality constraint is positive.</p> </li> <li> <code>**statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def add_constraint(\n    self,\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: MDOFunction.ConstraintType = MDOFunction.ConstraintType.INEQ,\n    constraint_name: str | None = None,\n    value: float | None = None,\n    positive: bool = False,\n    **statistic_parameters: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        statistic_name: The name of the statistic to be applied to the constraint.\n        statistic_parameters: The values of the parameters of the statistic\n            to be applied to the constraint, if any.\n    \"\"\"  # noqa: D205 D212 D415\n    self._mdo_formulation.add_observable(output_name)\n    sub_opt_problem = self._mdo_formulation.optimization_problem\n    constraint = self._statistic_function_class(\n        self,\n        sub_opt_problem.observables[-1],\n        MDOFunction.FunctionType.NONE,\n        statistic_name,\n        sub_opt_problem,\n        **statistic_parameters,\n    )\n    name = self.__compute_name(output_name, statistic_name, **statistic_parameters)\n    constraint.output_names = [name]\n    if constraint_name is None:\n        constraint.name = name\n        constraint.has_default_name = True\n    else:\n        constraint.name = constraint_name\n        constraint.has_default_name = False\n    self.optimization_problem.add_constraint(\n        constraint,\n        value=value,\n        positive=positive,\n        constraint_type=constraint_type,\n    )\n    self._post_add_constraint()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation/#gemseo_umdo.formulations.base_umdo_formulation.BaseUMDOFormulation.add_observable","title":"add_observable","text":"<pre><code>add_observable(\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: str = \"\",\n    discipline: MDODiscipline | None = None,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Add an observable to the optimization problem.</p> <p>The repartition strategy of the observable is defined in the formulation class.</p> <p>Parameters:</p> <ul> <li> <code>output_names</code>               (<code>Sequence[str]</code>)           \u2013            <p>The name(s) of the output(s) to observe.</p> </li> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the observable.</p> </li> <li> <code>observable_name</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>The name of the observable. If empty, the output name is used by default.</p> </li> <li> <code>discipline</code>               (<code>MDODiscipline | None</code>, default:                   <code>None</code> )           \u2013            <p>The discipline computing the observed outputs. If <code>None</code>, the discipline is detected from inner disciplines.</p> </li> <li> <code>**statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def add_observable(\n    self,\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: str = \"\",\n    discipline: MDODiscipline | None = None,\n    **statistic_parameters: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        statistic_name: The name of the statistic to be applied to the observable.\n        statistic_parameters: The values of the parameters\n            of the statistic to be applied to the observable, if any.\n    \"\"\"  # noqa: D205 D212 D415\n    self._mdo_formulation.add_observable(\n        output_names,\n        observable_name=observable_name,\n        discipline=discipline,\n    )\n    sub_opt_problem = self._mdo_formulation.optimization_problem\n    observable = self._statistic_function_class(\n        self,\n        sub_opt_problem.observables[-1],\n        MDOFunction.FunctionType.NONE,\n        statistic_name,\n        sub_opt_problem,\n        **statistic_parameters,\n    )\n    observable.name = self.__compute_name(\n        observable_name or output_names, statistic_name, **statistic_parameters\n    )\n    self.optimization_problem.add_observable(observable)\n    self._post_add_observable()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation/#gemseo_umdo.formulations.base_umdo_formulation.BaseUMDOFormulation.get_expected_dataflow","title":"get_expected_dataflow","text":"<pre><code>get_expected_dataflow() -&gt; (\n    list[tuple[MDODiscipline, MDODiscipline, list[str]]]\n)\n</code></pre> <p>Get the expected data exchange sequence.</p> <p>This method is used for the XDSM representation and can be overloaded by subclasses.</p> <p>Returns:</p> <ul> <li> <code>list[tuple[MDODiscipline, MDODiscipline, list[str]]]</code>           \u2013            <p>The expected sequence of data exchange where the i-th item is described by the starting discipline, the ending discipline and the coupling variables.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def get_expected_dataflow(  # noqa: D102\n    self,\n) -&gt; list[tuple[MDODiscipline, MDODiscipline, list[str]]]:\n    return self._mdo_formulation.get_expected_dataflow()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation/#gemseo_umdo.formulations.base_umdo_formulation.BaseUMDOFormulation.get_expected_workflow","title":"get_expected_workflow","text":"<pre><code>get_expected_workflow() -&gt; (\n    list[ExecutionSequence, tuple[ExecutionSequence]]\n)\n</code></pre> <p>Get the expected sequence of execution of the disciplines.</p> <p>This method is used for the XDSM representation and can be overloaded by subclasses.</p> <p>For instance:</p> <ul> <li>[A, B] denotes the execution of A,   then the execution of B</li> <li>(A, B) denotes the concurrent execution of A and B</li> <li>[A, (B, C), D] denotes the execution of A,   then the concurrent execution of B and C,   then the execution of D.</li> </ul> <p>Returns:</p> <ul> <li> <code>list[ExecutionSequence, tuple[ExecutionSequence]]</code>           \u2013            <p>A sequence of elements which are either an :class:<code>.ExecutionSequence</code> or a tuple of :class:<code>.ExecutionSequence</code> for concurrent execution.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def get_expected_workflow(  # noqa: D102\n    self,\n) -&gt; list[ExecutionSequence, tuple[ExecutionSequence]]:\n    return self._mdo_formulation.get_expected_workflow()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation/#gemseo_umdo.formulations.base_umdo_formulation.BaseUMDOFormulation.get_top_level_disc","title":"get_top_level_disc","text":"<pre><code>get_top_level_disc() -&gt; list[MDODiscipline]\n</code></pre> <p>Return the disciplines which inputs are required to run the scenario.</p> <p>A formulation seeks to compute the objective and constraints from the input variables. It structures the optimization problem into multiple levels of disciplines. The disciplines directly depending on these inputs are called top level disciplines.</p> <p>By default, this method returns all disciplines. This method can be overloaded by subclasses.</p> <p>Returns:</p> <ul> <li> <code>list[MDODiscipline]</code>           \u2013            <p>The top level disciplines.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def get_top_level_disc(self) -&gt; list[MDODiscipline]:  # noqa: D102\n    return self._mdo_formulation.get_top_level_disc()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation/#gemseo_umdo.formulations.base_umdo_formulation.BaseUMDOFormulation.update_top_level_disciplines","title":"update_top_level_disciplines","text":"<pre><code>update_top_level_disciplines(\n    design_values: RealArray,\n) -&gt; None\n</code></pre> <p>Update the default input values of the top-level disciplines.</p> <p>Parameters:</p> <ul> <li> <code>design_values</code>               (<code>RealArray</code>)           \u2013            <p>The values of the design variables to update the default input values of the top-level disciplines.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def update_top_level_disciplines(self, design_values: RealArray) -&gt; None:\n    \"\"\"Update the default input values of the top-level disciplines.\n\n    Args:\n        design_values: The values of the design variables\n            to update the default input values of the top-level disciplines.\n    \"\"\"\n    design_values = split_array_to_dict_of_arrays(\n        design_values,\n        self.design_space.variable_sizes,\n        self.design_space.variable_names,\n    )\n    for discipline in self._mdo_formulation.get_top_level_disc():\n        discipline.default_inputs.update({\n            k: v for k, v in design_values.items() if k in discipline.input_grammar\n        })\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/control_variate/","title":"Control variate","text":""},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate","title":"control_variate","text":"<p>Control variate-based U-MDO formulation.</p> <p>ControlVariate is an BaseUMDOFormulation estimating the statistics with first-order Taylor polynomials as control variates:</p> \\[\\tilde{f}(x,u)=f(x,\\mu) + (u-\\mu)\\frac{\\partial f(x,\\mu)}{\\partial u}\\] <p>where \\(u\\) is a realization of the random variable \\(U\\) and \\(\\mu=\\mathbb{E}[U]\\).</p> <p>The expectation \\(\\mathbb{E}[f(x,U)]\\) can be approximated by the control variate estimator</p> \\[\\frac{1}{N}\\sum_{i=1}^N f\\left(x,U^{(i)}\\right) +\\alpha_N\\left(\\frac{1}{N}\\sum_{j=1}^N \\tilde{f}\\left(x,U^{(j)}\\right)-f(x,\\mu)\\right)\\] <p>where \\(\\alpha_N\\) is the empirical estimator of \\(\\frac{\\text{cov}\\left[f(x,U),\\tilde{f}(x,u)\\right]} {\\mathbb{V}\\left[f(x,U)\\right]}\\) and \\(U^{(1)},\\ldots,U^{(N)}\\) are \\(N\\) independent realizations of \\(U\\).</p>"},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate.ControlVariate","title":"ControlVariate","text":"<pre><code>ControlVariate(\n    disciplines: Sequence[MDODiscipline],\n    objective_name: str,\n    design_space: DesignSpace,\n    mdo_formulation: MDOFormulation,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    n_samples: int,\n    objective_statistic_parameters: Mapping[\n        str, Any\n    ] = READ_ONLY_EMPTY_DICT,\n    maximize_objective: bool = False,\n    grammar_type: GrammarType = MDODiscipline.GrammarType.JSON,\n    algo: str = OpenTURNS.OT_LHSO,\n    algo_options: Mapping[str, Any] = READ_ONLY_EMPTY_DICT,\n    seed: int = SEED,\n    **options: Any\n)\n</code></pre> <p>               Bases: <code>BaseUMDOFormulation</code></p> <p>Control variate-based U-MDO formulation.</p> <p>DOE algorithms</p> <p>This formulation uses a DOE algorithm; read the GEMSEO documentation. for more information about the available DOE algorithm names and options.</p> <p>Parameters:</p> <ul> <li> <code>disciplines</code>               (<code>Sequence[MDODiscipline]</code>)           \u2013            <p>The disciplines.</p> </li> <li> <code>objective_name</code>               (<code>str</code>)           \u2013            <p>The name(s) of the discipline output(s) used as objective. If multiple names are passed, the objective will be a vector.</p> </li> <li> <code>design_space</code>               (<code>DesignSpace</code>)           \u2013            <p>The design space.</p> </li> <li> <code>mdo_formulation</code>               (<code>MDOFormulation</code>)           \u2013            <p>The class name of the MDO formulation, e.g. \"MDF\".</p> </li> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain variables with their probability distributions.</p> </li> <li> <code>objective_statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the objective.</p> </li> <li> <code>n_samples</code>               (<code>int</code>)           \u2013            <p>The number of samples, i.e. the size of the DOE.</p> </li> <li> <code>objective_statistic_parameters</code>               (<code>Mapping[str, Any]</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The values of the parameters of the statistic to be applied to the objective, if any.</p> </li> <li> <code>maximize_objective</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to maximize the objective.</p> </li> <li> <code>grammar_type</code>               (<code>GrammarType</code>, default:                   <code>JSON</code> )           \u2013            <p>The type of the input and output grammars.</p> </li> <li> <code>algo</code>               (<code>str</code>, default:                   <code>OT_LHSO</code> )           \u2013            <p>The name of the DOE algorithm.</p> </li> <li> <code>algo_options</code>               (<code>Mapping[str, Any]</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The options of the DOE algorithm.</p> </li> <li> <code>seed</code>               (<code>int</code>, default:                   <code>SEED</code> )           \u2013            <p>The seed for reproducibility.</p> </li> <li> <code>**options</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The options of the formulation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/control_variate.py</code> <pre><code>def __init__(\n    self,\n    disciplines: Sequence[MDODiscipline],\n    objective_name: str,\n    design_space: DesignSpace,\n    mdo_formulation: MDOFormulation,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    n_samples: int,\n    objective_statistic_parameters: Mapping[str, Any] = READ_ONLY_EMPTY_DICT,\n    maximize_objective: bool = False,\n    grammar_type: MDODiscipline.GrammarType = MDODiscipline.GrammarType.JSON,\n    algo: str = OpenTURNS.OT_LHSO,\n    algo_options: Mapping[str, Any] = READ_ONLY_EMPTY_DICT,\n    seed: int = SEED,\n    **options: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        n_samples: The number of samples, i.e. the size of the DOE.\n        algo: The name of the DOE algorithm.\n        algo_options: The options of the DOE algorithm.\n        seed: The seed for reproducibility.\n    \"\"\"  # noqa: D205 D212 D415\n    self._statistic_function_class = StatisticFunctionForControlVariate\n    self._statistic_factory = ControlVariateEstimatorFactory()\n    self.__doe_algo = DOELibraryFactory().create(algo)\n    self.__doe_algo_options = dict(algo_options)\n    self.__doe_algo_options[\"n_samples\"] = n_samples\n    self.__n_samples = n_samples\n    self.__seed = seed\n    super().__init__(\n        disciplines,\n        objective_name,\n        design_space,\n        mdo_formulation,\n        uncertain_space,\n        objective_statistic_name,\n        objective_statistic_parameters=objective_statistic_parameters,\n        maximize_objective=maximize_objective,\n        grammar_type=grammar_type,\n        **options,\n    )\n    mdo_formulation = self._mdo_formulation\n    self.__linearization_problem = OptimizationProblem(self.uncertain_space)\n    self.__linearization_problem.objective = (\n        mdo_formulation.optimization_problem.objective\n    )\n    self.name = (\n        f\"{self.__class__.__name__}\"\n        f\"[{mdo_formulation.__class__.__name__}; {algo}({n_samples})]\"\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate.ControlVariate-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate.ControlVariate.available_statistics","title":"available_statistics  <code>property</code>","text":"<pre><code>available_statistics: list[str]\n</code></pre> <p>The names of the statistics to quantify the output uncertainties.</p>"},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate.ControlVariate.doe_algo","title":"doe_algo  <code>property</code>","text":"<pre><code>doe_algo: DOELibrary\n</code></pre> <p>The DOE library configured with an algorithm.</p>"},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate.ControlVariate.input_data_to_output_data","title":"input_data_to_output_data  <code>instance-attribute</code>","text":"<pre><code>input_data_to_output_data: dict[\n    HashableNdarray, dict[str, Any]\n] = {}\n</code></pre> <p>The output samples or output statistics associated with the input data.</p>"},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate.ControlVariate.linearization_problem","title":"linearization_problem  <code>property</code>","text":"<pre><code>linearization_problem: OptimizationProblem\n</code></pre> <p>The problem related to the linearization of the functions.</p>"},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate.ControlVariate.mdo_formulation","title":"mdo_formulation  <code>property</code>","text":"<pre><code>mdo_formulation: MDOFormulation\n</code></pre> <p>The MDO formulation.</p>"},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate.ControlVariate.uncertain_space","title":"uncertain_space  <code>property</code>","text":"<pre><code>uncertain_space: ParameterSpace\n</code></pre> <p>The uncertain variable space.</p>"},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate.ControlVariate-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate.ControlVariate.add_constraint","title":"add_constraint","text":"<pre><code>add_constraint(\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: ConstraintType = MDOFunction.ConstraintType.INEQ,\n    constraint_name: str | None = None,\n    value: float | None = None,\n    positive: bool = False,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Add an equality or inequality constraint to the optimization problem.</p> <p>An equality constraint is written as :math:<code>c(x)=a</code>, a positive inequality constraint is written as :math:<code>c(x)\\geq a</code> and a negative inequality constraint is written as :math:<code>c(x)\\leq a</code>.</p> <p>This constraint is in addition to those created by the formulation, e.g. consistency constraints in IDF.</p> <p>The strategy of repartition of the constraints is defined by the formulation.</p> <p>Parameters:</p> <ul> <li> <code>output_name</code>               (<code>str | Sequence[str]</code>)           \u2013            <p>The name(s) of the outputs computed by :math:<code>c(x)</code>. If several names are given, a single discipline must provide all outputs.</p> </li> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the constraint.</p> </li> <li> <code>constraint_type</code>               (<code>ConstraintType</code>, default:                   <code>INEQ</code> )           \u2013            <p>The type of constraint.</p> </li> <li> <code>constraint_name</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>The name of the constraint to be stored. If empty, the name of the constraint is generated from <code>output_name</code>, <code>constraint_type</code>, <code>value</code> and <code>positive</code>.</p> </li> <li> <code>value</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>The value :math:<code>a</code>.</p> </li> <li> <code>positive</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether the inequality constraint is positive.</p> </li> <li> <code>**statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def add_constraint(\n    self,\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: MDOFunction.ConstraintType = MDOFunction.ConstraintType.INEQ,\n    constraint_name: str | None = None,\n    value: float | None = None,\n    positive: bool = False,\n    **statistic_parameters: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        statistic_name: The name of the statistic to be applied to the constraint.\n        statistic_parameters: The values of the parameters of the statistic\n            to be applied to the constraint, if any.\n    \"\"\"  # noqa: D205 D212 D415\n    self._mdo_formulation.add_observable(output_name)\n    sub_opt_problem = self._mdo_formulation.optimization_problem\n    constraint = self._statistic_function_class(\n        self,\n        sub_opt_problem.observables[-1],\n        MDOFunction.FunctionType.NONE,\n        statistic_name,\n        sub_opt_problem,\n        **statistic_parameters,\n    )\n    name = self.__compute_name(output_name, statistic_name, **statistic_parameters)\n    constraint.output_names = [name]\n    if constraint_name is None:\n        constraint.name = name\n        constraint.has_default_name = True\n    else:\n        constraint.name = constraint_name\n        constraint.has_default_name = False\n    self.optimization_problem.add_constraint(\n        constraint,\n        value=value,\n        positive=positive,\n        constraint_type=constraint_type,\n    )\n    self._post_add_constraint()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate.ControlVariate.add_observable","title":"add_observable","text":"<pre><code>add_observable(\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: str = \"\",\n    discipline: MDODiscipline | None = None,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Add an observable to the optimization problem.</p> <p>The repartition strategy of the observable is defined in the formulation class.</p> <p>Parameters:</p> <ul> <li> <code>output_names</code>               (<code>Sequence[str]</code>)           \u2013            <p>The name(s) of the output(s) to observe.</p> </li> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the observable.</p> </li> <li> <code>observable_name</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>The name of the observable. If empty, the output name is used by default.</p> </li> <li> <code>discipline</code>               (<code>MDODiscipline | None</code>, default:                   <code>None</code> )           \u2013            <p>The discipline computing the observed outputs. If <code>None</code>, the discipline is detected from inner disciplines.</p> </li> <li> <code>**statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def add_observable(\n    self,\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: str = \"\",\n    discipline: MDODiscipline | None = None,\n    **statistic_parameters: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        statistic_name: The name of the statistic to be applied to the observable.\n        statistic_parameters: The values of the parameters\n            of the statistic to be applied to the observable, if any.\n    \"\"\"  # noqa: D205 D212 D415\n    self._mdo_formulation.add_observable(\n        output_names,\n        observable_name=observable_name,\n        discipline=discipline,\n    )\n    sub_opt_problem = self._mdo_formulation.optimization_problem\n    observable = self._statistic_function_class(\n        self,\n        sub_opt_problem.observables[-1],\n        MDOFunction.FunctionType.NONE,\n        statistic_name,\n        sub_opt_problem,\n        **statistic_parameters,\n    )\n    observable.name = self.__compute_name(\n        observable_name or output_names, statistic_name, **statistic_parameters\n    )\n    self.optimization_problem.add_observable(observable)\n    self._post_add_observable()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate.ControlVariate.compute_samples","title":"compute_samples","text":"<pre><code>compute_samples(\n    problem: OptimizationProblem, input_data: RealArray\n) -&gt; None\n</code></pre> <p>Evaluate the functions of a problem with a DOE algorithm.</p> <p>Parameters:</p> <ul> <li> <code>problem</code>               (<code>OptimizationProblem</code>)           \u2013            <p>The problem.</p> </li> <li> <code>input_data</code>               (<code>RealArray</code>)           \u2013            <p>The input point at which to estimate the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/control_variate.py</code> <pre><code>def compute_samples(\n    self, problem: OptimizationProblem, input_data: RealArray\n) -&gt; None:\n    \"\"\"Evaluate the functions of a problem with a DOE algorithm.\n\n    Args:\n        problem: The problem.\n        input_data: The input point at which to estimate the statistic.\n    \"\"\"\n    with LoggingContext(logging.getLogger(\"gemseo\")):\n        self.__doe_algo.seed = self.__seed\n        self.__doe_algo.execute(problem, **self.__doe_algo_options)\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate.ControlVariate.evaluate_with_mean","title":"evaluate_with_mean","text":"<pre><code>evaluate_with_mean() -&gt; None\n</code></pre> <p>Evaluate the Taylor polynomials at the mean value of the uncertain vector.</p> Source code in <code>src/gemseo_umdo/formulations/control_variate.py</code> <pre><code>def evaluate_with_mean(self) -&gt; None:\n    \"\"\"Evaluate the Taylor polynomials at the mean value of the uncertain vector.\"\"\"\n    if self.__linearization_problem.nonproc_objective is None:\n        self.__linearization_problem.preprocess_functions(\n            is_function_input_normalized=False, eval_obs_jac=True\n        )\n    self.__linearization_problem.evaluate_functions(\n        self._uncertain_space.distribution.mean, eval_jac=True\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate.ControlVariate.get_expected_dataflow","title":"get_expected_dataflow","text":"<pre><code>get_expected_dataflow() -&gt; (\n    list[tuple[MDODiscipline, MDODiscipline, list[str]]]\n)\n</code></pre> <p>Get the expected data exchange sequence.</p> <p>This method is used for the XDSM representation and can be overloaded by subclasses.</p> <p>Returns:</p> <ul> <li> <code>list[tuple[MDODiscipline, MDODiscipline, list[str]]]</code>           \u2013            <p>The expected sequence of data exchange where the i-th item is described by the starting discipline, the ending discipline and the coupling variables.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def get_expected_dataflow(  # noqa: D102\n    self,\n) -&gt; list[tuple[MDODiscipline, MDODiscipline, list[str]]]:\n    return self._mdo_formulation.get_expected_dataflow()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate.ControlVariate.get_expected_workflow","title":"get_expected_workflow","text":"<pre><code>get_expected_workflow() -&gt; (\n    list[ExecutionSequence, tuple[ExecutionSequence]]\n)\n</code></pre> <p>Get the expected sequence of execution of the disciplines.</p> <p>This method is used for the XDSM representation and can be overloaded by subclasses.</p> <p>For instance:</p> <ul> <li>[A, B] denotes the execution of A,   then the execution of B</li> <li>(A, B) denotes the concurrent execution of A and B</li> <li>[A, (B, C), D] denotes the execution of A,   then the concurrent execution of B and C,   then the execution of D.</li> </ul> <p>Returns:</p> <ul> <li> <code>list[ExecutionSequence, tuple[ExecutionSequence]]</code>           \u2013            <p>A sequence of elements which are either an :class:<code>.ExecutionSequence</code> or a tuple of :class:<code>.ExecutionSequence</code> for concurrent execution.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def get_expected_workflow(  # noqa: D102\n    self,\n) -&gt; list[ExecutionSequence, tuple[ExecutionSequence]]:\n    return self._mdo_formulation.get_expected_workflow()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate.ControlVariate.get_top_level_disc","title":"get_top_level_disc","text":"<pre><code>get_top_level_disc() -&gt; list[MDODiscipline]\n</code></pre> <p>Return the disciplines which inputs are required to run the scenario.</p> <p>A formulation seeks to compute the objective and constraints from the input variables. It structures the optimization problem into multiple levels of disciplines. The disciplines directly depending on these inputs are called top level disciplines.</p> <p>By default, this method returns all disciplines. This method can be overloaded by subclasses.</p> <p>Returns:</p> <ul> <li> <code>list[MDODiscipline]</code>           \u2013            <p>The top level disciplines.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def get_top_level_disc(self) -&gt; list[MDODiscipline]:  # noqa: D102\n    return self._mdo_formulation.get_top_level_disc()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate.ControlVariate.update_top_level_disciplines","title":"update_top_level_disciplines","text":"<pre><code>update_top_level_disciplines(\n    design_values: RealArray,\n) -&gt; None\n</code></pre> <p>Update the default input values of the top-level disciplines.</p> <p>Parameters:</p> <ul> <li> <code>design_values</code>               (<code>RealArray</code>)           \u2013            <p>The values of the design variables to update the default input values of the top-level disciplines.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def update_top_level_disciplines(self, design_values: RealArray) -&gt; None:\n    \"\"\"Update the default input values of the top-level disciplines.\n\n    Args:\n        design_values: The values of the design variables\n            to update the default input values of the top-level disciplines.\n    \"\"\"\n    design_values = split_array_to_dict_of_arrays(\n        design_values,\n        self.design_space.variable_sizes,\n        self.design_space.variable_names,\n    )\n    for discipline in self._mdo_formulation.get_top_level_disc():\n        discipline.default_inputs.update({\n            k: v for k, v in design_values.items() if k in discipline.input_grammar\n        })\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/factory/","title":"Factory","text":""},{"location":"reference/gemseo_umdo/formulations/factory/#gemseo_umdo.formulations.factory","title":"factory","text":"<p>Factory of U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/factory/#gemseo_umdo.formulations.factory-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/factory/#gemseo_umdo.formulations.factory.UMDOFormulationsFactory","title":"UMDOFormulationsFactory","text":"<p>               Bases: <code>MDOFormulationFactory</code></p> <p>The factory of U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/","title":"Pce","text":""},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce","title":"pce","text":"<p>PCE-based U-MDO formulation.</p> <p>PCE is an BaseUMDOFormulation estimating the statistics from the coefficients of a polynomial chaos expansion (PCE).</p> <p>E.g.</p> \\[\\mathbb{E}[f(x,U)] \\approx \\alpha_0\\] <p>or</p> \\[\\mathbb{V}[f(x,U)] \\approx \\sum_{1&lt;i\\leq P}\\alpha_i^2\\] <p>where \\((\\alpha_i)_{1\\leq i \\leq N}\\) are the coefficients of the PCE</p> \\[\\hat{f}_x(U)=\\alpha_0 + \\sum_{1&lt;i\\leq P}\\alpha_i\\Phi_i(U)\\] <p>built at \\(x\\) over the uncertain space.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE","title":"PCE","text":"<pre><code>PCE(\n    disciplines: Sequence[MDODiscipline],\n    objective_name: str,\n    design_space: DesignSpace,\n    mdo_formulation: MDOFormulation,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    objective_statistic_parameters: Mapping[\n        str, Any\n    ] = READ_ONLY_EMPTY_DICT,\n    maximize_objective: bool = False,\n    grammar_type: GrammarType = MDODiscipline.GrammarType.JSON,\n    doe_algo: str = OpenTURNS.OT_LHSO,\n    doe_algo_options: Mapping[\n        str, Any\n    ] = READ_ONLY_EMPTY_DICT,\n    doe_n_samples: int | None = None,\n    doe_seed: int = SEED,\n    pce_options: Mapping[str, Any] = READ_ONLY_EMPTY_DICT,\n    quality_name: str = \"R2Measure\",\n    quality_threshold: (\n        float | Mapping[str, float | Iterable[float]]\n    ) = 0.9,\n    quality_cv_compute: bool = True,\n    quality_cv_n_folds: int = 5,\n    quality_cv_randomize: bool = True,\n    quality_cv_seed: int | None = None,\n    quality_cv_threshold: (\n        float | Mapping[str, float | Iterable[float]]\n    ) = 0.8,\n    **options: Any\n)\n</code></pre> <p>               Bases: <code>BaseUMDOFormulation</code></p> <p>PCE-based U-MDO formulation.</p> <p>DOE algorithms</p> <p>This formulation uses a DOE algorithm; read the GEMSEO documentation. for more information about the available DOE algorithm names and options.</p> <p>Parameters:</p> <ul> <li> <code>disciplines</code>               (<code>Sequence[MDODiscipline]</code>)           \u2013            <p>The disciplines.</p> </li> <li> <code>objective_name</code>               (<code>str</code>)           \u2013            <p>The name(s) of the discipline output(s) used as objective. If multiple names are passed, the objective will be a vector.</p> </li> <li> <code>design_space</code>               (<code>DesignSpace</code>)           \u2013            <p>The design space.</p> </li> <li> <code>mdo_formulation</code>               (<code>MDOFormulation</code>)           \u2013            <p>The class name of the MDO formulation, e.g. \"MDF\".</p> </li> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain variables with their probability distributions.</p> </li> <li> <code>objective_statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the objective.</p> </li> <li> <code>objective_statistic_parameters</code>               (<code>Mapping[str, Any]</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The values of the parameters of the statistic to be applied to the objective, if any.</p> </li> <li> <code>maximize_objective</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to maximize the objective.</p> </li> <li> <code>grammar_type</code>               (<code>GrammarType</code>, default:                   <code>JSON</code> )           \u2013            <p>The type of the input and output grammars.</p> </li> <li> <code>doe_algo</code>               (<code>str</code>, default:                   <code>OT_LHSO</code> )           \u2013            <p>The name of the DOE algorithm.</p> </li> <li> <code>doe_algo_options</code>               (<code>Mapping[str, Any]</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The options of the DOE algorithm.</p> </li> <li> <code>doe_n_samples</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>The number of samples to be generated by the DOE algorithm. If <code>None</code>, the DOE algorithm does not use <code>doe_n_samples</code> argument but potentially a mandatory argument to be defined in <code>doe_algo_options</code> (e.g. <code>samples</code> for the <code>CustomDOE</code> algorithm).</p> </li> <li> <code>doe_seed</code>               (<code>int</code>, default:                   <code>SEED</code> )           \u2013            <p>The seed for reproducibility.</p> </li> <li> <code>pce_options</code>               (<code>Mapping[str, Any]</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The options of the PCERegressor.</p> </li> <li> <code>quality_name</code>               (<code>str</code>, default:                   <code>'R2Measure'</code> )           \u2013            <p>The name of the measure to assess the quality of the PCE regressor.</p> </li> <li> <code>quality_threshold</code>               (<code>float | Mapping[str, float | Iterable[float]]</code>, default:                   <code>0.9</code> )           \u2013            <p>The learning quality threshold below which a warning is logged.</p> </li> <li> <code>quality_cv_compute</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to estimate the quality by cross-validation (CV).</p> </li> <li> <code>quality_cv_n_folds</code>               (<code>int</code>, default:                   <code>5</code> )           \u2013            <p>The description is missing.</p> </li> <li> <code>quality_cv_randomize</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to shuffle the samples before dividing them in folds in the case of the CV technique.</p> </li> <li> <code>quality_cv_seed</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>The seed of the pseudo-random number generator. If <code>None</code>, an unpredictable generator is used.</p> </li> <li> <code>quality_cv_threshold</code>               (<code>float | Mapping[str, float | Iterable[float]]</code>, default:                   <code>0.8</code> )           \u2013            <p>The CV quality threshold below which a warning is logged.</p> </li> <li> <code>**options</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The options of the formulation.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>When <code>n_samples</code> is <code>None</code>, whereas it is required by the DOE algorithm.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/pce.py</code> <pre><code>def __init__(\n    self,\n    disciplines: Sequence[MDODiscipline],\n    objective_name: str,\n    design_space: DesignSpace,\n    mdo_formulation: MDOFormulation,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    objective_statistic_parameters: Mapping[str, Any] = READ_ONLY_EMPTY_DICT,\n    maximize_objective: bool = False,\n    grammar_type: MDODiscipline.GrammarType = MDODiscipline.GrammarType.JSON,\n    doe_algo: str = OpenTURNS.OT_LHSO,\n    doe_algo_options: Mapping[str, Any] = READ_ONLY_EMPTY_DICT,\n    doe_n_samples: int | None = None,\n    doe_seed: int = SEED,\n    pce_options: Mapping[str, Any] = READ_ONLY_EMPTY_DICT,\n    quality_name: str = \"R2Measure\",\n    quality_threshold: float | Mapping[str, float | Iterable[float]] = 0.9,\n    quality_cv_compute: bool = True,\n    quality_cv_n_folds: int = 5,\n    quality_cv_randomize: bool = True,\n    quality_cv_seed: int | None = None,\n    quality_cv_threshold: float | Mapping[str, float | Iterable[float]] = 0.8,\n    **options: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        doe_n_samples: The number of samples to be generated by the DOE algorithm.\n            If `None`,\n            the DOE algorithm does not use `doe_n_samples` argument\n            but potentially a mandatory argument to be defined in `doe_algo_options`\n            (e.g. `samples` for the `CustomDOE` algorithm).\n        doe_algo: The name of the DOE algorithm.\n        doe_algo_options: The options of the DOE algorithm.\n        doe_seed: The seed for reproducibility.\n        pce_options: The options of the\n            [PCERegressor][gemseo.mlearning.regression.algos.pce.PCERegressor].\n        quality_threshold: The learning quality threshold\n            below which a warning is logged.\n        quality_name: The name of the measure\n            to assess the quality of the PCE regressor.\n        quality_cv_compute: Whether to estimate the quality\n            by cross-validation (CV).\n        quality_n_folds: The number of folds in the case of the CV technique.\n        quality_cv_randomize: Whether to shuffle the samples\n            before dividing them in folds in the case of the CV technique.\n        quality_cv_seed: The seed of the pseudo-random number generator.\n            If ``None``,\n            an unpredictable generator is used.\n        quality_cv_threshold: The CV quality threshold\n            below which a warning is logged.\n\n    Raises:\n        ValueError: When `n_samples` is `None`,\n            whereas it is required by the DOE algorithm.\n    \"\"\"  # noqa: D205 D212 D415\n    self.input_data_to_output_samples = {}\n    self._statistic_factory = PCEEstimatorFactory()\n    self._statistic_function_class = StatisticFunctionForPCE\n    self.__doe_algo = DOELibraryFactory().create(doe_algo)\n    self.__doe_algo_options = dict(doe_algo_options)\n    if DOELibrary.N_SAMPLES in self.__doe_algo.option_grammar:\n        if doe_n_samples is None:\n            msg = (\n                \"The doe_n_samples argument of the U-MDO formulation 'PCE' \"\n                \"is required.\"\n            )\n            raise ValueError(msg)\n        self.__doe_algo_options[DOELibrary.N_SAMPLES] = doe_n_samples\n\n    if DOELibrary.SEED in self.__doe_algo.option_grammar:\n        self.__doe_algo_options[DOELibrary.SEED] = doe_seed\n\n    self.__n_samples = doe_n_samples\n    self._estimators = []\n    self.pce_options = pce_options\n    self.quality = RegressorQualityFactory().get_class(quality_name)\n    if quality_cv_compute:\n        self.quality_cv_options = {\n            \"n_folds\": quality_cv_n_folds,\n            \"seed\": quality_cv_seed,\n            \"randomize\": quality_cv_randomize,\n        }\n    else:\n        self.quality_cv_options = {}\n\n    self.quality_threshold = quality_threshold\n    self.quality_cv_threshold = quality_cv_threshold\n    super().__init__(\n        disciplines,\n        objective_name,\n        design_space,\n        mdo_formulation,\n        uncertain_space,\n        objective_statistic_name,\n        objective_statistic_options=objective_statistic_parameters,\n        maximize_objective=maximize_objective,\n        grammar_type=grammar_type,\n        **options,\n    )\n    mdo_formulation = self._mdo_formulation.__class__.__name__\n    formulation = self.__class__.__name__\n    self.name = f\"{formulation}[{mdo_formulation}; {doe_algo}({doe_n_samples})]\"\n    smaller_is_better = self.quality.SMALLER_IS_BETTER\n    self.is_pce_quality_bad = gt if smaller_is_better else lt\n    self.quality_operators = (\"&lt;=\", \"&gt;\") if smaller_is_better else (\"&gt;=\", \"&lt;\")\n    self.threshold = {}\n    self.cv_threshold = {}\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.available_statistics","title":"available_statistics  <code>property</code>","text":"<pre><code>available_statistics: list[str]\n</code></pre> <p>The names of the statistics to quantify the output uncertainties.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.cv_threshold","title":"cv_threshold  <code>instance-attribute</code>","text":"<pre><code>cv_threshold: dict[str, RealArray] = {}\n</code></pre> <p>The cross-validation threshold component-wise.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.input_data_to_output_data","title":"input_data_to_output_data  <code>instance-attribute</code>","text":"<pre><code>input_data_to_output_data: dict[\n    HashableNdarray, dict[str, Any]\n] = {}\n</code></pre> <p>The output samples or output statistics associated with the input data.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.is_pce_quality_bad","title":"is_pce_quality_bad  <code>instance-attribute</code>","text":"<pre><code>is_pce_quality_bad: Callable[[float, float], bool] = (\n    gt if smaller_is_better else lt\n)\n</code></pre> <p>A function to indicate if the PCE has a good quality for an output component.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.mdo_formulation","title":"mdo_formulation  <code>property</code>","text":"<pre><code>mdo_formulation: MDOFormulation\n</code></pre> <p>The MDO formulation.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.pce_options","title":"pce_options  <code>instance-attribute</code>","text":"<pre><code>pce_options: Mapping[str, Any] = pce_options\n</code></pre> <p>The PCERegressor options.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.quality","title":"quality  <code>instance-attribute</code>","text":"<pre><code>quality: type[BaseRegressorQuality] = get_class(\n    quality_name\n)\n</code></pre> <p>The class to assess the quality of the PCE regressor.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.quality_cv_options","title":"quality_cv_options  <code>instance-attribute</code>","text":"<pre><code>quality_cv_options: dict[str, bool | int | None]\n</code></pre> <p>The options of the CV technique; if empty, do not use it.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.quality_cv_threshold","title":"quality_cv_threshold  <code>instance-attribute</code>","text":"<pre><code>quality_cv_threshold: (\n    float | Mapping[str, float | Iterable[float]]\n) = quality_cv_threshold\n</code></pre> <p>The CV quality threshold below which a warning is logged.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.quality_operators","title":"quality_operators  <code>instance-attribute</code>","text":"<pre><code>quality_operators: tuple[str, str] = (\n    (\"&lt;=\", \"&gt;\") if smaller_is_better else (\"&gt;=\", \"&lt;\")\n)\n</code></pre> <p>The operators <code>(o1, o2)</code> to compare the quality of the PCE and a threshold.</p> <p>\"A o1 B\" means that A is better or equal to B. \"A o2 B\" means that A is less good than B.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.quality_threshold","title":"quality_threshold  <code>instance-attribute</code>","text":"<pre><code>quality_threshold: (\n    float | Mapping[str, float | Iterable[float]]\n) = quality_threshold\n</code></pre> <p>The learning quality threshold below which a warning is logged.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.threshold","title":"threshold  <code>instance-attribute</code>","text":"<pre><code>threshold: dict[str, RealArray] = {}\n</code></pre> <p>The learning quality threshold component-wise.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.uncertain_space","title":"uncertain_space  <code>property</code>","text":"<pre><code>uncertain_space: ParameterSpace\n</code></pre> <p>The uncertain variable space.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.add_constraint","title":"add_constraint","text":"<pre><code>add_constraint(\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: ConstraintType = MDOFunction.ConstraintType.INEQ,\n    constraint_name: str | None = None,\n    value: float | None = None,\n    positive: bool = False,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Add an equality or inequality constraint to the optimization problem.</p> <p>An equality constraint is written as :math:<code>c(x)=a</code>, a positive inequality constraint is written as :math:<code>c(x)\\geq a</code> and a negative inequality constraint is written as :math:<code>c(x)\\leq a</code>.</p> <p>This constraint is in addition to those created by the formulation, e.g. consistency constraints in IDF.</p> <p>The strategy of repartition of the constraints is defined by the formulation.</p> <p>Parameters:</p> <ul> <li> <code>output_name</code>               (<code>str | Sequence[str]</code>)           \u2013            <p>The name(s) of the outputs computed by :math:<code>c(x)</code>. If several names are given, a single discipline must provide all outputs.</p> </li> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the constraint.</p> </li> <li> <code>constraint_type</code>               (<code>ConstraintType</code>, default:                   <code>INEQ</code> )           \u2013            <p>The type of constraint.</p> </li> <li> <code>constraint_name</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>The name of the constraint to be stored. If empty, the name of the constraint is generated from <code>output_name</code>, <code>constraint_type</code>, <code>value</code> and <code>positive</code>.</p> </li> <li> <code>value</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>The value :math:<code>a</code>.</p> </li> <li> <code>positive</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether the inequality constraint is positive.</p> </li> <li> <code>**statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def add_constraint(\n    self,\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: MDOFunction.ConstraintType = MDOFunction.ConstraintType.INEQ,\n    constraint_name: str | None = None,\n    value: float | None = None,\n    positive: bool = False,\n    **statistic_parameters: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        statistic_name: The name of the statistic to be applied to the constraint.\n        statistic_parameters: The values of the parameters of the statistic\n            to be applied to the constraint, if any.\n    \"\"\"  # noqa: D205 D212 D415\n    self._mdo_formulation.add_observable(output_name)\n    sub_opt_problem = self._mdo_formulation.optimization_problem\n    constraint = self._statistic_function_class(\n        self,\n        sub_opt_problem.observables[-1],\n        MDOFunction.FunctionType.NONE,\n        statistic_name,\n        sub_opt_problem,\n        **statistic_parameters,\n    )\n    name = self.__compute_name(output_name, statistic_name, **statistic_parameters)\n    constraint.output_names = [name]\n    if constraint_name is None:\n        constraint.name = name\n        constraint.has_default_name = True\n    else:\n        constraint.name = constraint_name\n        constraint.has_default_name = False\n    self.optimization_problem.add_constraint(\n        constraint,\n        value=value,\n        positive=positive,\n        constraint_type=constraint_type,\n    )\n    self._post_add_constraint()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.add_observable","title":"add_observable","text":"<pre><code>add_observable(\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: str = \"\",\n    discipline: MDODiscipline | None = None,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Add an observable to the optimization problem.</p> <p>The repartition strategy of the observable is defined in the formulation class.</p> <p>Parameters:</p> <ul> <li> <code>output_names</code>               (<code>Sequence[str]</code>)           \u2013            <p>The name(s) of the output(s) to observe.</p> </li> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the observable.</p> </li> <li> <code>observable_name</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>The name of the observable. If empty, the output name is used by default.</p> </li> <li> <code>discipline</code>               (<code>MDODiscipline | None</code>, default:                   <code>None</code> )           \u2013            <p>The discipline computing the observed outputs. If <code>None</code>, the discipline is detected from inner disciplines.</p> </li> <li> <code>**statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def add_observable(\n    self,\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: str = \"\",\n    discipline: MDODiscipline | None = None,\n    **statistic_parameters: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        statistic_name: The name of the statistic to be applied to the observable.\n        statistic_parameters: The values of the parameters\n            of the statistic to be applied to the observable, if any.\n    \"\"\"  # noqa: D205 D212 D415\n    self._mdo_formulation.add_observable(\n        output_names,\n        observable_name=observable_name,\n        discipline=discipline,\n    )\n    sub_opt_problem = self._mdo_formulation.optimization_problem\n    observable = self._statistic_function_class(\n        self,\n        sub_opt_problem.observables[-1],\n        MDOFunction.FunctionType.NONE,\n        statistic_name,\n        sub_opt_problem,\n        **statistic_parameters,\n    )\n    observable.name = self.__compute_name(\n        observable_name or output_names, statistic_name, **statistic_parameters\n    )\n    self.optimization_problem.add_observable(observable)\n    self._post_add_observable()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.compute_samples","title":"compute_samples","text":"<pre><code>compute_samples(problem: OptimizationProblem) -&gt; IODataset\n</code></pre> <p>Evaluate the functions of a problem with a DOE algorithm.</p> <p>Parameters:</p> <ul> <li> <code>problem</code>               (<code>OptimizationProblem</code>)           \u2013            <p>The problem.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/pce.py</code> <pre><code>def compute_samples(self, problem: OptimizationProblem) -&gt; IODataset:\n    \"\"\"Evaluate the functions of a problem with a DOE algorithm.\n\n    Args:\n        problem: The problem.\n    \"\"\"\n    with LoggingContext(logging.getLogger(\"gemseo\")):\n        self.__doe_algo.execute(problem, **self.__doe_algo_options)\n\n    io_dataset = problem.to_dataset(opt_naming=False)\n    if not self.threshold:\n        names_to_sizes = {\n            name: len(\n                io_dataset.get_variable_components(io_dataset.OUTPUT_GROUP, name)\n            )\n            for name in io_dataset.output_names\n        }\n        self.threshold = self.__compute_threshold(\n            names_to_sizes, self.quality_threshold\n        )\n        self.cv_threshold = self.__compute_threshold(\n            names_to_sizes, self.quality_cv_threshold\n        )\n\n    return io_dataset\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.get_expected_dataflow","title":"get_expected_dataflow","text":"<pre><code>get_expected_dataflow() -&gt; (\n    list[tuple[MDODiscipline, MDODiscipline, list[str]]]\n)\n</code></pre> <p>Get the expected data exchange sequence.</p> <p>This method is used for the XDSM representation and can be overloaded by subclasses.</p> <p>Returns:</p> <ul> <li> <code>list[tuple[MDODiscipline, MDODiscipline, list[str]]]</code>           \u2013            <p>The expected sequence of data exchange where the i-th item is described by the starting discipline, the ending discipline and the coupling variables.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def get_expected_dataflow(  # noqa: D102\n    self,\n) -&gt; list[tuple[MDODiscipline, MDODiscipline, list[str]]]:\n    return self._mdo_formulation.get_expected_dataflow()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.get_expected_workflow","title":"get_expected_workflow","text":"<pre><code>get_expected_workflow() -&gt; (\n    list[ExecutionSequence, tuple[ExecutionSequence]]\n)\n</code></pre> <p>Get the expected sequence of execution of the disciplines.</p> <p>This method is used for the XDSM representation and can be overloaded by subclasses.</p> <p>For instance:</p> <ul> <li>[A, B] denotes the execution of A,   then the execution of B</li> <li>(A, B) denotes the concurrent execution of A and B</li> <li>[A, (B, C), D] denotes the execution of A,   then the concurrent execution of B and C,   then the execution of D.</li> </ul> <p>Returns:</p> <ul> <li> <code>list[ExecutionSequence, tuple[ExecutionSequence]]</code>           \u2013            <p>A sequence of elements which are either an :class:<code>.ExecutionSequence</code> or a tuple of :class:<code>.ExecutionSequence</code> for concurrent execution.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def get_expected_workflow(  # noqa: D102\n    self,\n) -&gt; list[ExecutionSequence, tuple[ExecutionSequence]]:\n    return self._mdo_formulation.get_expected_workflow()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.get_top_level_disc","title":"get_top_level_disc","text":"<pre><code>get_top_level_disc() -&gt; list[MDODiscipline]\n</code></pre> <p>Return the disciplines which inputs are required to run the scenario.</p> <p>A formulation seeks to compute the objective and constraints from the input variables. It structures the optimization problem into multiple levels of disciplines. The disciplines directly depending on these inputs are called top level disciplines.</p> <p>By default, this method returns all disciplines. This method can be overloaded by subclasses.</p> <p>Returns:</p> <ul> <li> <code>list[MDODiscipline]</code>           \u2013            <p>The top level disciplines.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def get_top_level_disc(self) -&gt; list[MDODiscipline]:  # noqa: D102\n    return self._mdo_formulation.get_top_level_disc()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.update_top_level_disciplines","title":"update_top_level_disciplines","text":"<pre><code>update_top_level_disciplines(\n    design_values: RealArray,\n) -&gt; None\n</code></pre> <p>Update the default input values of the top-level disciplines.</p> <p>Parameters:</p> <ul> <li> <code>design_values</code>               (<code>RealArray</code>)           \u2013            <p>The values of the design variables to update the default input values of the top-level disciplines.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def update_top_level_disciplines(self, design_values: RealArray) -&gt; None:\n    \"\"\"Update the default input values of the top-level disciplines.\n\n    Args:\n        design_values: The values of the design variables\n            to update the default input values of the top-level disciplines.\n    \"\"\"\n    design_values = split_array_to_dict_of_arrays(\n        design_values,\n        self.design_space.variable_sizes,\n        self.design_space.variable_names,\n    )\n    for discipline in self._mdo_formulation.get_top_level_disc():\n        discipline.default_inputs.update({\n            k: v for k, v in design_values.items() if k in discipline.input_grammar\n        })\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/sampling/","title":"Sampling","text":""},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling","title":"sampling","text":"<p>Sampling-based U-MDO formulation.</p> <p>Sampling is an BaseUMDOFormulation estimating the statistics with (quasi) Monte Carlo techniques.</p> <p>E.g.</p> \\[\\mathbb{E}[f(x,U)] \\approx \\frac{1}{N}\\sum_{i=1}^N f\\left(x,U^{(i)}\\right)\\] <p>or</p> \\[\\mathbb{V}[f(x,U)] \\approx \\frac{1}{N}\\sum_{i=1}^N \\left(f\\left(x,U^{(i)}\\right)- \\frac{1}{N}\\sum_{j=1}^N f\\left(x,U^{(j)}\\right)\\right)^2\\] <p>where \\(U\\) is normally distributed with mean \\(\\mu\\) and variance \\(\\sigma^2\\) and \\(U^{(1)},\\ldots,U^{(N)}\\) are \\(N\\) realizations of \\(U\\) obtained with an optimized Latin hypercube sampling technique.</p>"},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling.Sampling","title":"Sampling","text":"<pre><code>Sampling(\n    disciplines: Sequence[MDODiscipline],\n    objective_name: str,\n    design_space: DesignSpace,\n    mdo_formulation: MDOFormulation,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    n_samples: int | None = None,\n    objective_statistic_parameters: Mapping[\n        str, Any\n    ] = READ_ONLY_EMPTY_DICT,\n    maximize_objective: bool = False,\n    grammar_type: GrammarType = MDODiscipline.GrammarType.JSON,\n    algo: str = OpenTURNS.OT_LHSO,\n    algo_options: Mapping[str, Any] = READ_ONLY_EMPTY_DICT,\n    seed: int = SEED,\n    estimate_statistics_iteratively: bool = True,\n    samples_directory_path: str | Path = \"\",\n    **options: Any\n)\n</code></pre> <p>               Bases: <code>BaseUMDOFormulation</code></p> <p>Sampling-based U-MDO formulation.</p> <p>DOE algorithms</p> <p>This formulation uses a DOE algorithm; read the GEMSEO documentation. for more information about the available DOE algorithm names and options.</p> <p>Parameters:</p> <ul> <li> <code>disciplines</code>               (<code>Sequence[MDODiscipline]</code>)           \u2013            <p>The disciplines.</p> </li> <li> <code>objective_name</code>               (<code>str</code>)           \u2013            <p>The name(s) of the discipline output(s) used as objective. If multiple names are passed, the objective will be a vector.</p> </li> <li> <code>design_space</code>               (<code>DesignSpace</code>)           \u2013            <p>The design space.</p> </li> <li> <code>mdo_formulation</code>               (<code>MDOFormulation</code>)           \u2013            <p>The class name of the MDO formulation, e.g. \"MDF\".</p> </li> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain variables with their probability distributions.</p> </li> <li> <code>objective_statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the objective.</p> </li> <li> <code>n_samples</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>The number of samples to be generated by the DOE algorithm. If <code>None</code>, the DOE algorithm uses no <code>n_samples</code> argument but potentially a mandatory argument to be defined in <code>algo_options</code> (e.g. <code>samples</code> for the <code>CustomDOE</code> algorithm).</p> </li> <li> <code>objective_statistic_parameters</code>               (<code>Mapping[str, Any]</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The values of the parameters of the statistic to be applied to the objective, if any.</p> </li> <li> <code>maximize_objective</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to maximize the objective.</p> </li> <li> <code>grammar_type</code>               (<code>GrammarType</code>, default:                   <code>JSON</code> )           \u2013            <p>The type of the input and output grammars.</p> </li> <li> <code>algo</code>               (<code>str</code>, default:                   <code>OT_LHSO</code> )           \u2013            <p>The name of the DOE algorithm.</p> </li> <li> <code>algo_options</code>               (<code>Mapping[str, Any]</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The options of the DOE algorithm.</p> </li> <li> <code>seed</code>               (<code>int</code>, default:                   <code>SEED</code> )           \u2013            <p>The seed for reproducibility.</p> </li> <li> <code>estimate_statistics_iteratively</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to estimate the statistics iteratively for memory reasons. This argument is ignored when <code>samples_directory_path</code> is defined; in this case, the statistics are not estimated iteratively.</p> </li> <li> <code>samples_directory_path</code>               (<code>str | Path</code>, default:                   <code>''</code> )           \u2013            <p>The path to a new directory where the samples stored as :class:<code>.IODataset</code> objects will be saved (one object per file, one file per iteration). This directory must not exist; it will be created by the formulation. If empty, do not save the samples.</p> </li> <li> <code>**options</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The options of the formulation.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>When <code>n_samples</code> is <code>None</code>, whereas it is required by the DOE algorithm.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/sampling.py</code> <pre><code>def __init__(\n    self,\n    disciplines: Sequence[MDODiscipline],\n    objective_name: str,\n    design_space: DesignSpace,\n    mdo_formulation: MDOFormulation,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    n_samples: int | None = None,\n    objective_statistic_parameters: Mapping[str, Any] = READ_ONLY_EMPTY_DICT,\n    maximize_objective: bool = False,\n    grammar_type: MDODiscipline.GrammarType = MDODiscipline.GrammarType.JSON,\n    algo: str = OpenTURNS.OT_LHSO,\n    algo_options: Mapping[str, Any] = READ_ONLY_EMPTY_DICT,\n    seed: int = SEED,\n    estimate_statistics_iteratively: bool = True,\n    samples_directory_path: str | Path = \"\",\n    **options: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        n_samples: The number of samples to be generated by the DOE algorithm.\n            If `None`,\n            the DOE algorithm uses no `n_samples` argument\n            but potentially a mandatory argument to be defined in `algo_options`\n            (e.g. `samples` for the `CustomDOE` algorithm).\n        algo: The name of the DOE algorithm.\n        algo_options: The options of the DOE algorithm.\n        seed: The seed for reproducibility.\n        estimate_statistics_iteratively: Whether to estimate\n            the statistics iteratively for memory reasons.\n            This argument is ignored when `samples_directory_path` is defined;\n            in this case, the statistics are not estimated iteratively.\n        samples_directory_path: The path to a new directory\n            where the samples stored as :class:`.IODataset` objects will be saved\n            (one object per file, one file per iteration).\n            This directory must not exist; it will be created by the formulation.\n            If empty, do not save the samples.\n\n    Raises:\n        ValueError: When `n_samples` is `None`,\n            whereas it is required by the DOE algorithm.\n    \"\"\"  # noqa: D205 D212 D415\n    self.callbacks = []\n    self.input_data_to_output_samples = {}\n    if samples_directory_path:\n        self.__samples_directory_path = Path(samples_directory_path)\n        self.__samples_directory_path.mkdir()\n        estimate_statistics_iteratively = False\n    else:\n        self.__samples_directory_path = \"\"\n\n    self._estimate_statistics_iteratively = estimate_statistics_iteratively\n    if estimate_statistics_iteratively:\n        self._statistic_factory = IterativeSamplingEstimatorFactory()\n        self._statistic_function_class = StatisticFunctionForIterativeSampling\n    else:\n        self._statistic_factory = SamplingEstimatorFactory()\n        self._statistic_function_class = StatisticFunctionForStandardSampling\n\n    self.__doe_algo = DOELibraryFactory().create(algo)\n    self.__doe_algo_options = dict(algo_options)\n    self.__doe_algo_options[\n        DOELibrary.USE_DATABASE_OPTION\n    ] = not estimate_statistics_iteratively\n    if DOELibrary.N_SAMPLES in self.__doe_algo.option_grammar:\n        if n_samples is None:\n            msg = \"Sampling: n_samples is required.\"\n            raise ValueError(msg)\n        self.__doe_algo_options[DOELibrary.N_SAMPLES] = n_samples\n\n    if DOELibrary.SEED in self.__doe_algo.option_grammar:\n        self.__doe_algo_options[DOELibrary.SEED] = seed\n\n    self.__n_samples = n_samples\n    self._estimators = []\n    super().__init__(\n        disciplines,\n        objective_name,\n        design_space,\n        mdo_formulation,\n        uncertain_space,\n        objective_statistic_name,\n        objective_statistic_options=objective_statistic_parameters,\n        maximize_objective=maximize_objective,\n        grammar_type=grammar_type,\n        **options,\n    )\n    mdo_formulation = self._mdo_formulation.__class__.__name__\n    formulation = self.__class__.__name__\n    self.name = f\"{formulation}[{mdo_formulation}; {algo}({n_samples})]\"\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling.Sampling-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling.Sampling.available_statistics","title":"available_statistics  <code>property</code>","text":"<pre><code>available_statistics: list[str]\n</code></pre> <p>The names of the statistics to quantify the output uncertainties.</p>"},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling.Sampling.callbacks","title":"callbacks  <code>instance-attribute</code>","text":"<pre><code>callbacks: list[CallbackType] = []\n</code></pre> <p>The callback functions for the DOE algorithm.</p>"},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling.Sampling.input_data_to_output_data","title":"input_data_to_output_data  <code>instance-attribute</code>","text":"<pre><code>input_data_to_output_data: dict[\n    HashableNdarray, dict[str, Any]\n] = {}\n</code></pre> <p>The output samples or output statistics associated with the input data.</p>"},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling.Sampling.mdo_formulation","title":"mdo_formulation  <code>property</code>","text":"<pre><code>mdo_formulation: MDOFormulation\n</code></pre> <p>The MDO formulation.</p>"},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling.Sampling.uncertain_space","title":"uncertain_space  <code>property</code>","text":"<pre><code>uncertain_space: ParameterSpace\n</code></pre> <p>The uncertain variable space.</p>"},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling.Sampling-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling.Sampling.add_constraint","title":"add_constraint","text":"<pre><code>add_constraint(\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: ConstraintType = MDOFunction.ConstraintType.INEQ,\n    constraint_name: str | None = None,\n    value: float | None = None,\n    positive: bool = False,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Add an equality or inequality constraint to the optimization problem.</p> <p>An equality constraint is written as :math:<code>c(x)=a</code>, a positive inequality constraint is written as :math:<code>c(x)\\geq a</code> and a negative inequality constraint is written as :math:<code>c(x)\\leq a</code>.</p> <p>This constraint is in addition to those created by the formulation, e.g. consistency constraints in IDF.</p> <p>The strategy of repartition of the constraints is defined by the formulation.</p> <p>Parameters:</p> <ul> <li> <code>output_name</code>               (<code>str | Sequence[str]</code>)           \u2013            <p>The name(s) of the outputs computed by :math:<code>c(x)</code>. If several names are given, a single discipline must provide all outputs.</p> </li> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the constraint.</p> </li> <li> <code>constraint_type</code>               (<code>ConstraintType</code>, default:                   <code>INEQ</code> )           \u2013            <p>The type of constraint.</p> </li> <li> <code>constraint_name</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>The name of the constraint to be stored. If empty, the name of the constraint is generated from <code>output_name</code>, <code>constraint_type</code>, <code>value</code> and <code>positive</code>.</p> </li> <li> <code>value</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>The value :math:<code>a</code>.</p> </li> <li> <code>positive</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether the inequality constraint is positive.</p> </li> <li> <code>**statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def add_constraint(\n    self,\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: MDOFunction.ConstraintType = MDOFunction.ConstraintType.INEQ,\n    constraint_name: str | None = None,\n    value: float | None = None,\n    positive: bool = False,\n    **statistic_parameters: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        statistic_name: The name of the statistic to be applied to the constraint.\n        statistic_parameters: The values of the parameters of the statistic\n            to be applied to the constraint, if any.\n    \"\"\"  # noqa: D205 D212 D415\n    self._mdo_formulation.add_observable(output_name)\n    sub_opt_problem = self._mdo_formulation.optimization_problem\n    constraint = self._statistic_function_class(\n        self,\n        sub_opt_problem.observables[-1],\n        MDOFunction.FunctionType.NONE,\n        statistic_name,\n        sub_opt_problem,\n        **statistic_parameters,\n    )\n    name = self.__compute_name(output_name, statistic_name, **statistic_parameters)\n    constraint.output_names = [name]\n    if constraint_name is None:\n        constraint.name = name\n        constraint.has_default_name = True\n    else:\n        constraint.name = constraint_name\n        constraint.has_default_name = False\n    self.optimization_problem.add_constraint(\n        constraint,\n        value=value,\n        positive=positive,\n        constraint_type=constraint_type,\n    )\n    self._post_add_constraint()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling.Sampling.add_observable","title":"add_observable","text":"<pre><code>add_observable(\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: str = \"\",\n    discipline: MDODiscipline | None = None,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Add an observable to the optimization problem.</p> <p>The repartition strategy of the observable is defined in the formulation class.</p> <p>Parameters:</p> <ul> <li> <code>output_names</code>               (<code>Sequence[str]</code>)           \u2013            <p>The name(s) of the output(s) to observe.</p> </li> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the observable.</p> </li> <li> <code>observable_name</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>The name of the observable. If empty, the output name is used by default.</p> </li> <li> <code>discipline</code>               (<code>MDODiscipline | None</code>, default:                   <code>None</code> )           \u2013            <p>The discipline computing the observed outputs. If <code>None</code>, the discipline is detected from inner disciplines.</p> </li> <li> <code>**statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def add_observable(\n    self,\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: str = \"\",\n    discipline: MDODiscipline | None = None,\n    **statistic_parameters: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        statistic_name: The name of the statistic to be applied to the observable.\n        statistic_parameters: The values of the parameters\n            of the statistic to be applied to the observable, if any.\n    \"\"\"  # noqa: D205 D212 D415\n    self._mdo_formulation.add_observable(\n        output_names,\n        observable_name=observable_name,\n        discipline=discipline,\n    )\n    sub_opt_problem = self._mdo_formulation.optimization_problem\n    observable = self._statistic_function_class(\n        self,\n        sub_opt_problem.observables[-1],\n        MDOFunction.FunctionType.NONE,\n        statistic_name,\n        sub_opt_problem,\n        **statistic_parameters,\n    )\n    observable.name = self.__compute_name(\n        observable_name or output_names, statistic_name, **statistic_parameters\n    )\n    self.optimization_problem.add_observable(observable)\n    self._post_add_observable()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling.Sampling.compute_samples","title":"compute_samples","text":"<pre><code>compute_samples(\n    problem: OptimizationProblem, input_data: RealArray\n) -&gt; None\n</code></pre> <p>Evaluate the functions of a problem with a DOE algorithm.</p> <p>Parameters:</p> <ul> <li> <code>problem</code>               (<code>OptimizationProblem</code>)           \u2013            <p>The sampling problem.</p> </li> <li> <code>input_data</code>               (<code>RealArray</code>)           \u2013            <p>The input point at which to estimate the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/sampling.py</code> <pre><code>def compute_samples(\n    self, problem: OptimizationProblem, input_data: RealArray\n) -&gt; None:\n    \"\"\"Evaluate the functions of a problem with a DOE algorithm.\n\n    Args:\n        problem: The sampling problem.\n        input_data: The input point at which to estimate the statistic.\n    \"\"\"\n    self.__doe_algo_options[\"callbacks\"] = set.union(\n        set(self.__doe_algo_options.get(\"callbacks\", set())), set(self.callbacks)\n    )\n    with LoggingContext(logging.getLogger(\"gemseo\")):\n        self.__doe_algo.execute(problem, **self.__doe_algo_options)\n\n    if self.__samples_directory_path:\n        main_problem = self.optimization_problem\n        iteration = main_problem.current_iter + 1\n        dataset = problem.to_dataset(f\"Iteration {iteration}\", opt_naming=False)\n        dataset.misc.update(main_problem.design_space.array_to_dict(input_data))\n        dataset.to_pickle(self.__samples_directory_path / f\"{iteration}.pkl\")\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling.Sampling.get_expected_dataflow","title":"get_expected_dataflow","text":"<pre><code>get_expected_dataflow() -&gt; (\n    list[tuple[MDODiscipline, MDODiscipline, list[str]]]\n)\n</code></pre> <p>Get the expected data exchange sequence.</p> <p>This method is used for the XDSM representation and can be overloaded by subclasses.</p> <p>Returns:</p> <ul> <li> <code>list[tuple[MDODiscipline, MDODiscipline, list[str]]]</code>           \u2013            <p>The expected sequence of data exchange where the i-th item is described by the starting discipline, the ending discipline and the coupling variables.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def get_expected_dataflow(  # noqa: D102\n    self,\n) -&gt; list[tuple[MDODiscipline, MDODiscipline, list[str]]]:\n    return self._mdo_formulation.get_expected_dataflow()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling.Sampling.get_expected_workflow","title":"get_expected_workflow","text":"<pre><code>get_expected_workflow() -&gt; (\n    list[ExecutionSequence, tuple[ExecutionSequence]]\n)\n</code></pre> <p>Get the expected sequence of execution of the disciplines.</p> <p>This method is used for the XDSM representation and can be overloaded by subclasses.</p> <p>For instance:</p> <ul> <li>[A, B] denotes the execution of A,   then the execution of B</li> <li>(A, B) denotes the concurrent execution of A and B</li> <li>[A, (B, C), D] denotes the execution of A,   then the concurrent execution of B and C,   then the execution of D.</li> </ul> <p>Returns:</p> <ul> <li> <code>list[ExecutionSequence, tuple[ExecutionSequence]]</code>           \u2013            <p>A sequence of elements which are either an :class:<code>.ExecutionSequence</code> or a tuple of :class:<code>.ExecutionSequence</code> for concurrent execution.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def get_expected_workflow(  # noqa: D102\n    self,\n) -&gt; list[ExecutionSequence, tuple[ExecutionSequence]]:\n    return self._mdo_formulation.get_expected_workflow()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling.Sampling.get_top_level_disc","title":"get_top_level_disc","text":"<pre><code>get_top_level_disc() -&gt; list[MDODiscipline]\n</code></pre> <p>Return the disciplines which inputs are required to run the scenario.</p> <p>A formulation seeks to compute the objective and constraints from the input variables. It structures the optimization problem into multiple levels of disciplines. The disciplines directly depending on these inputs are called top level disciplines.</p> <p>By default, this method returns all disciplines. This method can be overloaded by subclasses.</p> <p>Returns:</p> <ul> <li> <code>list[MDODiscipline]</code>           \u2013            <p>The top level disciplines.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def get_top_level_disc(self) -&gt; list[MDODiscipline]:  # noqa: D102\n    return self._mdo_formulation.get_top_level_disc()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling.Sampling.update_top_level_disciplines","title":"update_top_level_disciplines","text":"<pre><code>update_top_level_disciplines(\n    design_values: RealArray,\n) -&gt; None\n</code></pre> <p>Update the default input values of the top-level disciplines.</p> <p>Parameters:</p> <ul> <li> <code>design_values</code>               (<code>RealArray</code>)           \u2013            <p>The values of the design variables to update the default input values of the top-level disciplines.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def update_top_level_disciplines(self, design_values: RealArray) -&gt; None:\n    \"\"\"Update the default input values of the top-level disciplines.\n\n    Args:\n        design_values: The values of the design variables\n            to update the default input values of the top-level disciplines.\n    \"\"\"\n    design_values = split_array_to_dict_of_arrays(\n        design_values,\n        self.design_space.variable_sizes,\n        self.design_space.variable_names,\n    )\n    for discipline in self._mdo_formulation.get_top_level_disc():\n        discipline.default_inputs.update({\n            k: v for k, v in design_values.items() if k in discipline.input_grammar\n        })\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/","title":"Sequential sampling","text":""},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling","title":"sequential_sampling","text":"<p>Sequential sampling-based U-MDO formulation.</p> <p>SequentialSampling is a BaseUMDOFormulation estimating the statistics with sequential (quasi) Monte Carlo techniques.</p> <p>E.g.</p> \\[\\mathbb{E}[f(x,U)] \\approx \\frac{1}{N_k}\\sum_{i=1}^{N_k} f\\left(x,U^{(k,i)}\\right)\\] <p>or</p> \\[\\mathbb{V}[f(x,U)] \\approx \\frac{1}{N_k-1}\\sum_{i=1}^{N_k} \\left(f\\left(x,U^{(k,i)}\\right)- \\frac{1}{N_k}\\sum_{j=1}^{N_k} f\\left(x,U^{(k,j)}\\right)\\right)^2\\] <p>where \\(U\\) is normally distributed with mean \\(\\mu\\) and variance \\(\\sigma^2\\) and \\(U^{(k,1)},\\ldots,U^{(k,N_k)}\\) are \\(N_k\\) realizations of \\(U\\) obtained at the \\(k\\)-th iteration of the optimization loop with an optimized Latin hypercube sampling technique.</p>"},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling.SequentialSampling","title":"SequentialSampling","text":"<pre><code>SequentialSampling(\n    disciplines: Sequence[MDODiscipline],\n    objective_name: str,\n    design_space: DesignSpace,\n    mdo_formulation: MDOFormulation,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    n_samples: int,\n    initial_n_samples: int = 1,\n    n_samples_increment: int = 1,\n    objective_statistic_parameters: Mapping[\n        str, Any\n    ] = READ_ONLY_EMPTY_DICT,\n    maximize_objective: bool = False,\n    grammar_type: GrammarType = MDODiscipline.GrammarType.JSON,\n    algo: str = OpenTURNS.OT_LHSO,\n    algo_options: Mapping[str, Any] = READ_ONLY_EMPTY_DICT,\n    seed: int = SEED,\n    estimate_statistics_iteratively: bool = True,\n    samples_directory_path: str | Path = \"\",\n    **options: Any\n)\n</code></pre> <p>               Bases: <code>Sampling</code></p> <p>Sequential sampling-based U-MDO formulation.</p> <p>DOE algorithms</p> <p>This formulation uses a DOE algorithm; read the GEMSEO documentation. for more information about the available DOE algorithm names and options.</p> <p>Parameters:</p> <ul> <li> <code>disciplines</code>               (<code>Sequence[MDODiscipline]</code>)           \u2013            <p>The disciplines.</p> </li> <li> <code>objective_name</code>               (<code>str</code>)           \u2013            <p>The name(s) of the discipline output(s) used as objective. If multiple names are passed, the objective will be a vector.</p> </li> <li> <code>design_space</code>               (<code>DesignSpace</code>)           \u2013            <p>The design space.</p> </li> <li> <code>mdo_formulation</code>               (<code>MDOFormulation</code>)           \u2013            <p>The class name of the MDO formulation, e.g. \"MDF\".</p> </li> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain variables with their probability distributions.</p> </li> <li> <code>objective_statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the objective.</p> </li> <li> <code>n_samples</code>               (<code>int</code>)           \u2013            <p>The number of samples to be generated by the DOE algorithm. If <code>None</code>, the DOE algorithm uses no <code>n_samples</code> argument but potentially a mandatory argument to be defined in <code>algo_options</code> (e.g. <code>samples</code> for the <code>CustomDOE</code> algorithm).</p> </li> <li> <code>initial_n_samples</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>The initial sampling size.</p> </li> <li> <code>n_samples_increment</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>The increment of the sampling size.</p> </li> <li> <code>objective_statistic_parameters</code>               (<code>Mapping[str, Any]</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The values of the parameters of the statistic to be applied to the objective, if any.</p> </li> <li> <code>maximize_objective</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to maximize the objective.</p> </li> <li> <code>grammar_type</code>               (<code>GrammarType</code>, default:                   <code>JSON</code> )           \u2013            <p>The type of the input and output grammars.</p> </li> <li> <code>algo</code>               (<code>str</code>, default:                   <code>OT_LHSO</code> )           \u2013            <p>The name of the DOE algorithm.</p> </li> <li> <code>algo_options</code>               (<code>Mapping[str, Any]</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The options of the DOE algorithm.</p> </li> <li> <code>seed</code>               (<code>int</code>, default:                   <code>SEED</code> )           \u2013            <p>The seed for reproducibility.</p> </li> <li> <code>estimate_statistics_iteratively</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to estimate the statistics iteratively for memory reasons. This argument is ignored when <code>samples_directory_path</code> is defined; in this case, the statistics are not estimated iteratively.</p> </li> <li> <code>samples_directory_path</code>               (<code>str | Path</code>, default:                   <code>''</code> )           \u2013            <p>The path to a new directory where the samples stored as :class:<code>.IODataset</code> objects will be saved (one object per file, one file per iteration). This directory must not exist; it will be created by the formulation. If empty, do not save the samples.</p> </li> <li> <code>**options</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The options of the formulation.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>When <code>n_samples</code> is <code>None</code>, whereas it is required by the DOE algorithm.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/sequential_sampling.py</code> <pre><code>def __init__(\n    self,\n    disciplines: Sequence[MDODiscipline],\n    objective_name: str,\n    design_space: DesignSpace,\n    mdo_formulation: MDOFormulation,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    n_samples: int,\n    initial_n_samples: int = 1,\n    n_samples_increment: int = 1,\n    objective_statistic_parameters: Mapping[str, Any] = READ_ONLY_EMPTY_DICT,\n    maximize_objective: bool = False,\n    grammar_type: MDODiscipline.GrammarType = MDODiscipline.GrammarType.JSON,\n    algo: str = OpenTURNS.OT_LHSO,\n    algo_options: Mapping[str, Any] = READ_ONLY_EMPTY_DICT,\n    seed: int = SEED,\n    estimate_statistics_iteratively: bool = True,\n    samples_directory_path: str | Path = \"\",\n    **options: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        initial_n_samples: The initial sampling size.\n        n_samples_increment: The increment of the sampling size.\n    \"\"\"  # noqa: D205 D212 D415\n    super().__init__(\n        disciplines,\n        objective_name,\n        design_space,\n        mdo_formulation,\n        uncertain_space,\n        objective_statistic_name,\n        initial_n_samples,\n        objective_statistic_parameters=objective_statistic_parameters,\n        maximize_objective=maximize_objective,\n        grammar_type=grammar_type,\n        algo=algo,\n        algo_options=algo_options,\n        seed=seed,\n        estimate_statistics_iteratively=estimate_statistics_iteratively,\n        samples_directory_path=samples_directory_path,\n        **options,\n    )\n    self.__final_n_samples = n_samples\n    self.__n_samples_increment = n_samples_increment\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling.SequentialSampling-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling.SequentialSampling.available_statistics","title":"available_statistics  <code>property</code>","text":"<pre><code>available_statistics: list[str]\n</code></pre> <p>The names of the statistics to quantify the output uncertainties.</p>"},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling.SequentialSampling.callbacks","title":"callbacks  <code>instance-attribute</code>","text":"<pre><code>callbacks: list[CallbackType] = []\n</code></pre> <p>The callback functions for the DOE algorithm.</p>"},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling.SequentialSampling.input_data_to_output_data","title":"input_data_to_output_data  <code>instance-attribute</code>","text":"<pre><code>input_data_to_output_data: dict[\n    HashableNdarray, dict[str, Any]\n] = {}\n</code></pre> <p>The output samples or output statistics associated with the input data.</p>"},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling.SequentialSampling.mdo_formulation","title":"mdo_formulation  <code>property</code>","text":"<pre><code>mdo_formulation: MDOFormulation\n</code></pre> <p>The MDO formulation.</p>"},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling.SequentialSampling.uncertain_space","title":"uncertain_space  <code>property</code>","text":"<pre><code>uncertain_space: ParameterSpace\n</code></pre> <p>The uncertain variable space.</p>"},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling.SequentialSampling-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling.SequentialSampling.add_constraint","title":"add_constraint","text":"<pre><code>add_constraint(\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: ConstraintType = MDOFunction.ConstraintType.INEQ,\n    constraint_name: str | None = None,\n    value: float | None = None,\n    positive: bool = False,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Add an equality or inequality constraint to the optimization problem.</p> <p>An equality constraint is written as :math:<code>c(x)=a</code>, a positive inequality constraint is written as :math:<code>c(x)\\geq a</code> and a negative inequality constraint is written as :math:<code>c(x)\\leq a</code>.</p> <p>This constraint is in addition to those created by the formulation, e.g. consistency constraints in IDF.</p> <p>The strategy of repartition of the constraints is defined by the formulation.</p> <p>Parameters:</p> <ul> <li> <code>output_name</code>               (<code>str | Sequence[str]</code>)           \u2013            <p>The name(s) of the outputs computed by :math:<code>c(x)</code>. If several names are given, a single discipline must provide all outputs.</p> </li> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the constraint.</p> </li> <li> <code>constraint_type</code>               (<code>ConstraintType</code>, default:                   <code>INEQ</code> )           \u2013            <p>The type of constraint.</p> </li> <li> <code>constraint_name</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>The name of the constraint to be stored. If empty, the name of the constraint is generated from <code>output_name</code>, <code>constraint_type</code>, <code>value</code> and <code>positive</code>.</p> </li> <li> <code>value</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>The value :math:<code>a</code>.</p> </li> <li> <code>positive</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether the inequality constraint is positive.</p> </li> <li> <code>**statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def add_constraint(\n    self,\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: MDOFunction.ConstraintType = MDOFunction.ConstraintType.INEQ,\n    constraint_name: str | None = None,\n    value: float | None = None,\n    positive: bool = False,\n    **statistic_parameters: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        statistic_name: The name of the statistic to be applied to the constraint.\n        statistic_parameters: The values of the parameters of the statistic\n            to be applied to the constraint, if any.\n    \"\"\"  # noqa: D205 D212 D415\n    self._mdo_formulation.add_observable(output_name)\n    sub_opt_problem = self._mdo_formulation.optimization_problem\n    constraint = self._statistic_function_class(\n        self,\n        sub_opt_problem.observables[-1],\n        MDOFunction.FunctionType.NONE,\n        statistic_name,\n        sub_opt_problem,\n        **statistic_parameters,\n    )\n    name = self.__compute_name(output_name, statistic_name, **statistic_parameters)\n    constraint.output_names = [name]\n    if constraint_name is None:\n        constraint.name = name\n        constraint.has_default_name = True\n    else:\n        constraint.name = constraint_name\n        constraint.has_default_name = False\n    self.optimization_problem.add_constraint(\n        constraint,\n        value=value,\n        positive=positive,\n        constraint_type=constraint_type,\n    )\n    self._post_add_constraint()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling.SequentialSampling.add_observable","title":"add_observable","text":"<pre><code>add_observable(\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: str = \"\",\n    discipline: MDODiscipline | None = None,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Add an observable to the optimization problem.</p> <p>The repartition strategy of the observable is defined in the formulation class.</p> <p>Parameters:</p> <ul> <li> <code>output_names</code>               (<code>Sequence[str]</code>)           \u2013            <p>The name(s) of the output(s) to observe.</p> </li> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the observable.</p> </li> <li> <code>observable_name</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>The name of the observable. If empty, the output name is used by default.</p> </li> <li> <code>discipline</code>               (<code>MDODiscipline | None</code>, default:                   <code>None</code> )           \u2013            <p>The discipline computing the observed outputs. If <code>None</code>, the discipline is detected from inner disciplines.</p> </li> <li> <code>**statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def add_observable(\n    self,\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: str = \"\",\n    discipline: MDODiscipline | None = None,\n    **statistic_parameters: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        statistic_name: The name of the statistic to be applied to the observable.\n        statistic_parameters: The values of the parameters\n            of the statistic to be applied to the observable, if any.\n    \"\"\"  # noqa: D205 D212 D415\n    self._mdo_formulation.add_observable(\n        output_names,\n        observable_name=observable_name,\n        discipline=discipline,\n    )\n    sub_opt_problem = self._mdo_formulation.optimization_problem\n    observable = self._statistic_function_class(\n        self,\n        sub_opt_problem.observables[-1],\n        MDOFunction.FunctionType.NONE,\n        statistic_name,\n        sub_opt_problem,\n        **statistic_parameters,\n    )\n    observable.name = self.__compute_name(\n        observable_name or output_names, statistic_name, **statistic_parameters\n    )\n    self.optimization_problem.add_observable(observable)\n    self._post_add_observable()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling.SequentialSampling.compute_samples","title":"compute_samples","text":"<pre><code>compute_samples(\n    problem: OptimizationProblem, input_data: RealArray\n) -&gt; None\n</code></pre> <p>Evaluate the functions of a problem with a DOE algorithm.</p> <p>Parameters:</p> <ul> <li> <code>problem</code>               (<code>OptimizationProblem</code>)           \u2013            <p>The sampling problem.</p> </li> <li> <code>input_data</code>               (<code>RealArray</code>)           \u2013            <p>The input point at which to estimate the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/sequential_sampling.py</code> <pre><code>def compute_samples(  # noqa: D102\n    self, problem: OptimizationProblem, input_data: RealArray\n) -&gt; None:\n    super().compute_samples(problem, input_data)\n    if self._n_samples &lt; self.__final_n_samples:\n        self._n_samples = min(\n            self.__final_n_samples, self._n_samples + self.__n_samples_increment\n        )\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling.SequentialSampling.get_expected_dataflow","title":"get_expected_dataflow","text":"<pre><code>get_expected_dataflow() -&gt; (\n    list[tuple[MDODiscipline, MDODiscipline, list[str]]]\n)\n</code></pre> <p>Get the expected data exchange sequence.</p> <p>This method is used for the XDSM representation and can be overloaded by subclasses.</p> <p>Returns:</p> <ul> <li> <code>list[tuple[MDODiscipline, MDODiscipline, list[str]]]</code>           \u2013            <p>The expected sequence of data exchange where the i-th item is described by the starting discipline, the ending discipline and the coupling variables.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def get_expected_dataflow(  # noqa: D102\n    self,\n) -&gt; list[tuple[MDODiscipline, MDODiscipline, list[str]]]:\n    return self._mdo_formulation.get_expected_dataflow()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling.SequentialSampling.get_expected_workflow","title":"get_expected_workflow","text":"<pre><code>get_expected_workflow() -&gt; (\n    list[ExecutionSequence, tuple[ExecutionSequence]]\n)\n</code></pre> <p>Get the expected sequence of execution of the disciplines.</p> <p>This method is used for the XDSM representation and can be overloaded by subclasses.</p> <p>For instance:</p> <ul> <li>[A, B] denotes the execution of A,   then the execution of B</li> <li>(A, B) denotes the concurrent execution of A and B</li> <li>[A, (B, C), D] denotes the execution of A,   then the concurrent execution of B and C,   then the execution of D.</li> </ul> <p>Returns:</p> <ul> <li> <code>list[ExecutionSequence, tuple[ExecutionSequence]]</code>           \u2013            <p>A sequence of elements which are either an :class:<code>.ExecutionSequence</code> or a tuple of :class:<code>.ExecutionSequence</code> for concurrent execution.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def get_expected_workflow(  # noqa: D102\n    self,\n) -&gt; list[ExecutionSequence, tuple[ExecutionSequence]]:\n    return self._mdo_formulation.get_expected_workflow()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling.SequentialSampling.get_top_level_disc","title":"get_top_level_disc","text":"<pre><code>get_top_level_disc() -&gt; list[MDODiscipline]\n</code></pre> <p>Return the disciplines which inputs are required to run the scenario.</p> <p>A formulation seeks to compute the objective and constraints from the input variables. It structures the optimization problem into multiple levels of disciplines. The disciplines directly depending on these inputs are called top level disciplines.</p> <p>By default, this method returns all disciplines. This method can be overloaded by subclasses.</p> <p>Returns:</p> <ul> <li> <code>list[MDODiscipline]</code>           \u2013            <p>The top level disciplines.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def get_top_level_disc(self) -&gt; list[MDODiscipline]:  # noqa: D102\n    return self._mdo_formulation.get_top_level_disc()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling.SequentialSampling.update_top_level_disciplines","title":"update_top_level_disciplines","text":"<pre><code>update_top_level_disciplines(\n    design_values: RealArray,\n) -&gt; None\n</code></pre> <p>Update the default input values of the top-level disciplines.</p> <p>Parameters:</p> <ul> <li> <code>design_values</code>               (<code>RealArray</code>)           \u2013            <p>The values of the design variables to update the default input values of the top-level disciplines.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def update_top_level_disciplines(self, design_values: RealArray) -&gt; None:\n    \"\"\"Update the default input values of the top-level disciplines.\n\n    Args:\n        design_values: The values of the design variables\n            to update the default input values of the top-level disciplines.\n    \"\"\"\n    design_values = split_array_to_dict_of_arrays(\n        design_values,\n        self.design_space.variable_sizes,\n        self.design_space.variable_names,\n    )\n    for discipline in self._mdo_formulation.get_top_level_disc():\n        discipline.default_inputs.update({\n            k: v for k, v in design_values.items() if k in discipline.input_grammar\n        })\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/","title":"Taylor polynomial","text":""},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial","title":"taylor_polynomial","text":"<p>U-MDO formulation based on Taylor polynomials.</p> <p>TaylorPolynomial is an BaseUMDOFormulation estimating the statistics with first- or second-order Taylor polynomials around the expectation of the uncertain variables:</p> \\[f(x,U)\\approx f(x,\\mu) + (U-\\mu)f'(x,\\mu).\\] <p>E.g.</p> \\[\\mathbb{E}[f(x,U)]\\approx \\frac{1}{N}\\sum_{i=1}^N f\\left(x,U^{(i)}\\right)\\] <p>or</p> \\[\\mathbb{V}[f(x,U)]\\approx \\sigma^2f'(x,\\mu)\\] <p>where \\(U\\) is normally distributed with mean \\(\\mu\\) and variance \\(\\sigma^2\\).</p>"},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial.TaylorPolynomial","title":"TaylorPolynomial","text":"<pre><code>TaylorPolynomial(\n    disciplines: Sequence[MDODiscipline],\n    objective_name: str,\n    design_space: DesignSpace,\n    mdo_formulation: MDOFormulation,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    objective_statistic_parameters: Mapping[\n        str, Any\n    ] = READ_ONLY_EMPTY_DICT,\n    maximize_objective: bool = False,\n    grammar_type: GrammarType = MDODiscipline.GrammarType.JSON,\n    differentiation_method: DifferentiationMethod = OptimizationProblem.DifferentiationMethod.USER_GRAD,\n    second_order: bool = False,\n    **options: Any\n)\n</code></pre> <p>               Bases: <code>BaseUMDOFormulation</code></p> <p>U-MDO formulation based on Taylor polynomials.</p> <p>Parameters:</p> <ul> <li> <code>disciplines</code>               (<code>Sequence[MDODiscipline]</code>)           \u2013            <p>The disciplines.</p> </li> <li> <code>objective_name</code>               (<code>str</code>)           \u2013            <p>The name(s) of the discipline output(s) used as objective. If multiple names are passed, the objective will be a vector.</p> </li> <li> <code>design_space</code>               (<code>DesignSpace</code>)           \u2013            <p>The design space.</p> </li> <li> <code>mdo_formulation</code>               (<code>MDOFormulation</code>)           \u2013            <p>The class name of the MDO formulation, e.g. \"MDF\".</p> </li> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain variables with their probability distributions.</p> </li> <li> <code>objective_statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the objective.</p> </li> <li> <code>objective_statistic_parameters</code>               (<code>Mapping[str, Any]</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The values of the parameters of the statistic to be applied to the objective, if any.</p> </li> <li> <code>maximize_objective</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to maximize the objective.</p> </li> <li> <code>grammar_type</code>               (<code>GrammarType</code>, default:                   <code>JSON</code> )           \u2013            <p>The type of the input and output grammars.</p> </li> <li> <code>differentiation_method</code>               (<code>DifferentiationMethod</code>, default:                   <code>USER_GRAD</code> )           \u2013            <p>The type of method to compute the gradients.</p> </li> <li> <code>second_order</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to use second-order Taylor polynomials instead of first-order Taylor polynomials.</p> </li> <li> <code>**options</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The options of the formulation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/taylor_polynomial.py</code> <pre><code>def __init__(  # noqa: D107\n    self,\n    disciplines: Sequence[MDODiscipline],\n    objective_name: str,\n    design_space: DesignSpace,\n    mdo_formulation: MDOFormulation,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    objective_statistic_parameters: Mapping[str, Any] = READ_ONLY_EMPTY_DICT,\n    maximize_objective: bool = False,\n    grammar_type: MDODiscipline.GrammarType = MDODiscipline.GrammarType.JSON,\n    differentiation_method: OptimizationProblem.DifferentiationMethod = OptimizationProblem.DifferentiationMethod.USER_GRAD,  # noqa: E501\n    second_order: bool = False,\n    **options: Any,\n) -&gt; None:  # noqa: D205 D212 D415\n    \"\"\"\n    Args:\n        differentiation_method: The type of method to compute the gradients.\n        second_order: Whether to use second-order Taylor polynomials\n            instead of first-order Taylor polynomials.\n    \"\"\"  # noqa: D205 D212 D415\n    self.__second_order = second_order\n    self._statistic_function_class = StatisticFunctionForTaylorPolynomial\n    self._statistic_factory = TaylorPolynomialEstimatorFactory()\n    super().__init__(\n        disciplines,\n        objective_name,\n        design_space,\n        mdo_formulation,\n        uncertain_space,\n        objective_statistic_name,\n        objective_statistic_parameters=objective_statistic_parameters,\n        maximize_objective=maximize_objective,\n        grammar_type=grammar_type,\n        **options,\n    )\n\n    self.__hessian_fd_problem = None\n    finite_differences = (\n        self.optimization_problem.ApproximationMode.FINITE_DIFFERENCES\n    )\n    if self.__second_order:\n        problem = self._mdo_formulation.optimization_problem\n        self.__hessian_fd_problem = OptimizationProblem(self.uncertain_space)\n        self.__hessian_fd_problem.objective = HessianFunction(problem.objective)\n\n    problem = self._mdo_formulation.optimization_problem\n    problem.differentiation_method = differentiation_method\n    problem.design_space = problem.design_space.to_design_space()\n    self.optimization_problem.differentiation_method = finite_differences\n    self.optimization_problem.fd_step = 1e-6\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial.TaylorPolynomial-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial.TaylorPolynomial.available_statistics","title":"available_statistics  <code>property</code>","text":"<pre><code>available_statistics: list[str]\n</code></pre> <p>The names of the statistics to quantify the output uncertainties.</p>"},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial.TaylorPolynomial.hessian_fd_problem","title":"hessian_fd_problem  <code>property</code>","text":"<pre><code>hessian_fd_problem: OptimizationProblem | None\n</code></pre> <p>The problem related to the approximation of the Hessian.</p>"},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial.TaylorPolynomial.input_data_to_output_data","title":"input_data_to_output_data  <code>instance-attribute</code>","text":"<pre><code>input_data_to_output_data: dict[\n    HashableNdarray, dict[str, Any]\n] = {}\n</code></pre> <p>The output samples or output statistics associated with the input data.</p>"},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial.TaylorPolynomial.mdo_formulation","title":"mdo_formulation  <code>property</code>","text":"<pre><code>mdo_formulation: MDOFormulation\n</code></pre> <p>The MDO formulation.</p>"},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial.TaylorPolynomial.second_order","title":"second_order  <code>property</code>","text":"<pre><code>second_order: bool\n</code></pre> <p>Whether to use a second order approximation.</p>"},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial.TaylorPolynomial.uncertain_space","title":"uncertain_space  <code>property</code>","text":"<pre><code>uncertain_space: ParameterSpace\n</code></pre> <p>The uncertain variable space.</p>"},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial.TaylorPolynomial-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial.TaylorPolynomial.add_constraint","title":"add_constraint","text":"<pre><code>add_constraint(\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: ConstraintType = MDOFunction.ConstraintType.INEQ,\n    constraint_name: str | None = None,\n    value: float | None = None,\n    positive: bool = False,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Add an equality or inequality constraint to the optimization problem.</p> <p>An equality constraint is written as :math:<code>c(x)=a</code>, a positive inequality constraint is written as :math:<code>c(x)\\geq a</code> and a negative inequality constraint is written as :math:<code>c(x)\\leq a</code>.</p> <p>This constraint is in addition to those created by the formulation, e.g. consistency constraints in IDF.</p> <p>The strategy of repartition of the constraints is defined by the formulation.</p> <p>Parameters:</p> <ul> <li> <code>output_name</code>               (<code>str | Sequence[str]</code>)           \u2013            <p>The name(s) of the outputs computed by :math:<code>c(x)</code>. If several names are given, a single discipline must provide all outputs.</p> </li> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the constraint.</p> </li> <li> <code>constraint_type</code>               (<code>ConstraintType</code>, default:                   <code>INEQ</code> )           \u2013            <p>The type of constraint.</p> </li> <li> <code>constraint_name</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>The name of the constraint to be stored. If empty, the name of the constraint is generated from <code>output_name</code>, <code>constraint_type</code>, <code>value</code> and <code>positive</code>.</p> </li> <li> <code>value</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>The value :math:<code>a</code>.</p> </li> <li> <code>positive</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether the inequality constraint is positive.</p> </li> <li> <code>**statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/taylor_polynomial.py</code> <pre><code>def add_constraint(  # noqa: D102\n    self,\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: MDOFunction.ConstraintType = MDOFunction.ConstraintType.INEQ,\n    constraint_name: str | None = None,\n    value: float | None = None,\n    positive: bool = False,\n    **statistic_parameters: Any,\n) -&gt; None:\n    super().add_constraint(\n        output_name,\n        statistic_name,\n        constraint_type=constraint_type,\n        constraint_name=constraint_name,\n        value=value,\n        positive=positive,\n        **statistic_parameters,\n    )\n    if self.hessian_fd_problem is not None:\n        self.hessian_fd_problem.add_observable(\n            HessianFunction(\n                self._mdo_formulation.optimization_problem.observables[-1]\n            )\n        )\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial.TaylorPolynomial.add_observable","title":"add_observable","text":"<pre><code>add_observable(\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: Sequence[str] | None = None,\n    discipline: MDODiscipline | None = None,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Add an observable to the optimization problem.</p> <p>The repartition strategy of the observable is defined in the formulation class.</p> <p>Parameters:</p> <ul> <li> <code>output_names</code>               (<code>Sequence[str]</code>)           \u2013            <p>The name(s) of the output(s) to observe.</p> </li> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the observable.</p> </li> <li> <code>observable_name</code>               (<code>Sequence[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>The name of the observable. If empty, the output name is used by default.</p> </li> <li> <code>discipline</code>               (<code>MDODiscipline | None</code>, default:                   <code>None</code> )           \u2013            <p>The discipline computing the observed outputs. If <code>None</code>, the discipline is detected from inner disciplines.</p> </li> <li> <code>**statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/taylor_polynomial.py</code> <pre><code>def add_observable(  # noqa: D102\n    self,\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: Sequence[str] | None = None,\n    discipline: MDODiscipline | None = None,\n    **statistic_parameters: Any,\n) -&gt; None:\n    super().add_observable(\n        output_names,\n        statistic_name,\n        observable_name=observable_name,\n        discipline=discipline,\n        **statistic_parameters,\n    )\n    if self.hessian_fd_problem is not None:\n        self.hessian_fd_problem.add_observable(\n            HessianFunction(\n                self.mdo_formulation.optimization_problem.observables[-1]\n            ),\n        )\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial.TaylorPolynomial.evaluate_with_mean","title":"evaluate_with_mean","text":"<pre><code>evaluate_with_mean(\n    problem: OptimizationProblem, eval_jac: bool\n) -&gt; None\n</code></pre> <p>Evaluate the functions at the mean value of the uncertain vector.</p> <p>Parameters:</p> <ul> <li> <code>problem</code>               (<code>OptimizationProblem</code>)           \u2013            <p>The problem including the functions.</p> </li> <li> <code>eval_jac</code>               (<code>bool</code>)           \u2013            <p>Whether to evaluate the Jacobian functions.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/taylor_polynomial.py</code> <pre><code>def evaluate_with_mean(self, problem: OptimizationProblem, eval_jac: bool) -&gt; None:\n    \"\"\"Evaluate the functions at the mean value of the uncertain vector.\n\n    Args:\n        problem: The problem including the functions.\n        eval_jac: Whether to evaluate the Jacobian functions.\n    \"\"\"\n    if problem.nonproc_objective is None:\n        problem.preprocess_functions(\n            is_function_input_normalized=False, eval_obs_jac=eval_jac\n        )\n    problem.evaluate_functions(\n        self._uncertain_space.distribution.mean, eval_jac=eval_jac\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial.TaylorPolynomial.get_expected_dataflow","title":"get_expected_dataflow","text":"<pre><code>get_expected_dataflow() -&gt; (\n    list[tuple[MDODiscipline, MDODiscipline, list[str]]]\n)\n</code></pre> <p>Get the expected data exchange sequence.</p> <p>This method is used for the XDSM representation and can be overloaded by subclasses.</p> <p>Returns:</p> <ul> <li> <code>list[tuple[MDODiscipline, MDODiscipline, list[str]]]</code>           \u2013            <p>The expected sequence of data exchange where the i-th item is described by the starting discipline, the ending discipline and the coupling variables.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def get_expected_dataflow(  # noqa: D102\n    self,\n) -&gt; list[tuple[MDODiscipline, MDODiscipline, list[str]]]:\n    return self._mdo_formulation.get_expected_dataflow()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial.TaylorPolynomial.get_expected_workflow","title":"get_expected_workflow","text":"<pre><code>get_expected_workflow() -&gt; (\n    list[ExecutionSequence, tuple[ExecutionSequence]]\n)\n</code></pre> <p>Get the expected sequence of execution of the disciplines.</p> <p>This method is used for the XDSM representation and can be overloaded by subclasses.</p> <p>For instance:</p> <ul> <li>[A, B] denotes the execution of A,   then the execution of B</li> <li>(A, B) denotes the concurrent execution of A and B</li> <li>[A, (B, C), D] denotes the execution of A,   then the concurrent execution of B and C,   then the execution of D.</li> </ul> <p>Returns:</p> <ul> <li> <code>list[ExecutionSequence, tuple[ExecutionSequence]]</code>           \u2013            <p>A sequence of elements which are either an :class:<code>.ExecutionSequence</code> or a tuple of :class:<code>.ExecutionSequence</code> for concurrent execution.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def get_expected_workflow(  # noqa: D102\n    self,\n) -&gt; list[ExecutionSequence, tuple[ExecutionSequence]]:\n    return self._mdo_formulation.get_expected_workflow()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial.TaylorPolynomial.get_top_level_disc","title":"get_top_level_disc","text":"<pre><code>get_top_level_disc() -&gt; list[MDODiscipline]\n</code></pre> <p>Return the disciplines which inputs are required to run the scenario.</p> <p>A formulation seeks to compute the objective and constraints from the input variables. It structures the optimization problem into multiple levels of disciplines. The disciplines directly depending on these inputs are called top level disciplines.</p> <p>By default, this method returns all disciplines. This method can be overloaded by subclasses.</p> <p>Returns:</p> <ul> <li> <code>list[MDODiscipline]</code>           \u2013            <p>The top level disciplines.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def get_top_level_disc(self) -&gt; list[MDODiscipline]:  # noqa: D102\n    return self._mdo_formulation.get_top_level_disc()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial.TaylorPolynomial.update_top_level_disciplines","title":"update_top_level_disciplines","text":"<pre><code>update_top_level_disciplines(\n    design_values: RealArray,\n) -&gt; None\n</code></pre> <p>Update the default input values of the top-level disciplines.</p> <p>Parameters:</p> <ul> <li> <code>design_values</code>               (<code>RealArray</code>)           \u2013            <p>The values of the design variables to update the default input values of the top-level disciplines.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def update_top_level_disciplines(self, design_values: RealArray) -&gt; None:\n    \"\"\"Update the default input values of the top-level disciplines.\n\n    Args:\n        design_values: The values of the design variables\n            to update the default input values of the top-level disciplines.\n    \"\"\"\n    design_values = split_array_to_dict_of_arrays(\n        design_values,\n        self.design_space.variable_sizes,\n        self.design_space.variable_names,\n    )\n    for discipline in self._mdo_formulation.get_top_level_disc():\n        discipline.default_inputs.update({\n            k: v for k, v in design_values.items() if k in discipline.input_grammar\n        })\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_functions/","title":"functions","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/#gemseo_umdo.formulations._functions","title":"_functions","text":"<p>Functions to estimate statistics from a [BaseUMDOFormulation][gemseo_umdo.formulatio ns.base_umdo_formulation.BaseUMDOFormulation].</p> <p>The base function is a BaseStatisticFunction and derives from an MDOFunction. Most of the other _functions derive from BaseStatisticFunction and are associated with an BaseUMDOFormulation, e.g. Sampling. and TaylorPolynomial. The other modules are helpers.</p>"},{"location":"reference/gemseo_umdo/formulations/_functions/base_statistic_function/","title":"Base statistic function","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/base_statistic_function/#gemseo_umdo.formulations._functions.base_statistic_function","title":"base_statistic_function","text":"<p>A function to compute a statistic from a <code>BaseUMDOFormulation</code>.</p> <p>See Also: BaseUMDOFormulation.</p>"},{"location":"reference/gemseo_umdo/formulations/_functions/base_statistic_function/#gemseo_umdo.formulations._functions.base_statistic_function-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/base_statistic_function/#gemseo_umdo.formulations._functions.base_statistic_function.BaseStatisticFunction","title":"BaseStatisticFunction","text":"<pre><code>BaseStatisticFunction(\n    formulation: UMDOFormulationT,\n    func: MDOFunction,\n    function_type: FunctionType,\n    name: str,\n    sampling_problem: OptimizationProblem,\n    **statistic_options: Any\n)\n</code></pre> <p>               Bases: <code>MDOFunction</code>, <code>Generic[UMDOFormulationT]</code></p> <p>A function to compute a statistic from a <code>BaseUMDOFormulation</code>.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>formulation</code>               (<code>UMDOFormulationT</code>)           \u2013            <p>The U-MDO formulation to which the BaseStatisticFunction is attached.</p> </li> <li> <code>func</code>               (<code>MDOFunction</code>)           \u2013            <p>The function for which we want to estimate an output statistic.</p> </li> <li> <code>function_type</code>               (<code>FunctionType</code>)           \u2013            <p>The type of function.</p> </li> <li> <code>name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic.</p> </li> <li> <code>sampling_problem</code>               (<code>OptimizationProblem</code>)           \u2013            <p>The problem evaluating the function over the uncertain space.</p> </li> <li> <code>**statistic_options</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The options of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_functions/base_statistic_function.py</code> <pre><code>def __init__(\n    self,\n    formulation: UMDOFormulationT,\n    func: MDOFunction,\n    function_type: MDOFunction.FunctionType,\n    name: str,\n    sampling_problem: OptimizationProblem,\n    **statistic_options: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        formulation: The U-MDO formulation\n            to which the\n            [BaseStatisticFunction][gemseo_umdo.formulations._functions.base_statistic_function.BaseStatisticFunction]\n            is attached.\n        func: The function for which we want to estimate an output statistic.\n        function_type: The type of function.\n        name: The name of the statistic.\n        sampling_problem: The problem\n            evaluating the function over the uncertain space.\n        **statistic_options: The options of the statistic.\n    \"\"\"  # noqa: D205 D212 D415\n    self._function_name = func.name\n    self._formulation = formulation\n    self._estimate_statistic = formulation._statistic_factory.create(\n        name, *self._statistic_estimator_parameters, **statistic_options\n    )\n    self._update_sampling_problem(sampling_problem, func)\n    super().__init__(self._func, name=func.name, f_type=function_type)\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_functions/base_statistic_function_for_sampling/","title":"Base statistic function for sampling","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/base_statistic_function_for_sampling/#gemseo_umdo.formulations._functions.base_statistic_function_for_sampling","title":"base_statistic_function_for_sampling","text":"<p>A function to compute a statistic from <code>Sampling</code>.</p> <p>See also Sampling.</p>"},{"location":"reference/gemseo_umdo/formulations/_functions/base_statistic_function_for_sampling/#gemseo_umdo.formulations._functions.base_statistic_function_for_sampling-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/base_statistic_function_for_sampling/#gemseo_umdo.formulations._functions.base_statistic_function_for_sampling.BaseStatisticFunctionForSampling","title":"BaseStatisticFunctionForSampling","text":"<pre><code>BaseStatisticFunctionForSampling(\n    formulation: UMDOFormulationT,\n    func: MDOFunction,\n    function_type: FunctionType,\n    name: str,\n    sampling_problem: OptimizationProblem,\n    **statistic_options: Any\n)\n</code></pre> <p>               Bases: <code>BaseStatisticFunction[UMDOFormulationT]</code></p> <p>A function to compute a statistic from <code>Sampling</code>.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>formulation</code>               (<code>UMDOFormulationT</code>)           \u2013            <p>The U-MDO formulation to which the BaseStatisticFunction is attached.</p> </li> <li> <code>func</code>               (<code>MDOFunction</code>)           \u2013            <p>The function for which we want to estimate an output statistic.</p> </li> <li> <code>function_type</code>               (<code>FunctionType</code>)           \u2013            <p>The type of function.</p> </li> <li> <code>name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic.</p> </li> <li> <code>sampling_problem</code>               (<code>OptimizationProblem</code>)           \u2013            <p>The problem evaluating the function over the uncertain space.</p> </li> <li> <code>**statistic_options</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The options of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_functions/base_statistic_function.py</code> <pre><code>def __init__(\n    self,\n    formulation: UMDOFormulationT,\n    func: MDOFunction,\n    function_type: MDOFunction.FunctionType,\n    name: str,\n    sampling_problem: OptimizationProblem,\n    **statistic_options: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        formulation: The U-MDO formulation\n            to which the\n            [BaseStatisticFunction][gemseo_umdo.formulations._functions.base_statistic_function.BaseStatisticFunction]\n            is attached.\n        func: The function for which we want to estimate an output statistic.\n        function_type: The type of function.\n        name: The name of the statistic.\n        sampling_problem: The problem\n            evaluating the function over the uncertain space.\n        **statistic_options: The options of the statistic.\n    \"\"\"  # noqa: D205 D212 D415\n    self._function_name = func.name\n    self._formulation = formulation\n    self._estimate_statistic = formulation._statistic_factory.create(\n        name, *self._statistic_estimator_parameters, **statistic_options\n    )\n    self._update_sampling_problem(sampling_problem, func)\n    super().__init__(self._func, name=func.name, f_type=function_type)\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_functions/hessian_function/","title":"Hessian function","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/hessian_function/#gemseo_umdo.formulations._functions.hessian_function","title":"hessian_function","text":"<p>A function approximating the Hessian matrix by finite differences.</p>"},{"location":"reference/gemseo_umdo/formulations/_functions/hessian_function/#gemseo_umdo.formulations._functions.hessian_function-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/hessian_function/#gemseo_umdo.formulations._functions.hessian_function.HessianFunction","title":"HessianFunction","text":"<pre><code>HessianFunction(func: MDOFunction)\n</code></pre> <p>               Bases: <code>MDOFunction</code></p> <p>A function approximating the Hessian matrix by finite differences.</p> <p>Take an original function and approximate its Hessian with finite differences applied to its analytical or approximated Jacobian.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>func</code>               (<code>MDOFunction</code>)           \u2013            <p>The original function.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_functions/hessian_function.py</code> <pre><code>def __init__(self, func: MDOFunction) -&gt; None:\n    \"\"\"\n    Args:\n        func: The original function.\n    \"\"\"  # noqa: D205 D212 D415\n    self.__jac = func.jac if func.has_jac else FirstOrderFD(func.func).f_gradient\n    grad_tag = Database.GRAD_TAG\n    super().__init__(\n        FirstOrderFD(self._compute_jac).f_gradient,\n        f\"{grad_tag}{grad_tag}{func.name}\",\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_functions/iterative_estimation/","title":"Iterative estimation","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/iterative_estimation/#gemseo_umdo.formulations._functions.iterative_estimation","title":"iterative_estimation","text":"<p>A function updating the estimation of a statistic.</p>"},{"location":"reference/gemseo_umdo/formulations/_functions/iterative_estimation/#gemseo_umdo.formulations._functions.iterative_estimation-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/iterative_estimation/#gemseo_umdo.formulations._functions.iterative_estimation.IterativeEstimation","title":"IterativeEstimation","text":"<pre><code>IterativeEstimation(\n    name: str, update_estimation: BaseSamplingEstimator\n)\n</code></pre> <p>A functor to estimate a statistic iteratively.</p> <p>Call this functor to update the estimation of the statistic and access the last evaluation with :attr:<code>.last_evaluation</code>.</p> <p>The Sampling U-MDO formulation passes such functors to a DOELibrary as callback functions to update the statistics of the objective, constraints and observables.</p> <p>Parameters:</p> <ul> <li> <code>name</code>               (<code>str</code>)           \u2013            <p>The name of the output for which to estimate the statistic.</p> </li> <li> <code>update_estimation</code>               (<code>BaseSamplingEstimator</code>)           \u2013            <p>The function to update the estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_functions/iterative_estimation.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    update_estimation: BaseSamplingEstimator,\n) -&gt; None:\n    \"\"\"\n    Args:\n        name: The name of the output for which to estimate the statistic.\n        update_estimation: The function to update the estimation of the statistic.\n    \"\"\"  # noqa: D202 D205 D212 D415\n    self._name = name\n    self._last_estimation = array([])\n    self._update_estimation = update_estimation\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_functions/iterative_estimation/#gemseo_umdo.formulations._functions.iterative_estimation.IterativeEstimation-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/iterative_estimation/#gemseo_umdo.formulations._functions.iterative_estimation.IterativeEstimation.last_estimation","title":"last_estimation  <code>property</code>","text":"<pre><code>last_estimation: RealArray\n</code></pre> <p>The last estimation of the statistic.</p>"},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_control_variate/","title":"Statistic function for control variate","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_control_variate/#gemseo_umdo.formulations._functions.statistic_function_for_control_variate","title":"statistic_function_for_control_variate","text":"<p>A function to compute a statistic from <code>ControlVariate</code>.</p> <p>See also ControlVariate.</p>"},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_control_variate/#gemseo_umdo.formulations._functions.statistic_function_for_control_variate-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_control_variate/#gemseo_umdo.formulations._functions.statistic_function_for_control_variate.StatisticFunctionForControlVariate","title":"StatisticFunctionForControlVariate","text":"<pre><code>StatisticFunctionForControlVariate(\n    formulation: UMDOFormulationT,\n    func: MDOFunction,\n    function_type: FunctionType,\n    name: str,\n    sampling_problem: OptimizationProblem,\n    **statistic_options: Any\n)\n</code></pre> <p>               Bases: <code>BaseStatisticFunction[ControlVariateT]</code></p> <p>A function to compute a statistic from <code>ControlVariate</code>.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>formulation</code>               (<code>UMDOFormulationT</code>)           \u2013            <p>The U-MDO formulation to which the BaseStatisticFunction is attached.</p> </li> <li> <code>func</code>               (<code>MDOFunction</code>)           \u2013            <p>The function for which we want to estimate an output statistic.</p> </li> <li> <code>function_type</code>               (<code>FunctionType</code>)           \u2013            <p>The type of function.</p> </li> <li> <code>name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic.</p> </li> <li> <code>sampling_problem</code>               (<code>OptimizationProblem</code>)           \u2013            <p>The problem evaluating the function over the uncertain space.</p> </li> <li> <code>**statistic_options</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The options of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_functions/base_statistic_function.py</code> <pre><code>def __init__(\n    self,\n    formulation: UMDOFormulationT,\n    func: MDOFunction,\n    function_type: MDOFunction.FunctionType,\n    name: str,\n    sampling_problem: OptimizationProblem,\n    **statistic_options: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        formulation: The U-MDO formulation\n            to which the\n            [BaseStatisticFunction][gemseo_umdo.formulations._functions.base_statistic_function.BaseStatisticFunction]\n            is attached.\n        func: The function for which we want to estimate an output statistic.\n        function_type: The type of function.\n        name: The name of the statistic.\n        sampling_problem: The problem\n            evaluating the function over the uncertain space.\n        **statistic_options: The options of the statistic.\n    \"\"\"  # noqa: D205 D212 D415\n    self._function_name = func.name\n    self._formulation = formulation\n    self._estimate_statistic = formulation._statistic_factory.create(\n        name, *self._statistic_estimator_parameters, **statistic_options\n    )\n    self._update_sampling_problem(sampling_problem, func)\n    super().__init__(self._func, name=func.name, f_type=function_type)\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_iterative_sampling/","title":"Statistic function for iterative sampling","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_iterative_sampling/#gemseo_umdo.formulations._functions.statistic_function_for_iterative_sampling","title":"statistic_function_for_iterative_sampling","text":"<p>A function to compute a statistic from <code>Sampling</code>.</p> <p>See also Sampling.</p>"},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_iterative_sampling/#gemseo_umdo.formulations._functions.statistic_function_for_iterative_sampling-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_iterative_sampling/#gemseo_umdo.formulations._functions.statistic_function_for_iterative_sampling.StatisticFunctionForIterativeSampling","title":"StatisticFunctionForIterativeSampling","text":"<pre><code>StatisticFunctionForIterativeSampling(\n    formulation: UMDOFormulationT,\n    func: MDOFunction,\n    function_type: FunctionType,\n    name: str,\n    sampling_problem: OptimizationProblem,\n    **statistic_options: Any\n)\n</code></pre> <p>               Bases: <code>BaseStatisticFunctionForSampling[SamplingT]</code></p> <p>A function to compute a statistic from <code>Sampling</code>.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>formulation</code>               (<code>UMDOFormulationT</code>)           \u2013            <p>The U-MDO formulation to which the BaseStatisticFunction is attached.</p> </li> <li> <code>func</code>               (<code>MDOFunction</code>)           \u2013            <p>The function for which we want to estimate an output statistic.</p> </li> <li> <code>function_type</code>               (<code>FunctionType</code>)           \u2013            <p>The type of function.</p> </li> <li> <code>name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic.</p> </li> <li> <code>sampling_problem</code>               (<code>OptimizationProblem</code>)           \u2013            <p>The problem evaluating the function over the uncertain space.</p> </li> <li> <code>**statistic_options</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The options of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_functions/base_statistic_function.py</code> <pre><code>def __init__(\n    self,\n    formulation: UMDOFormulationT,\n    func: MDOFunction,\n    function_type: MDOFunction.FunctionType,\n    name: str,\n    sampling_problem: OptimizationProblem,\n    **statistic_options: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        formulation: The U-MDO formulation\n            to which the\n            [BaseStatisticFunction][gemseo_umdo.formulations._functions.base_statistic_function.BaseStatisticFunction]\n            is attached.\n        func: The function for which we want to estimate an output statistic.\n        function_type: The type of function.\n        name: The name of the statistic.\n        sampling_problem: The problem\n            evaluating the function over the uncertain space.\n        **statistic_options: The options of the statistic.\n    \"\"\"  # noqa: D205 D212 D415\n    self._function_name = func.name\n    self._formulation = formulation\n    self._estimate_statistic = formulation._statistic_factory.create(\n        name, *self._statistic_estimator_parameters, **statistic_options\n    )\n    self._update_sampling_problem(sampling_problem, func)\n    super().__init__(self._func, name=func.name, f_type=function_type)\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_pce/","title":"Statistic function for pce","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_pce/#gemseo_umdo.formulations._functions.statistic_function_for_pce","title":"statistic_function_for_pce","text":"<p>A function to compute a statistic from <code>PCE</code>.</p> <p>See also PCE.</p>"},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_pce/#gemseo_umdo.formulations._functions.statistic_function_for_pce-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_pce/#gemseo_umdo.formulations._functions.statistic_function_for_pce.StatisticFunctionForPCE","title":"StatisticFunctionForPCE","text":"<pre><code>StatisticFunctionForPCE(\n    formulation: UMDOFormulationT,\n    func: MDOFunction,\n    function_type: FunctionType,\n    name: str,\n    sampling_problem: OptimizationProblem,\n    **statistic_options: Any\n)\n</code></pre> <p>               Bases: <code>BaseStatisticFunction[PCET]</code></p> <p>A function to compute a statistic from <code>PCE</code>.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>formulation</code>               (<code>UMDOFormulationT</code>)           \u2013            <p>The U-MDO formulation to which the BaseStatisticFunction is attached.</p> </li> <li> <code>func</code>               (<code>MDOFunction</code>)           \u2013            <p>The function for which we want to estimate an output statistic.</p> </li> <li> <code>function_type</code>               (<code>FunctionType</code>)           \u2013            <p>The type of function.</p> </li> <li> <code>name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic.</p> </li> <li> <code>sampling_problem</code>               (<code>OptimizationProblem</code>)           \u2013            <p>The problem evaluating the function over the uncertain space.</p> </li> <li> <code>**statistic_options</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The options of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_functions/base_statistic_function.py</code> <pre><code>def __init__(\n    self,\n    formulation: UMDOFormulationT,\n    func: MDOFunction,\n    function_type: MDOFunction.FunctionType,\n    name: str,\n    sampling_problem: OptimizationProblem,\n    **statistic_options: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        formulation: The U-MDO formulation\n            to which the\n            [BaseStatisticFunction][gemseo_umdo.formulations._functions.base_statistic_function.BaseStatisticFunction]\n            is attached.\n        func: The function for which we want to estimate an output statistic.\n        function_type: The type of function.\n        name: The name of the statistic.\n        sampling_problem: The problem\n            evaluating the function over the uncertain space.\n        **statistic_options: The options of the statistic.\n    \"\"\"  # noqa: D205 D212 D415\n    self._function_name = func.name\n    self._formulation = formulation\n    self._estimate_statistic = formulation._statistic_factory.create(\n        name, *self._statistic_estimator_parameters, **statistic_options\n    )\n    self._update_sampling_problem(sampling_problem, func)\n    super().__init__(self._func, name=func.name, f_type=function_type)\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_standard_sampling/","title":"Statistic function for standard sampling","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_standard_sampling/#gemseo_umdo.formulations._functions.statistic_function_for_standard_sampling","title":"statistic_function_for_standard_sampling","text":"<p>A function to compute a statistic from <code>Sampling</code>.</p> <p>See also Sampling.</p>"},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_standard_sampling/#gemseo_umdo.formulations._functions.statistic_function_for_standard_sampling-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_standard_sampling/#gemseo_umdo.formulations._functions.statistic_function_for_standard_sampling.StatisticFunctionForStandardSampling","title":"StatisticFunctionForStandardSampling","text":"<pre><code>StatisticFunctionForStandardSampling(\n    formulation: UMDOFormulationT,\n    func: MDOFunction,\n    function_type: FunctionType,\n    name: str,\n    sampling_problem: OptimizationProblem,\n    **statistic_options: Any\n)\n</code></pre> <p>               Bases: <code>BaseStatisticFunctionForSampling[SamplingT]</code></p> <p>A function to compute a statistic from <code>Sampling</code>.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>formulation</code>               (<code>UMDOFormulationT</code>)           \u2013            <p>The U-MDO formulation to which the BaseStatisticFunction is attached.</p> </li> <li> <code>func</code>               (<code>MDOFunction</code>)           \u2013            <p>The function for which we want to estimate an output statistic.</p> </li> <li> <code>function_type</code>               (<code>FunctionType</code>)           \u2013            <p>The type of function.</p> </li> <li> <code>name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic.</p> </li> <li> <code>sampling_problem</code>               (<code>OptimizationProblem</code>)           \u2013            <p>The problem evaluating the function over the uncertain space.</p> </li> <li> <code>**statistic_options</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The options of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_functions/base_statistic_function.py</code> <pre><code>def __init__(\n    self,\n    formulation: UMDOFormulationT,\n    func: MDOFunction,\n    function_type: MDOFunction.FunctionType,\n    name: str,\n    sampling_problem: OptimizationProblem,\n    **statistic_options: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        formulation: The U-MDO formulation\n            to which the\n            [BaseStatisticFunction][gemseo_umdo.formulations._functions.base_statistic_function.BaseStatisticFunction]\n            is attached.\n        func: The function for which we want to estimate an output statistic.\n        function_type: The type of function.\n        name: The name of the statistic.\n        sampling_problem: The problem\n            evaluating the function over the uncertain space.\n        **statistic_options: The options of the statistic.\n    \"\"\"  # noqa: D205 D212 D415\n    self._function_name = func.name\n    self._formulation = formulation\n    self._estimate_statistic = formulation._statistic_factory.create(\n        name, *self._statistic_estimator_parameters, **statistic_options\n    )\n    self._update_sampling_problem(sampling_problem, func)\n    super().__init__(self._func, name=func.name, f_type=function_type)\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_taylor_polynomial/","title":"Statistic function for taylor polynomial","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_taylor_polynomial/#gemseo_umdo.formulations._functions.statistic_function_for_taylor_polynomial","title":"statistic_function_for_taylor_polynomial","text":"<p>A function to compute a statistic from <code>TaylorPolynomial</code>.</p> <p>See also TaylorPolynomial.</p>"},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_taylor_polynomial/#gemseo_umdo.formulations._functions.statistic_function_for_taylor_polynomial-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_taylor_polynomial/#gemseo_umdo.formulations._functions.statistic_function_for_taylor_polynomial.StatisticFunctionForTaylorPolynomial","title":"StatisticFunctionForTaylorPolynomial","text":"<pre><code>StatisticFunctionForTaylorPolynomial(\n    formulation: UMDOFormulationT,\n    func: MDOFunction,\n    function_type: FunctionType,\n    name: str,\n    sampling_problem: OptimizationProblem,\n    **statistic_options: Any\n)\n</code></pre> <p>               Bases: <code>BaseStatisticFunction[TaylorPolynomialT]</code></p> <p>A function to compute a statistic from <code>TaylorPolynomial</code>.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>formulation</code>               (<code>UMDOFormulationT</code>)           \u2013            <p>The U-MDO formulation to which the BaseStatisticFunction is attached.</p> </li> <li> <code>func</code>               (<code>MDOFunction</code>)           \u2013            <p>The function for which we want to estimate an output statistic.</p> </li> <li> <code>function_type</code>               (<code>FunctionType</code>)           \u2013            <p>The type of function.</p> </li> <li> <code>name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic.</p> </li> <li> <code>sampling_problem</code>               (<code>OptimizationProblem</code>)           \u2013            <p>The problem evaluating the function over the uncertain space.</p> </li> <li> <code>**statistic_options</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The options of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_functions/base_statistic_function.py</code> <pre><code>def __init__(\n    self,\n    formulation: UMDOFormulationT,\n    func: MDOFunction,\n    function_type: MDOFunction.FunctionType,\n    name: str,\n    sampling_problem: OptimizationProblem,\n    **statistic_options: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        formulation: The U-MDO formulation\n            to which the\n            [BaseStatisticFunction][gemseo_umdo.formulations._functions.base_statistic_function.BaseStatisticFunction]\n            is attached.\n        func: The function for which we want to estimate an output statistic.\n        function_type: The type of function.\n        name: The name of the statistic.\n        sampling_problem: The problem\n            evaluating the function over the uncertain space.\n        **statistic_options: The options of the statistic.\n    \"\"\"  # noqa: D205 D212 D415\n    self._function_name = func.name\n    self._formulation = formulation\n    self._estimate_statistic = formulation._statistic_factory.create(\n        name, *self._statistic_estimator_parameters, **statistic_options\n    )\n    self._update_sampling_problem(sampling_problem, func)\n    super().__init__(self._func, name=func.name, f_type=function_type)\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/","title":"statistics","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/#gemseo_umdo.formulations._statistics","title":"_statistics","text":"<p>Estimators of statistics associated with a U-MDO formulation.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/base_statistic_estimator/","title":"Base statistic estimator","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/base_statistic_estimator/#gemseo_umdo.formulations._statistics.base_statistic_estimator","title":"base_statistic_estimator","text":"<p>Base estimator of statistic associated with a U-MDO formulation.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/base_statistic_estimator/#gemseo_umdo.formulations._statistics.base_statistic_estimator-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/base_statistic_estimator/#gemseo_umdo.formulations._statistics.base_statistic_estimator.BaseStatisticEstimator","title":"BaseStatisticEstimator","text":"<p>The base statistic estimator for U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/","title":"Control variate","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/#gemseo_umdo.formulations._statistics.control_variate","title":"control_variate","text":"<p>Estimators of statistics for U-MDO formulations based on control variates.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/base_control_variate_estimator/","title":"Base control variate estimator","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/base_control_variate_estimator/#gemseo_umdo.formulations._statistics.control_variate.base_control_variate_estimator","title":"base_control_variate_estimator","text":"<p>Base statistic estimator for U-MDO formulation based on control variates.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/base_control_variate_estimator/#gemseo_umdo.formulations._statistics.control_variate.base_control_variate_estimator-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/base_control_variate_estimator/#gemseo_umdo.formulations._statistics.control_variate.base_control_variate_estimator.BaseControlVariateEstimator","title":"BaseControlVariateEstimator","text":"<pre><code>BaseControlVariateEstimator(\n    uncertain_space: ParameterSpace,\n)\n</code></pre> <p>               Bases: <code>BaseStatisticEstimator</code></p> <p>Base statistic estimator for a U-MDO formulation using control variates.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain space.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/control_variate/base_control_variate_estimator.py</code> <pre><code>def __init__(self, uncertain_space: ParameterSpace) -&gt; None:\n    \"\"\"\n    Args:\n        uncertain_space: The uncertain space.\n    \"\"\"  # noqa: D205 D212 D415\n    self._u_mean = uncertain_space.distribution.mean\n    self._u_standard_deviation = uncertain_space.distribution.standard_deviation\n    self._uncertain_space = uncertain_space\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/factory/","title":"Factory","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/factory/#gemseo_umdo.formulations._statistics.control_variate.factory","title":"factory","text":"<p>A factory of statistic estimators for U-MDO formulations based on control variate.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/factory/#gemseo_umdo.formulations._statistics.control_variate.factory-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/factory/#gemseo_umdo.formulations._statistics.control_variate.factory.ControlVariateEstimatorFactory","title":"ControlVariateEstimatorFactory","text":"<p>               Bases: <code>BaseFactory</code></p> <p>The factory of statistic estimators based on control variates.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/margin/","title":"Margin","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/margin/#gemseo_umdo.formulations._statistics.control_variate.margin","title":"margin","text":"<p>Estimator of a margin for U-MDO formulations based on control variates.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/margin/#gemseo_umdo.formulations._statistics.control_variate.margin-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/margin/#gemseo_umdo.formulations._statistics.control_variate.margin.Margin","title":"Margin","text":"<pre><code>Margin(\n    uncertain_space: ParameterSpace, factor: float = 2.0\n)\n</code></pre> <p>               Bases: <code>BaseControlVariateEstimator</code></p> <p>Estimator of a margin, i.e. mean + factor * deviation.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain space.</p> </li> <li> <code>factor</code>               (<code>float</code>, default:                   <code>2.0</code> )           \u2013            <p>The factor related to the standard deviation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/control_variate/margin.py</code> <pre><code>def __init__(self, uncertain_space: ParameterSpace, factor: float = 2.0) -&gt; None:\n    \"\"\"\n    Args:\n        factor: The factor related to the standard deviation.\n    \"\"\"  # noqa: D205 D212 D415\n    super().__init__(uncertain_space)\n    self.__mean = Mean(uncertain_space)\n    self.__standard_deviation = StandardDeviation(uncertain_space)\n    self.__factor = factor\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/mean/","title":"Mean","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/mean/#gemseo_umdo.formulations._statistics.control_variate.mean","title":"mean","text":"<p>Estimator of the expectation for U-MDO formulations based on control variates.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/mean/#gemseo_umdo.formulations._statistics.control_variate.mean-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/mean/#gemseo_umdo.formulations._statistics.control_variate.mean.Mean","title":"Mean","text":"<pre><code>Mean(uncertain_space: ParameterSpace)\n</code></pre> <p>               Bases: <code>BaseControlVariateEstimator</code></p> <p>Estimator of the expectation.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain space.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/control_variate/base_control_variate_estimator.py</code> <pre><code>def __init__(self, uncertain_space: ParameterSpace) -&gt; None:\n    \"\"\"\n    Args:\n        uncertain_space: The uncertain space.\n    \"\"\"  # noqa: D205 D212 D415\n    self._u_mean = uncertain_space.distribution.mean\n    self._u_standard_deviation = uncertain_space.distribution.standard_deviation\n    self._uncertain_space = uncertain_space\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/probability/","title":"Probability","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/probability/#gemseo_umdo.formulations._statistics.control_variate.probability","title":"probability","text":"<p>Estimator of a probability for U-MDO formulations based on control variates.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/probability/#gemseo_umdo.formulations._statistics.control_variate.probability-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/probability/#gemseo_umdo.formulations._statistics.control_variate.probability.Probability","title":"Probability","text":"<pre><code>Probability(\n    uncertain_space: ParameterSpace,\n    threshold: float = 0.0,\n    greater: bool = True,\n    n_samples: int = 10000,\n)\n</code></pre> <p>               Bases: <code>BaseControlVariateEstimator</code></p> <p>Estimator of a probability.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain space.</p> </li> <li> <code>threshold</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>The threshold against which the probability is estimated.</p> </li> <li> <code>greater</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to compute the probability of exceeding the threshold.</p> </li> <li> <code>n_samples</code>               (<code>int</code>, default:                   <code>10000</code> )           \u2013            <p>A high number of samples to approximate the statistic with the low-fidelity model.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/control_variate/probability.py</code> <pre><code>def __init__(\n    self,\n    uncertain_space: ParameterSpace,\n    threshold: float = 0.0,\n    greater: bool = True,\n    n_samples: int = 10000,\n) -&gt; None:\n    \"\"\"\n    Args:\n        threshold: The threshold against which the probability is estimated.\n        greater: Whether to compute the probability of exceeding the threshold.\n        n_samples: A high number of samples to approximate the statistic\n            with the low-fidelity model.\n    \"\"\"  # noqa: D205 D212 D415\n    super().__init__(uncertain_space)\n    self.__threshold = threshold\n    self.__compare = ge if greater else le\n    self.__n_samples = n_samples\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/standard_deviation/","title":"Standard deviation","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/standard_deviation/#gemseo_umdo.formulations._statistics.control_variate.standard_deviation","title":"standard_deviation","text":"<p>Estimator of the standard deviation for control variate-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/standard_deviation/#gemseo_umdo.formulations._statistics.control_variate.standard_deviation-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/standard_deviation/#gemseo_umdo.formulations._statistics.control_variate.standard_deviation.StandardDeviation","title":"StandardDeviation","text":"<pre><code>StandardDeviation(uncertain_space: ParameterSpace)\n</code></pre> <p>               Bases: <code>Variance</code></p> <p>Estimator of the standard deviation.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain space.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/control_variate/base_control_variate_estimator.py</code> <pre><code>def __init__(self, uncertain_space: ParameterSpace) -&gt; None:\n    \"\"\"\n    Args:\n        uncertain_space: The uncertain space.\n    \"\"\"  # noqa: D205 D212 D415\n    self._u_mean = uncertain_space.distribution.mean\n    self._u_standard_deviation = uncertain_space.distribution.standard_deviation\n    self._uncertain_space = uncertain_space\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/variance/","title":"Variance","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/variance/#gemseo_umdo.formulations._statistics.control_variate.variance","title":"variance","text":"<p>Estimators of the variance for U-MDO formulation based on control variates.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/variance/#gemseo_umdo.formulations._statistics.control_variate.variance-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/variance/#gemseo_umdo.formulations._statistics.control_variate.variance.Variance","title":"Variance","text":"<pre><code>Variance(uncertain_space: ParameterSpace)\n</code></pre> <p>               Bases: <code>BaseControlVariateEstimator</code></p> <p>Estimator of the variance.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain space.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/control_variate/base_control_variate_estimator.py</code> <pre><code>def __init__(self, uncertain_space: ParameterSpace) -&gt; None:\n    \"\"\"\n    Args:\n        uncertain_space: The uncertain space.\n    \"\"\"  # noqa: D205 D212 D415\n    self._u_mean = uncertain_space.distribution.mean\n    self._u_standard_deviation = uncertain_space.distribution.standard_deviation\n    self._uncertain_space = uncertain_space\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/","title":"Iterative sampling","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/#gemseo_umdo.formulations._statistics.iterative_sampling","title":"iterative_sampling","text":"<p>Iterative estimators of statistics for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_central_moment/","title":"Base central moment","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_central_moment/#gemseo_umdo.formulations._statistics.iterative_sampling.base_central_moment","title":"base_central_moment","text":"<p>Iterative estimator of a moment for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_central_moment/#gemseo_umdo.formulations._statistics.iterative_sampling.base_central_moment-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_central_moment/#gemseo_umdo.formulations._statistics.iterative_sampling.base_central_moment.BaseCentralMoment","title":"BaseCentralMoment","text":"<pre><code>BaseCentralMoment()\n</code></pre> <p>               Bases: <code>BaseSamplingEstimator</code></p> <p>Base iterative estimator of a central moment, e.g. expectation or variance.</p> <p>This class iteratively computes a central moment of an increasing dataset without storing any data in memory.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator.py</code> <pre><code>def __init__(self) -&gt; None:  # noqa: D107\n    super().__init__()\n    self._size = 0\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_central_moment/#gemseo_umdo.formulations._statistics.iterative_sampling.base_central_moment.BaseCentralMoment-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_central_moment/#gemseo_umdo.formulations._statistics.iterative_sampling.base_central_moment.BaseCentralMoment.reset","title":"reset","text":"<pre><code>reset() -&gt; None\n</code></pre> <p>Reset the estimator of the statistic.</p> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/base_central_moment.py</code> <pre><code>def reset(self) -&gt; None:  # noqa: D102\n    self._estimator = IterativeMoments(self._ORDER, self._size)\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator/","title":"Base sampling estimator","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator/#gemseo_umdo.formulations._statistics.iterative_sampling.base_sampling_estimator","title":"base_sampling_estimator","text":"<p>Base statistic iterative estimator for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator/#gemseo_umdo.formulations._statistics.iterative_sampling.base_sampling_estimator-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator/#gemseo_umdo.formulations._statistics.iterative_sampling.base_sampling_estimator.BaseSamplingEstimator","title":"BaseSamplingEstimator","text":"<pre><code>BaseSamplingEstimator()\n</code></pre> <p>               Bases: <code>BaseStatisticEstimator</code></p> <p>Base statistic iterative estimator for a U-MDO formulation using sampling.</p> <p>This class enables to iteratively compute estimators of an increasing dataset without storing any data in memory.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator.py</code> <pre><code>def __init__(self) -&gt; None:  # noqa: D107\n    super().__init__()\n    self._size = 0\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator/#gemseo_umdo.formulations._statistics.iterative_sampling.base_sampling_estimator.BaseSamplingEstimator-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator/#gemseo_umdo.formulations._statistics.iterative_sampling.base_sampling_estimator.BaseSamplingEstimator.reset","title":"reset  <code>abstractmethod</code>","text":"<pre><code>reset() -&gt; None\n</code></pre> <p>Reset the estimator of the statistic.</p> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator.py</code> <pre><code>@abstractmethod\ndef reset(self) -&gt; None:\n    \"\"\"Reset the estimator of the statistic.\"\"\"\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/factory/","title":"Factory","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/factory/#gemseo_umdo.formulations._statistics.iterative_sampling.factory","title":"factory","text":"<p>A factory of iterative statistic estimators for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/factory/#gemseo_umdo.formulations._statistics.iterative_sampling.factory-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/factory/#gemseo_umdo.formulations._statistics.iterative_sampling.factory.SamplingEstimatorFactory","title":"SamplingEstimatorFactory","text":"<p>               Bases: <code>BaseFactory</code></p> <p>The factory of iterative sampling estimators.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/margin/","title":"Margin","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/margin/#gemseo_umdo.formulations._statistics.iterative_sampling.margin","title":"margin","text":"<p>Iterative estimator of a margin for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/margin/#gemseo_umdo.formulations._statistics.iterative_sampling.margin-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/margin/#gemseo_umdo.formulations._statistics.iterative_sampling.margin.Margin","title":"Margin","text":"<pre><code>Margin(factor: float = 2.0)\n</code></pre> <p>               Bases: <code>BaseSamplingEstimator</code></p> <p>Iterative estimator of a margin, i.e. mean + factor * deviation.</p> <p>This class iteratively computes a margin of an increasing dataset without storing any data in memory.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>factor</code>               (<code>float</code>, default:                   <code>2.0</code> )           \u2013            <p>The factor related to the standard deviation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/margin.py</code> <pre><code>def __init__(self, factor: float = 2.0) -&gt; None:\n    \"\"\"\n    Args:\n        factor: The factor related to the standard deviation.\n    \"\"\"  # noqa: D205 D212 D415\n    super().__init__()\n    self.__mean = Mean()\n    self.__standard_deviation = StandardDeviation()\n    self.__factor = factor\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/margin/#gemseo_umdo.formulations._statistics.iterative_sampling.margin.Margin-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/margin/#gemseo_umdo.formulations._statistics.iterative_sampling.margin.Margin.reset","title":"reset","text":"<pre><code>reset() -&gt; None\n</code></pre> <p>Reset the estimator of the statistic.</p> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/margin.py</code> <pre><code>def reset(self) -&gt; None:  # noqa: D102\n    self.__mean.reset()\n    self.__standard_deviation.reset()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/mean/","title":"Mean","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/mean/#gemseo_umdo.formulations._statistics.iterative_sampling.mean","title":"mean","text":"<p>Iterative estimator of the expectation for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/mean/#gemseo_umdo.formulations._statistics.iterative_sampling.mean-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/mean/#gemseo_umdo.formulations._statistics.iterative_sampling.mean.Mean","title":"Mean","text":"<pre><code>Mean()\n</code></pre> <p>               Bases: <code>BaseCentralMoment</code></p> <p>Iterative estimator of the expectation.</p> <p>This class iteratively computes the mean of an increasing dataset without storing any data in memory.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator.py</code> <pre><code>def __init__(self) -&gt; None:  # noqa: D107\n    super().__init__()\n    self._size = 0\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/mean/#gemseo_umdo.formulations._statistics.iterative_sampling.mean.Mean-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/mean/#gemseo_umdo.formulations._statistics.iterative_sampling.mean.Mean.reset","title":"reset","text":"<pre><code>reset() -&gt; None\n</code></pre> <p>Reset the estimator of the statistic.</p> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/base_central_moment.py</code> <pre><code>def reset(self) -&gt; None:  # noqa: D102\n    self._estimator = IterativeMoments(self._ORDER, self._size)\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/probability/","title":"Probability","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/probability/#gemseo_umdo.formulations._statistics.iterative_sampling.probability","title":"probability","text":"<p>Iterative estimator of a probability for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/probability/#gemseo_umdo.formulations._statistics.iterative_sampling.probability-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/probability/#gemseo_umdo.formulations._statistics.iterative_sampling.probability.Probability","title":"Probability","text":"<pre><code>Probability(threshold: float = 0.0, greater: bool = True)\n</code></pre> <p>               Bases: <code>BaseSamplingEstimator</code></p> <p>Iterative estimator of a probability.</p> <p>This class iteratively computes a probability on an increasing dataset without storing any data in memory.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>threshold</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>The threshold against which the probability is estimated.</p> </li> <li> <code>greater</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to compute the probability of exceeding the threshold.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/probability.py</code> <pre><code>def __init__(\n    self,\n    threshold: float = 0.0,\n    greater: bool = True,\n) -&gt; None:\n    \"\"\"\n    Args:\n        threshold: The threshold against which the probability is estimated.\n        greater: Whether to compute the probability of exceeding the threshold.\n    \"\"\"  # noqa: D205 D212 D415\n    super().__init__()\n    self.__threshold = threshold\n    self.__greater = greater\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/probability/#gemseo_umdo.formulations._statistics.iterative_sampling.probability.Probability-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/probability/#gemseo_umdo.formulations._statistics.iterative_sampling.probability.Probability.reset","title":"reset","text":"<pre><code>reset() -&gt; None\n</code></pre> <p>Reset the estimator of the statistic.</p> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/probability.py</code> <pre><code>def reset(self) -&gt; None:  # noqa: D102\n    self._estimator = IterativeThresholdExceedance(self._size, self.__threshold)\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/standard_deviation/","title":"Standard deviation","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/standard_deviation/#gemseo_umdo.formulations._statistics.iterative_sampling.standard_deviation","title":"standard_deviation","text":"<p>Iterative estimator of a standard deviation for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/standard_deviation/#gemseo_umdo.formulations._statistics.iterative_sampling.standard_deviation-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/standard_deviation/#gemseo_umdo.formulations._statistics.iterative_sampling.standard_deviation.StandardDeviation","title":"StandardDeviation","text":"<pre><code>StandardDeviation()\n</code></pre> <p>               Bases: <code>Variance</code></p> <p>Iterative estimator of the standard deviation.</p> <p>This class iteratively computes the standard deviation of an increasing dataset without storing any data in memory.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator.py</code> <pre><code>def __init__(self) -&gt; None:  # noqa: D107\n    super().__init__()\n    self._size = 0\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/standard_deviation/#gemseo_umdo.formulations._statistics.iterative_sampling.standard_deviation.StandardDeviation-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/standard_deviation/#gemseo_umdo.formulations._statistics.iterative_sampling.standard_deviation.StandardDeviation.reset","title":"reset","text":"<pre><code>reset() -&gt; None\n</code></pre> <p>Reset the estimator of the statistic.</p> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/base_central_moment.py</code> <pre><code>def reset(self) -&gt; None:  # noqa: D102\n    self._estimator = IterativeMoments(self._ORDER, self._size)\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/variance/","title":"Variance","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/variance/#gemseo_umdo.formulations._statistics.iterative_sampling.variance","title":"variance","text":"<p>Iterative estimator of the variance for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/variance/#gemseo_umdo.formulations._statistics.iterative_sampling.variance-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/variance/#gemseo_umdo.formulations._statistics.iterative_sampling.variance.Variance","title":"Variance","text":"<pre><code>Variance()\n</code></pre> <p>               Bases: <code>BaseCentralMoment</code></p> <p>Iterative estimator of the variance.</p> <p>This class iteratively computes the variance of an increasing dataset without storing any data in memory.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator.py</code> <pre><code>def __init__(self) -&gt; None:  # noqa: D107\n    super().__init__()\n    self._size = 0\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/variance/#gemseo_umdo.formulations._statistics.iterative_sampling.variance.Variance-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/variance/#gemseo_umdo.formulations._statistics.iterative_sampling.variance.Variance.reset","title":"reset","text":"<pre><code>reset() -&gt; None\n</code></pre> <p>Reset the estimator of the statistic.</p> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/base_central_moment.py</code> <pre><code>def reset(self) -&gt; None:  # noqa: D102\n    self._estimator = IterativeMoments(self._ORDER, self._size)\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/","title":"Pce","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/#gemseo_umdo.formulations._statistics.pce","title":"pce","text":"<p>Estimators of statistics for U-MDO formulations based on PCE.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/base_pce_estimator/","title":"Base pce estimator","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/base_pce_estimator/#gemseo_umdo.formulations._statistics.pce.base_pce_estimator","title":"base_pce_estimator","text":"<p>Base statistic estimator for a U-MDO formulations based on PCE.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/base_pce_estimator/#gemseo_umdo.formulations._statistics.pce.base_pce_estimator-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/base_pce_estimator/#gemseo_umdo.formulations._statistics.pce.base_pce_estimator.BasePCEEstimator","title":"BasePCEEstimator","text":"<p>               Bases: <code>BaseStatisticEstimator</code></p> <p>Base statistic estimator for a U-MDO formulation using PCE.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/base_pce_estimator/#gemseo_umdo.formulations._statistics.pce.base_pce_estimator.BasePCEEstimator-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/base_pce_estimator/#gemseo_umdo.formulations._statistics.pce.base_pce_estimator.BasePCEEstimator.ARG_NAMES","title":"ARG_NAMES  <code>class-attribute</code>","text":"<pre><code>ARG_NAMES: tuple[str] = ()\n</code></pre> <p>The names of the arguments to be used for the estimator.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/base_pce_estimator/#gemseo_umdo.formulations._statistics.pce.base_pce_estimator.BasePCEEstimator.MEAN_ARG_NAME","title":"MEAN_ARG_NAME  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MEAN_ARG_NAME: Final[str] = 'mean'\n</code></pre> <p>The name of the mean argument.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/base_pce_estimator/#gemseo_umdo.formulations._statistics.pce.base_pce_estimator.BasePCEEstimator.STD_ARG_NAME","title":"STD_ARG_NAME  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>STD_ARG_NAME: Final[str] = 'std'\n</code></pre> <p>The name of the standard deviation argument.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/base_pce_estimator/#gemseo_umdo.formulations._statistics.pce.base_pce_estimator.BasePCEEstimator.VAR_ARG_NAME","title":"VAR_ARG_NAME  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>VAR_ARG_NAME: Final[str] = 'var'\n</code></pre> <p>The name of the variance argument.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/factory/","title":"Factory","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/factory/#gemseo_umdo.formulations._statistics.pce.factory","title":"factory","text":"<p>A factory of statistic estimators for a U-MDO formulations using PCE.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/factory/#gemseo_umdo.formulations._statistics.pce.factory-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/factory/#gemseo_umdo.formulations._statistics.pce.factory.PCEEstimatorFactory","title":"PCEEstimatorFactory","text":"<p>               Bases: <code>BaseFactory</code></p> <p>The factory of statistic estimators based on PCE.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/margin/","title":"Margin","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/margin/#gemseo_umdo.formulations._statistics.pce.margin","title":"margin","text":"<p>Estimators of a margin for a U-MDO formulation based on PCE.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/margin/#gemseo_umdo.formulations._statistics.pce.margin-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/margin/#gemseo_umdo.formulations._statistics.pce.margin.Margin","title":"Margin","text":"<pre><code>Margin(factor: float = 2.0)\n</code></pre> <p>               Bases: <code>BasePCEEstimator</code></p> <p>Estimator of a margin, i.e. mean + factor * deviation.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>factor</code>               (<code>float</code>, default:                   <code>2.0</code> )           \u2013            <p>The factor related to the standard deviation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/pce/margin.py</code> <pre><code>def __init__(self, factor: float = 2.0) -&gt; None:\n    \"\"\"\n    Args:\n        factor: The factor related to the standard deviation.\n    \"\"\"  # noqa: D205 D212 D415\n    self.__factor = factor\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/margin/#gemseo_umdo.formulations._statistics.pce.margin.Margin-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/margin/#gemseo_umdo.formulations._statistics.pce.margin.Margin.ARG_NAMES","title":"ARG_NAMES  <code>class-attribute</code>","text":"<pre><code>ARG_NAMES: tuple[str] = (MEAN_ARG_NAME, STD_ARG_NAME)\n</code></pre> <p>The names of the arguments to be used for the estimator.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/margin/#gemseo_umdo.formulations._statistics.pce.margin.Margin.MEAN_ARG_NAME","title":"MEAN_ARG_NAME  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MEAN_ARG_NAME: Final[str] = 'mean'\n</code></pre> <p>The name of the mean argument.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/margin/#gemseo_umdo.formulations._statistics.pce.margin.Margin.STD_ARG_NAME","title":"STD_ARG_NAME  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>STD_ARG_NAME: Final[str] = 'std'\n</code></pre> <p>The name of the standard deviation argument.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/margin/#gemseo_umdo.formulations._statistics.pce.margin.Margin.VAR_ARG_NAME","title":"VAR_ARG_NAME  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>VAR_ARG_NAME: Final[str] = 'var'\n</code></pre> <p>The name of the variance argument.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/mean/","title":"Mean","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/mean/#gemseo_umdo.formulations._statistics.pce.mean","title":"mean","text":"<p>Estimator of the expectation for a U-MDO formulations based on PCE.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/mean/#gemseo_umdo.formulations._statistics.pce.mean-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/mean/#gemseo_umdo.formulations._statistics.pce.mean.Mean","title":"Mean","text":"<p>               Bases: <code>BasePCEEstimator</code></p> <p>Estimator of the expectation.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/mean/#gemseo_umdo.formulations._statistics.pce.mean.Mean-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/mean/#gemseo_umdo.formulations._statistics.pce.mean.Mean.ARG_NAMES","title":"ARG_NAMES  <code>class-attribute</code>","text":"<pre><code>ARG_NAMES: tuple[str] = (MEAN_ARG_NAME)\n</code></pre> <p>The names of the arguments to be used for the estimator.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/mean/#gemseo_umdo.formulations._statistics.pce.mean.Mean.MEAN_ARG_NAME","title":"MEAN_ARG_NAME  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MEAN_ARG_NAME: Final[str] = 'mean'\n</code></pre> <p>The name of the mean argument.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/mean/#gemseo_umdo.formulations._statistics.pce.mean.Mean.STD_ARG_NAME","title":"STD_ARG_NAME  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>STD_ARG_NAME: Final[str] = 'std'\n</code></pre> <p>The name of the standard deviation argument.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/mean/#gemseo_umdo.formulations._statistics.pce.mean.Mean.VAR_ARG_NAME","title":"VAR_ARG_NAME  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>VAR_ARG_NAME: Final[str] = 'var'\n</code></pre> <p>The name of the variance argument.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/standard_deviation/","title":"Standard deviation","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/standard_deviation/#gemseo_umdo.formulations._statistics.pce.standard_deviation","title":"standard_deviation","text":"<p>Estimator of the standard deviation for a U-MDO formulations based on PCE.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/standard_deviation/#gemseo_umdo.formulations._statistics.pce.standard_deviation-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/standard_deviation/#gemseo_umdo.formulations._statistics.pce.standard_deviation.StandardDeviation","title":"StandardDeviation","text":"<p>               Bases: <code>BasePCEEstimator</code></p> <p>Estimator of the standard deviation.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/standard_deviation/#gemseo_umdo.formulations._statistics.pce.standard_deviation.StandardDeviation-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/standard_deviation/#gemseo_umdo.formulations._statistics.pce.standard_deviation.StandardDeviation.ARG_NAMES","title":"ARG_NAMES  <code>class-attribute</code>","text":"<pre><code>ARG_NAMES: tuple[str] = (STD_ARG_NAME)\n</code></pre> <p>The names of the arguments to be used for the estimator.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/standard_deviation/#gemseo_umdo.formulations._statistics.pce.standard_deviation.StandardDeviation.MEAN_ARG_NAME","title":"MEAN_ARG_NAME  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MEAN_ARG_NAME: Final[str] = 'mean'\n</code></pre> <p>The name of the mean argument.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/standard_deviation/#gemseo_umdo.formulations._statistics.pce.standard_deviation.StandardDeviation.STD_ARG_NAME","title":"STD_ARG_NAME  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>STD_ARG_NAME: Final[str] = 'std'\n</code></pre> <p>The name of the standard deviation argument.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/standard_deviation/#gemseo_umdo.formulations._statistics.pce.standard_deviation.StandardDeviation.VAR_ARG_NAME","title":"VAR_ARG_NAME  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>VAR_ARG_NAME: Final[str] = 'var'\n</code></pre> <p>The name of the variance argument.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/variance/","title":"Variance","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/variance/#gemseo_umdo.formulations._statistics.pce.variance","title":"variance","text":"<p>Estimator of the variance for a U-MDO formulations based on PCE.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/variance/#gemseo_umdo.formulations._statistics.pce.variance-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/variance/#gemseo_umdo.formulations._statistics.pce.variance.Variance","title":"Variance","text":"<p>               Bases: <code>BasePCEEstimator</code></p> <p>Estimator of the variance.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/variance/#gemseo_umdo.formulations._statistics.pce.variance.Variance-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/variance/#gemseo_umdo.formulations._statistics.pce.variance.Variance.ARG_NAMES","title":"ARG_NAMES  <code>class-attribute</code>","text":"<pre><code>ARG_NAMES: tuple[str] = (VAR_ARG_NAME)\n</code></pre> <p>The names of the arguments to be used for the estimator.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/variance/#gemseo_umdo.formulations._statistics.pce.variance.Variance.MEAN_ARG_NAME","title":"MEAN_ARG_NAME  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MEAN_ARG_NAME: Final[str] = 'mean'\n</code></pre> <p>The name of the mean argument.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/variance/#gemseo_umdo.formulations._statistics.pce.variance.Variance.STD_ARG_NAME","title":"STD_ARG_NAME  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>STD_ARG_NAME: Final[str] = 'std'\n</code></pre> <p>The name of the standard deviation argument.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/variance/#gemseo_umdo.formulations._statistics.pce.variance.Variance.VAR_ARG_NAME","title":"VAR_ARG_NAME  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>VAR_ARG_NAME: Final[str] = 'var'\n</code></pre> <p>The name of the variance argument.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/","title":"Sampling","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/#gemseo_umdo.formulations._statistics.sampling","title":"sampling","text":"<p>Estimators of statistics for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/base_sampling_estimator/","title":"Base sampling estimator","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/base_sampling_estimator/#gemseo_umdo.formulations._statistics.sampling.base_sampling_estimator","title":"base_sampling_estimator","text":"<p>Base statistic estimator for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/base_sampling_estimator/#gemseo_umdo.formulations._statistics.sampling.base_sampling_estimator-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/base_sampling_estimator/#gemseo_umdo.formulations._statistics.sampling.base_sampling_estimator.BaseSamplingEstimator","title":"BaseSamplingEstimator","text":"<p>               Bases: <code>BaseStatisticEstimator</code></p> <p>Base statistic estimator for a U-MDO formulation using sampling.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/factory/","title":"Factory","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/factory/#gemseo_umdo.formulations._statistics.sampling.factory","title":"factory","text":"<p>A factory of statistic estimators for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/factory/#gemseo_umdo.formulations._statistics.sampling.factory-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/factory/#gemseo_umdo.formulations._statistics.sampling.factory.SamplingEstimatorFactory","title":"SamplingEstimatorFactory","text":"<p>               Bases: <code>BaseFactory</code></p> <p>The factory of sampling-based statistic estimators.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/margin/","title":"Margin","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/margin/#gemseo_umdo.formulations._statistics.sampling.margin","title":"margin","text":"<p>Estimator of a margin for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/margin/#gemseo_umdo.formulations._statistics.sampling.margin-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/margin/#gemseo_umdo.formulations._statistics.sampling.margin.Margin","title":"Margin","text":"<pre><code>Margin(factor: float = 2.0)\n</code></pre> <p>               Bases: <code>BaseSamplingEstimator</code></p> <p>Estimator of a margin, i.e. mean + factor * deviation.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>factor</code>               (<code>float</code>, default:                   <code>2.0</code> )           \u2013            <p>The factor related to the standard deviation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/sampling/margin.py</code> <pre><code>def __init__(self, factor: float = 2.0) -&gt; None:\n    \"\"\"\n    Args:\n        factor: The factor related to the standard deviation.\n    \"\"\"  # noqa: D205 D212 D415\n    super().__init__()\n    self.__mean = Mean()\n    self.__standard_deviation = StandardDeviation()\n    self.__factor = factor\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/mean/","title":"Mean","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/mean/#gemseo_umdo.formulations._statistics.sampling.mean","title":"mean","text":"<p>Estimator of the expectation for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/mean/#gemseo_umdo.formulations._statistics.sampling.mean-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/mean/#gemseo_umdo.formulations._statistics.sampling.mean.Mean","title":"Mean","text":"<p>               Bases: <code>BaseSamplingEstimator</code></p> <p>Estimator of the expectation.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/probability/","title":"Probability","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/probability/#gemseo_umdo.formulations._statistics.sampling.probability","title":"probability","text":"<p>Estimator of a probability for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/probability/#gemseo_umdo.formulations._statistics.sampling.probability-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/probability/#gemseo_umdo.formulations._statistics.sampling.probability.Probability","title":"Probability","text":"<pre><code>Probability(threshold: float = 0.0, greater: bool = True)\n</code></pre> <p>               Bases: <code>BaseSamplingEstimator</code></p> <p>Estimator of a probability.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>threshold</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>The threshold against which the probability is estimated.</p> </li> <li> <code>greater</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to compute the probability of exceeding the threshold.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/sampling/probability.py</code> <pre><code>def __init__(self, threshold: float = 0.0, greater: bool = True) -&gt; None:\n    \"\"\"\n    Args:\n        threshold: The threshold against which the probability is estimated.\n        greater: Whether to compute the probability of exceeding the threshold.\n    \"\"\"  # noqa: D205 D212 D415\n    super().__init__()\n    self.__threshold = threshold\n    self.__compare = ge if greater else le\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/standard_deviation/","title":"Standard deviation","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/standard_deviation/#gemseo_umdo.formulations._statistics.sampling.standard_deviation","title":"standard_deviation","text":"<p>Estimator of the standard deviation for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/standard_deviation/#gemseo_umdo.formulations._statistics.sampling.standard_deviation-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/standard_deviation/#gemseo_umdo.formulations._statistics.sampling.standard_deviation.StandardDeviation","title":"StandardDeviation","text":"<p>               Bases: <code>Variance</code></p> <p>Estimator of the standard deviation.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/variance/","title":"Variance","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/variance/#gemseo_umdo.formulations._statistics.sampling.variance","title":"variance","text":"<p>Estimator of the variance for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/variance/#gemseo_umdo.formulations._statistics.sampling.variance-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/variance/#gemseo_umdo.formulations._statistics.sampling.variance.Variance","title":"Variance","text":"<p>               Bases: <code>BaseSamplingEstimator</code></p> <p>Estimator of the variance.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/","title":"Taylor polynomial","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/#gemseo_umdo.formulations._statistics.taylor_polynomial","title":"taylor_polynomial","text":"<p>Estimators of statistics for U-MDO formulations based on Taylor polynomials.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/base_taylor_polynomial_estimator/","title":"Base taylor polynomial estimator","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/base_taylor_polynomial_estimator/#gemseo_umdo.formulations._statistics.taylor_polynomial.base_taylor_polynomial_estimator","title":"base_taylor_polynomial_estimator","text":"<p>Base statistic estimator for U-MDO formulations based on Taylor polynomials.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/base_taylor_polynomial_estimator/#gemseo_umdo.formulations._statistics.taylor_polynomial.base_taylor_polynomial_estimator-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/base_taylor_polynomial_estimator/#gemseo_umdo.formulations._statistics.taylor_polynomial.base_taylor_polynomial_estimator.BaseTaylorPolynomialEstimator","title":"BaseTaylorPolynomialEstimator","text":"<pre><code>BaseTaylorPolynomialEstimator(\n    uncertain_space: ParameterSpace,\n)\n</code></pre> <p>               Bases: <code>BaseStatisticEstimator</code></p> <p>Base statistic estimator for a U-MDO formulation using Taylor polynomials.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain variables with their probability distributions.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/taylor_polynomial/base_taylor_polynomial_estimator.py</code> <pre><code>def __init__(self, uncertain_space: ParameterSpace) -&gt; None:\n    \"\"\"\n    Args:\n        uncertain_space: The uncertain variables\n            with their probability distributions.\n    \"\"\"  # noqa: D205 D212 D415\n    self._standard_deviations = uncertain_space.distribution.standard_deviation\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/factory/","title":"Factory","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/factory/#gemseo_umdo.formulations._statistics.taylor_polynomial.factory","title":"factory","text":"<p>A factory of statistic estimators for U-MDO formulations using Taylor polynomials.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/factory/#gemseo_umdo.formulations._statistics.taylor_polynomial.factory-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/factory/#gemseo_umdo.formulations._statistics.taylor_polynomial.factory.TaylorPolynomialEstimatorFactory","title":"TaylorPolynomialEstimatorFactory","text":"<p>               Bases: <code>BaseFactory</code></p> <p>The factory of statistic estimators based on Taylor polynomials.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/margin/","title":"Margin","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/margin/#gemseo_umdo.formulations._statistics.taylor_polynomial.margin","title":"margin","text":"<p>Estimators of a margin for U-MDO formulation based on Taylor polynomials.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/margin/#gemseo_umdo.formulations._statistics.taylor_polynomial.margin-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/margin/#gemseo_umdo.formulations._statistics.taylor_polynomial.margin.Margin","title":"Margin","text":"<pre><code>Margin(\n    uncertain_space: ParameterSpace, factor: float = 2.0\n)\n</code></pre> <p>               Bases: <code>BaseTaylorPolynomialEstimator</code></p> <p>Estimator of a margin, i.e. mean + factor * deviation.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain variables with their probability distributions.</p> </li> <li> <code>factor</code>               (<code>float</code>, default:                   <code>2.0</code> )           \u2013            <p>The factor related to the standard deviation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/taylor_polynomial/margin.py</code> <pre><code>def __init__(self, uncertain_space: ParameterSpace, factor: float = 2.0) -&gt; None:\n    \"\"\"\n    Args:\n        factor: The factor related to the standard deviation.\n    \"\"\"  # noqa: D205 D212 D415\n    super().__init__(uncertain_space)\n    self.__mean = Mean(uncertain_space)\n    self.__standard_deviation = StandardDeviation(uncertain_space)\n    self.__factor = factor\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/mean/","title":"Mean","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/mean/#gemseo_umdo.formulations._statistics.taylor_polynomial.mean","title":"mean","text":"<p>Estimator of the expectation for U-MDO formulations based on Taylor polynomials.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/mean/#gemseo_umdo.formulations._statistics.taylor_polynomial.mean-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/mean/#gemseo_umdo.formulations._statistics.taylor_polynomial.mean.Mean","title":"Mean","text":"<pre><code>Mean(uncertain_space: ParameterSpace)\n</code></pre> <p>               Bases: <code>BaseTaylorPolynomialEstimator</code></p> <p>Estimator of the expectation.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain variables with their probability distributions.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/taylor_polynomial/base_taylor_polynomial_estimator.py</code> <pre><code>def __init__(self, uncertain_space: ParameterSpace) -&gt; None:\n    \"\"\"\n    Args:\n        uncertain_space: The uncertain variables\n            with their probability distributions.\n    \"\"\"  # noqa: D205 D212 D415\n    self._standard_deviations = uncertain_space.distribution.standard_deviation\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/standard_deviation/","title":"Standard deviation","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/standard_deviation/#gemseo_umdo.formulations._statistics.taylor_polynomial.standard_deviation","title":"standard_deviation","text":"<p>Estimator of the standard deviation for U-MDO formulations based on Taylor.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/standard_deviation/#gemseo_umdo.formulations._statistics.taylor_polynomial.standard_deviation-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/standard_deviation/#gemseo_umdo.formulations._statistics.taylor_polynomial.standard_deviation.StandardDeviation","title":"StandardDeviation","text":"<pre><code>StandardDeviation(uncertain_space: ParameterSpace)\n</code></pre> <p>               Bases: <code>Variance</code></p> <p>Estimator of the standard deviation.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain variables with their probability distributions.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/taylor_polynomial/base_taylor_polynomial_estimator.py</code> <pre><code>def __init__(self, uncertain_space: ParameterSpace) -&gt; None:\n    \"\"\"\n    Args:\n        uncertain_space: The uncertain variables\n            with their probability distributions.\n    \"\"\"  # noqa: D205 D212 D415\n    self._standard_deviations = uncertain_space.distribution.standard_deviation\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/variance/","title":"Variance","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/variance/#gemseo_umdo.formulations._statistics.taylor_polynomial.variance","title":"variance","text":"<p>Estimator of the variance for U-MDO formulations based on Taylor polynomials.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/variance/#gemseo_umdo.formulations._statistics.taylor_polynomial.variance-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/variance/#gemseo_umdo.formulations._statistics.taylor_polynomial.variance.Variance","title":"Variance","text":"<pre><code>Variance(uncertain_space: ParameterSpace)\n</code></pre> <p>               Bases: <code>BaseTaylorPolynomialEstimator</code></p> <p>Estimator of the variance.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain variables with their probability distributions.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/taylor_polynomial/base_taylor_polynomial_estimator.py</code> <pre><code>def __init__(self, uncertain_space: ParameterSpace) -&gt; None:\n    \"\"\"\n    Args:\n        uncertain_space: The uncertain variables\n            with their probability distributions.\n    \"\"\"  # noqa: D205 D212 D415\n    self._standard_deviations = uncertain_space.distribution.standard_deviation\n</code></pre>"},{"location":"reference/gemseo_umdo/scenarios/","title":"Scenarios","text":""},{"location":"reference/gemseo_umdo/scenarios/#gemseo_umdo.scenarios","title":"scenarios","text":"<p>Scenarios to address multidisciplinary design problems under uncertainty.</p>"},{"location":"reference/gemseo_umdo/scenarios/base_u_scenario/","title":"Base u scenario","text":""},{"location":"reference/gemseo_umdo/scenarios/base_u_scenario/#gemseo_umdo.scenarios.base_u_scenario","title":"base_u_scenario","text":"<p>Scenarios to address multidisciplinary design problems under uncertainty.</p>"},{"location":"reference/gemseo_umdo/scenarios/base_u_scenario/#gemseo_umdo.scenarios.base_u_scenario-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/scenarios/base_u_scenario/#gemseo_umdo.scenarios.base_u_scenario.BaseUScenario","title":"BaseUScenario","text":"<pre><code>BaseUScenario(\n    disciplines: Sequence[MDODiscipline],\n    formulation: str,\n    objective_name: str,\n    design_space: DesignSpace,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    objective_statistic_parameters: Mapping[\n        str, Any\n    ] = READ_ONLY_EMPTY_DICT,\n    statistic_estimation: str = \"Sampling\",\n    statistic_estimation_parameters: Mapping[\n        str, Any\n    ] = READ_ONLY_EMPTY_DICT,\n    uncertain_design_variables: Mapping[\n        str, str | tuple[str, str]\n    ] = READ_ONLY_EMPTY_DICT,\n    name: str | None = None,\n    grammar_type: GrammarType = MDODiscipline.GrammarType.JSON,\n    maximize_objective: bool = False,\n    **formulation_options: Any\n)\n</code></pre> <p>               Bases: <code>Scenario</code></p> <p>Base scenario for multidisciplinary design problems under uncertainty.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>disciplines</code>               (<code>Sequence[MDODiscipline]</code>)           \u2013            <p>The disciplines used to compute the objective, constraints and observables from the design variables.</p> </li> <li> <code>formulation</code>               (<code>str</code>)           \u2013            <p>The class name of the :class:<code>.MDOFormulation</code>, e.g. <code>\"MDF\"</code>, <code>\"IDF\"</code> or <code>\"BiLevel\"</code>.</p> </li> <li> <code>objective_name</code>               (<code>str</code>)           \u2013            <p>The name(s) of the discipline output(s) used as objective. If multiple names are passed, the objective will be a vector.</p> </li> <li> <code>design_space</code>               (<code>DesignSpace</code>)           \u2013            <p>The search space including at least the design variables (some formulations requires additional variables, e.g. :class:<code>.IDF</code> with the coupling variables).</p> </li> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain variables with their probability distributions.</p> </li> <li> <code>objective_statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the objective, e.g. \"margin\".</p> </li> <li> <code>objective_statistic_parameters</code>               (<code>Mapping[str, Any]</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The parameters of the statistics to be applied to the objective, e.g. <code>{\"factor\": 2.}</code> when <code>objective_statistic=\"margin\"</code>.</p> </li> <li> <code>statistic_estimation</code>               (<code>str</code>, default:                   <code>'Sampling'</code> )           \u2013            <p>The name of the method to estimate the statistic.</p> </li> <li> <code>statistic_estimation_parameters</code>               (<code>Mapping[str, Any]</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The options of <code>statistic_estimation</code>.</p> </li> <li> <code>uncertain_design_variables</code>               (<code>Mapping[str, str | tuple[str, str]]</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>This argument facilitates the definition of uncertain design variables in two ways. The first way consists of passing a dictionary of the form <code>{\"x1\": (\"+\", \"u1\"), \"x2\": (\"*\", \"u2\"), ...}</code> which defines the uncertain design variables as <code>x1 = dv_x1 + u1</code> and <code>x2 = dv_x2 * (1 + u2)</code>. Here <code>\"x1\"</code> and <code>\"x2\"</code> are the names of the design variables made uncertain by the random variables <code>\"u_1\"</code> and <code>\"u_2\"</code> which typically have zero mean. <code>\"x1\"</code> and <code>\"x2\"</code> are the names of the design variables actually used in <code>disciplines</code> while the names <code>\"dv_x1\"</code> and <code>dv_x2</code> are generated by the scenario. More generally, the first element of the tuple is assumed to be either the class name or the SHORT_NAME of a BaseNoiser (feel free to create new noising disciplines). The second way of defining these uncertain design variables consists of passing a set of more complex expressions of the form <code>{\"x\": \"{} + u\", ...}</code> where <code>\"x\"</code> is the name of the design variable actually used in the equations, <code>\"u\"</code> is the name of the uncertain variable defined in the <code>uncertain_space</code> and <code>\"{}\"</code> is the optimization variable. Leave <code>\"{}\"</code> as is; it will be automatically replaced by <code>\"dv_x\"</code>. This more complex format assumes variables of dimension 1. If <code>None</code>, do not consider other variable relations than those defined by <code>disciplines</code>.</p> </li> <li> <code>name</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>The name to be given to this scenario. If empty, use the name of the class.</p> </li> <li> <code>grammar_type</code>               (<code>GrammarType</code>, default:                   <code>JSON</code> )           \u2013            <p>The grammar for the scenario and the MDO formulation.</p> </li> <li> <code>maximize_objective</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to maximize the statistic of the objective.</p> </li> <li> <code>**formulation_options</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The options of the :class:<code>.MDOFormulation</code>.</p> </li> </ul> Source code in <code>src/gemseo_umdo/scenarios/base_u_scenario.py</code> <pre><code>def __init__(\n    self,\n    disciplines: Sequence[MDODiscipline],\n    formulation: str,\n    objective_name: str,\n    design_space: DesignSpace,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    objective_statistic_parameters: Mapping[str, Any] = READ_ONLY_EMPTY_DICT,\n    statistic_estimation: str = \"Sampling\",\n    statistic_estimation_parameters: Mapping[str, Any] = READ_ONLY_EMPTY_DICT,\n    uncertain_design_variables: Mapping[\n        str, str | tuple[str, str]\n    ] = READ_ONLY_EMPTY_DICT,\n    name: str | None = None,\n    grammar_type: MDODiscipline.GrammarType = MDODiscipline.GrammarType.JSON,\n    maximize_objective: bool = False,\n    **formulation_options: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        uncertain_space: The uncertain variables\n            with their probability distributions.\n        objective_statistic_name: The name of the statistic\n            to be applied to the objective, e.g. \"margin\".\n        objective_statistic_parameters: The parameters of the statistics\n            to be applied to the objective,\n            e.g. `{\"factor\": 2.}` when `objective_statistic=\"margin\"`.\n        statistic_estimation: The name of the method to estimate the statistic.\n        statistic_estimation_parameters: The options of `statistic_estimation`.\n        uncertain_design_variables: This argument facilitates\n            the definition of uncertain design variables in two ways.\n            The first way consists of passing a dictionary\n            of the form `{\"x1\": (\"+\", \"u1\"), \"x2\": (\"*\", \"u2\"), ...}`\n            which defines the uncertain design variables as\n            `x1 = dv_x1 + u1` and `x2 = dv_x2 * (1 + u2)`.\n            Here `\"x1\"` and `\"x2\"` are the names of the design variables\n            made uncertain by the random variables `\"u_1\"` and `\"u_2\"`\n            which typically have zero mean.\n            `\"x1\"` and `\"x2\"` are the names of the design variables\n            actually used in `disciplines`\n            while the names `\"dv_x1\"` and `dv_x2` are generated by the scenario.\n            More generally,\n            the first element of the tuple is assumed\n            to be either the class name or the\n            [SHORT_NAME][gemseo_umdo.disciplines.base_noiser.BaseNoiser.SHORT_NAME]\n            of a\n            [BaseNoiser][gemseo_umdo.disciplines.base_noiser.BaseNoiser]\n            (feel free to create new noising disciplines).\n            The second way of defining these uncertain design variables\n            consists of passing a set of more complex expressions\n            of the form `{\"x\": \"{} + u\", ...}`\n            where `\"x\"` is the name of the design variable\n            actually used in the equations,\n            `\"u\"` is the name of the uncertain variable\n            defined in the `uncertain_space`\n            and `\"{}\"` is the optimization variable.\n            Leave `\"{}\"` as is; it will be automatically replaced by `\"dv_x\"`.\n            This more complex format assumes variables of dimension 1.\n            If `None`,\n            do not consider other variable relations\n            than those defined by `disciplines`.\n        maximize_objective: Whether to maximize the statistic of the objective.\n    \"\"\"  # noqa: D205 D212 D415\n    disciplines = list(disciplines)\n    if uncertain_design_variables:\n        self.__add_noising_discipline_chain(\n            disciplines, design_space, uncertain_design_variables\n        )\n\n    formulations_factory = MDOFormulationFactory()\n    mdo_formulation = formulations_factory.create(\n        formulation,\n        disciplines,\n        objective_name,\n        uncertain_space,\n        grammar_type=grammar_type,\n        **formulation_options,\n    )\n\n    filtered_design_space = formulations_factory.create(\n        formulation,\n        disciplines,\n        objective_name,\n        design_space,\n        **formulation_options,\n    ).design_space\n\n    super().__init__(\n        disciplines,\n        statistic_estimation,\n        objective_name,\n        filtered_design_space,\n        name=name,\n        mdo_formulation=mdo_formulation,\n        objective_statistic_name=objective_statistic_name,\n        objective_statistic_parameters=objective_statistic_parameters,\n        uncertain_space=uncertain_space,\n        maximize_objective=maximize_objective,\n        # TODO: simplify this line in gemseo-umdo 3.0.0\n        **(statistic_estimation_parameters or {}),\n    )\n\n    self.formulation_name = self.formulation.name\n</code></pre>"},{"location":"reference/gemseo_umdo/scenarios/base_u_scenario/#gemseo_umdo.scenarios.base_u_scenario.BaseUScenario-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/scenarios/base_u_scenario/#gemseo_umdo.scenarios.base_u_scenario.BaseUScenario.available_statistics","title":"available_statistics  <code>property</code>","text":"<pre><code>available_statistics: list[str]\n</code></pre> <p>The names of the available statistics.</p>"},{"location":"reference/gemseo_umdo/scenarios/base_u_scenario/#gemseo_umdo.scenarios.base_u_scenario.BaseUScenario.mdo_formulation","title":"mdo_formulation  <code>property</code>","text":"<pre><code>mdo_formulation: MDOFormulation\n</code></pre> <p>The MDO formulation.</p>"},{"location":"reference/gemseo_umdo/scenarios/base_u_scenario/#gemseo_umdo.scenarios.base_u_scenario.BaseUScenario.uncertain_space","title":"uncertain_space  <code>property</code>","text":"<pre><code>uncertain_space: ParameterSpace\n</code></pre> <p>The uncertain variable space.</p>"},{"location":"reference/gemseo_umdo/scenarios/base_u_scenario/#gemseo_umdo.scenarios.base_u_scenario.BaseUScenario-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/scenarios/base_u_scenario/#gemseo_umdo.scenarios.base_u_scenario.BaseUScenario.add_constraint","title":"add_constraint","text":"<pre><code>add_constraint(\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: ConstraintType = MDOFunction.ConstraintType.INEQ,\n    constraint_name: str | None = None,\n    value: float | None = None,\n    positive: bool = False,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Add an equality or inequality constraint to the optimization problem.</p> <p>An equality constraint is written as :math:<code>c(x)=a</code>, a positive inequality constraint is written as :math:<code>c(x)\\geq a</code> and a negative inequality constraint is written as :math:<code>c(x)\\leq a</code>.</p> <p>This constraint is in addition to those created by the formulation, e.g. consistency constraints in IDF.</p> <p>The strategy of repartition of the constraints is defined by the formulation.</p> <p>Parameters:</p> <ul> <li> <code>output_name</code>               (<code>str | Sequence[str]</code>)           \u2013            <p>The name(s) of the outputs computed by :math:<code>c(x)</code>. If several names are given, a single discipline must provide all outputs.</p> </li> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the constraint, e.g. \"margin\".</p> </li> <li> <code>constraint_type</code>               (<code>ConstraintType</code>, default:                   <code>INEQ</code> )           \u2013            <p>The type of constraint.</p> </li> <li> <code>constraint_name</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>The name of the constraint to be stored. If empty, the name of the constraint is generated from <code>output_name</code>, <code>constraint_type</code>, <code>value</code> and <code>positive</code>.</p> </li> <li> <code>value</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>The value :math:<code>a</code>.</p> </li> <li> <code>positive</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether the inequality constraint is positive.</p> </li> <li> <code>**statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The description is missing.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the constraint type is neither 'eq' nor 'ineq'.</p> </li> </ul> Source code in <code>src/gemseo_umdo/scenarios/base_u_scenario.py</code> <pre><code>def add_constraint(\n    self,\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: MDOFunction.ConstraintType = MDOFunction.ConstraintType.INEQ,\n    constraint_name: str | None = None,\n    value: float | None = None,\n    positive: bool = False,\n    **statistic_parameters: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        statistic_name: The name of the statistic\n            to be applied to the constraint, e.g. \"margin\".\n        statistic_parameters: The parameters of the statistics\n            to be applied to the constraint,\n            `{\"factor\": 2.}` when `objective_statistic=\"margin\"`.\n    \"\"\"  # noqa: D205 D212 D415\n    self.formulation.add_constraint(\n        output_name,\n        statistic_name,\n        constraint_type=constraint_type,\n        constraint_name=constraint_name,\n        value=value,\n        positive=positive,\n        **statistic_parameters,\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/scenarios/base_u_scenario/#gemseo_umdo.scenarios.base_u_scenario.BaseUScenario.add_observable","title":"add_observable","text":"<pre><code>add_observable(\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: Sequence[str] | None = None,\n    discipline: MDODiscipline | None = None,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Add an observable to the optimization problem.</p> <p>The repartition strategy of the observable is defined in the formulation class. When more than one output name is provided, the observable function returns a concatenated array of the output values.</p> <p>Parameters:</p> <ul> <li> <code>output_names</code>               (<code>Sequence[str]</code>)           \u2013            <p>The names of the outputs to observe.</p> </li> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the constraint, e.g. \"margin\".</p> </li> <li> <code>observable_name</code>               (<code>Sequence[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>The name to be given to the observable. If empty, the output name is used by default.</p> </li> <li> <code>discipline</code>               (<code>MDODiscipline | None</code>, default:                   <code>None</code> )           \u2013            <p>The discipline used to build the observable function. If <code>None</code>, detect the discipline from the inner disciplines.</p> </li> <li> <code>**statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/scenarios/base_u_scenario.py</code> <pre><code>def add_observable(\n    self,\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: Sequence[str] | None = None,\n    discipline: MDODiscipline | None = None,\n    **statistic_parameters: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        statistic_name: The name of the statistic\n            to be applied to the constraint, e.g. \"margin\".\n        statistic_parameters: The parameters of the statistics\n            to be applied to the constraint,\n            `{\"factor\": 2.}` when `objective_statistic=\"margin\"`.\n    \"\"\"  # noqa: D205 D212 D415\n    self.formulation.add_observable(\n        output_names,\n        statistic_name,\n        observable_name=observable_name,\n        discipline=discipline,\n        **statistic_parameters,\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/scenarios/udoe_scenario/","title":"Udoe scenario","text":""},{"location":"reference/gemseo_umdo/scenarios/udoe_scenario/#gemseo_umdo.scenarios.udoe_scenario","title":"udoe_scenario","text":"<p>Scenario for multidisciplinary design sampling problems under uncertainty.</p>"},{"location":"reference/gemseo_umdo/scenarios/udoe_scenario/#gemseo_umdo.scenarios.udoe_scenario-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/scenarios/udoe_scenario/#gemseo_umdo.scenarios.udoe_scenario.UDOEScenario","title":"UDOEScenario","text":"<pre><code>UDOEScenario(\n    disciplines: Sequence[MDODiscipline],\n    formulation: str,\n    objective_name: str,\n    design_space: DesignSpace,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    objective_statistic_parameters: Mapping[\n        str, Any\n    ] = READ_ONLY_EMPTY_DICT,\n    statistic_estimation: str = \"Sampling\",\n    statistic_estimation_parameters: Mapping[\n        str, Any\n    ] = READ_ONLY_EMPTY_DICT,\n    uncertain_design_variables: Mapping[\n        str, str | tuple[str, str]\n    ] = READ_ONLY_EMPTY_DICT,\n    name: str | None = None,\n    grammar_type: GrammarType = MDODiscipline.GrammarType.JSON,\n    maximize_objective: bool = False,\n    **formulation_options: Any\n)\n</code></pre> <p>               Bases: <code>BaseUScenario</code>, <code>DOEScenario</code></p> <p>A DOE-based scenario for multidisciplinary design under uncertainty.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>disciplines</code>               (<code>Sequence[MDODiscipline]</code>)           \u2013            <p>The disciplines used to compute the objective, constraints and observables from the design variables.</p> </li> <li> <code>formulation</code>               (<code>str</code>)           \u2013            <p>The class name of the :class:<code>.MDOFormulation</code>, e.g. <code>\"MDF\"</code>, <code>\"IDF\"</code> or <code>\"BiLevel\"</code>.</p> </li> <li> <code>objective_name</code>               (<code>str</code>)           \u2013            <p>The name(s) of the discipline output(s) used as objective. If multiple names are passed, the objective will be a vector.</p> </li> <li> <code>design_space</code>               (<code>DesignSpace</code>)           \u2013            <p>The search space including at least the design variables (some formulations requires additional variables, e.g. :class:<code>.IDF</code> with the coupling variables).</p> </li> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain variables with their probability distributions.</p> </li> <li> <code>objective_statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the objective, e.g. \"margin\".</p> </li> <li> <code>objective_statistic_parameters</code>               (<code>Mapping[str, Any]</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The parameters of the statistics to be applied to the objective, e.g. <code>{\"factor\": 2.}</code> when <code>objective_statistic=\"margin\"</code>.</p> </li> <li> <code>statistic_estimation</code>               (<code>str</code>, default:                   <code>'Sampling'</code> )           \u2013            <p>The name of the method to estimate the statistic.</p> </li> <li> <code>statistic_estimation_parameters</code>               (<code>Mapping[str, Any]</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The options of <code>statistic_estimation</code>.</p> </li> <li> <code>uncertain_design_variables</code>               (<code>Mapping[str, str | tuple[str, str]]</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>This argument facilitates the definition of uncertain design variables in two ways. The first way consists of passing a dictionary of the form <code>{\"x1\": (\"+\", \"u1\"), \"x2\": (\"*\", \"u2\"), ...}</code> which defines the uncertain design variables as <code>x1 = dv_x1 + u1</code> and <code>x2 = dv_x2 * (1 + u2)</code>. Here <code>\"x1\"</code> and <code>\"x2\"</code> are the names of the design variables made uncertain by the random variables <code>\"u_1\"</code> and <code>\"u_2\"</code> which typically have zero mean. <code>\"x1\"</code> and <code>\"x2\"</code> are the names of the design variables actually used in <code>disciplines</code> while the names <code>\"dv_x1\"</code> and <code>dv_x2</code> are generated by the scenario. More generally, the first element of the tuple is assumed to be either the class name or the SHORT_NAME of a BaseNoiser (feel free to create new noising disciplines). The second way of defining these uncertain design variables consists of passing a set of more complex expressions of the form <code>{\"x\": \"{} + u\", ...}</code> where <code>\"x\"</code> is the name of the design variable actually used in the equations, <code>\"u\"</code> is the name of the uncertain variable defined in the <code>uncertain_space</code> and <code>\"{}\"</code> is the optimization variable. Leave <code>\"{}\"</code> as is; it will be automatically replaced by <code>\"dv_x\"</code>. This more complex format assumes variables of dimension 1. If <code>None</code>, do not consider other variable relations than those defined by <code>disciplines</code>.</p> </li> <li> <code>name</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>The name to be given to this scenario. If empty, use the name of the class.</p> </li> <li> <code>grammar_type</code>               (<code>GrammarType</code>, default:                   <code>JSON</code> )           \u2013            <p>The grammar for the scenario and the MDO formulation.</p> </li> <li> <code>maximize_objective</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to maximize the statistic of the objective.</p> </li> <li> <code>**formulation_options</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The options of the :class:<code>.MDOFormulation</code>.</p> </li> </ul> Source code in <code>src/gemseo_umdo/scenarios/base_u_scenario.py</code> <pre><code>def __init__(\n    self,\n    disciplines: Sequence[MDODiscipline],\n    formulation: str,\n    objective_name: str,\n    design_space: DesignSpace,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    objective_statistic_parameters: Mapping[str, Any] = READ_ONLY_EMPTY_DICT,\n    statistic_estimation: str = \"Sampling\",\n    statistic_estimation_parameters: Mapping[str, Any] = READ_ONLY_EMPTY_DICT,\n    uncertain_design_variables: Mapping[\n        str, str | tuple[str, str]\n    ] = READ_ONLY_EMPTY_DICT,\n    name: str | None = None,\n    grammar_type: MDODiscipline.GrammarType = MDODiscipline.GrammarType.JSON,\n    maximize_objective: bool = False,\n    **formulation_options: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        uncertain_space: The uncertain variables\n            with their probability distributions.\n        objective_statistic_name: The name of the statistic\n            to be applied to the objective, e.g. \"margin\".\n        objective_statistic_parameters: The parameters of the statistics\n            to be applied to the objective,\n            e.g. `{\"factor\": 2.}` when `objective_statistic=\"margin\"`.\n        statistic_estimation: The name of the method to estimate the statistic.\n        statistic_estimation_parameters: The options of `statistic_estimation`.\n        uncertain_design_variables: This argument facilitates\n            the definition of uncertain design variables in two ways.\n            The first way consists of passing a dictionary\n            of the form `{\"x1\": (\"+\", \"u1\"), \"x2\": (\"*\", \"u2\"), ...}`\n            which defines the uncertain design variables as\n            `x1 = dv_x1 + u1` and `x2 = dv_x2 * (1 + u2)`.\n            Here `\"x1\"` and `\"x2\"` are the names of the design variables\n            made uncertain by the random variables `\"u_1\"` and `\"u_2\"`\n            which typically have zero mean.\n            `\"x1\"` and `\"x2\"` are the names of the design variables\n            actually used in `disciplines`\n            while the names `\"dv_x1\"` and `dv_x2` are generated by the scenario.\n            More generally,\n            the first element of the tuple is assumed\n            to be either the class name or the\n            [SHORT_NAME][gemseo_umdo.disciplines.base_noiser.BaseNoiser.SHORT_NAME]\n            of a\n            [BaseNoiser][gemseo_umdo.disciplines.base_noiser.BaseNoiser]\n            (feel free to create new noising disciplines).\n            The second way of defining these uncertain design variables\n            consists of passing a set of more complex expressions\n            of the form `{\"x\": \"{} + u\", ...}`\n            where `\"x\"` is the name of the design variable\n            actually used in the equations,\n            `\"u\"` is the name of the uncertain variable\n            defined in the `uncertain_space`\n            and `\"{}\"` is the optimization variable.\n            Leave `\"{}\"` as is; it will be automatically replaced by `\"dv_x\"`.\n            This more complex format assumes variables of dimension 1.\n            If `None`,\n            do not consider other variable relations\n            than those defined by `disciplines`.\n        maximize_objective: Whether to maximize the statistic of the objective.\n    \"\"\"  # noqa: D205 D212 D415\n    disciplines = list(disciplines)\n    if uncertain_design_variables:\n        self.__add_noising_discipline_chain(\n            disciplines, design_space, uncertain_design_variables\n        )\n\n    formulations_factory = MDOFormulationFactory()\n    mdo_formulation = formulations_factory.create(\n        formulation,\n        disciplines,\n        objective_name,\n        uncertain_space,\n        grammar_type=grammar_type,\n        **formulation_options,\n    )\n\n    filtered_design_space = formulations_factory.create(\n        formulation,\n        disciplines,\n        objective_name,\n        design_space,\n        **formulation_options,\n    ).design_space\n\n    super().__init__(\n        disciplines,\n        statistic_estimation,\n        objective_name,\n        filtered_design_space,\n        name=name,\n        mdo_formulation=mdo_formulation,\n        objective_statistic_name=objective_statistic_name,\n        objective_statistic_parameters=objective_statistic_parameters,\n        uncertain_space=uncertain_space,\n        maximize_objective=maximize_objective,\n        # TODO: simplify this line in gemseo-umdo 3.0.0\n        **(statistic_estimation_parameters or {}),\n    )\n\n    self.formulation_name = self.formulation.name\n</code></pre>"},{"location":"reference/gemseo_umdo/scenarios/umdo_scenario/","title":"Umdo scenario","text":""},{"location":"reference/gemseo_umdo/scenarios/umdo_scenario/#gemseo_umdo.scenarios.umdo_scenario","title":"umdo_scenario","text":"<p>Scenario for multidisciplinary design optimization problems under uncertainty.</p>"},{"location":"reference/gemseo_umdo/scenarios/umdo_scenario/#gemseo_umdo.scenarios.umdo_scenario-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/scenarios/umdo_scenario/#gemseo_umdo.scenarios.umdo_scenario.UMDOScenario","title":"UMDOScenario","text":"<pre><code>UMDOScenario(\n    disciplines: Sequence[MDODiscipline],\n    formulation: str,\n    objective_name: str,\n    design_space: DesignSpace,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    objective_statistic_parameters: Mapping[\n        str, Any\n    ] = READ_ONLY_EMPTY_DICT,\n    statistic_estimation: str = \"Sampling\",\n    statistic_estimation_parameters: Mapping[\n        str, Any\n    ] = READ_ONLY_EMPTY_DICT,\n    uncertain_design_variables: Mapping[\n        str, str | tuple[str, str]\n    ] = READ_ONLY_EMPTY_DICT,\n    name: str | None = None,\n    grammar_type: GrammarType = MDODiscipline.GrammarType.JSON,\n    maximize_objective: bool = False,\n    **formulation_options: Any\n)\n</code></pre> <p>               Bases: <code>BaseUScenario</code>, <code>MDOScenario</code></p> <p>An optimizer-based scenario for multidisciplinary design under uncertainty.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>disciplines</code>               (<code>Sequence[MDODiscipline]</code>)           \u2013            <p>The disciplines used to compute the objective, constraints and observables from the design variables.</p> </li> <li> <code>formulation</code>               (<code>str</code>)           \u2013            <p>The class name of the :class:<code>.MDOFormulation</code>, e.g. <code>\"MDF\"</code>, <code>\"IDF\"</code> or <code>\"BiLevel\"</code>.</p> </li> <li> <code>objective_name</code>               (<code>str</code>)           \u2013            <p>The name(s) of the discipline output(s) used as objective. If multiple names are passed, the objective will be a vector.</p> </li> <li> <code>design_space</code>               (<code>DesignSpace</code>)           \u2013            <p>The search space including at least the design variables (some formulations requires additional variables, e.g. :class:<code>.IDF</code> with the coupling variables).</p> </li> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain variables with their probability distributions.</p> </li> <li> <code>objective_statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the objective, e.g. \"margin\".</p> </li> <li> <code>objective_statistic_parameters</code>               (<code>Mapping[str, Any]</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The parameters of the statistics to be applied to the objective, e.g. <code>{\"factor\": 2.}</code> when <code>objective_statistic=\"margin\"</code>.</p> </li> <li> <code>statistic_estimation</code>               (<code>str</code>, default:                   <code>'Sampling'</code> )           \u2013            <p>The name of the method to estimate the statistic.</p> </li> <li> <code>statistic_estimation_parameters</code>               (<code>Mapping[str, Any]</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The options of <code>statistic_estimation</code>.</p> </li> <li> <code>uncertain_design_variables</code>               (<code>Mapping[str, str | tuple[str, str]]</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>This argument facilitates the definition of uncertain design variables in two ways. The first way consists of passing a dictionary of the form <code>{\"x1\": (\"+\", \"u1\"), \"x2\": (\"*\", \"u2\"), ...}</code> which defines the uncertain design variables as <code>x1 = dv_x1 + u1</code> and <code>x2 = dv_x2 * (1 + u2)</code>. Here <code>\"x1\"</code> and <code>\"x2\"</code> are the names of the design variables made uncertain by the random variables <code>\"u_1\"</code> and <code>\"u_2\"</code> which typically have zero mean. <code>\"x1\"</code> and <code>\"x2\"</code> are the names of the design variables actually used in <code>disciplines</code> while the names <code>\"dv_x1\"</code> and <code>dv_x2</code> are generated by the scenario. More generally, the first element of the tuple is assumed to be either the class name or the SHORT_NAME of a BaseNoiser (feel free to create new noising disciplines). The second way of defining these uncertain design variables consists of passing a set of more complex expressions of the form <code>{\"x\": \"{} + u\", ...}</code> where <code>\"x\"</code> is the name of the design variable actually used in the equations, <code>\"u\"</code> is the name of the uncertain variable defined in the <code>uncertain_space</code> and <code>\"{}\"</code> is the optimization variable. Leave <code>\"{}\"</code> as is; it will be automatically replaced by <code>\"dv_x\"</code>. This more complex format assumes variables of dimension 1. If <code>None</code>, do not consider other variable relations than those defined by <code>disciplines</code>.</p> </li> <li> <code>name</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>The name to be given to this scenario. If empty, use the name of the class.</p> </li> <li> <code>grammar_type</code>               (<code>GrammarType</code>, default:                   <code>JSON</code> )           \u2013            <p>The grammar for the scenario and the MDO formulation.</p> </li> <li> <code>maximize_objective</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to maximize the statistic of the objective.</p> </li> <li> <code>**formulation_options</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The options of the :class:<code>.MDOFormulation</code>.</p> </li> </ul> Source code in <code>src/gemseo_umdo/scenarios/base_u_scenario.py</code> <pre><code>def __init__(\n    self,\n    disciplines: Sequence[MDODiscipline],\n    formulation: str,\n    objective_name: str,\n    design_space: DesignSpace,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    objective_statistic_parameters: Mapping[str, Any] = READ_ONLY_EMPTY_DICT,\n    statistic_estimation: str = \"Sampling\",\n    statistic_estimation_parameters: Mapping[str, Any] = READ_ONLY_EMPTY_DICT,\n    uncertain_design_variables: Mapping[\n        str, str | tuple[str, str]\n    ] = READ_ONLY_EMPTY_DICT,\n    name: str | None = None,\n    grammar_type: MDODiscipline.GrammarType = MDODiscipline.GrammarType.JSON,\n    maximize_objective: bool = False,\n    **formulation_options: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        uncertain_space: The uncertain variables\n            with their probability distributions.\n        objective_statistic_name: The name of the statistic\n            to be applied to the objective, e.g. \"margin\".\n        objective_statistic_parameters: The parameters of the statistics\n            to be applied to the objective,\n            e.g. `{\"factor\": 2.}` when `objective_statistic=\"margin\"`.\n        statistic_estimation: The name of the method to estimate the statistic.\n        statistic_estimation_parameters: The options of `statistic_estimation`.\n        uncertain_design_variables: This argument facilitates\n            the definition of uncertain design variables in two ways.\n            The first way consists of passing a dictionary\n            of the form `{\"x1\": (\"+\", \"u1\"), \"x2\": (\"*\", \"u2\"), ...}`\n            which defines the uncertain design variables as\n            `x1 = dv_x1 + u1` and `x2 = dv_x2 * (1 + u2)`.\n            Here `\"x1\"` and `\"x2\"` are the names of the design variables\n            made uncertain by the random variables `\"u_1\"` and `\"u_2\"`\n            which typically have zero mean.\n            `\"x1\"` and `\"x2\"` are the names of the design variables\n            actually used in `disciplines`\n            while the names `\"dv_x1\"` and `dv_x2` are generated by the scenario.\n            More generally,\n            the first element of the tuple is assumed\n            to be either the class name or the\n            [SHORT_NAME][gemseo_umdo.disciplines.base_noiser.BaseNoiser.SHORT_NAME]\n            of a\n            [BaseNoiser][gemseo_umdo.disciplines.base_noiser.BaseNoiser]\n            (feel free to create new noising disciplines).\n            The second way of defining these uncertain design variables\n            consists of passing a set of more complex expressions\n            of the form `{\"x\": \"{} + u\", ...}`\n            where `\"x\"` is the name of the design variable\n            actually used in the equations,\n            `\"u\"` is the name of the uncertain variable\n            defined in the `uncertain_space`\n            and `\"{}\"` is the optimization variable.\n            Leave `\"{}\"` as is; it will be automatically replaced by `\"dv_x\"`.\n            This more complex format assumes variables of dimension 1.\n            If `None`,\n            do not consider other variable relations\n            than those defined by `disciplines`.\n        maximize_objective: Whether to maximize the statistic of the objective.\n    \"\"\"  # noqa: D205 D212 D415\n    disciplines = list(disciplines)\n    if uncertain_design_variables:\n        self.__add_noising_discipline_chain(\n            disciplines, design_space, uncertain_design_variables\n        )\n\n    formulations_factory = MDOFormulationFactory()\n    mdo_formulation = formulations_factory.create(\n        formulation,\n        disciplines,\n        objective_name,\n        uncertain_space,\n        grammar_type=grammar_type,\n        **formulation_options,\n    )\n\n    filtered_design_space = formulations_factory.create(\n        formulation,\n        disciplines,\n        objective_name,\n        design_space,\n        **formulation_options,\n    ).design_space\n\n    super().__init__(\n        disciplines,\n        statistic_estimation,\n        objective_name,\n        filtered_design_space,\n        name=name,\n        mdo_formulation=mdo_formulation,\n        objective_statistic_name=objective_statistic_name,\n        objective_statistic_parameters=objective_statistic_parameters,\n        uncertain_space=uncertain_space,\n        maximize_objective=maximize_objective,\n        # TODO: simplify this line in gemseo-umdo 3.0.0\n        **(statistic_estimation_parameters or {}),\n    )\n\n    self.formulation_name = self.formulation.name\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/","title":"Statistics","text":""},{"location":"reference/gemseo_umdo/statistics/#gemseo_umdo.statistics","title":"statistics","text":"<p>Tools for the estimation of statistics.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/","title":"Multilevel","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/#gemseo_umdo.statistics.multilevel","title":"multilevel","text":"<p>Multilevel Monte Carlo (MLMC) algorithms.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/base_pilot/","title":"Base pilot","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/base_pilot/#gemseo_umdo.statistics.multilevel.base_pilot","title":"base_pilot","text":"<p>The base pilot for multilevel algorithms.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/base_pilot/#gemseo_umdo.statistics.multilevel.base_pilot-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/base_pilot/#gemseo_umdo.statistics.multilevel.base_pilot.BasePilot","title":"BasePilot","text":"<pre><code>BasePilot(\n    sampling_ratios: NDArray[float], costs: NDArray[float]\n)\n</code></pre> <p>The base pilot for multilevel algorithms.</p> <p>A pilot is associated with a statistic, e.g. mean. The method compute_next_level_and_statistic() returns a multilevel estimation of the statistic based on the current samples and the next level \\(\\ell^*\\) of the telescopic sum to sample in order to improve this estimation.</p> <p>This level \\(\\ell^*\\) maximizes the criterion</p> \\[\\frac{\\mathcal{V}_\\ell} {r_\\ell n_\\ell^2(\\mathcal{C}_\\ell+\\mathcal{C}_{\\ell-1})}\\] <p>where \\(\\mathcal{C}_{\\ell}\\) is the unit evaluation cost of the model \\(f_\\ell\\) (with \\(\\mathcal{C}_{-1}=0\\)), \\(n_\\ell\\) is the current number of evaluations of \\(f_\\ell\\) and \\(r_\\ell\\) is the factor by which \\(n_\\ell\\) would be increased by choosing the level \\(\\ell\\). Regarding \\(\\mathcal{V}_\\ell\\), it represents the variance of the \\(\\ell\\)-th term of the telescopic sum characteristic of the MLMC techniques. For instance, \\(\\mathcal{V}_\\ell=\\mathbb{E}[Y_\\ell-Y_{\\ell}]\\) in the case of the expectation.</p> See Also <p>El Amri et al., Algo. 1, Multilevel Surrogate-based Control Variates, 2023.</p> <p>Parameters:</p> <ul> <li> <code>sampling_ratios</code>               (<code>NDArray[float]</code>)           \u2013            <p>The sampling ratios \\(r_0,\\ldots,r_L\\); the sampling ratio \\(r_\\ell\\) is the factor by which \\(n_\\ell\\) is increased between two sampling steps on the level \\(ell\\).</p> </li> <li> <code>costs</code>               (<code>NDArray[float]</code>)           \u2013            <p>The unit sampling costs of each level of the telescopic sum. Namely, \\((\\mathcal{C}_{\\ell-1}+\\mathcal{C}_\\ell)_{\\ell\\in\\{0,\\ldots,L\\}}\\) with \\(\\mathcal{C}_{-1}=0\\).</p> </li> </ul> Source code in <code>src/gemseo_umdo/statistics/multilevel/base_pilot.py</code> <pre><code>def __init__(self, sampling_ratios: NDArray[float], costs: NDArray[float]) -&gt; None:\n    r\"\"\"\n    Args:\n        sampling_ratios: The sampling ratios $r_0,\\ldots,r_L$;\n            the sampling ratio $r_\\ell$ is\n            the factor by which $n_\\ell$ is increased\n            between two sampling steps on the level $ell$.\n        costs: The unit sampling costs of each level of the telescopic sum.\n            Namely,\n            $(\\mathcal{C}_{\\ell-1}+\\mathcal{C}_\\ell)_{\\ell\\in\\{0,\\ldots,L\\}}$\n            with $\\mathcal{C}_{-1}=0$.\n    \"\"\"  # noqa: D205 D212 D415\n    self.__costs = costs\n    self.__r_l = sampling_ratios\n    self.V_l = array([nan] * len(self.__r_l))\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/base_pilot/#gemseo_umdo.statistics.multilevel.base_pilot.BasePilot-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/base_pilot/#gemseo_umdo.statistics.multilevel.base_pilot.BasePilot.V_l","title":"V_l  <code>instance-attribute</code>","text":"<pre><code>V_l: NDArray[float] = array([nan] * len(__r_l))\n</code></pre> <p>The terms variances \\(\\mathcal{V}_0,\\ldots,\\mathcal{V}_L\\).</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/base_pilot/#gemseo_umdo.statistics.multilevel.base_pilot.BasePilot-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/base_pilot/#gemseo_umdo.statistics.multilevel.base_pilot.BasePilot.compute_next_level_and_statistic","title":"compute_next_level_and_statistic","text":"<pre><code>compute_next_level_and_statistic(\n    levels: Iterable[int],\n    total_n_samples: NDArray[int],\n    samples: Sequence[NDArray[float]],\n    *pilot_parameters: Any\n) -&gt; tuple[int, NDArray[float]]\n</code></pre> <p>Compute the next level \\(\\ell^*\\) to sample and estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>levels</code>               (<code>Iterable[int]</code>)           \u2013            <p>The levels that have just been sampled.</p> </li> <li> <code>total_n_samples</code>               (<code>NDArray[int]</code>)           \u2013            <p>The total number of samples of each level.</p> </li> <li> <code>samples</code>               (<code>Sequence[NDArray[float]]</code>)           \u2013            <p>The samples of the different quantities of each level.</p> </li> <li> <code>*pilot_parameters</code>               (<code>Any</code>, default:                   <code>()</code> )           \u2013            <p>The parameters of the pilot.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[int, NDArray[float]]</code>           \u2013            <p>The next level \\(\\ell^*\\) to sample and an estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/statistics/multilevel/base_pilot.py</code> <pre><code>def compute_next_level_and_statistic(\n    self,\n    levels: Iterable[int],\n    total_n_samples: NDArray[int],\n    samples: Sequence[NDArray[float]],\n    *pilot_parameters: Any,\n) -&gt; tuple[int, NDArray[float]]:\n    r\"\"\"Compute the next level $\\ell^*$ to sample and estimate the statistic.\n\n    Args:\n        levels: The levels that have just been sampled.\n        total_n_samples: The total number of samples of each level.\n        samples: The samples of the different quantities of each level.\n        *pilot_parameters: The parameters of the pilot.\n\n    Returns:\n        The next level $\\ell^*$ to sample and an estimation of the statistic.\n    \"\"\"\n    self.V_l = self._compute_V_l(levels, samples, *pilot_parameters)\n    # WARNING: do not replace \"/ total_n_samples / total_n_samples\"\n    #          by \"/ total_n_samples**2\"\n    #          to avoid numerical division issue due to an excessively big number.\n    return (\n        argmax(\n            self.V_l / self.__r_l / total_n_samples / total_n_samples / self.__costs\n        ),\n        self._compute_statistic(),\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/","title":"Mlmc","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/#gemseo_umdo.statistics.multilevel.mlmc","title":"mlmc","text":"<p>Multilevel Monte Carlo (MLMC) algorithm.</p> <p>The goal of the MLMC algorithm is to estimate a statistic \\(\\theta\\) (ex: mean, variance) of the output of a simulator \\(f\\) whose input \\(\\mathbf{X}\\) is random: that is, a statistic \\(\\theta\\) of \\(Y=f(\\mathbf{X})\\).</p> <p>Let \\((f_\\ell)_{\\ell = 0}^L\\) be a sequence of model levels with increasing accuracy and computational cost, such that \\(f_L = f\\). The MLMC algorithm uses all these models to estimate the statistic \\(\\theta_L\\) (a.k.a. \\(\\theta\\)) of the random output variable \\(f_L(\\mathbf{X})\\) where \\(\\mathbf{X}\\) is a random input vector.</p> <p>We denote by \\(Y_\\ell=f_\\ell(\\mathbf{X})\\) the random output variable associated with the model level \\(f_\\ell\\) and by \\((\\theta_\\ell)_{\\ell = 0}^L\\) the sequence of statistics increasingly close to \\(\\theta_L\\) where \\(\\theta_\\ell\\) is the statistic of \\(Y_\\ell\\).</p> <p>The statistical measure \\(\\theta_L\\) can be expressed as a telescoping sum \\(\\theta_L = \\sum \\limits_{\\ell = 0}^{L} T_\\ell\\), where \\(T_\\ell = \\theta_\\ell - \\theta_{\\ell-1}\\), and by convention \\(\\theta_{-1} = 0\\).</p> <p>Let \\(\\hat{\\theta}_{\\ell,n_\\ell}^{\\mathrm{MC},(\\ell)}\\) and \\(\\hat{\\theta}_{\\ell-1,n_\\ell}^{\\mathrm{MC},(\\ell)}\\) be respectively the Monte Carlo (MC) estimators of \\(\\theta_\\ell\\) and \\(\\theta_{\\ell-1}\\) using the same \\(n_{\\ell}\\)-sample.</p> <p>Then, the MLMC estimator \\(\\hat{\\theta}_L^{\\mathrm{ML}}\\) of \\(\\theta_L\\) may be expressed as:</p> \\[\\hat{\\theta}_L^{\\mathrm{MLMC}} = \\sum \\limits_{\\ell = 0}^{L} \\hat{T}_{\\ell,n_\\ell}^{\\mathrm{MC}} = \\sum \\limits_{\\ell = 0}^{L} \\hat{\\theta}_{\\ell,n_\\ell}^{\\mathrm{MC},(\\ell)} - \\hat{\\theta}_{\\ell-1,n_\\ell}^{\\mathrm{MC},(\\ell)}. \\]"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/level/","title":"Level","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/level/#gemseo_umdo.statistics.multilevel.mlmc.level","title":"level","text":"<p>A level \\(\\ell\\) for the MLMC algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/level/#gemseo_umdo.statistics.multilevel.mlmc.level-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/level/#gemseo_umdo.statistics.multilevel.mlmc.level.Level","title":"Level  <code>dataclass</code>","text":"<pre><code>Level(\n    model: MDOFunction,\n    cost: float | None = None,\n    n_cost_estimation_samples: int = 1,\n    n_initial_samples: int = 10,\n    sampling_ratio: float = 2.0,\n)\n</code></pre> <p>A level \\(\\ell\\) for the MLMC algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/level/#gemseo_umdo.statistics.multilevel.mlmc.level.Level-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/level/#gemseo_umdo.statistics.multilevel.mlmc.level.Level.cost","title":"cost  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cost: float | None = None\n</code></pre> <p>The cost \\(\\mathcal{C}_\\ell\\) to evaluate \\(f_\\ell\\), if known.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/level/#gemseo_umdo.statistics.multilevel.mlmc.level.Level.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model: MDOFunction\n</code></pre> <p>The model \\(f_\\ell\\) to sample.</p> <p>This model can be set from any callable taking a NumPy array of float numbers as input and outputting either a float number or a NumPy array of float numbers.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/level/#gemseo_umdo.statistics.multilevel.mlmc.level.Level.n_cost_estimation_samples","title":"n_cost_estimation_samples  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>n_cost_estimation_samples: int = 1\n</code></pre> <p>The number of \\(f_\\ell\\) calls to estimate \\(\\mathcal{C}_\\ell\\).</p> <p>It will be used only if <code>cost</code> is <code>None</code>.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/level/#gemseo_umdo.statistics.multilevel.mlmc.level.Level.n_initial_samples","title":"n_initial_samples  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>n_initial_samples: int = 10\n</code></pre> <p>The number of samples \\(n_\\ell\\) at the first iteration of the algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/level/#gemseo_umdo.statistics.multilevel.mlmc.level.Level.sampling_ratio","title":"sampling_ratio  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>sampling_ratio: float = 2.0\n</code></pre> <p>The number \\(r_\\ell\\) by which \\(n_\\ell\\) is increased.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/mlmc/","title":"Mlmc","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/mlmc/#gemseo_umdo.statistics.multilevel.mlmc.mlmc","title":"mlmc","text":"<p>A generic algorithm for multilevel Monte Carlo (MLMC) sampling.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/mlmc/#gemseo_umdo.statistics.multilevel.mlmc.mlmc-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/mlmc/#gemseo_umdo.statistics.multilevel.mlmc.mlmc.MLMC","title":"MLMC","text":"<pre><code>MLMC(\n    levels: Iterable[Level],\n    uncertain_space: ParameterSpace,\n    n_samples: float,\n    pilot_statistic_name: str = \"Mean\",\n    seed: int = SEED,\n)\n</code></pre> <p>Multilevel Monte Carlo (MLMC) algorithm.</p> <p>This algorithm aims at sampling the different model levels in an adaptive way, with many evaluations for the coarsest model and a few evaluations for the finest one.</p> <p>This adaptive sampling is guided by a BasePilot.</p> <p>This algorithm depends on the execution cost ratio between two consecutive levels, that can be estimated from the models, and on the sampling size ratio between two sampling steps on the same level.</p> <p>At a given iteration, the algorithm</p> <ol> <li>considers a level \\(\\ell^*\\) and a sample size \\(n_{\\ell^*}\\)</li> <li>samples the models involved in the statistic \\(T_{\\ell^*}\\)    of the telescoping sum (TS) \\(\\theta_L = \\sum_{\\ell=0}^L T_\\ell\\),</li> <li>computes the new level \\(\\ell^*\\) to sample    and the corresponding sample size \\(n_{\\ell^*}\\).</li> </ol> <p>Parameters:</p> <ul> <li> <code>levels</code>               (<code>Iterable[Level]</code>)           \u2013            <p>The levels defined in terms of model, evaluation cost and initial number of calls.</p> </li> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain space on which to sample the functions.</p> </li> <li> <code>n_samples</code>               (<code>float</code>)           \u2013            <p>The sampling budget expressed as the number of model evaluations equivalent to evaluations of the finest model. This number is not necessarily an integer; for instance, if \\(f_L\\) is twice as expensive as \\(f_{L-1}\\), then <code>n_samples=1.5</code> can correspond to 1 evaluation of \\(f_L\\) and 1 evaluation of \\(f_{L-1}\\).</p> </li> <li> <code>pilot_statistic_name</code>               (<code>str</code>, default:                   <code>'Mean'</code> )           \u2013            <p>The name of the statistic used to drive the algorithm.</p> </li> <li> <code>seed</code>               (<code>int</code>, default:                   <code>SEED</code> )           \u2013            <p>The initial random seed for reproducibility. Then, the seed is incremented at each level of the telescopic sum and at each algorithm iteration.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>When the minimum cost is greater than the maximum cost.</p> </li> </ul> Source code in <code>src/gemseo_umdo/statistics/multilevel/mlmc/mlmc.py</code> <pre><code>def __init__(\n    self,\n    levels: Iterable[Level],\n    uncertain_space: ParameterSpace,\n    n_samples: float,\n    pilot_statistic_name: str = \"Mean\",\n    seed: int = SEED,\n) -&gt; None:\n    r\"\"\"\n    Args:\n        levels: The levels\n            defined in terms of model, evaluation cost and initial number of calls.\n        uncertain_space: The uncertain space on which to sample the functions.\n        n_samples: The sampling budget expressed as\n            the number of model evaluations\n            equivalent to evaluations of the finest model.\n            This number is not necessarily an integer;\n            for instance,\n            if $f_L$ is twice as expensive as $f_{L-1}$,\n            then `n_samples=1.5` can correspond to\n            1 evaluation of $f_L$ and 1 evaluation of $f_{L-1}$.\n        pilot_statistic_name: The name of the statistic used to drive the algorithm.\n        seed: The initial random seed for reproducibility.\n            Then,\n            the seed is incremented at each level of the telescopic sum\n            and at each algorithm iteration.\n\n    Raises:\n        ValueError: When the minimum cost is greater than the maximum cost.\n    \"\"\"  # noqa: D205 D212 D415\n    self._algorithm_name = \"MLMC\"\n\n    # Initialize the seed.\n    self.__seed = seed\n\n    # Set the models f_0, f_1, ..., f_L.\n    self.__f_l = [level.model for level in levels]\n    for l, f_l in enumerate(self.__f_l):  # noqa: E741\n        f_l.name = f\"f[{l}]\"\n\n    # Set the number of levels.\n    self._n_levels = len(self.__f_l)\n\n    # Set the unit sampling costs of each level of the telescopic sum (TS).\n    C_l = array(  # noqa: N806\n        [level.cost if level.cost is not None else nan for level in levels]\n    )\n    self.__C_l = C_l = C_l / C_l[-1]  # noqa: N806\n    self.__total_execution_times = array([0] * self._n_levels)\n    self.__costs = array([C_l[0], *(C_l[1:] + C_l[:-1]).tolist()])\n\n    # Set the sampling ratios r_l of each level of the TS.\n    self.__r_l = array([level.sampling_ratio for level in levels])\n\n    # Set the Monte Carlo samplers of each level of the TS.\n    self._samplers = tuple(\n        MonteCarloSampler(uncertain_space) for _ in range(self._n_levels)\n    )\n    self._add_functions_to_samplers()\n\n    # Set the numbers of samples to be added at each level of the TS.\n    self.__delta_n_l = [level.n_initial_samples for level in levels]\n\n    # Initialize the history of numbers of samples added at each level of the TS.\n    self.__n_samples_history = [self.__delta_n_l.copy()]\n\n    # Initialize the numbers of samples of each level of the TS.\n    self.__n_l = array(self.__n_samples_history[0], dtype=\"int64\")\n\n    self.__minimum_budget = sum(\n        nl * cost for nl, cost in zip(self.__n_samples_history[0], self.__costs)\n    )\n    self.__total_budget = n_samples\n    self.__current_budget = self.__total_budget\n    self.__budget_history = []\n    self.__use_empirical_C_l = isnan(self.__minimum_budget)\n    if not self.__use_empirical_C_l and self.__minimum_budget &gt; n_samples:\n        msg = (\n            f\"The minimum budget {self.__minimum_budget} is greater \"\n            f\"than the total budget {n_samples}.\"\n        )\n        raise ValueError(msg)\n\n    # Set the estimator of the pilot statistic and initialize its estimation.\n    self.__pilot_statistic_estimation = array([])\n    self.__pilot_statistic_estimator = self._PILOT_FACTORY().create(\n        pilot_statistic_name,\n        sampling_ratios=self.__r_l,\n        costs=self.__costs,\n    )\n    self._pilot_statistic_estimator_parameters = []\n    self.__V_l = 0\n    LOGGER.info(\"%s\", self)\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/mlmc/#gemseo_umdo.statistics.multilevel.mlmc.mlmc.MLMC-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/mlmc/#gemseo_umdo.statistics.multilevel.mlmc.mlmc.MLMC.budget_history","title":"budget_history  <code>property</code>","text":"<pre><code>budget_history: NDArray[float]\n</code></pre> <p>The history of the budget.</p> <p><code>algo.budget_history[i]</code> is the budget at iteration <code>i+1</code>.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/mlmc/#gemseo_umdo.statistics.multilevel.mlmc.mlmc.MLMC.level_costs","title":"level_costs  <code>property</code>","text":"<pre><code>level_costs: NDArray[float]\n</code></pre> <p>The evaluation costs of the different levels.</p> <p><code>algo.level_costs[l]</code> is the cost of one evaluation of the <code>l</code>-th level.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/mlmc/#gemseo_umdo.statistics.multilevel.mlmc.mlmc.MLMC.model_costs","title":"model_costs  <code>property</code>","text":"<pre><code>model_costs: NDArray[float]\n</code></pre> <p>The evaluation costs of the different models.</p> <p><code>algo.model_costs[l]</code> is the cost of one evaluation of the <code>l</code>-th model.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/mlmc/#gemseo_umdo.statistics.multilevel.mlmc.mlmc.MLMC.n_total_samples","title":"n_total_samples  <code>property</code>","text":"<pre><code>n_total_samples: NDArray[int]\n</code></pre> <p>The total numbers of samples per level.</p> <p><code>algo.n_total_samples[l]</code> is the total number of samples at level <code>l</code>.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/mlmc/#gemseo_umdo.statistics.multilevel.mlmc.mlmc.MLMC.pilot_statistic_estimation","title":"pilot_statistic_estimation  <code>property</code>","text":"<pre><code>pilot_statistic_estimation: NDArray[float]\n</code></pre> <p>The estimation of the pilot statistic.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/mlmc/#gemseo_umdo.statistics.multilevel.mlmc.mlmc.MLMC.sampling_history","title":"sampling_history  <code>property</code>","text":"<pre><code>sampling_history: NDArray[int]\n</code></pre> <p>The history of the numbers of samples of each level of the telescopic sum.</p> <p><code>algo.sampling_size_history[i, l]</code> is the number of samples at iteration <code>i+1</code> and level <code>l</code>.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/mlmc/#gemseo_umdo.statistics.multilevel.mlmc.mlmc.MLMC-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/mlmc/#gemseo_umdo.statistics.multilevel.mlmc.mlmc.MLMC.execute","title":"execute","text":"<pre><code>execute() -&gt; None\n</code></pre> <p>Execute the algorithm.</p> Source code in <code>src/gemseo_umdo/statistics/multilevel/mlmc/mlmc.py</code> <pre><code>def execute(self) -&gt; None:\n    \"\"\"Execute the algorithm.\"\"\"\n    # The current version of the algorithm samples only one level at a time,\n    # except at the first iteration where it samples them all.\n    levels_to_be_sampled = list(range(self._n_levels))\n\n    # Initialize the iteration of the algorithm.\n    is_last_iteration = False\n    iteration = 0\n\n    # As long as there is budget left\n    LOGGER.info(\"Start sampling with a total budget of %s\", self.__total_budget)\n    while self.__current_budget &gt;= 0:\n        iteration += 1\n        if is_last_iteration:\n            LOGGER.info(\"   Iteration #%s (last iteration)\", iteration)\n        else:\n            LOGGER.info(\"   Iteration #%s\", iteration)\n\n        # Append the budget to the budget history.\n        self.__budget_history.append(self.__current_budget)\n\n        # Sample the selected levels of the TS.\n        levels_to_samples = self.__compute_samples(*levels_to_be_sampled)\n\n        # Select the next level l_star of the TS to be sampled\n        # and estimate the statistic.\n        (\n            l_star,\n            self.__pilot_statistic_estimation,\n        ) = self.__pilot_statistic_estimator.compute_next_level_and_statistic(\n            levels_to_be_sampled,\n            self.__n_l,\n            levels_to_samples,\n            *self._pilot_statistic_estimator_parameters,\n        )\n\n        # Stop the algorithm if it is the last iteration.\n        if is_last_iteration:\n            break\n\n        # The current version of the algorithm samples only one level at a time.\n        levels_to_be_sampled = [l_star]\n\n        # Define the corresponding sample size.\n        delta_n_l_star = int(\n            math.floor((self.__r_l[l_star] - 1) * self.__n_l[l_star])\n        )\n        n_l_star = self.__n_l[l_star] + delta_n_l_star\n        LOGGER.info(\"      Find the next level to sample\")\n        LOGGER.info(\"         l_star = %s\", l_star)\n        LOGGER.info(\"         d_n_l_star = %s\", delta_n_l_star)\n        LOGGER.info(\"         n_l_star = %s\", n_l_star)\n\n        # If the new sampling stage is too expensive, reduce the number of samples.\n        posterior_budget = (\n            self.__current_budget - delta_n_l_star * self.__costs[l_star]\n        )\n        if posterior_budget &lt; 0:\n            LOGGER.info(\"         Maximum budget exceeded by %s\", -posterior_budget)\n            LOGGER.info(\n                \"         Decrease d_n_l_star to respect the maximum budget\"\n            )\n\n            # There is a budget to do at most one iteration.\n            is_last_iteration = True\n\n            # Update the numbers of additional samples at level l_star\n            # to achieve a positive or zero budget.\n            delta_n_l_star = int(\n                delta_n_l_star + posterior_budget / self.__costs[l_star]\n            )\n            n_l_star = self.__n_l[l_star] + delta_n_l_star\n            LOGGER.info(\"         d_n_l_star = %s\", delta_n_l_star)\n            LOGGER.info(\"         n_l_star = %s\", n_l_star)\n            # Stop the algorithm if one can no longer sample l_star.\n            if delta_n_l_star == 0:\n                LOGGER.info(\n                    \"Stop the algorithm as sampling l_star is too expensive.\"\n                )\n                break\n\n        # Update the history of number of samples of each level\n        # (0 for all the levels, but l_star).\n        self.__delta_n_l = zeros(self._n_levels)\n        self.__delta_n_l[l_star] = delta_n_l_star\n        self.__n_l[l_star] += delta_n_l_star\n        self.__n_samples_history.extend([self.__delta_n_l.copy()])\n\n    LOGGER.info(\"Sampling completed\")\n    LOGGER.info(\"Results\")\n    LOGGER.info(\"   Pilot statistic = %s\", self.pilot_statistic_estimation)\n    LOGGER.info(\"   Total cost = %s\", sum(self.__n_l * self.__costs))\n    LOGGER.info(\"   Cost allocation\")\n    levels_to_total_costs = self.__n_l * self.__costs\n    levels_to_total_costs = levels_to_total_costs / sum(levels_to_total_costs)\n    for level, total_cost in enumerate(levels_to_total_costs):\n        LOGGER.info(\"      Level %s: %s\", level, f\"{total_cost:.1%}\")\n\n    LOGGER.info(\"   n_l\")\n    for level in range(self._n_levels):\n        LOGGER.info(\"       n_%s = %s\", level, self.__n_l[level])\n\n    LOGGER.info(\"   V_l\")\n    self.__V_l = self.__pilot_statistic_estimator.V_l\n    for level in range(self._n_levels):\n        LOGGER.info(\"       V_%s = %s\", level, f\"{self.__V_l[level]:.2e}\")\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/mlmc/#gemseo_umdo.statistics.multilevel.mlmc.mlmc.MLMC.plot_evaluation_history","title":"plot_evaluation_history","text":"<pre><code>plot_evaluation_history(\n    show: bool = True,\n    file_path: str | Path | None = None,\n    log_n_evaluations: bool = True,\n    log_budget: bool = False,\n) -&gt; None\n</code></pre> <p>Plot the history of the model evaluations in terms of sample size and budget.</p> <p>Parameters:</p> <ul> <li> <code>show</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to display the graph.</p> </li> <li> <code>file_path</code>               (<code>str | Path | None</code>, default:                   <code>None</code> )           \u2013            <p>The file path to save the graph.</p> </li> <li> <code>log_n_evaluations</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to use a log-scale for the number of evaluations.</p> </li> <li> <code>log_budget</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to use a log-scale for the budget.</p> </li> </ul> Source code in <code>src/gemseo_umdo/statistics/multilevel/mlmc/mlmc.py</code> <pre><code>def plot_evaluation_history(\n    self,\n    show: bool = True,\n    file_path: str | Path | None = None,\n    log_n_evaluations: bool = True,\n    log_budget: bool = False,\n) -&gt; None:\n    \"\"\"Plot the history of the model evaluations in terms of sample size and budget.\n\n    Args:\n        show: Whether to display the graph.\n        file_path: The file path to save the graph.\n        log_n_evaluations: Whether to use a log-scale for the number of evaluations.\n        log_budget: Whether to use a log-scale for the budget.\n    \"\"\"\n    fig, (ax1, ax2) = plt.subplots(ncols=2)\n    iterations = [i + 1 for i, _ in enumerate(self.__n_samples_history)]\n    ax1.plot(\n        iterations,\n        cumsum(array(self.__n_samples_history), axis=0),\n        label=[rf\"$f_{level}$\" for level in range(self._n_levels)],\n        marker=\".\",\n    )\n    if log_n_evaluations:\n        ax1.set_yscale(\"log\")\n\n    ax1.set_xlabel(\"Iteration\")\n    ax1.set_ylabel(\"Cumulated number of evaluations\")\n    ax1.legend(title=\"Simulators\")\n    ax1.grid(which=\"both\")\n    data = (array(self.__n_samples_history) * self.__costs).T\n    ax2.bar(iterations, data[0], label=r\"$f_0$\")\n    for index, row in enumerate(data[1:]):\n        ax2.bar(\n            iterations,\n            row,\n            bottom=data[0 : index + 1].sum(0),\n            label=rf\"$f_{index + 1}$\",\n        )\n\n    if log_budget:\n        ax2.set_yscale(\"log\")\n\n    ax2.set_xlabel(\"Iteration\")\n    ax2.set_ylabel(\"Cost\")\n    ax2.legend(title=\"Simulators\")\n    ax2.grid(which=\"both\")\n    ax2.set_axisbelow(True)\n    save_show_figure(fig, show, file_path, fig_size=(10, 3))\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/","title":"Pilots","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/#gemseo_umdo.statistics.multilevel.mlmc.pilots","title":"pilots","text":"<p>A set of pilots for the MLMC algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/base_mlmc_pilot/","title":"Base mlmc pilot","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/base_mlmc_pilot/#gemseo_umdo.statistics.multilevel.mlmc.pilots.base_mlmc_pilot","title":"base_mlmc_pilot","text":"<p>The base pilot class for the MLMC algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/base_mlmc_pilot/#gemseo_umdo.statistics.multilevel.mlmc.pilots.base_mlmc_pilot-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/base_mlmc_pilot/#gemseo_umdo.statistics.multilevel.mlmc.pilots.base_mlmc_pilot.BaseMLMCPilot","title":"BaseMLMCPilot","text":"<pre><code>BaseMLMCPilot(\n    sampling_ratios: NDArray[float], costs: NDArray[float]\n)\n</code></pre> <p>               Bases: <code>BasePilot</code></p> <p>The base pilot class for the MLMC algorithm.</p> See Also <p>El Amri et al., Algo. 1, Multilevel Surrogate-based Control Variates, 2023.</p> <p>Parameters:</p> <ul> <li> <code>sampling_ratios</code>               (<code>NDArray[float]</code>)           \u2013            <p>The sampling ratios \\(r_0,\\ldots,r_L\\); the sampling ratio \\(r_\\ell\\) is the factor by which \\(n_\\ell\\) is increased between two sampling steps on the level \\(ell\\).</p> </li> <li> <code>costs</code>               (<code>NDArray[float]</code>)           \u2013            <p>The unit sampling costs of each level of the telescopic sum. Namely, \\((\\mathcal{C}_{\\ell-1}+\\mathcal{C}_\\ell)_{\\ell\\in\\{0,\\ldots,L\\}}\\) with \\(\\mathcal{C}_{-1}=0\\).</p> </li> </ul> Source code in <code>src/gemseo_umdo/statistics/multilevel/base_pilot.py</code> <pre><code>def __init__(self, sampling_ratios: NDArray[float], costs: NDArray[float]) -&gt; None:\n    r\"\"\"\n    Args:\n        sampling_ratios: The sampling ratios $r_0,\\ldots,r_L$;\n            the sampling ratio $r_\\ell$ is\n            the factor by which $n_\\ell$ is increased\n            between two sampling steps on the level $ell$.\n        costs: The unit sampling costs of each level of the telescopic sum.\n            Namely,\n            $(\\mathcal{C}_{\\ell-1}+\\mathcal{C}_\\ell)_{\\ell\\in\\{0,\\ldots,L\\}}$\n            with $\\mathcal{C}_{-1}=0$.\n    \"\"\"  # noqa: D205 D212 D415\n    self.__costs = costs\n    self.__r_l = sampling_ratios\n    self.V_l = array([nan] * len(self.__r_l))\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/factory/","title":"Factory","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/factory/#gemseo_umdo.statistics.multilevel.mlmc.pilots.factory","title":"factory","text":"<p>A factory of pilots for the MLMC algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/factory/#gemseo_umdo.statistics.multilevel.mlmc.pilots.factory-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/factory/#gemseo_umdo.statistics.multilevel.mlmc.pilots.factory.MLMCPilotFactory","title":"MLMCPilotFactory","text":"<p>               Bases: <code>BaseFactory</code></p> <p>A factory of pilots for the MLMC algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/mean/","title":"Mean","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/mean/#gemseo_umdo.statistics.multilevel.mlmc.pilots.mean","title":"mean","text":"<p>The mean-based pilot for the MLMC algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/mean/#gemseo_umdo.statistics.multilevel.mlmc.pilots.mean-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/mean/#gemseo_umdo.statistics.multilevel.mlmc.pilots.mean.Mean","title":"Mean","text":"<pre><code>Mean(\n    sampling_ratios: NDArray[float], costs: NDArray[float]\n)\n</code></pre> <p>               Bases: <code>BaseMLMCPilot</code></p> <p>The mean-based pilot for the MLMC algorithm.</p> See Also <p>El Amri et al., Algo. 1, Multilevel Surrogate-based Control Variates, 2023.</p> <p>Parameters:</p> <ul> <li> <code>sampling_ratios</code>               (<code>NDArray[float]</code>)           \u2013            <p>The sampling ratios \\(r_0,\\ldots,r_L\\); the sampling ratio \\(r_\\ell\\) is the factor by which \\(n_\\ell\\) is increased between two sampling steps on the level \\(ell\\).</p> </li> <li> <code>costs</code>               (<code>NDArray[float]</code>)           \u2013            <p>The unit sampling costs of each level of the telescopic sum. Namely, \\((\\mathcal{C}_{\\ell-1}+\\mathcal{C}_\\ell)_{\\ell\\in\\{0,\\ldots,L\\}}\\) with \\(\\mathcal{C}_{-1}=0\\).</p> </li> </ul> Source code in <code>src/gemseo_umdo/statistics/multilevel/mlmc/pilots/mean.py</code> <pre><code>def __init__(  # noqa: D107\n    self, sampling_ratios: NDArray[float], costs: NDArray[float]\n) -&gt; None:\n    super().__init__(sampling_ratios, costs)\n    self.__delta = [array([]) for _ in range(len(sampling_ratios))]\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/mean/#gemseo_umdo.statistics.multilevel.mlmc.pilots.mean.Mean-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/mean/#gemseo_umdo.statistics.multilevel.mlmc.pilots.mean.Mean.V_l","title":"V_l  <code>instance-attribute</code>","text":"<pre><code>V_l: NDArray[float] = array([nan] * len(__r_l))\n</code></pre> <p>The terms variances \\(\\mathcal{V}_0,\\ldots,\\mathcal{V}_L\\).</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/mean/#gemseo_umdo.statistics.multilevel.mlmc.pilots.mean.Mean-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/mean/#gemseo_umdo.statistics.multilevel.mlmc.pilots.mean.Mean.compute_next_level_and_statistic","title":"compute_next_level_and_statistic","text":"<pre><code>compute_next_level_and_statistic(\n    levels: Iterable[int],\n    total_n_samples: NDArray[int],\n    samples: Sequence[NDArray[float]],\n    *pilot_parameters: Any\n) -&gt; tuple[int, NDArray[float]]\n</code></pre> <p>Compute the next level \\(\\ell^*\\) to sample and estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>levels</code>               (<code>Iterable[int]</code>)           \u2013            <p>The levels that have just been sampled.</p> </li> <li> <code>total_n_samples</code>               (<code>NDArray[int]</code>)           \u2013            <p>The total number of samples of each level.</p> </li> <li> <code>samples</code>               (<code>Sequence[NDArray[float]]</code>)           \u2013            <p>The samples of the different quantities of each level.</p> </li> <li> <code>*pilot_parameters</code>               (<code>Any</code>, default:                   <code>()</code> )           \u2013            <p>The parameters of the pilot.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[int, NDArray[float]]</code>           \u2013            <p>The next level \\(\\ell^*\\) to sample and an estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/statistics/multilevel/base_pilot.py</code> <pre><code>def compute_next_level_and_statistic(\n    self,\n    levels: Iterable[int],\n    total_n_samples: NDArray[int],\n    samples: Sequence[NDArray[float]],\n    *pilot_parameters: Any,\n) -&gt; tuple[int, NDArray[float]]:\n    r\"\"\"Compute the next level $\\ell^*$ to sample and estimate the statistic.\n\n    Args:\n        levels: The levels that have just been sampled.\n        total_n_samples: The total number of samples of each level.\n        samples: The samples of the different quantities of each level.\n        *pilot_parameters: The parameters of the pilot.\n\n    Returns:\n        The next level $\\ell^*$ to sample and an estimation of the statistic.\n    \"\"\"\n    self.V_l = self._compute_V_l(levels, samples, *pilot_parameters)\n    # WARNING: do not replace \"/ total_n_samples / total_n_samples\"\n    #          by \"/ total_n_samples**2\"\n    #          to avoid numerical division issue due to an excessively big number.\n    return (\n        argmax(\n            self.V_l / self.__r_l / total_n_samples / total_n_samples / self.__costs\n        ),\n        self._compute_statistic(),\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/variance/","title":"Variance","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/variance/#gemseo_umdo.statistics.multilevel.mlmc.pilots.variance","title":"variance","text":"<p>The variance-based pilot for the MLMC algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/variance/#gemseo_umdo.statistics.multilevel.mlmc.pilots.variance-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/variance/#gemseo_umdo.statistics.multilevel.mlmc.pilots.variance.Variance","title":"Variance","text":"<pre><code>Variance(\n    sampling_ratios: NDArray[float], costs: NDArray[float]\n)\n</code></pre> <p>               Bases: <code>BaseMLMCPilot</code></p> <p>The variance-based pilot for the MLMC algorithm.</p> See Also <p>El Amri et al., Algo. 1, Multilevel Surrogate-based Control Variates, 2023.</p> <p>Parameters:</p> <ul> <li> <code>sampling_ratios</code>               (<code>NDArray[float]</code>)           \u2013            <p>The sampling ratios \\(r_0,\\ldots,r_L\\); the sampling ratio \\(r_\\ell\\) is the factor by which \\(n_\\ell\\) is increased between two sampling steps on the level \\(ell\\).</p> </li> <li> <code>costs</code>               (<code>NDArray[float]</code>)           \u2013            <p>The unit sampling costs of each level of the telescopic sum. Namely, \\((\\mathcal{C}_{\\ell-1}+\\mathcal{C}_\\ell)_{\\ell\\in\\{0,\\ldots,L\\}}\\) with \\(\\mathcal{C}_{-1}=0\\).</p> </li> </ul> Source code in <code>src/gemseo_umdo/statistics/multilevel/mlmc/pilots/variance.py</code> <pre><code>def __init__(  # noqa: D107\n    self, sampling_ratios: NDArray[float], costs: NDArray[float]\n) -&gt; None:\n    super().__init__(sampling_ratios, costs)\n    n_levels = len(sampling_ratios)\n    self.__delta = [array([]) for _ in range(n_levels)]\n    self.__sigma = [array([]) for _ in range(n_levels)]\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/variance/#gemseo_umdo.statistics.multilevel.mlmc.pilots.variance.Variance-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/variance/#gemseo_umdo.statistics.multilevel.mlmc.pilots.variance.Variance.V_l","title":"V_l  <code>instance-attribute</code>","text":"<pre><code>V_l: NDArray[float] = array([nan] * len(__r_l))\n</code></pre> <p>The terms variances \\(\\mathcal{V}_0,\\ldots,\\mathcal{V}_L\\).</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/variance/#gemseo_umdo.statistics.multilevel.mlmc.pilots.variance.Variance-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/variance/#gemseo_umdo.statistics.multilevel.mlmc.pilots.variance.Variance.compute_next_level_and_statistic","title":"compute_next_level_and_statistic","text":"<pre><code>compute_next_level_and_statistic(\n    levels: Iterable[int],\n    total_n_samples: NDArray[int],\n    samples: Sequence[NDArray[float]],\n    *pilot_parameters: Any\n) -&gt; tuple[int, NDArray[float]]\n</code></pre> <p>Compute the next level \\(\\ell^*\\) to sample and estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>levels</code>               (<code>Iterable[int]</code>)           \u2013            <p>The levels that have just been sampled.</p> </li> <li> <code>total_n_samples</code>               (<code>NDArray[int]</code>)           \u2013            <p>The total number of samples of each level.</p> </li> <li> <code>samples</code>               (<code>Sequence[NDArray[float]]</code>)           \u2013            <p>The samples of the different quantities of each level.</p> </li> <li> <code>*pilot_parameters</code>               (<code>Any</code>, default:                   <code>()</code> )           \u2013            <p>The parameters of the pilot.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[int, NDArray[float]]</code>           \u2013            <p>The next level \\(\\ell^*\\) to sample and an estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/statistics/multilevel/base_pilot.py</code> <pre><code>def compute_next_level_and_statistic(\n    self,\n    levels: Iterable[int],\n    total_n_samples: NDArray[int],\n    samples: Sequence[NDArray[float]],\n    *pilot_parameters: Any,\n) -&gt; tuple[int, NDArray[float]]:\n    r\"\"\"Compute the next level $\\ell^*$ to sample and estimate the statistic.\n\n    Args:\n        levels: The levels that have just been sampled.\n        total_n_samples: The total number of samples of each level.\n        samples: The samples of the different quantities of each level.\n        *pilot_parameters: The parameters of the pilot.\n\n    Returns:\n        The next level $\\ell^*$ to sample and an estimation of the statistic.\n    \"\"\"\n    self.V_l = self._compute_V_l(levels, samples, *pilot_parameters)\n    # WARNING: do not replace \"/ total_n_samples / total_n_samples\"\n    #          by \"/ total_n_samples**2\"\n    #          to avoid numerical division issue due to an excessively big number.\n    return (\n        argmax(\n            self.V_l / self.__r_l / total_n_samples / total_n_samples / self.__costs\n        ),\n        self._compute_statistic(),\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/","title":"Mlmc mlcv","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv","title":"mlmc_mlcv","text":"<p>Multilevel Monte Carlo with multilevel control variate (MLMC-MLCV) algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/level/","title":"Level","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/level/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.level","title":"level","text":"<p>A level \\(\\ell\\) for the MLMC-MLCV algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/level/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.level-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/level/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.level.Level","title":"Level  <code>dataclass</code>","text":"<pre><code>Level(\n    model: MDOFunction,\n    surrogate_model: tuple[MDOFunction, float],\n    difference_surrogate_model: tuple[\n        MDOFunction, float\n    ] = (),\n    cost: float | None = None,\n    n_cost_estimation_samples: int = 1,\n    n_initial_samples: int = 10,\n    sampling_ratio: float = 2.0,\n)\n</code></pre> <p>A level \\(\\ell\\) for the MLMC-MLCV algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/level/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.level.Level-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/level/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.level.Level.cost","title":"cost  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cost: float | None = None\n</code></pre> <p>The cost \\(\\mathcal{C}_\\ell\\) to evaluate \\(f_\\ell\\), if known.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/level/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.level.Level.difference_surrogate_model","title":"difference_surrogate_model  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>difference_surrogate_model: tuple[MDOFunction, float] = ()\n</code></pre> <p>The surrogate model \\(h_\\ell\\) approximating \\(f_\\ell-f_{\\ell-1}\\).</p> <p>More precisely, \\(h_\\ell\\) and its statistic for the MLMCMLCV algorithm.</p> <p>Empty at level \\(\\ell=0\\).</p> <p>The surrogate model can be set from any callable taking a NumPy array of float numbers as input and outputting either a float number or a NumPy array of float numbers.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/level/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.level.Level.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model: MDOFunction\n</code></pre> <p>The model \\(f_\\ell\\) to sample.</p> <p>This model can be set from any callable taking a NumPy array of float numbers as input and outputting either a float number or a NumPy array of float numbers.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/level/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.level.Level.n_cost_estimation_samples","title":"n_cost_estimation_samples  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>n_cost_estimation_samples: int = 1\n</code></pre> <p>The number of \\(f_\\ell\\) calls to estimate \\(\\mathcal{C}_\\ell\\).</p> <p>It will be used only if <code>cost</code> is <code>None</code>.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/level/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.level.Level.n_initial_samples","title":"n_initial_samples  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>n_initial_samples: int = 10\n</code></pre> <p>The number of samples \\(n_\\ell\\) at the first iteration of the algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/level/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.level.Level.sampling_ratio","title":"sampling_ratio  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>sampling_ratio: float = 2.0\n</code></pre> <p>The factor \\(r_\\ell\\) by which \\(n_\\ell\\) is increased.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/level/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.level.Level.surrogate_model","title":"surrogate_model  <code>instance-attribute</code>","text":"<pre><code>surrogate_model: tuple[MDOFunction, float]\n</code></pre> <p>The surrogate model \\(g_\\ell\\) approximating \\(f_\\ell\\).</p> <p>More precisely, \\(g_\\ell\\) and its statistic for the MLMCMLCV algorithm.</p> <p>The surrogate model can be set from any callable taking a NumPy array of float numbers as input and outputting either a float number or a NumPy array of float numbers.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/","title":"Mlmc mlcv","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.mlmc_mlcv","title":"mlmc_mlcv","text":"<p>Multilevel Monte Carlo with multilevel control variates (MLMC-MLCV).</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.mlmc_mlcv-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.mlmc_mlcv.MLMCMLCV","title":"MLMCMLCV","text":"<pre><code>MLMCMLCV(\n    levels: Sequence[Level],\n    uncertain_space: ParameterSpace,\n    n_samples: float,\n    pilot: str = \"Mean\",\n    variant: Variant = Variant.MLMC_MLCV,\n    seed: int = SEED,\n)\n</code></pre> <p>               Bases: <code>MLMC</code></p> <p>Multilevel Monte Carlo with multilevel control variates (MLMC-MLCV).</p> <p>Parameters:</p> <ul> <li> <code>levels</code>               (<code>Iterable[Level]</code>)           \u2013            <p>The levels defined in terms of model, evaluation cost and initial number of calls.</p> </li> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain space on which to sample the functions.</p> </li> <li> <code>n_samples</code>               (<code>float</code>)           \u2013            <p>The sampling budget expressed as the number of model evaluations equivalent to evaluations of the finest model. This number is not necessarily an integer; for instance, if \\(f_L\\) is twice as expensive as \\(f_{L-1}\\), then <code>n_samples=1.5</code> can correspond to 1 evaluation of \\(f_L\\) and 1 evaluation of \\(f_{L-1}\\).</p> </li> <li> <code>pilot_statistic_name</code>               (<code>str</code>, default:                   <code>'Mean'</code> )           \u2013            <p>The name of the statistic used to drive the algorithm.</p> </li> <li> <code>seed</code>               (<code>int</code>, default:                   <code>SEED</code> )           \u2013            <p>The initial random seed for reproducibility. Then, the seed is incremented at each level of the telescopic sum and at each algorithm iteration.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>When the minimum cost is greater than the maximum cost.</p> </li> </ul> Source code in <code>src/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv.py</code> <pre><code>def __init__(  # noqa: D107\n    self,\n    levels: Sequence[Level],\n    uncertain_space: ParameterSpace,\n    n_samples: float,\n    pilot: str = \"Mean\",\n    variant: Variant = Variant.MLMC_MLCV,\n    seed: int = SEED,\n) -&gt; None:\n    self.__g_l = tuple(level.surrogate_model[0] for level in levels)\n    for l, g_l in enumerate(self.__g_l):  # noqa: E741\n        g_l.name = f\"g[{l}]\"\n\n    self.__h_l = tuple(\n        level.difference_surrogate_model[0]\n        for l, level in enumerate(levels)  # noqa: E741\n        if l != 0\n    )\n    for l, h_l in enumerate(self.__h_l):  # noqa: E741\n        h_l.name = f\"h[{l + 1}]\"\n    self.__variant = variant\n    super().__init__(\n        levels,\n        uncertain_space,\n        n_samples,\n        pilot_statistic_name=pilot,\n        seed=seed,\n    )\n\n    self._algorithm_name = variant.value\n    self._pilot_statistic_estimator_parameters = [\n        array([level.surrogate_model[1] for level in levels]),\n        array([\n            level.difference_surrogate_model[1]\n            for l, level in enumerate(levels)  # noqa: E741\n            if l != 0\n        ]),\n        variant,\n    ]\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.mlmc_mlcv.MLMCMLCV-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.mlmc_mlcv.MLMCMLCV.budget_history","title":"budget_history  <code>property</code>","text":"<pre><code>budget_history: NDArray[float]\n</code></pre> <p>The history of the budget.</p> <p><code>algo.budget_history[i]</code> is the budget at iteration <code>i+1</code>.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.mlmc_mlcv.MLMCMLCV.level_costs","title":"level_costs  <code>property</code>","text":"<pre><code>level_costs: NDArray[float]\n</code></pre> <p>The evaluation costs of the different levels.</p> <p><code>algo.level_costs[l]</code> is the cost of one evaluation of the <code>l</code>-th level.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.mlmc_mlcv.MLMCMLCV.model_costs","title":"model_costs  <code>property</code>","text":"<pre><code>model_costs: NDArray[float]\n</code></pre> <p>The evaluation costs of the different models.</p> <p><code>algo.model_costs[l]</code> is the cost of one evaluation of the <code>l</code>-th model.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.mlmc_mlcv.MLMCMLCV.n_total_samples","title":"n_total_samples  <code>property</code>","text":"<pre><code>n_total_samples: NDArray[int]\n</code></pre> <p>The total numbers of samples per level.</p> <p><code>algo.n_total_samples[l]</code> is the total number of samples at level <code>l</code>.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.mlmc_mlcv.MLMCMLCV.pilot_statistic_estimation","title":"pilot_statistic_estimation  <code>property</code>","text":"<pre><code>pilot_statistic_estimation: NDArray[float]\n</code></pre> <p>The estimation of the pilot statistic.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.mlmc_mlcv.MLMCMLCV.sampling_history","title":"sampling_history  <code>property</code>","text":"<pre><code>sampling_history: NDArray[int]\n</code></pre> <p>The history of the numbers of samples of each level of the telescopic sum.</p> <p><code>algo.sampling_size_history[i, l]</code> is the number of samples at iteration <code>i+1</code> and level <code>l</code>.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.mlmc_mlcv.MLMCMLCV-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.mlmc_mlcv.MLMCMLCV.Variant","title":"Variant","text":"<p>               Bases: <code>StrEnum</code></p> <p>A variant of the MLMC-MLCV algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.mlmc_mlcv.MLMCMLCV-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.mlmc_mlcv.MLMCMLCV.execute","title":"execute","text":"<pre><code>execute() -&gt; None\n</code></pre> <p>Execute the algorithm.</p> Source code in <code>src/gemseo_umdo/statistics/multilevel/mlmc/mlmc.py</code> <pre><code>def execute(self) -&gt; None:\n    \"\"\"Execute the algorithm.\"\"\"\n    # The current version of the algorithm samples only one level at a time,\n    # except at the first iteration where it samples them all.\n    levels_to_be_sampled = list(range(self._n_levels))\n\n    # Initialize the iteration of the algorithm.\n    is_last_iteration = False\n    iteration = 0\n\n    # As long as there is budget left\n    LOGGER.info(\"Start sampling with a total budget of %s\", self.__total_budget)\n    while self.__current_budget &gt;= 0:\n        iteration += 1\n        if is_last_iteration:\n            LOGGER.info(\"   Iteration #%s (last iteration)\", iteration)\n        else:\n            LOGGER.info(\"   Iteration #%s\", iteration)\n\n        # Append the budget to the budget history.\n        self.__budget_history.append(self.__current_budget)\n\n        # Sample the selected levels of the TS.\n        levels_to_samples = self.__compute_samples(*levels_to_be_sampled)\n\n        # Select the next level l_star of the TS to be sampled\n        # and estimate the statistic.\n        (\n            l_star,\n            self.__pilot_statistic_estimation,\n        ) = self.__pilot_statistic_estimator.compute_next_level_and_statistic(\n            levels_to_be_sampled,\n            self.__n_l,\n            levels_to_samples,\n            *self._pilot_statistic_estimator_parameters,\n        )\n\n        # Stop the algorithm if it is the last iteration.\n        if is_last_iteration:\n            break\n\n        # The current version of the algorithm samples only one level at a time.\n        levels_to_be_sampled = [l_star]\n\n        # Define the corresponding sample size.\n        delta_n_l_star = int(\n            math.floor((self.__r_l[l_star] - 1) * self.__n_l[l_star])\n        )\n        n_l_star = self.__n_l[l_star] + delta_n_l_star\n        LOGGER.info(\"      Find the next level to sample\")\n        LOGGER.info(\"         l_star = %s\", l_star)\n        LOGGER.info(\"         d_n_l_star = %s\", delta_n_l_star)\n        LOGGER.info(\"         n_l_star = %s\", n_l_star)\n\n        # If the new sampling stage is too expensive, reduce the number of samples.\n        posterior_budget = (\n            self.__current_budget - delta_n_l_star * self.__costs[l_star]\n        )\n        if posterior_budget &lt; 0:\n            LOGGER.info(\"         Maximum budget exceeded by %s\", -posterior_budget)\n            LOGGER.info(\n                \"         Decrease d_n_l_star to respect the maximum budget\"\n            )\n\n            # There is a budget to do at most one iteration.\n            is_last_iteration = True\n\n            # Update the numbers of additional samples at level l_star\n            # to achieve a positive or zero budget.\n            delta_n_l_star = int(\n                delta_n_l_star + posterior_budget / self.__costs[l_star]\n            )\n            n_l_star = self.__n_l[l_star] + delta_n_l_star\n            LOGGER.info(\"         d_n_l_star = %s\", delta_n_l_star)\n            LOGGER.info(\"         n_l_star = %s\", n_l_star)\n            # Stop the algorithm if one can no longer sample l_star.\n            if delta_n_l_star == 0:\n                LOGGER.info(\n                    \"Stop the algorithm as sampling l_star is too expensive.\"\n                )\n                break\n\n        # Update the history of number of samples of each level\n        # (0 for all the levels, but l_star).\n        self.__delta_n_l = zeros(self._n_levels)\n        self.__delta_n_l[l_star] = delta_n_l_star\n        self.__n_l[l_star] += delta_n_l_star\n        self.__n_samples_history.extend([self.__delta_n_l.copy()])\n\n    LOGGER.info(\"Sampling completed\")\n    LOGGER.info(\"Results\")\n    LOGGER.info(\"   Pilot statistic = %s\", self.pilot_statistic_estimation)\n    LOGGER.info(\"   Total cost = %s\", sum(self.__n_l * self.__costs))\n    LOGGER.info(\"   Cost allocation\")\n    levels_to_total_costs = self.__n_l * self.__costs\n    levels_to_total_costs = levels_to_total_costs / sum(levels_to_total_costs)\n    for level, total_cost in enumerate(levels_to_total_costs):\n        LOGGER.info(\"      Level %s: %s\", level, f\"{total_cost:.1%}\")\n\n    LOGGER.info(\"   n_l\")\n    for level in range(self._n_levels):\n        LOGGER.info(\"       n_%s = %s\", level, self.__n_l[level])\n\n    LOGGER.info(\"   V_l\")\n    self.__V_l = self.__pilot_statistic_estimator.V_l\n    for level in range(self._n_levels):\n        LOGGER.info(\"       V_%s = %s\", level, f\"{self.__V_l[level]:.2e}\")\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.mlmc_mlcv.MLMCMLCV.get_surrogate_positions","title":"get_surrogate_positions  <code>classmethod</code>","text":"<pre><code>get_surrogate_positions(\n    level: int, n_levels: int, variant: Variant\n) -&gt; slice\n</code></pre> <p>Return the positions of the surrogate models for given level and variant.</p> <p>These are their positions in a sequence starting to count at 0. So, the position of \\(g_\\ell\\) is \\(\\ell\\) for \\(\\ell\\in\\{0,\\ldots,L\\}\\) while the position of \\(h_\\ell\\) is \\(\\ell-1\\) for \\(\\ell\\in\\{1,\\ldots,L\\}\\).</p> <p>Parameters:</p> <ul> <li> <code>level</code>               (<code>int</code>)           \u2013            <p>The level of the telescopic sum.</p> </li> <li> <code>n_levels</code>               (<code>int</code>)           \u2013            <p>The number of levels.</p> </li> <li> <code>variant</code>               (<code>Variant</code>)           \u2013            <p>The variant of the algorithm.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>slice</code>           \u2013            <p>The positions of the surrogate models.</p> </li> </ul> See Also <p>El Amri et al., Table 1, Multilevel Surrogate-based Control Variates, 2023.</p> Source code in <code>src/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv.py</code> <pre><code>@classmethod\ndef get_surrogate_positions(\n    cls, level: int, n_levels: int, variant: Variant\n) -&gt; slice:\n    r\"\"\"Return the positions of the surrogate models for given level and variant.\n\n    These are their positions in a sequence starting to count at 0.\n    So,\n    the position of $g_\\ell$ is $\\ell$\n    for $\\ell\\in\\{0,\\ldots,L\\}$\n    while\n    the position of $h_\\ell$ is $\\ell-1$\n    for $\\ell\\in\\{1,\\ldots,L\\}$.\n\n    Args:\n        level: The level of the telescopic sum.\n        n_levels: The number of levels.\n        variant: The variant of the algorithm.\n\n    Returns:\n        The positions of the surrogate models.\n\n    See Also:\n        El Amri et al., Table 1, Multilevel Surrogate-based Control Variates, 2023.\n    \"\"\"\n    if level == 0:\n        if variant == cls.Variant.MLMC_MLCV:\n            return slice(0, n_levels)\n\n        if variant == cls.Variant.MLMC_CV:\n            return slice(0, 1)\n\n        if variant == cls.Variant.MLMC_MLCV_0:\n            return slice(0, 2)\n\n        return slice(0, 1)\n\n    if variant == cls.Variant.MLMC_MLCV:\n        return slice(0, n_levels - 1)\n\n    if variant == cls.Variant.MLMC_CV:\n        return slice(level - 1, level)\n\n    if variant == cls.Variant.MLMC_MLCV_0:\n        return slice(0, 1)\n\n    return slice(0, 0)\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.mlmc_mlcv.MLMCMLCV.plot_evaluation_history","title":"plot_evaluation_history","text":"<pre><code>plot_evaluation_history(\n    show: bool = True,\n    file_path: str | Path | None = None,\n    log_n_evaluations: bool = True,\n    log_budget: bool = False,\n) -&gt; None\n</code></pre> <p>Plot the history of the model evaluations in terms of sample size and budget.</p> <p>Parameters:</p> <ul> <li> <code>show</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to display the graph.</p> </li> <li> <code>file_path</code>               (<code>str | Path | None</code>, default:                   <code>None</code> )           \u2013            <p>The file path to save the graph.</p> </li> <li> <code>log_n_evaluations</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to use a log-scale for the number of evaluations.</p> </li> <li> <code>log_budget</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to use a log-scale for the budget.</p> </li> </ul> Source code in <code>src/gemseo_umdo/statistics/multilevel/mlmc/mlmc.py</code> <pre><code>def plot_evaluation_history(\n    self,\n    show: bool = True,\n    file_path: str | Path | None = None,\n    log_n_evaluations: bool = True,\n    log_budget: bool = False,\n) -&gt; None:\n    \"\"\"Plot the history of the model evaluations in terms of sample size and budget.\n\n    Args:\n        show: Whether to display the graph.\n        file_path: The file path to save the graph.\n        log_n_evaluations: Whether to use a log-scale for the number of evaluations.\n        log_budget: Whether to use a log-scale for the budget.\n    \"\"\"\n    fig, (ax1, ax2) = plt.subplots(ncols=2)\n    iterations = [i + 1 for i, _ in enumerate(self.__n_samples_history)]\n    ax1.plot(\n        iterations,\n        cumsum(array(self.__n_samples_history), axis=0),\n        label=[rf\"$f_{level}$\" for level in range(self._n_levels)],\n        marker=\".\",\n    )\n    if log_n_evaluations:\n        ax1.set_yscale(\"log\")\n\n    ax1.set_xlabel(\"Iteration\")\n    ax1.set_ylabel(\"Cumulated number of evaluations\")\n    ax1.legend(title=\"Simulators\")\n    ax1.grid(which=\"both\")\n    data = (array(self.__n_samples_history) * self.__costs).T\n    ax2.bar(iterations, data[0], label=r\"$f_0$\")\n    for index, row in enumerate(data[1:]):\n        ax2.bar(\n            iterations,\n            row,\n            bottom=data[0 : index + 1].sum(0),\n            label=rf\"$f_{index + 1}$\",\n        )\n\n    if log_budget:\n        ax2.set_yscale(\"log\")\n\n    ax2.set_xlabel(\"Iteration\")\n    ax2.set_ylabel(\"Cost\")\n    ax2.legend(title=\"Simulators\")\n    ax2.grid(which=\"both\")\n    ax2.set_axisbelow(True)\n    save_show_figure(fig, show, file_path, fig_size=(10, 3))\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/","title":"Pilots","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.pilots","title":"pilots","text":"<p>A set of pilots for the MLMC-MLCV algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/base_mlmc_mlcv_pilot/","title":"Base mlmc mlcv pilot","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/base_mlmc_mlcv_pilot/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.pilots.base_mlmc_mlcv_pilot","title":"base_mlmc_mlcv_pilot","text":"<p>The base pilot class for the MLMC-MLCV algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/base_mlmc_mlcv_pilot/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.pilots.base_mlmc_mlcv_pilot-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/base_mlmc_mlcv_pilot/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.pilots.base_mlmc_mlcv_pilot.BaseMLMCMLCVPilot","title":"BaseMLMCMLCVPilot","text":"<pre><code>BaseMLMCMLCVPilot(\n    sampling_ratios: NDArray[float], costs: NDArray[float]\n)\n</code></pre> <p>               Bases: <code>BasePilot</code></p> <p>The base pilot class for the MLMC-MLCV algorithm.</p> See Also <p>El Amri et al., Algo. 1, Multilevel Surrogate-based Control Variates, 2023.</p> <p>Parameters:</p> <ul> <li> <code>sampling_ratios</code>               (<code>NDArray[float]</code>)           \u2013            <p>The sampling ratios \\(r_0,\\ldots,r_L\\); the sampling ratio \\(r_\\ell\\) is the factor by which \\(n_\\ell\\) is increased between two sampling steps on the level \\(ell\\).</p> </li> <li> <code>costs</code>               (<code>NDArray[float]</code>)           \u2013            <p>The unit sampling costs of each level of the telescopic sum. Namely, \\((\\mathcal{C}_{\\ell-1}+\\mathcal{C}_\\ell)_{\\ell\\in\\{0,\\ldots,L\\}}\\) with \\(\\mathcal{C}_{-1}=0\\).</p> </li> </ul> Source code in <code>src/gemseo_umdo/statistics/multilevel/base_pilot.py</code> <pre><code>def __init__(self, sampling_ratios: NDArray[float], costs: NDArray[float]) -&gt; None:\n    r\"\"\"\n    Args:\n        sampling_ratios: The sampling ratios $r_0,\\ldots,r_L$;\n            the sampling ratio $r_\\ell$ is\n            the factor by which $n_\\ell$ is increased\n            between two sampling steps on the level $ell$.\n        costs: The unit sampling costs of each level of the telescopic sum.\n            Namely,\n            $(\\mathcal{C}_{\\ell-1}+\\mathcal{C}_\\ell)_{\\ell\\in\\{0,\\ldots,L\\}}$\n            with $\\mathcal{C}_{-1}=0$.\n    \"\"\"  # noqa: D205 D212 D415\n    self.__costs = costs\n    self.__r_l = sampling_ratios\n    self.V_l = array([nan] * len(self.__r_l))\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/factory/","title":"Factory","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/factory/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.pilots.factory","title":"factory","text":"<p>A factory of pilots for the MLMC-MLCV algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/factory/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.pilots.factory-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/factory/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.pilots.factory.MLMCMLCVPilotFactory","title":"MLMCMLCVPilotFactory","text":"<p>               Bases: <code>BaseFactory</code></p> <p>A factory of pilots for the MLMC-MLCV algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/mean/","title":"Mean","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/mean/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.pilots.mean","title":"mean","text":"<p>The mean-based pilot for the MLMC-MLCV algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/mean/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.pilots.mean-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/mean/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.pilots.mean.Mean","title":"Mean","text":"<pre><code>Mean(\n    sampling_ratios: NDArray[float], costs: NDArray[float]\n)\n</code></pre> <p>               Bases: <code>BaseMLMCMLCVPilot</code></p> <p>The mean-based pilot for the MLMC-MLCV algorithm.</p> See Also <p>El Amri et al., Algo. 1, Multilevel Surrogate-based Control Variates, 2023.</p> <p>Parameters:</p> <ul> <li> <code>sampling_ratios</code>               (<code>NDArray[float]</code>)           \u2013            <p>The sampling ratios \\(r_0,\\ldots,r_L\\); the sampling ratio \\(r_\\ell\\) is the factor by which \\(n_\\ell\\) is increased between two sampling steps on the level \\(ell\\).</p> </li> <li> <code>costs</code>               (<code>NDArray[float]</code>)           \u2013            <p>The unit sampling costs of each level of the telescopic sum. Namely, \\((\\mathcal{C}_{\\ell-1}+\\mathcal{C}_\\ell)_{\\ell\\in\\{0,\\ldots,L\\}}\\) with \\(\\mathcal{C}_{-1}=0\\).</p> </li> </ul> Source code in <code>src/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/mean.py</code> <pre><code>def __init__(  # noqa: D107\n    self, sampling_ratios: NDArray[float], costs: NDArray[float]\n) -&gt; None:\n    super().__init__(sampling_ratios, costs)\n    self.__delta = [array([]) for _ in range(len(sampling_ratios))]\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/mean/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.pilots.mean.Mean-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/mean/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.pilots.mean.Mean.V_l","title":"V_l  <code>instance-attribute</code>","text":"<pre><code>V_l: NDArray[float] = array([nan] * len(__r_l))\n</code></pre> <p>The terms variances \\(\\mathcal{V}_0,\\ldots,\\mathcal{V}_L\\).</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/mean/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.pilots.mean.Mean-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/mean/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.pilots.mean.Mean.compute_next_level_and_statistic","title":"compute_next_level_and_statistic","text":"<pre><code>compute_next_level_and_statistic(\n    levels: Iterable[int],\n    total_n_samples: NDArray[int],\n    samples: Sequence[NDArray[float]],\n    *pilot_parameters: Any\n) -&gt; tuple[int, NDArray[float]]\n</code></pre> <p>Compute the next level \\(\\ell^*\\) to sample and estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>levels</code>               (<code>Iterable[int]</code>)           \u2013            <p>The levels that have just been sampled.</p> </li> <li> <code>total_n_samples</code>               (<code>NDArray[int]</code>)           \u2013            <p>The total number of samples of each level.</p> </li> <li> <code>samples</code>               (<code>Sequence[NDArray[float]]</code>)           \u2013            <p>The samples of the different quantities of each level.</p> </li> <li> <code>*pilot_parameters</code>               (<code>Any</code>, default:                   <code>()</code> )           \u2013            <p>The parameters of the pilot.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[int, NDArray[float]]</code>           \u2013            <p>The next level \\(\\ell^*\\) to sample and an estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/statistics/multilevel/base_pilot.py</code> <pre><code>def compute_next_level_and_statistic(\n    self,\n    levels: Iterable[int],\n    total_n_samples: NDArray[int],\n    samples: Sequence[NDArray[float]],\n    *pilot_parameters: Any,\n) -&gt; tuple[int, NDArray[float]]:\n    r\"\"\"Compute the next level $\\ell^*$ to sample and estimate the statistic.\n\n    Args:\n        levels: The levels that have just been sampled.\n        total_n_samples: The total number of samples of each level.\n        samples: The samples of the different quantities of each level.\n        *pilot_parameters: The parameters of the pilot.\n\n    Returns:\n        The next level $\\ell^*$ to sample and an estimation of the statistic.\n    \"\"\"\n    self.V_l = self._compute_V_l(levels, samples, *pilot_parameters)\n    # WARNING: do not replace \"/ total_n_samples / total_n_samples\"\n    #          by \"/ total_n_samples**2\"\n    #          to avoid numerical division issue due to an excessively big number.\n    return (\n        argmax(\n            self.V_l / self.__r_l / total_n_samples / total_n_samples / self.__costs\n        ),\n        self._compute_statistic(),\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/use_cases/","title":"Use cases","text":""},{"location":"reference/gemseo_umdo/use_cases/#gemseo_umdo.use_cases","title":"use_cases","text":"<p>Some use cases for uncertainty quantification and robust optimization.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/","title":"Beam model","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/#gemseo_umdo.use_cases.beam_model","title":"beam_model","text":"<p>The beam model.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/advanced_uncertain_space/","title":"Advanced uncertain space","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/advanced_uncertain_space/#gemseo_umdo.use_cases.beam_model.advanced_uncertain_space","title":"advanced_uncertain_space","text":"<p>The advanced uncertain space for the beam use case.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/advanced_uncertain_space/#gemseo_umdo.use_cases.beam_model.advanced_uncertain_space-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/advanced_uncertain_space/#gemseo_umdo.use_cases.beam_model.advanced_uncertain_space-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/advanced_uncertain_space/#gemseo_umdo.use_cases.beam_model.advanced_uncertain_space.AdvancedBeamUncertainSpace","title":"AdvancedBeamUncertainSpace","text":"<pre><code>AdvancedBeamUncertainSpace(\n    nominal_values: Mapping[str, float] | None = None,\n    **dispersions: float\n)\n</code></pre> <p>               Bases: <code>ParameterSpace</code></p> <p>The advanced uncertain space for the beam use case.</p> <p>Parameters:</p> <ul> <li> <code>nominal_values</code>               (<code>Mapping[str, float] | None</code>, default:                   <code>None</code> )           \u2013            <p>The nominal values of some uncertain variables. For missing ones, use the default values of the variables available in <code>gemseo_umdo.use_cases.beam_model.core.variables</code>.</p> </li> <li> <code>**dispersions</code>               (<code>float</code>, default:                   <code>{}</code> )           \u2013            <p>The dispersions around the nominal values.</p> </li> </ul> Source code in <code>src/gemseo_umdo/use_cases/beam_model/advanced_uncertain_space.py</code> <pre><code>def __init__(\n    self, nominal_values: Mapping[str, float] | None = None, **dispersions: float\n) -&gt; None:\n    \"\"\"\n    Args:\n        nominal_values: The nominal values of some uncertain variables.\n            For missing ones,\n            use the default values of the variables available in\n            `gemseo_umdo.use_cases.beam_model.core.variables`.\n        **dispersions: The dispersions around the nominal values.\n    \"\"\"  # noqa: D205 D212 D415\n    super().__init__()\n    variables = [\n        b,\n        h,\n        t,\n        L,\n        alpha,\n        beta,\n        dy,\n        dz,\n        E,\n        Variable(\"Rd\", 180.0),\n        Variable(\"Ry\", 600.0),\n    ]\n    self.__nominal_values = {\n        variable.name: variable.value for variable in variables\n    }\n    if nominal_values is not None:\n        self.__nominal_values.update(nominal_values)\n\n    for variable in variables[:4]:\n        name = variable.name\n        nominal_value = variable.value\n        delta = dispersions.get(name, self.__DEFAULT_DISPERSION)\n        self.add_random_variable(\n            name,\n            \"OTUniformDistribution\",\n            minimum=nominal_value - delta,\n            maximum=nominal_value + delta,\n        )\n\n    for variable in variables[4:]:\n        self.__add_truncated_normal(variable.name, **dispersions)\n</code></pre>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/constraints/","title":"Constraints","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/constraints/#gemseo_umdo.use_cases.beam_model.constraints","title":"constraints","text":"<p>The discipline computing the constraints for the beam use case.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/constraints/#gemseo_umdo.use_cases.beam_model.constraints-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/constraints/#gemseo_umdo.use_cases.beam_model.constraints-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/constraints/#gemseo_umdo.use_cases.beam_model.constraints.BeamConstraints","title":"BeamConstraints","text":"<pre><code>BeamConstraints()\n</code></pre> <p>               Bases: <code>MDODiscipline</code></p> <p>The discipline computing the constraints of the beam problem.</p> <p>More particularly, the left-hand sides of</p> <ul> <li>the stress constraints \\(\\sigma_{\\mathrm{VM}}/\\sigma_{\\mathrm{all}} \\leq 1\\),</li> <li>the displacements constraints \\(\\Delta/\\Delta_{\\mathrm{min}} \\geq 1\\).</li> </ul> <p>Initialize self.  See help(type(self)) for accurate signature.</p> Source code in <code>src/gemseo_umdo/use_cases/beam_model/constraints.py</code> <pre><code>def __init__(self) -&gt; None:  # noqa: D107\n    super().__init__()\n    self.input_grammar.update_from_names([\n        self.__DISPL,\n        self.__SIGMA_VM,\n        sigma_all.name,\n    ])\n    self.output_grammar.update_from_names([self.__C_DISPL, self.__C_STRESS])\n    self.default_inputs = {\n        sigma_all.name: array([sigma_all.value]),\n        self.__SIGMA_VM: array([300.0]),\n        self.__DISPL: array([100.0]),\n    }\n</code></pre>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/design_space/","title":"Design space","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/design_space/#gemseo_umdo.use_cases.beam_model.design_space","title":"design_space","text":"<p>The design space for the beam use case.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/design_space/#gemseo_umdo.use_cases.beam_model.design_space-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/design_space/#gemseo_umdo.use_cases.beam_model.design_space.BeamDesignSpace","title":"BeamDesignSpace","text":"<pre><code>BeamDesignSpace()\n</code></pre> <p>               Bases: <code>DesignSpace</code></p> <p>The design space for the beam use case.</p> Source code in <code>src/gemseo_umdo/use_cases/beam_model/design_space.py</code> <pre><code>def __init__(self) -&gt; None:  # noqa: D107\n    super().__init__()\n    for variable in BeamDesignVariables:\n        self.add_variable(\n            variable.value.name,\n            l_b=variable.value.l_b,\n            u_b=variable.value.u_b,\n            value=variable.value.value,\n        )\n</code></pre>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/discipline/","title":"Discipline","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/discipline/#gemseo_umdo.use_cases.beam_model.discipline","title":"discipline","text":"<p>The discipline for the beam use case.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/discipline/#gemseo_umdo.use_cases.beam_model.discipline-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/discipline/#gemseo_umdo.use_cases.beam_model.discipline-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/discipline/#gemseo_umdo.use_cases.beam_model.discipline.Beam","title":"Beam","text":"<pre><code>Beam(n_y: int = 3, n_z: int = 3)\n</code></pre> <p>               Bases: <code>MDODiscipline</code></p> <p>The beam discipline.</p> See Also <p>BeamModel for more information about the beam model.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>n_y</code>               (<code>int</code>, default:                   <code>3</code> )           \u2013            <p>The number of discretization points in the y-direction.</p> </li> <li> <code>n_z</code>               (<code>int</code>, default:                   <code>3</code> )           \u2013            <p>The number of discretization points in the z-direction.</p> </li> </ul> Source code in <code>src/gemseo_umdo/use_cases/beam_model/discipline.py</code> <pre><code>def __init__(self, n_y: int = 3, n_z: int = 3) -&gt; None:\n    \"\"\"\n    Args:\n        n_y: The number of discretization points in the y-direction.\n        n_z: The number of discretization points in the z-direction.\n    \"\"\"  # noqa: D205 D212 D415\n    super().__init__()\n    input_variables = [b, h, t, L, E, alpha, beta, dy, dz, rho, F, nu]\n    self.input_grammar.update_from_names([\n        variable.name for variable in input_variables\n    ])\n    self.output_grammar.update_from_names([\n        f.name for f in fields(BeamModelOutputData)\n    ])\n    self.default_inputs = {\n        variable.name: array([variable.value]) for variable in input_variables\n    }\n    self.__beam_model = BeamModel(n_y, n_z)\n</code></pre>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/uncertain_space/","title":"Uncertain space","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/uncertain_space/#gemseo_umdo.use_cases.beam_model.uncertain_space","title":"uncertain_space","text":"<p>The uncertain space for the beam use case.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/uncertain_space/#gemseo_umdo.use_cases.beam_model.uncertain_space-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/uncertain_space/#gemseo_umdo.use_cases.beam_model.uncertain_space-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/uncertain_space/#gemseo_umdo.use_cases.beam_model.uncertain_space.BeamUncertainSpace","title":"BeamUncertainSpace","text":"<pre><code>BeamUncertainSpace(uniform: bool = True, **deltas: float)\n</code></pre> <p>               Bases: <code>ParameterSpace</code></p> <p>The advanced uncertain space for the beam use case.</p> <p>\\(F\\), \\(E\\) and \\(\\sigma_{\\text{all}}\\) are random variables with nominal values -200000, 73500 and 300 and deviation values 10%, 5% and 5%.</p> <p>Their probability distribution are centered in these values denoted \\(\\mu_F\\), \\(\\mu_E\\) and \\(\\mu_{\\sigma_{\\text{all}}}\\).</p> <p>Precisely, a uniform distribution is defined by the minimum \\(\\mu (1 - \\delta)\\) and the maximum \\(\\mu (1 + \\delta)\\) and a Gaussian distribution is defined by the mean \\(\\mu\\) and the standard deviation \\(|\\mu|\\delta/3\\), where \\(\\delta\\) is an aforementioned deviation value.</p> <p>Parameters:</p> <ul> <li> <code>uniform</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If <code>True</code>, use uniform distributions; otherwise, use Gaussian ones.</p> </li> <li> <code>**deltas</code>               (<code>float</code>, default:                   <code>{}</code> )           \u2013            <p>The percentage variations \\(\\delta\\) around the nominal values of the random variables.</p> </li> </ul> Source code in <code>src/gemseo_umdo/use_cases/beam_model/uncertain_space.py</code> <pre><code>def __init__(self, uniform: bool = True, **deltas: float) -&gt; None:\n    r\"\"\"\n    Args:\n        uniform: If `True`, use uniform distributions;\n            otherwise, use Gaussian ones.\n        **deltas: The percentage variations $\\delta$ around the nominal values\n            of the random variables.\n    \"\"\"  # noqa: D205 D212 D415\n    super().__init__()\n    for variable in [F, E, sigma_all]:\n        nominal = variable.value\n        name = variable.name\n        delta = deltas.pop(name, self.__DEFAULT_DELTA[name]) / 100\n        if uniform:\n            minimum, maximum = sorted([\n                nominal * (1 - delta),\n                nominal * (1 + delta),\n            ])\n            self.add_random_variable(\n                name,\n                \"OTUniformDistribution\",\n                minimum=minimum,\n                maximum=maximum,\n            )\n        else:\n            self.add_random_variable(\n                name,\n                \"OTNormalDistribution\",\n                mu=nominal,\n                sigma=abs(nominal) * delta / 3,\n            )\n</code></pre>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/","title":"Core","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/#gemseo_umdo.use_cases.beam_model.core","title":"core","text":"<p>The GEMSEO-free version of the beam use case.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/design_space/","title":"Design space","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/design_space/#gemseo_umdo.use_cases.beam_model.core.design_space","title":"design_space","text":"<p>The GEMSEO-free version of the design space for the beam use case.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/design_space/#gemseo_umdo.use_cases.beam_model.core.design_space-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/design_space/#gemseo_umdo.use_cases.beam_model.core.design_space-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/design_space/#gemseo_umdo.use_cases.beam_model.core.design_space.BeamDesignVariables","title":"BeamDesignVariables","text":"<p>               Bases: <code>Enum</code></p> <p>The design variables for the beam use case.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/design_space/#gemseo_umdo.use_cases.beam_model.core.design_space.BeamDesignVariables-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/design_space/#gemseo_umdo.use_cases.beam_model.core.design_space.BeamDesignVariables.h","title":"h  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>h = DesignVariable(name, 500, 800, value)\n</code></pre> <p>The height of the beam.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/design_space/#gemseo_umdo.use_cases.beam_model.core.design_space.BeamDesignVariables.t","title":"t  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>t = DesignVariable(name, 2, 10, value)\n</code></pre> <p>The thickness of the beam.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/design_space/#gemseo_umdo.use_cases.beam_model.core.design_space.DesignVariable","title":"DesignVariable","text":"<p>               Bases: <code>NamedTuple</code></p> <p>A design variable.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/design_space/#gemseo_umdo.use_cases.beam_model.core.design_space.DesignVariable-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/design_space/#gemseo_umdo.use_cases.beam_model.core.design_space.DesignVariable.l_b","title":"l_b  <code>instance-attribute</code>","text":"<pre><code>l_b: float\n</code></pre> <p>The lower bound of the design variable.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/design_space/#gemseo_umdo.use_cases.beam_model.core.design_space.DesignVariable.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre> <p>The name of the design variable.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/design_space/#gemseo_umdo.use_cases.beam_model.core.design_space.DesignVariable.u_b","title":"u_b  <code>instance-attribute</code>","text":"<pre><code>u_b: float\n</code></pre> <p>The upper bound of the design variable.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/design_space/#gemseo_umdo.use_cases.beam_model.core.design_space.DesignVariable.value","title":"value  <code>instance-attribute</code>","text":"<pre><code>value: float\n</code></pre> <p>The current value of the design variable.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/model/","title":"Model","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/model/#gemseo_umdo.use_cases.beam_model.core.model","title":"model","text":"<p>The GEMSEO-free version of the model for the beam use case.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/model/#gemseo_umdo.use_cases.beam_model.core.model-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/model/#gemseo_umdo.use_cases.beam_model.core.model-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/model/#gemseo_umdo.use_cases.beam_model.core.model.BeamModel","title":"BeamModel","text":"<pre><code>BeamModel(n_y: int = 3, n_z: int = 3)\n</code></pre> <p>The beam model.</p> <p>We consider an horizontal beam with length \\(L\\), width \\(b\\) and height \\(h\\). This beam is hollow and made of a material with a Young's modulus \\(E\\), a Poisson's ratio \\(\\nu\\) and a thickness \\(t\\). One of its ends is fixed at \\(x=0\\) (the \"root\") while the other  at \\(x=L\\) (the \"tip\") is free. The \\(y\\)-axis is horizontal and perpendicular to the beam, the \\(z\\) is vertical and the center of the root is at the origin \\((0, 0, 0)\\).</p> <p>A force \\(\\vec{F}\\) of amplitude \\(F\\) is applied to the beam at \\((L, dy, dz)\\) with an angle \\(\\alpha\\) w.r.t. \\(-\\vec{e}_y\\) in the xz-plane and an angle \\(\\beta\\) w.r.t. \\(-\\vec{e}_y\\) in the yz-plane, where \\(\\vec{e}_y\\) is the unit vector along the \\(y\\)-axis.</p> <p>From these settings, the model computes the weight of the beam \\(w=2 \\rho L (b + h -2t)\\) and several quantities on a regular \\(yz\\)-grid:</p> <ul> <li>the strain energy vector \\(\\vec{U}=(U_x,U_y,U_z)\\) at the tip,</li> <li>the normal stress \\(\\sigma\\) at the root,</li> <li>the torsional stress \\(\\tau\\) at the root,</li> <li>the displacement \\(\\delta\\) at the tip,</li> <li>the von Mises stress \\(\\sigma_{\\text{VM}}\\) at the root.</li> </ul> <p>The equations are:</p> <ul> <li>Force components<ul> <li>\\(F_x=F\\sin(\\alpha)\\)</li> <li>\\(F_y=F\\cos(\\alpha)\\sin(\\beta)\\)</li> <li>\\(F_z=F\\cos(\\alpha)\\cos(\\beta)\\)</li> </ul> </li> <li>Inertia<ul> <li>\\(I_x=(2tb^2h^2)/(b + h)\\)</li> <li>\\(I_y=(bh^3-(b-2t)(h-2t)^3)/12\\)</li> <li>\\(I_z=(hb^3-(h-2t)(b-2t)^3)/12\\)</li> </ul> </li> <li>Strain energy<ul> <li>\\(U_x = E^{-1} \\{ \\frac{ F_x L }{ 2t (b+h-2t) } +   zL (F_x dZ - F_z L/2) I_y^{-1} - yL (F_y L/2 - F_x dY) I_z^{-1} \\}\\)</li> <li>\\(U_y = E^{-1} \\{ (F_y L^3/3 - F_x dY L^2/2)I_z^{-1} -   zL \\frac{ F_zdY-F_ydZ }{ 2 (1+\\nu) I_x } \\}\\)</li> <li>\\(U_z = E^{-1} \\{ (F_z L^3/3 - F_xdZ L^2/2) I_y^{-1} +   yL \\frac{ F_zdY-F_ydZ }{ 2 (1+\\nu) I_x } \\}\\)</li> </ul> </li> <li>Displacements<ul> <li>\\(\\delta=\\sqrt{U_x^2+U_y^2+U_z^2}\\)</li> </ul> </li> <li>Torsional stress<ul> <li>\\(\\tau_x=(F_zdY-F_ydZ)/(2bht)\\)</li> <li>\\(\\tau_y= - (0.5|z|(b-t)+(b-t)^2(1-4y^2/(b-t)^2))F_y\\text{sign}(z)/(8I_z)\\)</li> <li>\\(\\tau_z=(0.5|y|(h-t)+(h-t)^2(1-4z^2/(h-t)^2))F_z\\text{sign}(y)/(8I_y)\\)</li> <li>\\(\\tau = \\tau_x + \\tau_y + \\tau_z\\)</li> </ul> </li> <li>Stress<ul> <li>\\(\\sigma = F_x/(2t(b+h-2t)) + y (F_xdY-F_yL)/I_z + z (F_xdZ-F_zL)/I_y\\)</li> </ul> </li> <li>von Mises stress<ul> <li>\\(\\sigma_{\\text{VM}} = \\sqrt{\\sigma^2 + 3\\tau^2}\\)</li> </ul> </li> </ul> <p>Parameters:</p> <ul> <li> <code>n_y</code>               (<code>int</code>, default:                   <code>3</code> )           \u2013            <p>The number of discretization points in the y-direction.</p> </li> <li> <code>n_z</code>               (<code>int</code>, default:                   <code>3</code> )           \u2013            <p>The number of discretization points in the z-direction.</p> </li> </ul> Source code in <code>src/gemseo_umdo/use_cases/beam_model/core/model.py</code> <pre><code>def __init__(self, n_y: int = 3, n_z: int = 3) -&gt; None:\n    \"\"\"\n    Args:\n        n_y: The number of discretization points in the y-direction.\n        n_z: The number of discretization points in the z-direction.\n    \"\"\"  # noqa: D205 D212 D415\n    self.__n_y = n_y\n    self.__n_z = n_z\n</code></pre>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/output_data/","title":"Output data","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/output_data/#gemseo_umdo.use_cases.beam_model.core.output_data","title":"output_data","text":"<p>The GEMSEO-free version of the output data for the beam use case.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/output_data/#gemseo_umdo.use_cases.beam_model.core.output_data-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/output_data/#gemseo_umdo.use_cases.beam_model.core.output_data.BeamModelOutputData","title":"BeamModelOutputData  <code>dataclass</code>","text":"<pre><code>BeamModelOutputData(\n    Ux: NDArray[float],\n    Uy: NDArray[float],\n    Uz: NDArray[float],\n    sigma: NDArray[float],\n    tau: NDArray[float],\n    displ: NDArray[float],\n    sigma_vm: NDArray[float],\n    w: float,\n    yz_grid: NDArray[float],\n)\n</code></pre> <p>Output data of the beam model.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/output_data/#gemseo_umdo.use_cases.beam_model.core.output_data.BeamModelOutputData-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/output_data/#gemseo_umdo.use_cases.beam_model.core.output_data.BeamModelOutputData.Ux","title":"Ux  <code>instance-attribute</code>","text":"<pre><code>Ux: NDArray[float]\n</code></pre> <p>The strain energy along the \\(x\\)-axis.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/output_data/#gemseo_umdo.use_cases.beam_model.core.output_data.BeamModelOutputData.Uy","title":"Uy  <code>instance-attribute</code>","text":"<pre><code>Uy: NDArray[float]\n</code></pre> <p>The strain energy along the \\(y\\)-axis.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/output_data/#gemseo_umdo.use_cases.beam_model.core.output_data.BeamModelOutputData.Uz","title":"Uz  <code>instance-attribute</code>","text":"<pre><code>Uz: NDArray[float]\n</code></pre> <p>The strain energy along the \\(z\\)-axis.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/output_data/#gemseo_umdo.use_cases.beam_model.core.output_data.BeamModelOutputData.displ","title":"displ  <code>instance-attribute</code>","text":"<pre><code>displ: NDArray[float]\n</code></pre> <p>The displacements at the tip section points.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/output_data/#gemseo_umdo.use_cases.beam_model.core.output_data.BeamModelOutputData.sigma","title":"sigma  <code>instance-attribute</code>","text":"<pre><code>sigma: NDArray[float]\n</code></pre> <p>The normal stress at the root section points.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/output_data/#gemseo_umdo.use_cases.beam_model.core.output_data.BeamModelOutputData.sigma_vm","title":"sigma_vm  <code>instance-attribute</code>","text":"<pre><code>sigma_vm: NDArray[float]\n</code></pre> <p>The von Mises stress at the root section points.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/output_data/#gemseo_umdo.use_cases.beam_model.core.output_data.BeamModelOutputData.tau","title":"tau  <code>instance-attribute</code>","text":"<pre><code>tau: NDArray[float]\n</code></pre> <p>The torsional stress at the root section points.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/output_data/#gemseo_umdo.use_cases.beam_model.core.output_data.BeamModelOutputData.w","title":"w  <code>instance-attribute</code>","text":"<pre><code>w: float\n</code></pre> <p>The weight of the beam.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/output_data/#gemseo_umdo.use_cases.beam_model.core.output_data.BeamModelOutputData.yz_grid","title":"yz_grid  <code>instance-attribute</code>","text":"<pre><code>yz_grid: NDArray[float]\n</code></pre> <p>The \\(yz\\)-grid coordinates.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/","title":"Variables","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables","title":"variables","text":"<p>Some variables of the GEMSEO-free version of the beam use case.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.E","title":"E  <code>module-attribute</code>","text":"<pre><code>E = Variable('E', 73500.0)\n</code></pre> <p>The Young's modulus of the material.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.F","title":"F  <code>module-attribute</code>","text":"<pre><code>F = Variable('F', -200000.0)\n</code></pre> <p>The load applied to a point at the tip of the beam.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.L","title":"L  <code>module-attribute</code>","text":"<pre><code>L = Variable('L', 5000.0)\n</code></pre> <p>The length of the beam.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.alpha","title":"alpha  <code>module-attribute</code>","text":"<pre><code>alpha = Variable('alpha', 0.0)\n</code></pre> <p>The angle between \\(-\\vec{e}_z\\) and \\(\\vec{F}\\) in \\(xy\\)-plane.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.b","title":"b  <code>module-attribute</code>","text":"<pre><code>b = Variable('b', 500.0)\n</code></pre> <p>The width of the beam.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.beta","title":"beta  <code>module-attribute</code>","text":"<pre><code>beta = Variable('beta', 0.0)\n</code></pre> <p>The angle between \\(-\\vec{e}_z\\) and \\(\\vec{F}\\) in \\(yz\\)-plane.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.dy","title":"dy  <code>module-attribute</code>","text":"<pre><code>dy = Variable('dy', 0.0)\n</code></pre> <p>The \\(y\\)-coordinate of the point where the force is applied.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.dz","title":"dz  <code>module-attribute</code>","text":"<pre><code>dz = Variable('dz', 0.0)\n</code></pre> <p>The \\(z\\)-coordinate of the point where the force is applied.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.h","title":"h  <code>module-attribute</code>","text":"<pre><code>h = Variable('h', 800.0)\n</code></pre> <p>The height of the beam.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.nu","title":"nu  <code>module-attribute</code>","text":"<pre><code>nu = Variable('nu', 0.33)\n</code></pre> <p>The Poisson's ratio.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.rho","title":"rho  <code>module-attribute</code>","text":"<pre><code>rho = Variable('rho', 2.8e-06)\n</code></pre> <p>The density of the material.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.sigma_all","title":"sigma_all  <code>module-attribute</code>","text":"<pre><code>sigma_all = Variable('sigma_all', 300.0)\n</code></pre> <p>A constant used by the stress constraints.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.t","title":"t  <code>module-attribute</code>","text":"<pre><code>t = Variable('t', 2.5)\n</code></pre> <p>The thickness of the beam.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.Variable","title":"Variable","text":"<p>               Bases: <code>NamedTuple</code></p> <p>A variable of the beam use case.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.Variable-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.Variable.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre> <p>The name of the variable.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.Variable.value","title":"value  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>value: float | None = None\n</code></pre> <p>The default value of the variable.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/","title":"Heat equation","text":""},{"location":"reference/gemseo_umdo/use_cases/heat_equation/#gemseo_umdo.use_cases.heat_equation","title":"heat_equation","text":"<p>The heat equation use case.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/configuration/","title":"Configuration","text":""},{"location":"reference/gemseo_umdo/use_cases/heat_equation/configuration/#gemseo_umdo.use_cases.heat_equation.configuration","title":"configuration","text":"<p>A configuration for the heat equation model.</p> <p>HeatEquationConfiguration is used by HeatEquationModel; read its docstring for more details.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/configuration/#gemseo_umdo.use_cases.heat_equation.configuration-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/use_cases/heat_equation/configuration/#gemseo_umdo.use_cases.heat_equation.configuration.HeatEquationConfiguration","title":"HeatEquationConfiguration  <code>dataclass</code>","text":"<pre><code>HeatEquationConfiguration(\n    mesh_size: int = 100,\n    n_modes: int = 21,\n    final_time: float = 0.5,\n    nu_bounds: tuple[float, float] = (0.001, 0.009),\n    rod_length: float = 1.0,\n)\n</code></pre> <p>A configuration for the heat equation model.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/configuration/#gemseo_umdo.use_cases.heat_equation.configuration.HeatEquationConfiguration-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/use_cases/heat_equation/configuration/#gemseo_umdo.use_cases.heat_equation.configuration.HeatEquationConfiguration.cost","title":"cost  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cost: int = field(init=False)\n</code></pre> <p>The evaluation cost of the HeatEquationModel.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/configuration/#gemseo_umdo.use_cases.heat_equation.configuration.HeatEquationConfiguration.expectation","title":"expectation  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>expectation: float = field(init=False)\n</code></pre> <p>The theoretical expectation of the integral of the temperature along the rod.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/configuration/#gemseo_umdo.use_cases.heat_equation.configuration.HeatEquationConfiguration.final_time","title":"final_time  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>final_time: float = 0.5\n</code></pre> <p>The time of interest, denoted \\(t_f\\).</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/configuration/#gemseo_umdo.use_cases.heat_equation.configuration.HeatEquationConfiguration.mesh","title":"mesh  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>mesh: NDArray[float] = field(init=False)\n</code></pre> <p>The mesh for the HeatEquationModel.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/configuration/#gemseo_umdo.use_cases.heat_equation.configuration.HeatEquationConfiguration.mesh_size","title":"mesh_size  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>mesh_size: int = 100\n</code></pre> <p>The number of equispaced spatial nodes.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/configuration/#gemseo_umdo.use_cases.heat_equation.configuration.HeatEquationConfiguration.n_modes","title":"n_modes  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>n_modes: int = 21\n</code></pre> <p>The number of modes of the truncated Fourier expansion.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/configuration/#gemseo_umdo.use_cases.heat_equation.configuration.HeatEquationConfiguration.nu_bounds","title":"nu_bounds  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>nu_bounds: tuple[float, float] = (0.001, 0.009)\n</code></pre> <p>The bounds of the thermal diffusivity.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/configuration/#gemseo_umdo.use_cases.heat_equation.configuration.HeatEquationConfiguration.rod_length","title":"rod_length  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>rod_length: float = 1.0\n</code></pre> <p>The length of the rod.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/discipline/","title":"Discipline","text":""},{"location":"reference/gemseo_umdo/use_cases/heat_equation/discipline/#gemseo_umdo.use_cases.heat_equation.discipline","title":"discipline","text":"<p>The heat equation discipline.</p> <p>This discipline wraps the HeatEquationModel; read its docstring for more details.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/discipline/#gemseo_umdo.use_cases.heat_equation.discipline-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/use_cases/heat_equation/discipline/#gemseo_umdo.use_cases.heat_equation.discipline.HeatEquation","title":"HeatEquation","text":"<pre><code>HeatEquation(\n    mesh_size: int = 100,\n    n_modes: int = 21,\n    final_time: float = 0.5,\n    nu_bounds: tuple[float, float] = (0.001, 0.009),\n    rod_length: float = 1.0,\n)\n</code></pre> <p>               Bases: <code>MDODiscipline</code></p> <p>The discipline computing the temperature averaged over the rod at final time.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>mesh_size</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>The number of equispaced spatial nodes.</p> </li> <li> <code>n_modes</code>               (<code>int</code>, default:                   <code>21</code> )           \u2013            <p>The number of modes of the truncated Fourier expansion.</p> </li> <li> <code>final_time</code>               (<code>float</code>, default:                   <code>0.5</code> )           \u2013            <p>The time of interest.</p> </li> <li> <code>nu_bounds</code>               (<code>tuple[float, float]</code>, default:                   <code>(0.001, 0.009)</code> )           \u2013            <p>The bounds of the thermal diffusivity.</p> </li> <li> <code>rod_length</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>The length of the rod.</p> </li> </ul> Source code in <code>src/gemseo_umdo/use_cases/heat_equation/discipline.py</code> <pre><code>def __init__(\n    self,\n    mesh_size: int = 100,\n    n_modes: int = 21,\n    final_time: float = 0.5,\n    nu_bounds: tuple[float, float] = (0.001, 0.009),\n    rod_length: float = 1.0,\n) -&gt; None:\n    \"\"\"\n    Args:\n        mesh_size: The number of equispaced spatial nodes.\n        n_modes: The number of modes of the truncated Fourier expansion.\n        final_time: The time of interest.\n        nu_bounds: The bounds of the thermal diffusivity.\n        rod_length: The length of the rod.\n    \"\"\"  # noqa: D205 D212 D415\n    super().__init__(name=f\"{self.__class__.__name__}({mesh_size})\")\n    self.input_grammar.update_from_names([f\"X_{i}\" for i in range(1, 8)])\n    self.output_grammar.update_from_names([\"u\", \"u_mesh\"])\n    self.__heat_equation_model = HeatEquationModel(\n        mesh_size=mesh_size,\n        n_modes=n_modes,\n        final_time=final_time,\n        nu_bounds=nu_bounds,\n        rod_length=rod_length,\n    )\n    self.default_inputs = {\n        \"X_1\": array([0.0]),\n        \"X_2\": array([0.0]),\n        \"X_3\": array([0.0]),\n        \"X_4\": array([0.005]),\n        \"X_5\": array([0.0]),\n        \"X_6\": array([0.0]),\n        \"X_7\": array([0.0]),\n    }\n</code></pre>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/discipline/#gemseo_umdo.use_cases.heat_equation.discipline.HeatEquation-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/use_cases/heat_equation/discipline/#gemseo_umdo.use_cases.heat_equation.discipline.HeatEquation.configuration","title":"configuration  <code>property</code>","text":"<pre><code>configuration: HeatEquationConfiguration\n</code></pre> <p>The configuration.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/model/","title":"Model","text":""},{"location":"reference/gemseo_umdo/use_cases/heat_equation/model/#gemseo_umdo.use_cases.heat_equation.model","title":"model","text":"<p>The heat equation model.</p> <p>This model solves the 1D transient equation, a.k.a. heat equation. It describes the temperature evolution \\(u\\) in a \\(L\\)-length rod from the initial time 0 to the final time \\(T\\) with a thermal diffusivity \\(\\nu(\\mathbf{X})\\) depending on a random vector \\(\\mathbf{X}\\). The heat equation is</p> \\[\\frac{\\partial u(x,t;\\mathbf{X})}{\\partial t}    - \\nu(\\mathbf{X})\\frac{\\partial^2 u(x,t;\\mathbf{X})}{\\partial x^2} = 0\\] <p>with the boundary condition \\(u(0,t;\\mathbf{X})=u(L,t;\\mathbf{X})=0\\) where \\(x\\in\\mathcal{D}=[0,L]\\) and \\(t\\in[0,T]\\).</p> <p>To obtain an analytical solution, Geraci et al. (2015) chose \\(L=1\\) and the uncertain initial condition:</p> \\[u(x,0;\\mathbf{X}) =    \\mathcal{G}(\\mathbf{X})\\mathcal{F}_1(x)    +\\mathcal{I}(\\mathbf{X})\\mathcal{F}_2(x) \\] <p>where</p> <ul> <li>\\(\\mathcal{F}_1(x)=\\sin(\\pi x)\\),</li> <li>\\(\\mathcal{F}_2(x)=\\sin(2\\pi x)+\\sin(3\\pi x)           +50\\left(\\sin(9\\pi x)+\\sin(21\\pi x)\\right)\\),</li> <li>\\(\\mathcal{I}(\\mathbf{X})=3.5          \\left(\\sin(X_1)+7\\sin^2(X_2)+0.1X_3^4\\sin(X_1)\\right)\\),</li> <li>\\(\\mathcal{G}(\\mathbf{X})=50\\prod_{i=5}^7(4|X_i|-1)\\).</li> </ul> <p>This uncertainty on the initial condition is modelled by the random variables \\(X_1,\\ldots X_7\\) that are independent and distributed as:</p> <ul> <li>\\(X_i\\sim\\mathcal{U}(-\\pi,\\pi)\\), for \\(i\\in\\{1,2,3\\}\\),</li> <li>\\(\\nu(\\mathbf{X})=X_4\\sim\\mathcal{U}(\\nu_{\\min},\\nu_{\\max})\\),</li> <li>\\(X_i\\sim\\mathcal{U}(-1,1)\\), for \\(i\\in\\{5,6,7\\}\\).</li> </ul> <p>Then, Geraci et al. (2015) consider the integral of the temperature along the rod</p> \\[\\mathcal{M}(\\mathbf{X}) = \\int_{\\mathcal{D}}u(x,T;\\mathbf{X})dx\\] <p>and are interested in the estimation of its HeatEquationConfiguration:</p> \\[\\mathbb{E}[\\mathcal{M}(\\mathbf{X})] = 50H_1+\\frac{49}{4}(H_3+50H_9+50H_{21})\\] <p>where \\(H_k=\\frac{2}{k^3\\pi^3T} \\frac{\\exp(-\\nu_{\\min}k^2\\pi^2T)-\\exp(-\\nu_{\\max}k^2\\pi^2T)}{\\nu_{\\max}-\\nu_{\\min}}\\).</p> <p>The HeatEquationModel computes the temperature at final time from instances of the random variables <code>\"X_1\"</code>, ..., <code>\"X_7\"</code> defined over the HeatEquationUncertainSpace. The temperature <code>\"u_mesh\"</code> is computed at each mesh node while the temperature <code>\"u\"</code> is an integral over the rod.</p> See Also <p>Geraci et al., A multifidelity control variate approach for the multilevel Monte Carlo technique, Center for Turbulence Research, Annual Research Briefs, 2015.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/model/#gemseo_umdo.use_cases.heat_equation.model-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/use_cases/heat_equation/model/#gemseo_umdo.use_cases.heat_equation.model.HeatEquationModel","title":"HeatEquationModel","text":"<pre><code>HeatEquationModel(\n    mesh_size: int = 100,\n    n_modes: int = 21,\n    final_time: float = 0.5,\n    nu_bounds: tuple[float, float] = (0.001, 0.009),\n    rod_length: float = 1.0,\n)\n</code></pre> <p>The discipline computing the temperature averaged over the rod at final time.</p> <p>This discipline can also compute a first-order polynomial centered at the mean input value.</p> <p>Parameters:</p> <ul> <li> <code>mesh_size</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>The number of equispaced spatial nodes.</p> </li> <li> <code>n_modes</code>               (<code>int</code>, default:                   <code>21</code> )           \u2013            <p>The number of modes of the truncated Fourier expansion.</p> </li> <li> <code>final_time</code>               (<code>float</code>, default:                   <code>0.5</code> )           \u2013            <p>The time of interest.</p> </li> <li> <code>nu_bounds</code>               (<code>tuple[float, float]</code>, default:                   <code>(0.001, 0.009)</code> )           \u2013            <p>The bounds of the thermal diffusivity.</p> </li> <li> <code>rod_length</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>The length of the rod.</p> </li> </ul> Source code in <code>src/gemseo_umdo/use_cases/heat_equation/model.py</code> <pre><code>def __init__(\n    self,\n    mesh_size: int = 100,\n    n_modes: int = 21,\n    final_time: float = 0.5,\n    nu_bounds: tuple[float, float] = (0.001, 0.009),\n    rod_length: float = 1.0,\n) -&gt; None:\n    \"\"\"\n    Args:\n        mesh_size: The number of equispaced spatial nodes.\n        n_modes: The number of modes of the truncated Fourier expansion.\n        final_time: The time of interest.\n        nu_bounds: The bounds of the thermal diffusivity.\n        rod_length: The length of the rod.\n    \"\"\"  # noqa: D205 D212 D415\n    self.configuration = HeatEquationConfiguration(\n        mesh_size, n_modes, final_time, nu_bounds, rod_length\n    )\n    self.__nu_delta = nu_bounds[1] - nu_bounds[0]\n    self.__modes = linspace(1, n_modes, n_modes)\n    xx, nn = meshgrid(self.configuration.mesh, self.__modes, copy=False)\n    self.__sinus = sin(xx * nn * pi)[:, :, newaxis]\n    self.__default_input_value = array([0.0, 0.0, 0.0, 0.005, 0.0, 0.0, 0.0])\n    pi_mesh = pi * self.configuration.mesh\n    self.__F1 = sin(pi_mesh)  # noqa: N806\n    self.__F2 = (  # noqa: N806\n        sin(2 * pi_mesh)\n        + sin(3 * pi_mesh)\n        + 50 * (sin(9 * pi_mesh) + sin(21 * pi_mesh))\n    )\n    self.__term1 = self.__term2 = self.__term3 = self.__f_at_mu_X = 0\n    self.__compute_taylor_materials()\n    self.taylor_mean = self.__f_at_mu_X + 600 * self.__term1\n</code></pre>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/model/#gemseo_umdo.use_cases.heat_equation.model.HeatEquationModel-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/use_cases/heat_equation/model/#gemseo_umdo.use_cases.heat_equation.model.HeatEquationModel.configuration","title":"configuration  <code>instance-attribute</code>","text":"<pre><code>configuration: HeatEquationConfiguration = (\n    HeatEquationConfiguration(\n        mesh_size,\n        n_modes,\n        final_time,\n        nu_bounds,\n        rod_length,\n    )\n)\n</code></pre> <p>The configuration of the heat equation problem.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/model/#gemseo_umdo.use_cases.heat_equation.model.HeatEquationModel.taylor_mean","title":"taylor_mean  <code>instance-attribute</code>","text":"<pre><code>taylor_mean: float = __f_at_mu_X + 600 * __term1\n</code></pre> <p>The expectation of the output of the first-order Taylor polynomial.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/model/#gemseo_umdo.use_cases.heat_equation.model.HeatEquationModel-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/use_cases/heat_equation/model/#gemseo_umdo.use_cases.heat_equation.model.HeatEquationModel.compute_taylor","title":"compute_taylor","text":"<pre><code>compute_taylor(\n    input_samples: NDArray[float],\n) -&gt; NDArray[float]\n</code></pre> <p>Evaluate the first-order Taylor polynomial.</p> <p>Parameters:</p> <ul> <li> <code>input_samples</code>               (<code>NDArray[float]</code>)           \u2013            <p>The input samples shaped as <code>(sample_size, input_dimension)</code> or <code>(input_dimension, )</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray[float]</code>           \u2013            <p>The output samples of the first-order Taylor polynomial shaped as <code>(sample_size, n_nodes)</code> or <code>(n_nodes, )</code>.</p> </li> </ul> Source code in <code>src/gemseo_umdo/use_cases/heat_equation/model.py</code> <pre><code>def compute_taylor(self, input_samples: NDArray[float]) -&gt; NDArray[float]:\n    \"\"\"Evaluate the first-order Taylor polynomial.\n\n    Args:\n        input_samples: The input samples\n            shaped as `(sample_size, input_dimension)` or `(input_dimension, )`.\n\n    Returns:\n        The output samples of the first-order Taylor polynomial\n        shaped as `(sample_size, n_nodes)` or `(n_nodes, )`.\n    \"\"\"\n    X = input_samples  # noqa: N806\n    mu_X = self.__default_input_value  # noqa: N806\n    return self.__f_at_mu_X + (\n        7 * X[..., [0]] * self.__term2\n        - (X[..., [3]] - mu_X[3]) * pi**2 * 0.5 * self.__term3\n        + 400\n        * self.__term1\n        * (abs(X[..., [4]]) + abs(X[..., [5]]) + abs(X[..., [6]]))\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/uncertain_space/","title":"Uncertain space","text":""},{"location":"reference/gemseo_umdo/use_cases/heat_equation/uncertain_space/#gemseo_umdo.use_cases.heat_equation.uncertain_space","title":"uncertain_space","text":"<p>The uncertain space to be used with the heat equation discipline.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/uncertain_space/#gemseo_umdo.use_cases.heat_equation.uncertain_space-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/use_cases/heat_equation/uncertain_space/#gemseo_umdo.use_cases.heat_equation.uncertain_space.HeatEquationUncertainSpace","title":"HeatEquationUncertainSpace","text":"<pre><code>HeatEquationUncertainSpace(\n    nu_bounds: tuple[float, float] = (0.001, 0.009)\n)\n</code></pre> <p>               Bases: <code>ParameterSpace</code></p> <p>The uncertain space to be used with the heat equation discipline.</p> <p>Parameters:</p> <ul> <li> <code>nu_bounds</code>               (<code>tuple[float, float]</code>, default:                   <code>(0.001, 0.009)</code> )           \u2013            <p>The lower and upper bounds of the thermal diffusivity \\(\\nu\\).</p> </li> </ul> Source code in <code>src/gemseo_umdo/use_cases/heat_equation/uncertain_space.py</code> <pre><code>def __init__(self, nu_bounds: tuple[float, float] = (0.001, 0.009)) -&gt; None:\n    r\"\"\"\n    Args:\n        nu_bounds: The lower and upper bounds\n            of the thermal diffusivity $\\nu$.\n    \"\"\"  # noqa: D205 D212 D415\n    distribution_name = \"OTUniformDistribution\"\n    super().__init__()\n    self.add_random_variable(\"X_1\", distribution_name, minimum=-pi, maximum=pi)\n    self.add_random_variable(\"X_2\", distribution_name, minimum=-pi, maximum=pi)\n    self.add_random_variable(\"X_3\", distribution_name, minimum=-pi, maximum=pi)\n    self.add_random_variable(\n        \"X_4\", distribution_name, minimum=nu_bounds[0], maximum=nu_bounds[1]\n    )\n    self.add_random_variable(\"X_5\", distribution_name, minimum=-1.0, maximum=1.0)\n    self.add_random_variable(\"X_6\", distribution_name, minimum=-1.0, maximum=1.0)\n    self.add_random_variable(\"X_7\", distribution_name, minimum=-1.0, maximum=1.0)\n</code></pre>"},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/","title":"Spring mass model","text":""},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/#gemseo_umdo.use_cases.spring_mass_model","title":"spring_mass_model","text":"<p>The spring-mass system under uncertainty.</p>"},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/discipline/","title":"Discipline","text":""},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/discipline/#gemseo_umdo.use_cases.spring_mass_model.discipline","title":"discipline","text":"<p>The spring-mass model use case.</p>"},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/discipline/#gemseo_umdo.use_cases.spring_mass_model.discipline-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/discipline/#gemseo_umdo.use_cases.spring_mass_model.discipline.SpringMassDiscipline","title":"SpringMassDiscipline","text":"<pre><code>SpringMassDiscipline(\n    mass: float = 1.5,\n    initial_state: tuple[float, float] = (0, 0),\n    initial_time: float = 0.0,\n    final_time: float = 10.0,\n    time_step: float = 0.1,\n    gravity: float = 9.8,\n)\n</code></pre> <p>               Bases: <code>MDODiscipline</code></p> <p>The GEMSEO-based spring-mass model \\(m\\frac{d^2z(t)}{dt^2} = -kz(t) + mg\\).</p> <p>This model computes the time displacement of an object attached to a spring in function of the stiffness of the spring.</p> <p>It computes also its maximum displacement.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>mass</code>               (<code>float</code>, default:                   <code>1.5</code> )           \u2013            <p>The mass of the object.</p> </li> <li> <code>initial_state</code>               (<code>tuple[float, float]</code>, default:                   <code>(0, 0)</code> )           \u2013            <p>The initial position and velocity of the object.</p> </li> <li> <code>initial_time</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>The initial time.</p> </li> <li> <code>final_time</code>               (<code>float</code>, default:                   <code>10.0</code> )           \u2013            <p>The final time.</p> </li> <li> <code>time_step</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>The time step.</p> </li> <li> <code>gravity</code>               (<code>float</code>, default:                   <code>9.8</code> )           \u2013            <p>The gravity acceleration.</p> </li> </ul> Source code in <code>src/gemseo_umdo/use_cases/spring_mass_model/discipline.py</code> <pre><code>def __init__(\n    self,\n    mass: float = 1.5,\n    initial_state: tuple[float, float] = (0, 0),\n    initial_time: float = 0.0,\n    final_time: float = 10.0,\n    time_step: float = 0.1,\n    gravity: float = 9.8,\n) -&gt; None:\n    \"\"\"\n    Args:\n        mass: The mass of the object.\n        initial_state: The initial position and velocity of the object.\n        initial_time: The initial time.\n        final_time: The final time.\n        time_step: The time step.\n        gravity: The gravity acceleration.\n    \"\"\"  # noqa: D205 D212 D415\n    super().__init__(name=f\"{self.__class__.__name__}({time_step})\")\n    self.input_grammar.update_from_names([self.__STIFFNESS])\n    self.output_grammar.update_from_names([\n        self.__MAX_DISPLACEMENT,\n        self.__DISPLACEMENT,\n    ])\n    self.__model = SpringMassModel(\n        mass=mass,\n        initial_state=initial_state,\n        initial_time=initial_time,\n        final_time=final_time,\n        time_step=time_step,\n        gravity=gravity,\n    )\n    self.default_inputs = {self.__STIFFNESS: array([2.25])}\n</code></pre>"},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/discipline/#gemseo_umdo.use_cases.spring_mass_model.discipline.SpringMassDiscipline-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/discipline/#gemseo_umdo.use_cases.spring_mass_model.discipline.SpringMassDiscipline.cost","title":"cost  <code>property</code>","text":"<pre><code>cost: float\n</code></pre> <p>The evaluation cost.</p>"},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/model/","title":"Model","text":""},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/model/#gemseo_umdo.use_cases.spring_mass_model.model","title":"model","text":"<p>The GEMSEO-free spring-mass model.</p>"},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/model/#gemseo_umdo.use_cases.spring_mass_model.model-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/model/#gemseo_umdo.use_cases.spring_mass_model.model.SpringMassModel","title":"SpringMassModel","text":"<pre><code>SpringMassModel(\n    mass: float = 1.5,\n    initial_state: tuple[float, float] = (0, 0),\n    initial_time: float = 0.0,\n    final_time: float = 10.0,\n    time_step: float = 0.1,\n    gravity: float = 9.8,\n)\n</code></pre> <p>The GEMSEO-free spring-mass model.</p> <p>This model computes the time displacement of an object attached to a spring in function of the stiffness of the spring.</p> <p>It computes also its maximum displacement.</p> <p>The ordinary differential equation is</p> \\[m\\frac{d^2z(t)}{dt^2} = -kz(t) + mg\\] <p>with \\(\\left.\\frac{dz(t)}{dt}\\right|_{t=0}=z(0)=z_0\\).</p> <p>Parameters:</p> <ul> <li> <code>mass</code>               (<code>float</code>, default:                   <code>1.5</code> )           \u2013            <p>The mass of the object.</p> </li> <li> <code>initial_state</code>               (<code>tuple[float, float]</code>, default:                   <code>(0, 0)</code> )           \u2013            <p>The initial position and velocity of the object.</p> </li> <li> <code>initial_time</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>The initial time.</p> </li> <li> <code>final_time</code>               (<code>float</code>, default:                   <code>10.0</code> )           \u2013            <p>The final time.</p> </li> <li> <code>time_step</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>The time step.</p> </li> <li> <code>gravity</code>               (<code>float</code>, default:                   <code>9.8</code> )           \u2013            <p>The gravity acceleration.</p> </li> </ul> Source code in <code>src/gemseo_umdo/use_cases/spring_mass_model/model.py</code> <pre><code>def __init__(\n    self,\n    mass: float = 1.5,\n    initial_state: tuple[float, float] = (0, 0),\n    initial_time: float = 0.0,\n    final_time: float = 10.0,\n    time_step: float = 0.1,\n    gravity: float = 9.8,\n) -&gt; None:\n    \"\"\"\n    Args:\n        mass: The mass of the object.\n        initial_state: The initial position and velocity of the object.\n        initial_time: The initial time.\n        final_time: The final time.\n        time_step: The time step.\n        gravity: The gravity acceleration.\n    \"\"\"  # noqa: D205 D212 D415\n    self.__mass = mass\n    self.__gravity = gravity\n    self.__initial_state = initial_state\n    self.__time = arange(initial_time, final_time, time_step)\n    self.__cost = 1.0 / time_step\n</code></pre>"},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/model/#gemseo_umdo.use_cases.spring_mass_model.model.SpringMassModel-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/model/#gemseo_umdo.use_cases.spring_mass_model.model.SpringMassModel.cost","title":"cost  <code>property</code>","text":"<pre><code>cost: float\n</code></pre> <p>The evaluation cost.</p>"},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/uncertain_space/","title":"Uncertain space","text":""},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/uncertain_space/#gemseo_umdo.use_cases.spring_mass_model.uncertain_space","title":"uncertain_space","text":"<p>The space of the uncertain variables of the spring-mass system.</p>"},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/uncertain_space/#gemseo_umdo.use_cases.spring_mass_model.uncertain_space-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/uncertain_space/#gemseo_umdo.use_cases.spring_mass_model.uncertain_space.SpringMassUncertainSpace","title":"SpringMassUncertainSpace","text":"<pre><code>SpringMassUncertainSpace()\n</code></pre> <p>               Bases: <code>ParameterSpace</code></p> <p>The space of the uncertain variables of the spring-mass system.</p> Source code in <code>src/gemseo_umdo/use_cases/spring_mass_model/uncertain_space.py</code> <pre><code>def __init__(self) -&gt; None:  # noqa: D107\n    super().__init__()\n    self.add_random_variable(\n        \"stiffness\",\n        \"OTDistribution\",\n        interfaced_distribution=\"Beta\",\n        interfaced_distribution_parameters=(3.0, 2.0, 1.0, 3.5),\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/visualizations/","title":"Visualizations","text":""},{"location":"reference/gemseo_umdo/visualizations/#gemseo_umdo.visualizations","title":"visualizations","text":"<p>Data visualization.</p>"},{"location":"reference/gemseo_umdo/visualizations/sobol_graph/","title":"Sobol graph","text":""},{"location":"reference/gemseo_umdo/visualizations/sobol_graph/#gemseo_umdo.visualizations.sobol_graph","title":"sobol_graph","text":"<p>A network of uncertain variables representing their Sobol' indices.</p>"},{"location":"reference/gemseo_umdo/visualizations/sobol_graph/#gemseo_umdo.visualizations.sobol_graph-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/visualizations/sobol_graph/#gemseo_umdo.visualizations.sobol_graph.SobolGraph","title":"SobolGraph","text":"<pre><code>SobolGraph(\n    first_order_indices: Mapping[str, float],\n    total_order_indices: Mapping[str, float],\n    second_order_indices: Mapping[tuple[str, str], float],\n    threshold: float = 0.1,\n    maximum_thickness: float = 10.0,\n)\n</code></pre> <p>               Bases: <code>GraphView</code></p> <p>A network of uncertain variables representing their Sobol' indices.</p> <p>A node represents an uncertain variable whose name is written inside, followed by its first-order and total-order Sobol' indices.</p> <p>The thickness of a node is proportional to the total-order Sobol' index of the variable while the thickness of an edge is proportional to the second-order Sobol' index of the corresponding pair of variables.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>first_order_indices</code>               (<code>Mapping[str, float]</code>)           \u2013            <p>The first-order Sobol' indices of the scalar inputs, shaped as <code>{name: index}</code>.</p> </li> <li> <code>total_order_indices</code>               (<code>Mapping[str, float]</code>)           \u2013            <p>The total-order Sobol' indices of the scalar inputs, shaped as <code>{name: index}</code>.</p> </li> <li> <code>second_order_indices</code>               (<code>Mapping[tuple[str, str], float]</code>)           \u2013            <p>The second-order Sobol' indices of the scalar inputs, shaped as <code>{(name, other_name): index}</code>.</p> </li> <li> <code>threshold</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>The sensitivity threshold above which a second-order index is significant and the corresponding edge plotted.</p> </li> <li> <code>maximum_thickness</code>               (<code>float</code>, default:                   <code>10.0</code> )           \u2013            <p>The maximum thickness of a line.</p> </li> </ul> Source code in <code>src/gemseo_umdo/visualizations/sobol_graph.py</code> <pre><code>def __init__(\n    self,\n    first_order_indices: Mapping[str, float],\n    total_order_indices: Mapping[str, float],\n    second_order_indices: Mapping[tuple[str, str], float],\n    threshold: float = 0.1,\n    maximum_thickness: float = 10.0,\n) -&gt; None:\n    \"\"\"\n    Args:\n        first_order_indices: The first-order Sobol' indices of the scalar inputs,\n            shaped as `{name: index}`.\n        second_order_indices:  The second-order Sobol' indices of the scalar inputs,\n            shaped as `{(name, other_name): index}`.\n        total_order_indices: The total-order Sobol' indices of the scalar inputs,\n            shaped as `{name: index}`.\n        threshold: The sensitivity threshold\n            above which a second-order index is significant\n            and the corresponding edge plotted.\n        maximum_thickness: The maximum thickness of a line.\n    \"\"\"  # noqa: D205 D212 D415\n    super().__init__(False)\n    variables_to_nodes = {}\n\n    # Add the nodes representing both first- and total-order indices.\n    for name, total_order_index in total_order_indices.items():\n        first_order_index = first_order_indices[name]\n        node_name = (\n            f\"{name}\\n\"\n            f\"({round(total_order_index * 100)}, {round(first_order_index * 100)})\"\n        )\n        variables_to_nodes[name] = node_name\n        self.node(\n            node_name,\n            penwidth=str(total_order_index * maximum_thickness),\n        )\n\n    # Add the edges representing the second-order indices.\n    for (name, other_name), index in second_order_indices.items():\n        if index &gt;= threshold:\n            self.edge(\n                variables_to_nodes[name],\n                variables_to_nodes[other_name],\n                penwidth=str(index * maximum_thickness),\n            )\n</code></pre>"},{"location":"reference/gemseo_umdo/visualizations/sobol_graph/#gemseo_umdo.visualizations.sobol_graph.SobolGraph-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/visualizations/sobol_graph/#gemseo_umdo.visualizations.sobol_graph.SobolGraph.DEFAULT_FILE_PATH","title":"DEFAULT_FILE_PATH  <code>class-attribute</code>","text":"<pre><code>DEFAULT_FILE_PATH: str | Path = 'sobol_graph.png'\n</code></pre> <p>The default file path to save the graph.</p>"},{"location":"reference/gemseo_umdo/visualizations/sobol_graph/#gemseo_umdo.visualizations.sobol_graph.SobolGraph.threshold","title":"threshold  <code>instance-attribute</code>","text":"<pre><code>threshold: float\n</code></pre> <p>The threshold above which an edge is significant.</p>"},{"location":"reference/gemseo_umdo/visualizations/sobol_graph/#gemseo_umdo.visualizations.sobol_graph.SobolGraph-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/visualizations/sobol_graph/#gemseo_umdo.visualizations.sobol_graph.SobolGraph.from_analysis","title":"from_analysis  <code>classmethod</code>","text":"<pre><code>from_analysis(\n    analysis: SobolAnalysis,\n    output_name: str,\n    output_component: int = 0,\n) -&gt; SobolGraph\n</code></pre> <p>Create the Sobol' graph from a Sobol' analysis.</p> <p>Parameters:</p> <ul> <li> <code>analysis</code>               (<code>SobolAnalysis</code>)           \u2013            <p>A Sobol' analysis.</p> </li> <li> <code>output_name</code>               (<code>str</code>)           \u2013            <p>The name of the output.</p> </li> <li> <code>output_component</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The component of the output.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>SobolGraph</code>           \u2013            <p>The Sobol' graph associated with this Sobol' analysis.</p> </li> </ul> Source code in <code>src/gemseo_umdo/visualizations/sobol_graph.py</code> <pre><code>@classmethod\ndef from_analysis(\n    cls, analysis: SobolAnalysis, output_name: str, output_component: int = 0\n) -&gt; SobolGraph:\n    \"\"\"Create the Sobol' graph from a Sobol' analysis.\n\n    Args:\n        analysis: A Sobol' analysis.\n        output_name: The name of the output.\n        output_component: The component of the output.\n\n    Returns:\n        The Sobol' graph associated with this Sobol' analysis.\n    \"\"\"\n    return cls(\n        cls.__preprocess(\n            analysis.first_order_indices[output_name][output_component]\n        ),\n        second_order_indices=cls.__preprocess_second_order(\n            analysis.second_order_indices[output_name][output_component]\n        ),\n        total_order_indices=cls.__preprocess(\n            analysis.total_order_indices[output_name][output_component]\n        ),\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/visualizations/uncertain_coupling_graph/","title":"Uncertain coupling graph","text":""},{"location":"reference/gemseo_umdo/visualizations/uncertain_coupling_graph/#gemseo_umdo.visualizations.uncertain_coupling_graph","title":"uncertain_coupling_graph","text":"<p>An uncertain coupling graph.</p>"},{"location":"reference/gemseo_umdo/visualizations/uncertain_coupling_graph/#gemseo_umdo.visualizations.uncertain_coupling_graph-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/visualizations/uncertain_coupling_graph/#gemseo_umdo.visualizations.uncertain_coupling_graph.UncertainCouplingGraph","title":"UncertainCouplingGraph","text":"<pre><code>UncertainCouplingGraph(\n    disciplines: Sequence[MDODiscipline],\n    uncertain_space: ParameterSpace,\n    variable_names: Iterable[str] | None = None,\n)\n</code></pre> <p>An uncertain coupling graph.</p> <p>A coupling graph whose disciplines are represented by nodes and coupling variables by edges whose thickness is proportional to its dispersion.</p> <p>The dispersion is computed using a DispersionMeasure such as the coefficient of variation (CV) or the quartile coefficient of dispersion (QCD).</p> <p>To be used as:</p> <ol> <li>Instantiate an    UncertainCouplingGraph.</li> <li>Sample the multidisciplinary system, using    sample().</li> <li>Generate the coupling graph for a given dispersion measure, using    visualize().</li> </ol> <p>If you want to change the dispersion measure or filter the variables, repeat Step 3 with another dispersion measure or a list of variable names.</p> <p>If you want to improve the estimations of the statistics, repeat Step 2 with additional evaluations and Step 3.</p> <p>Parameters:</p> <ul> <li> <code>disciplines</code>               (<code>Sequence[MDODiscipline]</code>)           \u2013            <p>The coupled disciplines.</p> </li> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The space of the uncertain variables.</p> </li> <li> <code>variable_names</code>               (<code>Iterable[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>The names of the coupling variables of interest. If <code>None</code>, use all the coupling variables.</p> </li> </ul> Source code in <code>src/gemseo_umdo/visualizations/uncertain_coupling_graph.py</code> <pre><code>def __init__(\n    self,\n    disciplines: Sequence[MDODiscipline],\n    uncertain_space: ParameterSpace,\n    variable_names: Iterable[str] | None = None,\n) -&gt; None:\n    \"\"\"\n    Args:\n        disciplines: The coupled disciplines.\n        uncertain_space: The space of the uncertain variables.\n        variable_names: The names of the coupling variables of interest.\n            If `None`, use all the coupling variables.\n    \"\"\"  # noqa: D205 D212 D415\n    if variable_names is None:\n        self.__output_names = get_all_outputs(disciplines)\n    else:\n        self.__output_names = variable_names\n\n    self.__scenario = DOEScenario(\n        disciplines, \"MDF\", self.__output_names[0], uncertain_space\n    )\n    for output_name in self.__output_names:\n        self.__scenario.add_observable(output_name)\n</code></pre>"},{"location":"reference/gemseo_umdo/visualizations/uncertain_coupling_graph/#gemseo_umdo.visualizations.uncertain_coupling_graph.UncertainCouplingGraph-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/visualizations/uncertain_coupling_graph/#gemseo_umdo.visualizations.uncertain_coupling_graph.UncertainCouplingGraph.DispersionMeasure","title":"DispersionMeasure","text":"<p>               Bases: <code>StrEnum</code></p> <p>A dispersion measure.</p>"},{"location":"reference/gemseo_umdo/visualizations/uncertain_coupling_graph/#gemseo_umdo.visualizations.uncertain_coupling_graph.UncertainCouplingGraph-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/visualizations/uncertain_coupling_graph/#gemseo_umdo.visualizations.uncertain_coupling_graph.UncertainCouplingGraph.sample","title":"sample","text":"<pre><code>sample(\n    n_samples: int,\n    algo_name: str = \"OT_OPT_LHS\",\n    **algo_options: Any\n) -&gt; None\n</code></pre> <p>Sample the multidisciplinary system.</p> <p>Parameters:</p> <ul> <li> <code>n_samples</code>               (<code>int</code>)           \u2013            <p>The number of evaluations of the multidisciplinary system.</p> </li> <li> <code>algo_name</code>               (<code>str</code>, default:                   <code>'OT_OPT_LHS'</code> )           \u2013            <p>The name of the DOE algorithm.</p> </li> <li> <code>**algo_options</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The options of the DOE algorithm.</p> </li> </ul> Source code in <code>src/gemseo_umdo/visualizations/uncertain_coupling_graph.py</code> <pre><code>def sample(\n    self, n_samples: int, algo_name: str = \"OT_OPT_LHS\", **algo_options: Any\n) -&gt; None:\n    \"\"\"Sample the multidisciplinary system.\n\n    Args:\n        n_samples: The number of evaluations of the multidisciplinary system.\n        algo_name: The name of the DOE algorithm.\n        **algo_options: The options of the DOE algorithm.\n    \"\"\"\n    self.__scenario.execute({\n        \"algo\": algo_name,\n        \"n_samples\": n_samples,\n        \"algo_options\": algo_options,\n    })\n</code></pre>"},{"location":"reference/gemseo_umdo/visualizations/uncertain_coupling_graph/#gemseo_umdo.visualizations.uncertain_coupling_graph.UncertainCouplingGraph.visualize","title":"visualize","text":"<pre><code>visualize(\n    maximum_thickness: int = 30,\n    dispersion_measure: DispersionMeasure = DispersionMeasure.QCD,\n    variable_names: Iterable[str] | None = None,\n    show: bool = True,\n    save: bool = True,\n    file_path: str | Path = \"\",\n    clean_up: bool = True,\n) -&gt; GraphView\n</code></pre> <p>Generate the uncertain coupling graph.</p> <p>Parameters:</p> <ul> <li> <code>maximum_thickness</code>               (<code>int</code>, default:                   <code>30</code> )           \u2013            <p>The maximum thickness of a line.</p> </li> <li> <code>dispersion_measure</code>               (<code>DispersionMeasure</code>, default:                   <code>QCD</code> )           \u2013            <p>A standardized measure of dispersion.</p> </li> <li> <code>variable_names</code>               (<code>Iterable[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>The names of the coupling variables of interest. If <code>None</code>, use all the coupling variables of interest defined at instantiation.</p> </li> <li> <code>show</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to display the graph with the default application associated to the file extension.</p> </li> <li> <code>save</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to save the graph on the disk.</p> </li> <li> <code>file_path</code>               (<code>str | Path</code>, default:                   <code>''</code> )           \u2013            <p>The file path with extension to save the graph. If <code>\"\"</code>, use the class name with PNG format.</p> </li> <li> <code>clean_up</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to remove the source files.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>GraphView</code>           \u2013            <p>The view of the uncertain coupling graph.</p> </li> </ul> Source code in <code>src/gemseo_umdo/visualizations/uncertain_coupling_graph.py</code> <pre><code>def visualize(\n    self,\n    maximum_thickness: int = 30,\n    dispersion_measure: DispersionMeasure = DispersionMeasure.QCD,\n    variable_names: Iterable[str] | None = None,\n    show: bool = True,\n    save: bool = True,\n    file_path: str | Path = \"\",\n    clean_up: bool = True,\n) -&gt; GraphView:\n    \"\"\"Generate the uncertain coupling graph.\n\n    Args:\n        maximum_thickness: The maximum thickness of a line.\n        dispersion_measure: A standardized measure of dispersion.\n        variable_names: The names of the coupling variables of interest.\n            If `None`,\n            use all the coupling variables of interest defined at instantiation.\n        show: Whether to display the graph\n            with the default application associated to the file extension.\n        save: Whether to save the graph on the disk.\n        file_path: The file path with extension to save the graph.\n            If `\"\"`, use the class name with PNG format.\n        clean_up: Whether to remove the source files.\n\n    Returns:\n        The view of the uncertain coupling graph.\n    \"\"\"\n    if variable_names is None:\n        all_output_names = self.__output_names\n    else:\n        all_output_names = variable_names\n\n    database = self.__scenario.formulation.optimization_problem.database\n    output_names_to_measures = {\n        output_name: self.__DISP_MEAS_TO_FUNCTION[dispersion_measure](\n            database.get_function_history(output_name)\n        )\n        for output_name in self.__output_names\n    }\n    dependency_graph = DependencyGraph(self.__scenario.disciplines).graph\n    graph_view = GraphView()\n    for discipline in self.__scenario.disciplines:\n        graph_view.node(discipline.name)\n\n    for head_disc, tail_disc, coupling_names in dependency_graph.edges(data=\"io\"):\n        variable_names = set(coupling_names).intersection(set(all_output_names))\n        for coupling_name in variable_names:\n            disp_meas = atleast_1d(output_names_to_measures[coupling_name])\n            coupling_size = disp_meas.size\n            for i in range(coupling_size):\n                graph_view.edge(\n                    head_disc.name,\n                    tail_disc.name,\n                    label=repr_variable(coupling_name, i, coupling_size),\n                    penwidth=str(round(abs(disp_meas[i] * maximum_thickness), 2)),\n                )\n\n    for discipline in dependency_graph.nodes:\n        coupling_names = set(discipline.get_input_data_names()).intersection(\n            discipline.get_output_data_names()\n        )\n        discipline_name = discipline.name\n        variable_names = set(coupling_names).intersection(set(all_output_names))\n        for coupling_name in variable_names:\n            disp_meas = atleast_1d(output_names_to_measures[coupling_name])\n            coupling_size = disp_meas.size\n            for i in range(coupling_size):\n                graph_view.edge(\n                    discipline_name,\n                    discipline_name,\n                    label=repr_variable(coupling_name, i, coupling_size),\n                    penwidth=str(round(abs(disp_meas[i] * maximum_thickness), 2)),\n                )\n\n    if save:\n        graph_view.visualize(show=show, file_path=file_path, clean_up=clean_up)\n\n    return graph_view\n</code></pre>"},{"location":"user_guide/statistics/","title":"Introduction","text":""},{"location":"user_guide/statistics/#statistics","title":"Statistics","text":""},{"location":"user_guide/statistics/multilevel/","title":"Multilevel Monte Carlo","text":""},{"location":"user_guide/statistics/multilevel/#multilevel-monte-carlo","title":"Multilevel Monte Carlo","text":"<p>A classical problem consists of estimating a statistic \\(\\theta\\) of the output of a simulator \\(f\\) whose input \\(\\mathbf{X}\\) is random: that is, a statistic \\(\\theta\\) of \\(Y=f(\\mathbf{X})\\).</p>"},{"location":"user_guide/statistics/multilevel/#multilevel-monte-carlo-methods","title":"Multilevel Monte Carlo methods","text":"<p>Crude Monte Carlo (MC) is the most standard method to estimate it. For instance, given a sample \\(\\left(\\mathbf{X}^{(1)},\\ldots,\\mathbf{X}^{(N)}\\right)\\) made of independent random variables distributed as \\(\\mathbf{X}\\), \\(\\frac{1}{N}\\sum_{i=1}^Nf(\\mathbf{X}^{(i)})\\) is an unbiased MC estimator of the expectation of \\(Y\\) whose variance is \\(\\mathcal{O}(N^{-1})\\). (N.B. by unbiasedness, the variance of the MC estimator equals its mean squared error.)</p> <p>In presence of a sequence of simulators \\((f_\\ell)_{\\ell = 0}^L\\) with increasing accuracy and computational cost, such that \\(f_L = f\\), multilevel Monte Carlo (MLMC) methods<sup>1</sup> can be relevant to reduce the variance of the MC estimator. The MLMC methods use all these models to estimate the statistic \\(\\theta_L\\) (a.k.a. \\(\\theta\\)) of the random output variable \\(f_L(\\mathbf{X})\\).</p> <p>We denote by \\(Y_\\ell=f_\\ell(\\mathbf{X})\\) the random output variable associated with the model level \\(f_\\ell\\) and by \\((\\theta_1,\\ldots,\\theta_L)\\) the sequence of statistics increasingly close to \\(\\theta_L\\), where \\(\\theta_\\ell\\) is the statistic of \\(Y_\\ell\\). Then, the statistical measure \\(\\theta_L\\) can be expressed as a telescoping sum \\(\\theta_L = \\sum \\limits_{\\ell = 0}^{L} T_\\ell\\), where \\(T_\\ell = \\theta_\\ell - \\theta_{\\ell-1}\\), and by convention \\(\\theta_{-1} = 0\\). Let \\(\\hat{\\theta}_{\\ell,n_\\ell}^{\\mathrm{MC},(\\ell)}\\) and \\(\\hat{\\theta}_{\\ell-1,n_\\ell}^{\\mathrm{MC},(\\ell)}\\) be respectively the Monte Carlo (MC) estimators of \\(\\theta_\\ell\\) and \\(\\theta_{\\ell-1}\\) using the same \\(n_{\\ell}\\)-sample.</p> <p>Then, the MLMC estimator \\(\\hat{\\theta}_L^{\\mathrm{ML}}\\) of \\(\\theta_L\\) may be expressed as:</p> \\[ \\hat{\\theta}_L^{\\mathrm{MLMC}} = \\sum \\limits_{\\ell = 0}^{L} \\hat{T}_{\\ell,n_\\ell}^{\\mathrm{MC}} = \\sum \\limits_{\\ell = 0}^{L} \\hat{\\theta}_{\\ell,n_\\ell}^{\\mathrm{MC},(\\ell)}- \\hat{\\theta}_{\\ell-1,n_\\ell}^{\\mathrm{MC},(\\ell)}. \\] <p>Many algorithms distributing the sampling budget between the different levels can be found in the literature. Their goal is often to get an MLMC estimator with an accuracy target set by the user. Recently, an allocation algorithm<sup>2</sup> has been proposed to get the best accuracy for a given sampling budget.</p>"},{"location":"user_guide/statistics/multilevel/#multilevel-monte-carlo-with-control-variates","title":"Multilevel Monte Carlo with control variates","text":"<p>When surrogate models are available as functions of the random input \\(\\mathbf{X}\\), their random outputs can be used as control variates (CVs) to reduce the variance of the MC estimators.</p> <p>In 2023, El Amri et al<sup>3</sup> have investigated the combination of CVs and MLMC in different ways and called the resulting algorithm MLMC-MLCV, standing for multilevel Monte Carlo with multilevel control variates. Their idea was to estimate each \\(T_\\ell\\) of the telescoping sum with a control variate approach based on surrogate models. They showed that even with surrogate models that are moderately correlated to the original models, the reduction in variance could be significant.</p> <ol> <li> <p>Michael B Giles. Multilevel Monte Carlo methods. Acta numerica, 24:259\u2013328, 2015.\u00a0\u21a9</p> </li> <li> <p>Paul Mycek and Matthias De Lozzo. Multilevel Monte Carlo covariance estimation for the computation of Sobol'indices. SIAM/ASA Journal on Uncertainty Quantification, 7(4):1323\u20131348, 2019.\u00a0\u21a9</p> </li> <li> <p>Mohamed Reda El Amri, Paul Mycek, Sophie Ricci, and Matthias De Lozzo. Multilevel surrogate-based control variates. 2023. arXiv:2306.10800.\u00a0\u21a9</p> </li> </ol>"},{"location":"user_guide/umdo/","title":"Introduction","text":""},{"location":"user_guide/umdo/#mdo-under-uncertainty","title":"MDO under uncertainty","text":""},{"location":"user_guide/umdo/#introduction","title":"Introduction","text":""},{"location":"user_guide/umdo/#optimization-problem","title":"Optimization problem","text":"<p>A standard optimization problem aims to find a vector \\(x^*\\) minimizing an objective function \\(f\\) over a search space \\(\\mathcal{X}\\subset\\mathbb{R}^d\\) while satisfying inequality constraints \\(g(x)\\leq 0\\) and equality constraints \\(h(x)=0\\):</p> \\[ \\begin{align} &amp;\\underset{x\\in\\mathcal{X}}{\\operatorname{minimize}}&amp; &amp; f(x) \\\\ &amp;\\operatorname{subject\\;to} &amp; &amp;g(x) \\leq 0 \\\\ &amp;&amp;&amp;h(x) = 0 \\end{align} \\] <p>where \\(f:\\mathcal{X}\\mapsto\\mathbb{R}\\), \\(g:\\mathcal{X}\\mapsto\\mathbb{R}^{p_g}\\) and \\(h:\\mathcal{X}\\mapsto\\mathbb{R}^{p_h}\\).</p> <p>Any optimization problem of the form</p> \\[ \\begin{align} &amp;\\underset{x\\in\\mathcal{X}}{\\operatorname{minimize}}&amp; &amp; f_{\\textrm{cost}}(x) \\\\ &amp;\\underset{x\\in\\mathcal{X}}{\\operatorname{maximize}}&amp; &amp; f_{\\textrm{performance}}(x) \\\\ &amp;\\operatorname{subject\\;to} &amp; &amp;g_n(x) \\leq t_{g_n} \\\\ &amp;&amp;&amp;g_p(x) \\geq t_{g_p} \\\\ &amp;&amp;&amp;\\tilde{h}(x) = t_h \\end{align} \\] <p>can be reduced to this standard optimization problem:</p> <ul> <li>an objective to minimize,</li> <li>upper inequality constraints with bounds equal to 0,</li> <li>equality constraints with right-hand sides equal to 0.</li> </ul> <p>API</p> <p>In GEMSEO, the user instantiates an OptimizationProblem from a DesignSpace, defines its objective functions and constraints with MDOFunction objects and solves it with an algorithm from a DriverLibrary. This algorithm can be either an optimizer or a design of experiments (DOE).</p> Example <p>The optimization problem</p> \\[ \\begin{align} &amp;\\underset{x\\in[-1,1]}{\\operatorname{minimize}}&amp; &amp; x^2 \\\\ &amp;\\operatorname{subject\\;to} &amp; &amp; x^3 \\ge 0.1 \\end{align} \\] <p>can be solved with the Python lines</p> <pre><code>from gemseo import execute_algo\nfrom gemseo.algos.optimization_problem import Optimization\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.core.mdofunctions.mdo_function import MDOFunction\n\ndesign_space = DesignSpace()\ndesign_space.add_variable(\"x\", l_b=-1., u_b=1.)\n\nproblem = OptimizationProblem(design_space)\nproblem.objective = MDOFunction(lambda x: x**2, \"f\")\nproblem.add_constraint(MDOFunction(lambda x: x**3, \"g\"), positive=True, value=0.1)\n\nexecute_algo(problem, \"fullfact\", n_samples=10, algo_type=\"doe\")\n</code></pre>"},{"location":"user_guide/umdo/#multidisciplinary-optimization-mdo-problem","title":"Multidisciplinary optimization (MDO) problem","text":"<p>In complex systems, the quantities \\(f(x)\\), \\(g(x)\\) and \\(h(x)\\) are often computed by \\(D\\) models, called disciplines, which can be weakly or strongly coupled. The vector \\(x\\) can be split into</p> <ul> <li>a sub-vector \\(x_0\\) shared by at least two disciplines,</li> <li>sub-vectors \\(x_i\\), each specific to a discipline \\(i\\).</li> </ul> <p>The problem is then called a multidisciplinary optimization (MDO) problem</p> \\[ \\begin{align} &amp;\\underset{x\\in\\mathcal{X},y\\in\\mathcal{Y}}{\\operatorname{minimize}}&amp;&amp;f(x,y)\\\\ &amp;\\operatorname{subject\\;to} &amp; &amp;g(x,y) \\leq 0 \\\\ &amp;&amp;&amp;h(x,y) = 0 \\\\ &amp;&amp;&amp;y=c(x,y) \\end{align} \\] <p>where \\(c_i:x_0,x_i,y_{-i}\\mapsto y_i\\) represents the \\(i\\)-th discipline with \\(y_{-i}=\\{y_j, 1\\leq j\\neq i \\leq D\\}\\).</p> <p>This MDO problem implies that the optimum \\((x^*,y^*)\\) must be multidisciplinary feasible, i.e. satisfying the coupling equations \\(y^*=c(x^*,y^*)\\). Solving these equations is called a multidisciplinary analysis (MDA).</p> Example: MDA with linear disciplines <p>Let us consider a simple MDO problem with two linear disciplines given by \\(c_1: x_0,x_1,y_2 \\mapsto x_0 + x_1 + y_2\\) and \\(c_2: x_0,x_2,y_1 \\mapsto x_0 + x_2 + 2y_1\\). Let us define the objective function as \\(f(x_0,x_1,x_2,y_1,y_2)=c_1(x_0,x_1,y_2)^2+c_2(x_0,x_2,y_1)^2\\). The coupling equations are \\(c_1(x_0,x_1,y_2)=y_1\\) and \\(c_2(x_0,x_2,y_1)=y_2\\). In this linear case, they can be solved analytically: \\(y_1(x) = -2x_0-x_1-x_2\\) and \\(y_2(x) = -3x_0-2x_1-x_2\\). Then, the objective function output can be rewritten as a function of \\(x\\) only: \\(f(x,y(x))=y_1(x)^2+y_2(x)^2\\), and the MDO problem becomes a simple optimization problem.</p> <p>In the case of non-linear disciplines, the MDA can be solved with Newton's method or a fixed-point technique.</p> <p>Last but not least, the efficient resolution of an MDO problem involves finding a suitable rewriting of the problem, called MDO formulation or architecture<sup>1</sup>.</p> <ul> <li> <p>The MDF (multidisciplinary feasible) formulation is certainly the best-known.   This architecture performs an MDA at each iteration of the optimization loop   and is thus qualified as coupled.</p> \\[ \\begin{align} &amp;\\underset{x\\in\\mathcal{X}}{\\operatorname{Minimize}}&amp;&amp;f(x,y(x))\\\\ &amp;\\operatorname{subject\\;to} &amp; &amp;g(x,y(x)) \\leq 0 \\\\ &amp;&amp;&amp;h(x,y(x)) = 0 \\\\ &amp;&amp;&amp;y(x)=c(x,y(x)). \\end{align} \\] </li> <li> <p>The IDF (individual disciplinary feasible) formulation is also popular.   This architecture evaluates the disciplines independently   at each iteration of the optimization loop   and is thus qualified as uncoupled.   The multidisciplinary feasibility is ensured   at convergence of the optimization algorithm   by means of consistency constraints.</p> \\[ \\begin{align} &amp;\\underset{x\\in\\mathcal{X},\\tilde{y}\\in\\mathcal{Y}}{\\operatorname{Minimize}}&amp;&amp;f(x,\\tilde{y})\\\\ &amp;\\operatorname{subject\\;to} &amp; &amp;g(x,\\tilde{y}) \\leq 0 \\\\ &amp;&amp;&amp;h(x,\\tilde{y}) = 0 \\\\ &amp;&amp;&amp;\\tilde{y} = c(x,\\tilde{y}). \\end{align} \\] </li> <li> <p>Bi-level formulations<sup>2</sup> split the optimization problem   into a top-level optimization problem controlling the shared variable \\(x_0\\)   and a collection of sub-optimization problems   whose \\(i\\)-th controls the local variable \\(x_i\\).</p> </li> </ul> <p>API</p> <p>GEMSEO offers implementations for the MDF, IDF and BiLevel formulations.</p> Example: MDF applied to the Sellar problem <pre><code>  from gemseo import create_scenario\n  from gemseo.algos.design_space import DesignSpace\n  from gemseo.disciplines.analytic import AnalyticDiscipline\n\n  disciplines = [\n      AnalyticDiscipline({\"y_1\": \"(z1**2+z2+x-0.2*y2)**0.5\"}, \"Sellar1\"),\n      AnalyticDiscipline({\"y_2\": \"abs(y1)+z1+z2\"}, \"Sellar2\"),\n      AnalyticDiscipline(\n          {\n              \"f\": \"x**2+z2+y**2+exp(-y_2)\",\n              \"c1\": \"3.16-y1**2\",\n              \"c2\": \"y2-24\"\n          },\n          \"SellarSystem\"\n      )\n  ]\n\n  design_space = DesignSpace()\n  design_space.add_variable(\"x\", l_b=0.0, u_b=10.0, value=1)\n  design_space.add_variable(\"z1\", l_b=-10, u_b=10.0, value=4.0)\n  design_space.add_variable(\"z2\", l_b=0.0, u_b=10.0, value=3.0)\n\n  scenario = create_scenario(disciplines, \"MDF\", \"f\", design_space)\n  scenario.add_constraint(\"c1\", \"ineq\")\n  scenario.add_constraint(\"c2\", \"ineq\")\n  scenario.execute({\"algo\": \"SLSQP\", \"max_iter\": 100})\n</code></pre>"},{"location":"user_guide/umdo/#optimization-problem-under-uncertainty","title":"Optimization problem under uncertainty","text":"<p>The models are often subject to uncertainties There are different ways of classifying uncertainties and different ways of modeling them. However, GEMSEO-UMDO is limited to the probability theory for the sake of simplicity and because this framework is the most popular and has proved its worth. And so, the uncertainties are modelled by random variables.</p> <p>Then, the objective \\(f(x,U)\\) and the constraints \\(g(x,U)\\) and \\(h(x,U)\\), where \\(U\\) denotes random inputs, are in turn random variables and the standard optimization problem is replaced by</p> \\[ \\begin{align} &amp;\\underset{x\\in\\mathcal{X}}{\\operatorname{minimize}}&amp; &amp; \\mathbb{K}_f[f(x,U)] \\\\ &amp;\\operatorname{subject\\;to} &amp; &amp;\\mathbb{K}_g[g(x,U)] \\leq 0 \\\\ &amp;&amp;&amp;\\mathbb{K}_h[h(x,U)] = 0 \\end{align} \\] <p>where \\(\\mathbb{K}_f\\), \\(\\mathbb{K}_g\\) and \\(\\mathbb{K}_h\\) are statistics.</p> <p>The statistic of a function \\(\\phi\\) can be the expectation \\(\\mathbb{E}[\\phi(x,U)]\\), the standard deviation \\(\\mathbb{S}[\\phi(x,U)]\\), the variance \\(\\mathbb{V}[\\phi(x,U)]\\), a margin \\(\\mathbb{E}[\\phi(x,U)]+\\kappa\\times\\mathbb{S}[\\phi(x,U)]\\) or a probability \\(\\mathbb{P}[m \\leq \\phi(x,U)\\leq M]\\). For the inequality constraints, \\(\\mathbb{K}_g[g(x,U)]\\) could be \\(\\mathbb{P}[g(x,U)\\geq\\epsilon]\\) or \\(\\mathbb{P}[g(x,U)\\geq 0]-\\varepsilon\\). For the equality constraints, \\(\\mathbb{K}_h[h(x,U)]\\) could be \\(\\mathbb{P}[|h(x,U)|\\geq\\epsilon]\\).</p> <p>Note</p> <p>When \\(\\phi(x,U)\\) is normally distributed, the margin \\(\\mathbb{E}[\\phi(x,U)]+q_\\alpha\\times\\mathbb{S}[\\phi(x,U)]\\) corresponds to the \\(\\alpha\\)-quantile of \\(\\phi(x,U)\\) where \\(q_\\alpha\\) is the \\(\\alpha\\)-quantile of the standard Gaussian distribution. For that reason, 2 or 3 are common candidates for \\(\\kappa\\) as in this case, the margins correspond to the 0.975- and 0.999- quantiles of \\(\\phi(x,U)\\) respectively.</p> <p>Typically, a margin is applied to the objective to ensure a robust optimum \\(x^*\\):</p> <ul> <li>a small value of \\(f(x^*,u)\\) by minimizing \\(\\mathbb{E}[f(x,U)]\\),</li> <li>whatever the realization \\(u\\) of \\(U\\) by minimizing \\(\\mathbb{S}[f(x,U)]\\).</li> </ul>"},{"location":"user_guide/umdo/#api","title":"API","text":"<p>Here is an outline of the API. Go to the examples for more information.</p>"},{"location":"user_guide/umdo/#disciplines","title":"Disciplines","text":"<p>When defining disciplines, do not forget to declare the uncertain variables as input variables so that the UMDOScenario and UDOEScenario can change their values.</p> <p>Example</p> <p>Let us implement an MDODiscipline outputting \\(f(x,U)=(x_1+U)^2+(x_2+U)^2\\): <pre><code>from numpy import array\nfrom gemseo.core.discipline import MDODiscipline\n\n\nclass MyDiscipline(MDODiscipline):\n\n    def __init__(self):\n        super().__init__()\n        self.input_grammar.update_from_names([\"x1\", \"x2\", \"U\"])\n        self.default_inputs = {\"x1\": array([0.]), \"x2\": array([0.]), \"U\": array([0.5])}\n\n    def _run(self):\n        x1, x2, U = self.get_local_data_by_name([\"x1\", \"x2\", \"U\"])\n        y = (x1+U)**2 + (x2+U)**2\n        self.store_local_data(y=y)\n</code></pre></p> <p>This discipline can be executed with different values of the uncertain variable \\(U\\): <pre><code>discipline.execute()  # default value, i.e. U=0.5\ndiscipline.execute({\"U\": array([0.2])})  # custom value: U=0.2\n</code></pre></p>"},{"location":"user_guide/umdo/#uncertain-space","title":"Uncertain space","text":"<p>The uncertain variables have to be defined in a ParameterSpace with the method add_random_variable.</p> <p>Example</p> <p>In the previous example, we could model the uncertain variable \\(U\\) as a random variable distributed according to a triangular distribution between 0.2 and 0.7 with a mode of 0.4:</p> <pre><code>from gemseo.algos.parameter_space import ParameterSpace\n\nuncertain_space = ParameterSpace()\nuncertan_space.add_random_variable(\n    \"U\", \"OTTriangularDistribution\", minimum=0.2, maximum=0.7, mode=0.4\n)\n</code></pre>"},{"location":"user_guide/umdo/#scenario","title":"Scenario","text":"<p>Given these disciplines and uncertain space and also a design space of course, the MDO problem can be set up.</p> <p>In the case of MDO without uncertainty, there are two scenarios to set up the MDO problem:</p> <ul> <li>DOEScenario   to solve it with a DOE,</li> <li>MDOScenario   to solve it with an optimizer.</li> </ul> <p>Both need knowledge of objective and constraint functions in addition to the disciplines and design space to solve the MDO problem.</p> <p>In the case of MDO with uncertainty, there are two similar scenarios to set up the MDO problem:</p> <ul> <li>UDOEScenario   to solve it with a DOE,</li> <li>UMDOScenario   to solve it with an optimizer.</li> </ul> <p>Both need knowledge of the statistics and their estimators in addition to the disciplines, design space, objective and constraints to solve the MDO problem under uncertainty.</p> <p>API</p> <p>The API of UDOEScenario is deliberately similar to the API of DOEScenario. And the same for UMDOScenario and MDOScenario. This choice was made not only to simplify the user's life, but also because an MDO problem under uncertainty is first and foremost an MDO problem.</p> <p>Example</p> <p>Continuing the previous example, we seek to minimize \\(\\mathbf{E}[(x_1+U)^2+(x_2+U)^2]\\) over the domain \\([-1,1]^2\\) with the gradient-free optimization algorithm COBYLA and a Monte Carlo estimator of the expectation.</p> <pre><code>from gemseo.algos.design_space import DesignSpace\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\ndesign_space = DesignSpace()\ndesign_space.add_variable(\"x1\", l_b=-1., u_b=1.)\ndesign_space.add_variable(\"x2\", l_b=-1, u_b=1.)\n\nscenario = UMDOScenario(\n    [discipline],\n    \"DisciplinaryOpt\",\n    \"y\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    statistic_estimation_parameters={\"n_samples\": 100},\n)\nscenario.execute({\"algo\": \"NLOPT_COBYLA\", \"max_iter\": 50})\n</code></pre>"},{"location":"user_guide/umdo/#u-mdo-formulations","title":"U-MDO formulations","text":"<p>By default, UDOEScenario and UMDOScenario estimate the statistics by sampling the random function \\(f(x,U)\\), \\(g(x,U)\\) and \\(h(x,U)\\).</p> <p>GEMSEO-UMDO offers other statistic estimations methods and refers to them as U-MDO formulations. A BaseUMDOFormulation can be combined to any MDO formulation.</p> Implementation <p>Given a DesignSpace and a collection of MDODisciplines, a DOEScenario generates and solves an OptimizationProblem that corresponds to an MDOFormulation. The resolution consists in sampling the objective and constraints over the DesignSpace, i.e. \\((x^{(i)},f(x^{(i)},U),g(x^{(i)},U),h(x^{(i)},U))_{1\\leq i \\leq N}\\), and returning either the \\(x^*\\) minimizing \\(f\\) while satisying \\(g\\) and \\(h\\) or the \\(x^*\\) that violates the least \\(g\\) and \\(h\\).</p> <p>GEMSEO-UMDO uses this sampling mechanism a first time with a ParameterSpace instead of the DesignSpace to estimate the statistics \\(\\mathbb{K}_f[f(x,U)]\\), \\(\\mathbb{K}_g[g(x,U)]\\) and \\(\\mathbb{K}_h[h(x,U)]\\) based on the samples \\((U^{(i)},f(x,U^{(i)}),g(x,U^{(i)}),h(x,U^{(i)}))_{1\\leq i \\leq M}\\). In the case of Monte Carlo sampling, \\(M\\) is the number of samples while in the case of Taylor expansion, \\(M\\in\\{1,1+q\\}\\) where \\(q\\) is the dimension of the uncertain space depending on whether the derivatives are known or to be estimated by finite differences. These statistics estimators \\(\\hat{\\mathbb{K}}_f[f(x,U)]\\), \\(\\hat{\\mathbb{K}}_g[g(x,U)]\\) and \\(\\hat{\\mathbb{K}}_h[h(x,U)]\\) are then used to build a new OptimizationProblem over the DesignSpace:</p> \\[ \\begin{align} &amp;\\underset{x\\in\\mathcal{X}}{\\operatorname{minimize}} &amp; &amp; \\hat{\\mathbb{K}}_f[f(x,U)] \\\\ &amp;\\operatorname{subject\\;to} &amp; &amp;\\hat{\\mathbb{K}}_g[g(x,U)] \\leq 0 \\\\ &amp;&amp;&amp;\\hat{\\mathbb{K}}_h[h(x,U)] = 0. \\end{align} \\] <p>Thus implemented, GEMSEO-UMDO should be able to set up any MDO problem under uncertainty from any MDOFormulation and any statistic estimation technique. This vision may be theoretical at the moment, but the ambition of GEMSEO-UMDO is to be an engine generating U-MDO formulations based on any MDO formulation and any statistic estimators.</p> <ol> <li> <p>Joaquim R. R. A. Martins and Andrew B. Lambe. Multidisciplinary design optimization: a survey of architectures. AIAA Journal, 51:2049\u20132075, 2013. doi:10.2514/1.J051895.\u00a0\u21a9</p> </li> <li> <p>Anne Gazaix, Francois Gallard, Vincent Ambert, Damien Gu\u00e9not, Maxime Hamadi, Patrick Sarouille, St\u00e9phane Grihon, Thierry Druot, Joel Brezillon, Thierry Lefebvre, Nathalie Bartoli, Remi Lafage, Vincent Gachelin, Justin Plakoo, Nicolas Desfachelles, Selime Gurol, Benoit Pauwels, and Charlie Vanaret. Industrial application of an advanced bi-level MDO formulation to an aircraft engine pylon optimization. In AIAA AVIATION Forum. American Institute of Aeronautics and Astronautics, 2019.\u00a0\u21a9</p> </li> </ol>"},{"location":"user_guide/umdo/control_variate/","title":"Control variate","text":""},{"location":"user_guide/umdo/control_variate/#control-variate","title":"Control variate","text":"<p>The U-MDO formulation ControlVariate can solve an MDO problem associated with an MDOFormulation by using control variates based on first-order Taylor polynomials.</p> <p>Control variates (CVs) method</p> <p>The control variates method is a variance reduction technique used in Monte Carlo sampling. Read more</p> <p>The Taylor polynomials are centered at \\(\\mu=\\mathbb{E}[U]\\) where \\(U\\) is the random input vector.</p> <p>This U-MDO formulation has one mandatory parameter, namely <code>n_samples</code>.</p> <p>Here is a typical scenario template:</p> <pre><code>scenario = UMDOScenario(\n    disciplines,\n    mdo_formulation_name,\n    objective_name,\n    design_space,\n    uncertain_space,\n    statistic_name,\n    statistic_estimation=\"ControlVariate\",\n)\n</code></pre>"},{"location":"user_guide/umdo/control_variate/#options","title":"Options","text":"<p>By default, the formulation uses the DOE algorithm <code>OT_OPT_LHS</code>: the Latin hypercube sampling (LHS) enhanced by simulated annealing of OpenTURNS. Simulated annealing is a global optimization technique that starts from an initial LHS and improves it to maximize its discrepancy and so to get a better space-filling LHS.</p> <p>The DOE algorithm can be set with the string parameter <code>algo</code> and its options with the dictionary parameter <code>algo_options</code>.</p> <p>API</p> <p>Use <code>statistic_estimation_parameters</code> to set the algorithm name and parameters, e.g.</p> <pre><code>scenario = UMDOScenario(\n    disciplines,\n    mdo_formulation_name,\n    objective_name,\n    design_space,\n    uncertain_space,\n    statistic_name,\n    statistic_estimation=\"ControlVariate\",\n    statistic_estimation_parameters={\n        \"algo\": \"OT_MONTE_CARLO\",\n        \"n_samples\": 20,\n        \"algo_options\": {\"n_processes\": 2}\n    }\n)\n</code></pre>"},{"location":"user_guide/umdo/control_variate/#statistics","title":"Statistics","text":"<p>This formulation has been implemented for the expectation, variance and probability, as well as combinations of these statistics.</p> <p>Only the average formula is noted here, for simplicity's sake</p> \\[\\mathbb{E}[\\varphi(x,U)] \\approx \\frac{1}{N}\\sum_{i=1}^N f\\left(x,U^{(i)}\\right) +\\alpha_N\\left(\\frac{1}{N}\\sum_{j=1}^N \\tilde{f}\\left(x,U^{(j)}\\right)-f(x,\\mu)\\right)\\] <p>where \\(\\tilde{f}(x)\\) is the first-order Taylor polynomial of \\(f(x)\\) at \\(\\mu\\), \\(\\alpha_N\\) is the empirical estimator of \\(\\frac{\\text{cov}\\left[f(x,U),\\tilde{f}(x,u)\\right]} {\\mathbb{V}\\left[f(x,U)\\right]}\\) and \\(U^{(1)},\\ldots,U^{(N)}\\) are \\(N\\) independent realizations of \\(U\\).</p>"},{"location":"user_guide/umdo/pce/","title":"Pce","text":""},{"location":"user_guide/umdo/pce/#polynomial-chaos-expansion","title":"Polynomial chaos expansion","text":"<p>The U-MDO formulation PCE can solve an MDO problem associated with an MDOFormulation with polynomial chaos expansions (PCEs).</p> <p>At each iteration of the optimization loop, a PCE is built over the uncertain space and its coefficients are used to estimate specific statistics, namely mean, standard deviation, variance and margin.</p> <p>The number of samples to build the PCE is mandatory and must be set with the parameter <code>doe_n_samples</code>.</p> <p>Here is a typical scenario template:</p> <pre><code>scenario = UMDOScenario(\n    disciplines,\n    mdo_formulation_name,\n    objective_name,\n    design_space,\n    uncertain_space,\n    statistic_name,\n    statistic_estimation=\"PCE\",\n    statistic_estimation_parameters={\"doe_n_samples\": 20}\n)\n</code></pre>"},{"location":"user_guide/umdo/pce/#options","title":"Options","text":""},{"location":"user_guide/umdo/pce/#doe-algorithm","title":"DOE algorithm","text":"<p>By default, the formulation uses the DOE algorithm <code>OT_OPT_LHS</code>: the Latin hypercube sampling (LHS) enhanced by simulated annealing of OpenTURNS. Simulated annealing is a global optimization technique that starts from an initial LHS and improves it to maximize its discrepancy and so to get a better space-filling LHS.</p> <p>The DOE algorithm can be set with the string parameter <code>doe_algo</code> and its options with the dictionary parameter <code>doe_algo_options</code>.</p> <p>API</p> <p>Use <code>statistic_estimation_parameters</code> to set the algorithm name and options, e.g.</p> <pre><code>scenario = UMDOScenario(\n    disciplines,\n    mdo_formulation_name,\n    objective_name,\n    design_space,\n    uncertain_space,\n    statistic_name,\n    statistic_estimation_parameters={\n        \"doe_algo\": \"OT_MONTE_CARLO\",\n        \"doe_n_samples\": 20,\n        \"doe_algo_options\": {\"n_processes\": 2}\n    }\n)\n</code></pre>"},{"location":"user_guide/umdo/pce/#pce-options","title":"PCE options","text":"<p>This U-MDO formulation is based on the PCERegressor available in GEMSEO, which wraps the OpenTURNS' PCE algorithm. Use the <code>pce_options</code> arguments to set the options of the PCERegressor.</p>"},{"location":"user_guide/umdo/pce/#statistics","title":"Statistics","text":"<p>This formulation has been implemented for the expectation and variance, as well as combinations of these statistics, from the coefficients \\((\\alpha_i)_{1\\leq i \\leq N\\}\\) of the PCE</p> \\[\\hat{f}_x(U)=\\alpha_0 + \\sum_{1&lt;i\\leq P}\\alpha_i\\Phi_i(U).\\]"},{"location":"user_guide/umdo/pce/#mean","title":"Mean","text":"\\[\\mathbb{E}[\\varphi(x,U)] \\approx \\alpha_0\\]"},{"location":"user_guide/umdo/pce/#variance","title":"Variance","text":"\\[\\mathbb{V}[\\varphi(x,U)] \\approx \\sum_{1&lt;i\\leq P}\\alpha_i^2\\]"},{"location":"user_guide/umdo/pce/#standard-deviation","title":"Standard deviation","text":"\\[\\mathbb{S}[\\varphi(x,U)] \\approx \\sqrt{\\sum_{1&lt;i\\leq P}\\alpha_i^2}\\]"},{"location":"user_guide/umdo/pce/#margin","title":"Margin","text":"\\[\\textrm{Margin}[\\varphi(x,U)] \\approx \\alpha_0 + \\kappa \\times \\sqrt{\\sum_{1&lt;i\\leq P}\\alpha_i^2}\\]"},{"location":"user_guide/umdo/sampling/","title":"Sampling","text":""},{"location":"user_guide/umdo/sampling/#sampling","title":"Sampling","text":"<p>The U-MDO formulation Sampling can solve an MDO problem associated with an MDOFormulation by using Monte Carlo sampling. This U-MDO formulation replaces the statistics by their unbiased empirical estimators.</p> <p>This is the default U-MDO formulation. So, the argument <code>statistic_estimation</code> does not have to be set to use it. However, the number of samples is mandatory and must be set with the parameter <code>n_samples</code>.</p> <p>Here is a typical scenario template:</p> <pre><code>scenario = UMDOScenario(\n    disciplines,\n    mdo_formulation_name,\n    objective_name,\n    design_space,\n    uncertain_space,\n    statistic_name,\n    statistic_estimation_parameters={\"n_samples\": n_samples}\n)\n</code></pre>"},{"location":"user_guide/umdo/sampling/#options","title":"Options","text":"<p>By default, the formulation uses the DOE algorithm <code>OT_OPT_LHS</code>: the Latin hypercube sampling (LHS) enhanced by simulated annealing of OpenTURNS. Simulated annealing is a global optimization technique that starts from an initial LHS and improves it to maximize its discrepancy and so to get a better space-filling LHS.</p> <p>The DOE algorithm can be set with the string parameter <code>algo</code> and its options with the dictionary parameter <code>algo_options</code>.</p> <p>API</p> <p>Use <code>statistic_estimation_parameters</code> to set the algorithm name and parameters, e.g.</p> <pre><code>scenario = UMDOScenario(\n    disciplines,\n    mdo_formulation_name,\n    objective_name,\n    design_space,\n    uncertain_space,\n    statistic_name,\n    statistic_estimation_parameters={\n        \"algo\": \"OT_MONTE_CARLO\",\n        \"n_samples\": 20,\n        \"algo_options\": {\"n_processes\": 2}\n    }\n)\n</code></pre>"},{"location":"user_guide/umdo/sampling/#statistics","title":"Statistics","text":"<p>This formulation has been implemented for the expectation, variance and probability, as well as combinations of these statistics.</p>"},{"location":"user_guide/umdo/sampling/#mean","title":"Mean","text":"\\[\\mathbb{E}[\\varphi(x,U)] \\approx E_N[\\varphi(x,U)] =\\frac{1}{N}\\sum_{i=1}^N\\varphi(x,U^{(i)})\\]"},{"location":"user_guide/umdo/sampling/#variance","title":"Variance","text":"\\[\\mathbb{V}[\\varphi(x,U)] \\approx V_N[\\varphi(x,U)] =\\frac{1}{N-1}\\sum_{i=1}^N\\left( \\varphi(x,U^{(i)})-\\frac{1}{N}\\sum_{j=1}^N\\varphi(x,U^{(j)}) \\right)^2\\]"},{"location":"user_guide/umdo/sampling/#standard-deviation","title":"Standard deviation","text":"\\[\\mathbb{S}[\\varphi(x,U)] \\approx S_N[\\varphi(x,U)] =\\sqrt{V_N[\\varphi(x,U)]}\\]"},{"location":"user_guide/umdo/sampling/#margin","title":"Margin","text":"\\[\\textrm{Margin}[\\varphi(x,U)] \\approx \\textrm{Margin}_N[\\varphi(x,U)] =E_N[\\varphi(x,U)]+\\kappa\\times S_N[\\varphi(x,U)]\\]"},{"location":"user_guide/umdo/sampling/#probability","title":"Probability","text":"\\[\\mathbb{P}[\\varphi(x,U)\\leq 0] \\approx P_N[\\varphi(x,U)\\leq 0] =E_N[\\mathbb{1}_{\\varphi(x,U)\\leq 0}]\\]"},{"location":"user_guide/umdo/sequential_sampling/","title":"Sequential sampling","text":""},{"location":"user_guide/umdo/sequential_sampling/#sequential-sampling","title":"Sequential sampling","text":"<p>The U-MDO formulation SequentialSampling can solve an MDO problem associated with an MDOFormulation by using Monte Carlo sampling. Contrary to Sampling, this U-MDO formulation does not use a constant sampling size but a sampling size that increases with the iterations of the optimization loop.</p> <p>The number of samples is mandatory and must be set with the parameter <code>n_samples</code>. It corresponds to the maximum number of samples for a given iteration of the optimization loop.</p> <p>Here is a typical scenario template:</p> <pre><code>scenario = UMDOScenario(\n    disciplines,\n    mdo_formulation_name,\n    objective_name,\n    design_space,\n    uncertain_space,\n    statistic_name,\n    statistic_estimation=\"SequentialSampling\",\n    statistic_estimation_parameters={\"n_samples\": n_samples}\n)\n</code></pre>"},{"location":"user_guide/umdo/sequential_sampling/#options","title":"Options","text":""},{"location":"user_guide/umdo/sequential_sampling/#algorithm","title":"Algorithm","text":"<p>By default, the formulation uses the algorithm <code>OT_OPT_LHS</code> to get a good space-filling design of experiments (DOE).</p> <p>DOE algorithms</p> <p>Read the GEMSEO documentation for more information about the available DOE algorithms.</p> <p>The DOE algorithm can be set with the string parameter <code>algo</code> and its options with the dictionary parameter <code>algo_options</code>.</p> <p>API</p> <p>Use <code>statistic_estimation_parameters</code> to set the algorithm name and parameters, e.g.</p> <pre><code>scenario = UMDOScenario(\n    disciplines,\n    mdo_formulation_name,\n    objective_name,\n    design_space,\n    uncertain_space,\n    statistic_name,\n    statistic_estimation_parameters={\n        \"algo\": \"OT_MONTE_CARLO\",\n        \"n_samples\": 20,\n        \"algo_options\": {\"n_processes\": 2}\n    }\n)\n</code></pre>"},{"location":"user_guide/umdo/sequential_sampling/#sampling-size-profile","title":"Sampling size profile","text":"<p>By default, the number of samples is equal to 1 at the first iteration and is incremented by 1 at each iteration of the optimization loop.</p> <p>These values can be changed with the statistic estimation parameters <code>initial_n_samples</code> and <code>n_samples_increment</code>.</p>"},{"location":"user_guide/umdo/sequential_sampling/#statistics","title":"Statistics","text":"<p>This formulation has been implemented for the expectation, variance and probability, as well as combinations of these statistics. The estimators are given below at the \\(k\\)-th iteration of the optimization loop.</p>"},{"location":"user_guide/umdo/sequential_sampling/#mean","title":"Mean","text":"\\[\\mathbb{E}[\\varphi(x,U)] \\approx E_{N_k}[\\varphi(x,U)] =\\frac{1}{N_k}\\sum_{i=1}^{N_k}\\varphi(x,U^{(k,i)})\\]"},{"location":"user_guide/umdo/sequential_sampling/#variance","title":"Variance","text":"\\[\\mathbb{V}[\\varphi(x,U)] \\approx V_{N_k}[\\varphi(x,U)] =\\frac{1}{N_k-1}\\sum_{i=1}^{N_k}\\left( \\varphi(x,U^{(k,i)})-\\frac{1}{N_k}\\sum_{j=1}^{N_k}\\varphi(x,U^{(k,j)}) \\right)^2\\]"},{"location":"user_guide/umdo/sequential_sampling/#standard-deviation","title":"Standard deviation","text":"\\[\\mathbb{S}[\\varphi(x,U)] \\approx S_{N_k}[\\varphi(x,U)] =\\sqrt{V_{N_k}[\\varphi(x,U)]}\\]"},{"location":"user_guide/umdo/sequential_sampling/#margin","title":"Margin","text":"\\[\\textrm{Margin}[\\varphi(x,U)] \\approx \\textrm{Margin}_{N_k}[\\varphi(x,U)] =E_{N_k}[\\varphi(x,U)]+\\kappa\\times S_{N_k}[\\varphi(x,U)]\\]"},{"location":"user_guide/umdo/sequential_sampling/#probability","title":"Probability","text":"\\[\\mathbb{P}[\\varphi(x,U)\\leq 0] \\approx P_{N_k}[\\varphi(x,U)\\leq 0] =E_{N_k}[\\mathbb{1}_{\\varphi(x,U)\\leq 0}]\\]"},{"location":"user_guide/umdo/taylor_polynomial/","title":"Taylor polynomial","text":""},{"location":"user_guide/umdo/taylor_polynomial/#taylor-polynomial","title":"Taylor polynomial","text":"<p>The U-MDO formulation TaylorPolynomial can solve an MDO problem associated with an MDOFormulation with Taylor polynomials.</p> <p>The Taylor polynomials are centered at \\(\\mu=\\mathbb{E}[U]\\) where \\(U\\) is the random input vector.</p> <p>When the derivatives with respect to the uncertain variables are available, this U-MDO formulation introduces no additional calculation cost associated with taking the uncertainties into account. Otherwise, finite differences are computed and so the additional cost is \\(d+1\\) evaluations of the process associated with the MDOFormulation where \\(d\\) is the dimension of the uncertain space.</p> <p>This U-MDO formulation has no mandatory parameters.</p> <p>Here is a typical scenario template:</p> <pre><code>scenario = UMDOScenario(\n    disciplines,\n    mdo_formulation_name,\n    objective_name,\n    design_space,\n    uncertain_space,\n    statistic_name,\n    statistic_estimation=\"TaylorPolynomial\",\n)\n</code></pre>"},{"location":"user_guide/umdo/taylor_polynomial/#options","title":"Options","text":""},{"location":"user_guide/umdo/taylor_polynomial/#derivatives-calculation","title":"Derivatives calculation","text":"<p>When the derivatives with respect to the uncertain variables are missing or when the process resulting from the MDOFormulation cannot be differentiated with respect to these variables, this U-MDO formulation uses finite difference approximations. One can also force the use of finite difference approximations by setting the statistic estimation parameter <code>differentiation_method</code> to <code>\"finite_differences\"</code>.</p> <p>API</p> <p>Use <code>statistic_estimation_parameters</code> to set the options, e.g.</p> <pre><code>scenario = UMDOScenario(\n    disciplines,\n    mdo_formulation_name,\n    objective_name,\n    design_space,\n    uncertain_space,\n    statistic_name,\n    statistic_estimation=\"TaylorPolynomial\",\n    statistic_estimation_parameters={\"differentiation_method\": \"finite_differences\"}\n)\n</code></pre>"},{"location":"user_guide/umdo/taylor_polynomial/#second-order","title":"Second-order","text":"<p>By default, this U-MDO formulation uses first-order Taylor polynomials. Second-order Taylor polynomials can also be used by setting the statistic estimation parameter <code>second_order</code> to <code>True</code>.</p> <p>Computational cost</p> <p>As GEMSEO does not support second-order derivatives, the second-order derivatives are estimated by finite-differences from the first-order derivatives. When the dimension of the uncertain space is large or when the first-order derivatives are already finite difference approximations, using second-order Taylor polynomials can be very costly.</p>"},{"location":"user_guide/umdo/taylor_polynomial/#statistics","title":"Statistics","text":"<p>This formulation has been implemented for the expectation and variance, as well as combinations of these statistics.</p> <p>Here are the expressions when using first-order Taylor polynomials.</p>"},{"location":"user_guide/umdo/taylor_polynomial/#mean","title":"Mean","text":"\\[\\mathbb{E}[\\varphi(x,U)] \\approx E_{\\textrm{TP}_1}[\\varphi(x,U)] =\\varphi(x,\\mu)\\]"},{"location":"user_guide/umdo/taylor_polynomial/#variance","title":"Variance","text":"\\[\\mathbb{V}[\\varphi(x,U)] \\approx V_{\\textrm{TP}_1}[\\varphi(x,U)] =\\nabla\\varphi(x,\\mu)^T\\Sigma \\nabla\\varphi(x,\\mu)\\] <p>where \\(\\Sigma=\\left(\\textrm{cov}(U_i,U_j)\\right)_{1\\leq i,j\\leq d}\\) is the covariance matrix of \\(U\\) and \\(\\nabla\\varphi(x,\\mu)= \\left(\\frac{\\partial\\varphi(x,\\mu)}{\\partial u_i}\\right)_{1\\leq i \\leq d}\\) is the column-vector of the partial derivatives of \\(\\varphi\\) with respect to the uncertain variables.</p>"},{"location":"user_guide/umdo/taylor_polynomial/#standard-deviation","title":"Standard deviation","text":"\\[\\mathbb{S}[\\varphi(x,U)] \\approx S_{\\textrm{TP}_1}[\\varphi(x,U)] =\\sqrt{V_{\\textrm{TP}_1}[\\varphi(x,U)]}\\]"},{"location":"user_guide/umdo/taylor_polynomial/#margin","title":"Margin","text":"\\[\\textrm{Margin}[\\varphi(x,U)] \\approx \\textrm{Margin}_{\\textrm{TP}_1}[\\varphi(x,U)] =E_{\\textrm{TP}_1}[\\varphi(x,U)]+\\kappa\\times S_{\\textrm{TP}_1}[\\varphi(x,U)]\\]"},{"location":"user_guide/visualization/","title":"Introduction","text":""},{"location":"user_guide/visualization/#visualization","title":"Visualization","text":""},{"location":"user_guide/visualization/sobol_graph/","title":"Sobol graph","text":""},{"location":"user_guide/visualization/sobol_graph/#sobol-sensitivity-graph","title":"Sobol' sensitivity graph","text":"<p>The Sobol' indices<sup>1</sup> are widely used in sensitivity analysis <sup>2</sup><sup>3</sup>.</p> <p>Sobol' index</p> <p>A Sobol' index represent the proportion of the variance of a quantity of interest explained by one or more uncertain inputs.</p> <p>The proportion explained by a single uncertain input is called a first-order index, the proportion explained by the interaction of two uncertain inputs is called a second-order index, ... and the proportion explained by an uncertain input separately or in interaction with other uncertain inputs is called a total-order index.</p>"},{"location":"user_guide/visualization/sobol_graph/#visualize-sobol-indices","title":"Visualize Sobol' indices","text":"<p>These sensitivity indices are often represented with pie charts and bar charts. These charts display the first-order and total-order Sobol' indices associated with the different uncertain inputs.</p> <p>The pie charts represent the first- and second-order indices as pie slices while the bar charts represent the first- and total-order indices with confidence intervals.</p> <p>Bar charts can help to determine whether the indices are well estimated or whether the variance of the quantity of interest is explained by the interaction between some uncertain inputs.</p> <p></p> <p>Bar chart generated by GEMSEO from the Ishigami function.</p> <p>Pie charts can help to determine whether interactions of order greater than 2 explain the variance of the quantity of interest.</p> <p></p> <p>Pie chart generated from synthetic data.</p> <p>Info</p> <p>Most of the UQ libraries propose only first-order indices and total-order indices; some of them propose also the second-order indices.</p>"},{"location":"user_guide/visualization/sobol_graph/#fanova-graph","title":"FANOVA graph","text":""},{"location":"user_guide/visualization/sobol_graph/#introduction","title":"Introduction","text":"<p>In the case of second-order Sobol' indices, a FANOVA graph<sup>4</sup> can be used to display the interactions between the uncertain variables. This graph is a network of uncertain variables representing their Sobol' indices:</p> <ul> <li>A node represents an uncertain variable whose name is written inside,   followed by its first-order and total-order Sobol' indices,</li> <li>The thickness of a node   is proportional to the total-order Sobol' index   of the variable   while the thickness of an edge   is proportional to the second-order Sobol' index   of the corresponding pair of variables.</li> </ul>"},{"location":"user_guide/visualization/sobol_graph/#api","title":"API","text":"<p>The SobolGraph can be built from three dictionaries:</p> <ul> <li>the first-order indices defined as <code>{name: sobol_index}</code>,</li> <li>the second-order indices defined as <code>{(name, other_name): sobol_index}</code>,</li> <li>the total-order indices defined as <code>{name: sobol_index}</code>.</li> </ul> <p>Then, this graph can be both displayed in a window and saved on the disk:</p> <pre><code>sobol_graph = SobolGraph(first_sobol, second_sobol, total_sobol)\nsobol_graph.visualize()\n</code></pre> <p></p> <p>Sobol' graph for the Ishigami function.</p> <p>Note</p> <p>Several examples of Sobol' graphs, including this one, can be found in a dedicated gallery.</p> <p>Lastly, given one or more disciplines and an uncertain space, the SobolAnalysis proposed by GEMSEO computes the Sobol' indices for several discipline outputs. Then, the SobolGraph associated with a specific discipline output can be generated from this analysis:</p> <pre><code>sobol_graph = SobolGraph.from_analysis(sobol_analysis, output_name)\nsobol_graph.visualize()\n</code></pre>"},{"location":"user_guide/visualization/sobol_graph/#options","title":"Options","text":"<p>At instantiation, the float argument <code>threshold</code> allows to set the sensitivity threshold above which a second-order index is declared as significant and the corresponding edge plotted.</p> <p>One can also change the maximum thickness of a line with the argument <code>maximum_thickness</code>.</p> <ol> <li> <p>I.M Sobol\u2032. Global sensitivity indices for nonlinear mathematical models and their Monte Carlo estimates. Mathematics and Computers in Simulation, 55(1):271\u2013280, 2001.\u00a0\u21a9</p> </li> <li> <p>Andrea Saltelli, Marco Ratto, Terry Andres, Francesca Campolongo, Jessica Cariboni, Debora Gatelli, Michaela Saisana, and Stefano Tarantola. Global sensitivity analysis: the primer. John Wiley &amp; Sons, 2008.\u00a0\u21a9</p> </li> <li> <p>Bertrand Iooss and Paul Lema\u00eetre. A review on global sensitivity analysis methods. Uncertainty management in simulation-optimization of complex systems: algorithms and applications, pages 101\u2013122, 2015.\u00a0\u21a9</p> </li> <li> <p>Thomas Muehlenstaedt, Olivier Roustant, Laurent Carraro, and Sonja Kuhnt. Data-driven Kriging models based on FANOVA-decomposition. Statistics and Computing, 22:723\u2013738, 2012.\u00a0\u21a9</p> </li> </ol>"},{"location":"user_guide/visualization/uncertain_coupling_graph/","title":"Uncertain coupling graph","text":""},{"location":"user_guide/visualization/uncertain_coupling_graph/#uncertain-coupling-graph","title":"Uncertain coupling graph","text":""},{"location":"user_guide/visualization/uncertain_coupling_graph/#introduction","title":"Introduction","text":"<p>Standard sensitivity analysis<sup>1</sup><sup>2</sup> seeks to identify the uncertain inputs that have an impact on a model output. Similarly, in the case of a multidisciplinary system, some uncertain inputs can have a more significant impact on certain disciplines.</p>"},{"location":"user_guide/visualization/uncertain_coupling_graph/#graph","title":"Graph","text":"<p>Then, the goal of the UncertainCouplingGraph proposed by GEMSEO-UMDO is to identify:</p> <ul> <li>the coupling variables that are not impacted by the uncertain inputs,</li> <li>the disciplines that are not impacted by the uncertain inputs.</li> </ul> <p>The nodes of this graph represent the disciplines while the edges represent the coupling variables.</p> <p>The thickness of an edge is proportional to the absolute value of the dispersion of the corresponding coupling variable.</p> <p>A node connected only by ultra-thin edges will therefore be judged to be very insensitive to uncertain inputs.</p>"},{"location":"user_guide/visualization/uncertain_coupling_graph/#dispersion-measures","title":"Dispersion measures","text":"<p>The dispersion of a coupling variable is computed using a DispersionMeasure. GEMSEO-UMDO proposes two dispersion measures.</p> <p>The coefficient of variation (COV) represents the standard deviation normalized by the mean value:</p> \\[\\textrm{COV}[Y]=\\frac{\\mathbb{S}[Y]}{\\mathbb{E}[Y]}\\] <p>where \\(\\mathbb{E}[Y]\\) and \\(\\mathbb{S}[Y]\\) are the expectation and standard deviation of the random variable \\(Y\\). \\(\\textrm{COV}[Y]\\) tends to infinity as \\(\\textrm{E}[Y]\\) tends to 0, which makes it sensitive to small changes in \\(\\textrm{E}[Y]\\) for values near zero.</p> <p>The quartile coefficient of dispersion (QCD) represents the interquartile range (IQR) normalized by the sum of the first and third quartile:</p> \\[\\textrm{QCD}[Y]=\\frac{\\mathbb{q}_{75\\%}[Y]-\\mathbb{q}_{25\\%}[Y]}{\\mathbb{q}_{25\\%}[Y]+\\mathbb{q}_{75\\%}[Y]}\\] <p>where \\(\\mathbb{q}_{\\alpha}[Y]\\) is the \\(\\alpha\\)-quantile of \\(Y\\).</p>"},{"location":"user_guide/visualization/uncertain_coupling_graph/#api","title":"API","text":"<p>Firstly, the UncertainCouplingGraph is built from a collection of disciplines, an uncertain space and possibly a subset of coupling variable names.</p> <pre><code>graph = UncertainCouplingGraph(disciplines, uncertain_space)\n</code></pre> <p>Then, the disciplines are sampled using an optimized Latin hypercube sampling technique:</p> <pre><code>graph.sample(100)\n</code></pre> <p>Warning</p> <p>Setting the number of samples is mandatory. In the previous example, we used 100 samples.</p> <p>Lastly, this graph can be both displayed in a window and saved on the disk:</p> <pre><code>graph.visualize()\n</code></pre> <p></p> <p>Uncertainty coupling graph from the Sobieski's SSBJ problem.</p> <p>Note</p> <p>Several examples of uncertain coupling graphs, including this one, can be found in a dedicated gallery.</p>"},{"location":"user_guide/visualization/uncertain_coupling_graph/#options","title":"Options","text":"<p>At the sampling stage, the algorithm can be modified by setting the arguments <code>algo_name</code> and <code>algo_options</code> of the method sample().</p> <p>At the visualization stage, the string argument <code>dispersion_measure</code> allows to change the dispersion measure (QCD by default).</p> <p>It is also possible to filter some coupling variables with the argument <code>variable_names</code> (all coupling variables are displayed by default).</p> <p>Lastly, the float argument <code>maximum_thickness</code> can be used to set the maximum edge thickness.</p> <ol> <li> <p>Andrea Saltelli, Marco Ratto, Terry Andres, Francesca Campolongo, Jessica Cariboni, Debora Gatelli, Michaela Saisana, and Stefano Tarantola. Global sensitivity analysis: the primer. John Wiley &amp; Sons, 2008.\u00a0\u21a9</p> </li> <li> <p>Bertrand Iooss and Paul Lema\u00eetre. A review on global sensitivity analysis methods. Uncertainty management in simulation-optimization of complex systems: algorithms and applications, pages 101\u2013122, 2015.\u00a0\u21a9</p> </li> </ol>"}]}