{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# The Rosenbrock mono-disciplinary problem\n\nIn this example, we consider the Rosenbrock mono-disciplinary optimization problem\n\n$$\\min_{x,y\\in[-2,2]} \\mathbb{E}[(U-x)^2+100(y-x^2)^2]$$\n\nwhere $U\\sim\\mathcal{N}(0,0.0025)$ is a Gaussian variable and $\\mathbb{E}$ is the\nexpectation operator.\n\nIn the following, we will call $f$ the function computing $(U-x)^2+100(y-x^2)^2$ given\n$x$, $y$ and $U$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nconfigure_logger()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Firstly,\nwe define the discipline implementing the Rosenbrock function $f$:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "discipline = AnalyticDiscipline({\"z\": \"(u-x)**2+100*(y-x**2)**2\"}, name=\"Rosenbrock\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "where $x,y$ belongs to the interval $[-2,2]$:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "design_space = DesignSpace()\ndesign_space.add_variable(\"x\", l_b=-2, u_b=2.0, value=-2.0)\ndesign_space.add_variable(\"y\", l_b=-2, u_b=2.0, value=-2.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and $U$ is a Gaussian variable with unit mean\nand standard deviation equal to 0.05:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "uncertain_space = ParameterSpace()\nuncertain_space.add_random_variable(\"u\", \"OTNormalDistribution\", mu=1.0, sigma=0.05)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then,\nwe define a [UMDOScenario][gemseo_umdo.scenarios.umdo_scenario.UMDOScenario]\nto minimize the statistic $\\mathbb{E}[(U-x)^2+100(y-x^2)^2]$\nestimated using a control variates technique\nbased on Taylor polynomials and 50 samples at each iteration of the optimization loop:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scenario = UMDOScenario(\n    [discipline],\n    \"DisciplinaryOpt\",\n    \"z\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    statistic_estimation=\"ControlVariate\",\n    statistic_estimation_parameters={\"n_samples\": 30},\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We execute it with the gradient-based optimizer SLSQP:\n\n!!! warning\n    The implementation of statistic estimators do not allow for the moment\n    to use analytical derivatives.\n    Please use finite differences or complex step to approximate the gradients.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scenario.set_differentiation_method(\"finite_differences\")\nscenario.execute({\"algo\": \"NLOPT_SLSQP\", \"max_iter\": 100})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and plot the optimization history:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scenario.post_process(\"OptHistoryView\", save=False, show=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lastly,\nwe can compare the numerical solution of this Rosenbrock problem under uncertainty\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "(scenario.optimization_result.x_opt, scenario.optimization_result.f_opt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "to the solution of the Rosenbrock problem without uncertainty,\nnamely\n$(x^*,f^*)=([1, 1], 0)$.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}