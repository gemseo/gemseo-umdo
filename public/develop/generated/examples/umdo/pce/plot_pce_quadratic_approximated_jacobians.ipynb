{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# A quadratic mono-disciplinary problem with approximated statistics Jacobian\n\nIn this example, we consider the quadratic mono-disciplinary optimization problem\n\n$$\\min_{x\\in[-1,1]} \\mathbb{E}[(x+U)^2]$$\n\nwhere $U\\sim\\mathcal{N}(0,1)$ is a standard Gaussian variable and $\\mathbb{E}$ is the\nexpectation operator.\n\nThe objective can be rewritten as $x^2+1$ and then the solution is obvious, namely\n\n$$(x^*,\\mathbb{E}[(x^*+U)^2])=(0,1).$$\n\nIn the following, we will call $f$ the function computing $(x+U)^2$ given $x$ and $U$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.auto_py import AutoPyDiscipline\n\nfrom gemseo_umdo.formulations.pce_settings import PCE_Settings\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nconfigure_logger()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Firstly,\nwe define an [AnalyticDiscipline][gemseo.disciplines.analytic.AnalyticDiscipline]\nimplementing the function $f$:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def f(x, u):\n    y = (x + u) ** 2\n    return y\n\n\ndiscipline = AutoPyDiscipline(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "as well as the design space:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "design_space = DesignSpace()\ndesign_space.add_variable(\"x\", lower_bound=-1, upper_bound=1.0, value=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and the uncertain space:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "uncertain_space = ParameterSpace()\nuncertain_space.add_random_variable(\"u\", \"OTNormalDistribution\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then,\nwe define a [UMDOScenario][gemseo_umdo.scenarios.umdo_scenario.UMDOScenario]\nto minimize the statistic $\\mathbb{E}[(x+U)^2]$\nestimated using a polynomial chaos expansion (PCE)\ntrained from 20 samples at each iteration of the optimization loop:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scenario = UMDOScenario(\n    [discipline],\n    \"y\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    formulation_name=\"DisciplinaryOpt\",\n    statistic_estimation_settings=PCE_Settings(\n        n_samples=20, approximate_statistics_jacobians=True\n    ),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "!!! note\n    The mean, standard deviation and variance\n    of the PCE built over the uncertain space\n    are differentiable with respect to the design variables\n    if both the disciplines and the MDO formulation are differentiable,\n    which is the case in this example.\n    This implies that a gradient-based optimization algorithm can be used\n    without approximating the derivatives of the objective.\n    If this is not the case\n    or if we do not want to compute the derivatives of the disciplines\n    to reduce the calculation budget,\n    we can activate the `approximate_statistics_jacobians` option as done above\n    to use the approximation technique\n    proposed in Section II.C.3 of a paper by Mura _et al._[@Mura2020]\n    and parametrized by the `differentiation_step` option (default: `1e-6`) .\n\nWe execute this scenario using the gradient-base optimizer SLSQP:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scenario.execute(algo_name=\"NLOPT_SLSQP\", max_iter=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and plot the optimization history:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scenario.post_process(post_name=\"OptHistoryView\", save=False, show=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice that the numerical solution\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "(scenario.optimization_result.x_opt[0], scenario.optimization_result.f_opt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "is close to the theoretical solution $(x^*,\\mathbb{E}[(x^*+U)^2])=(0,1)$.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.22"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}