{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Managing uncertain equality constraints\n\nThis example shows a simple way\nto manage an uncertain equality constraint associated with a threshold,\nby forcing the mean of its left-hand side to be equal to this threshold\nand its variance to be zero.\n\nThe reference optimization problem consists in\nminimizing the Rosenbrock function $f(x,y)=(1-x)^2+100(y-x^2)^2$ over $[-2,2]^2$\nunder the equality constraint $h(x,y)=r^2$ with $h(x,y)=(x-1)^2+(y-1)^2$ and $r=0.25$.\n\nIn the following,\nwe suppose that $f(x,y)$ and $h(x,y)$ depend on uncertain parameters $a$ and $b$,\nas $f(x,y)=(a-x)^2+100(y-x^2)^2$ and $h(x,y)=(x-b)^2+(y-1)^2$,\nand seek to minimize $\\mathbb{E}[f(x,y)]$\nunder the equality constraints $\\mathbb{E}[h(x,y)]=r^2$ and $\\mathbb{V}[h(x,y)]=0$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gemseo import configure_logger\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\nfrom gemseo.scenarios.mdo_scenario import MDOScenario\nfrom matplotlib import pyplot as plt\nfrom matplotlib.pyplot import colormaps\nfrom numpy import array\n\nfrom gemseo_umdo.formulations.sampling_settings import Sampling_Settings\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nconfigure_logger()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Discipline and design space\n\nFirst,\nwe create a discipline to evaluate $f$ and $h$\nfrom the design variables $x$ and $y$\nand from the uncertain variables $a$ and $b$ initialized at 1:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "discipline = AnalyticDiscipline({\n    \"f\": \"(a-x)**2+100*(y-x**2)**2\",\n    \"h\": \"(x-b)**2+(y-1)**2\",\n})\ndiscipline.io.input_grammar.defaults[\"a\"] = array([1.0])\ndiscipline.io.input_grammar.defaults[\"b\"] = array([1.0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then,\nwe create the design space:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "design_space = DesignSpace()\ndesign_space.add_variable(\"x\", lower_bound=-2, upper_bound=2.0)\ndesign_space.add_variable(\"y\", lower_bound=-2, upper_bound=2.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and the initial design point:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "initial_design = array([1.75, 1.75])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For visualization purposes,\nwe sample the objective function over a regular grid:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scenario = MDOScenario(\n    [discipline],\n    \"f\",\n    design_space,\n    formulation_name=\"DisciplinaryOpt\",\n)\nscenario.execute(algo_name=\"OT_FULLFACT\", n_samples=20 * 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and store the 400 samples:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "samples = scenario.to_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Constrained optimization problem\n\nThen,\nwe define the uncertainty-free constrained optimization problem:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "radius = 0.25\nscenario = MDOScenario(\n    [discipline],\n    \"f\",\n    design_space,\n    formulation_name=\"DisciplinaryOpt\",\n)\nscenario.add_constraint(\"h\", value=radius**2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and solve it using the gradient-based SLSQP algorithm:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scenario.execute(algo_name=\"SLSQP\", max_iter=100)\nx_opt = scenario.optimization_result.x_opt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Constrained optimization problem under uncertainty\n\nLastly,\nwe create the constrained optimization problem under uncertainty.\n\n### Uncertain space\n\nFirst,\nwe need to define the uncertain space\nwith independent normal variables centered at 1 with standard deviation equal to 1/6:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "uncertain_space = ParameterSpace()\nuncertain_space.add_random_variable(\"a\", \"OTNormalDistribution\", mu=1.0, sigma=1 / 6)\nuncertain_space.add_random_variable(\"b\", \"OTNormalDistribution\", mu=1.0, sigma=1 / 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem\n\nThen,\nwe reset the design space to the initial solution\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "design_space.set_current_value(initial_design)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and create the scenario\nby forcing the mean of $h(x,y)$ to be equal to $r^2$ and its variance to be zero:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scenario = UMDOScenario(\n    [discipline],\n    \"f\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    Sampling_Settings(n_samples=100, estimate_statistics_iteratively=False),\n    formulation_name=\"DisciplinaryOpt\",\n)\nscenario.add_constraint(\"h\", \"Mean\", constraint_type=\"eq\", value=radius**2)\nscenario.add_constraint(\"h\", \"Variance\", constraint_type=\"eq\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally,\nwe solve this optimization problem using the gradient-based SLSQP algorithm:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scenario.execute(algo_name=\"SLSQP\", max_iter=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results\nIn this last section,\nwe plot and analyze the results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n# The Rosenbrock function plotted as filled contours:\nax.contourf(\n    samples.get_view(variable_names=\"x\").to_numpy().reshape((20, 20)),\n    samples.get_view(variable_names=\"y\").to_numpy().reshape((20, 20)),\n    samples.get_view(variable_names=\"f\").to_numpy().reshape((20, 20)),\n    levels=20,\n    cmap=colormaps[\"Greys\"],\n)\n# The initial design solution:\nax.plot(*initial_design, \"dk\", label=\"Initial solution\")\n# The solution of the uncertainty-free unconstrained optimization problem:\nax.plot(1.0, 1.0, \"*k\", label=\"argmin f(a=1,x,y)\")\n# The solution of the uncertainty-free constrained optimization problem:\nax.plot(\n    *x_opt,\n    \"ob\",\n    label=\"argmin f(a=1,x,y) s.t. h(b=1,x,y)=r\u00b2\",\n)\n# The level set associated with the equality constraint:\nax.add_patch(plt.Circle((1.0, 1.0), radius, fill=False, label=\"x,y s.t. h(b=1,x,y)=r\u00b2\"))\n# The solution of the constrained optimization problem under uncertainty:\nax.plot(\n    *scenario.optimization_result.x_opt,\n    \"sr\",\n    label=\"argmin E[f(a,x,y)] s.t. E[h(b,x,y)]=r\u00b2 and V[h(b,x,y)]=0\",\n)\nax.set_aspect(\"equal\", adjustable=\"box\")\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that\nthe uncertainty-free and uncertainty-based optima are close but different.\nWe can also note that\nthe solution under uncertainty is unfortunately not feasible.\nThis could be corrected by better tuning the statistics estimation algorithm\nor by changing the optimization algorithm.\nHowever,\nthis is beyond the scope of this example,\nthe aim of which is to show a simple way of dealing with equality constraints.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}