{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Control variate vs Sampling\n\nIn this example,\nwe will compare the performance of the `Sampling` and `ControlVariate` techniques\nto estimate statistics in an MDO problem under uncertainty.\nFor that purpose,\nwe consider a version of the Rosenbrock problem under uncertainty:\n\n$$\\min_{x_1,x_2\\in[-1,2]} \\mathbb{E}[f(x_1,x_2,U)]$$\n\nwhere $f(x_1,x_2,u)=(u-x_1)^2+100(x_2-x_1^2)^2$\nand $U$ is a Gaussian random variable with mean 1 and standard deviation 0.1.\n\nNote that this problem can be rewritten as\n\n$$\\min_{x_1,x_2\\in[-1,2]} \\sigma^2 + \\tilde{f}(x_1,x_2)$$\n\nwhere $\\tilde{f}(x_1,x_2)=f(x_1,x_2,1)$ is the standard Rosenbrock function.\nTherefore,\nthe analytical solution is $(x^*,f(x_1^*,x_2^*))=((1,1),0)$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n\nfrom typing import TYPE_CHECKING\n\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.datasets.dataset import Dataset\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\nfrom gemseo.post.dataset.boxplot import Boxplot\nfrom gemseo.settings.doe import OT_MONTE_CARLO_Settings\nfrom numpy import array\nfrom numpy.linalg import norm\n\nfrom gemseo_umdo.formulations.control_variate_settings import ControlVariate_Settings\nfrom gemseo_umdo.formulations.sampling_settings import Sampling_Settings\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nif TYPE_CHECKING:\n    from gemseo.typing import RealArray\n\n    from gemseo_umdo.formulations.base_umdo_formulation_settings import (\n        BaseUMDOFormulationSettings,\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First,\nwe define the discipline\nto compute the output $z=f(x_1,x_2,u)$ from the inputs $x_1$, $x_2$ and $u$:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "discipline = AnalyticDiscipline({\"z\": \"(u-x1)**2+100*(x2-x1**2)**2\"}, name=\"f\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "as well as the design space $[-2,2]^2$:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "design_space = DesignSpace()\ndesign_space.add_variable(\"x1\", lower_bound=-2, upper_bound=2.0, value=-2.0)\ndesign_space.add_variable(\"x2\", lower_bound=-2, upper_bound=2.0, value=-2.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and the uncertain space:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "uncertain_space = ParameterSpace()\nsigma = 0.1\nuncertain_space.add_random_variable(\"u\", \"OTNormalDistribution\", mu=1.0, sigma=sigma)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then,\nwe create a function to solve the optimization problem under uncertainty\nfrom a statistics estimation technique\nand a seed for the pseudo-random numbers generator:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def solve_problem(\n    settings_class: type[BaseUMDOFormulationSettings], seed: int\n) -> RealArray:\n    \"\"\"Solve the optimization problem under uncertainty.\n\n    Args:\n        settings_class: The class\n            for defining the settings of the statistics estimation technique.\n        seed: The seed for the pseudo-random numbers generator.\n\n    Returns:\n        The optimal values of the design variables.\n    \"\"\"\n    discipline.cache.clear()\n    scenario = UMDOScenario(\n        [discipline],\n        \"z\",\n        design_space,\n        uncertain_space,\n        \"Mean\",\n        formulation_name=\"DisciplinaryOpt\",\n        statistic_estimation_settings=settings_class(\n            doe_algo_settings=OT_MONTE_CARLO_Settings(n_samples=50, seed=i)\n        ),\n    )\n    scenario.set_differentiation_method(\"finite_differences\")\n    scenario.execute(algo_name=\"NLOPT_SLSQP\", max_iter=100)\n    return scenario.optimization_result.x_opt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now,\nwe are ready to solve the optimization problem under uncertainty\nwith the `Sampling` and `ControlVariate` techniques\nand repeat this experiment 10 times to account for samples variability:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x_opt_s = []\nx_opt_cv = []\nx_star = array([1.0, 1.0])\nfor i in range(20):\n    x_opt = solve_problem(Sampling_Settings, i)\n    x_opt_s.append([norm(x_opt - x_star)])\n    x_opt = solve_problem(ControlVariate_Settings, i)\n    x_opt_cv.append([norm(x_opt - x_star)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In these lines,\nthe point `x_star` represents the analytical solution $x^*$\nwhile `x_opt_method[i]` represents the numerical solution obtained\nwith the method `Sampling` (s) or `ControlVariate` (cv)\nat the `i`-th repetition.\n\nFinally,\nwe use boxplots to compare the `Sampling` and `ControlVariate` techniques\nin terms of estimation error\nby looking not only at the average value but also at the variability.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset_s = Dataset()\ndataset_s.add_variable(\"x_opt\", x_opt_s)\ndataset_s.name = \"Sampling\"\n\ndataset_cv = Dataset()\ndataset_cv.add_variable(\"x_opt\", x_opt_cv)\ndataset_cv.name = \"Control variate\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below are the boxplots\nshowing the estimation error in the Euclidean norm for the optimal design:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "boxplot = Boxplot(dataset_s, dataset_cv, variables=[\"x_opt\"])\nboxplot.execute(save=False, show=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the results are more accurate with the `ControlVariate` technique\neven though the calculation budget is the same.\n\nTo conclude,\nthe [control variates](https://en.wikipedia.org/wiki/Control_variates) method\nis a powerful variance reduction technique\nand its combination with surrogate models,\nsuch as first-order Taylor polynomial in this example,\ncan facilitate its adoption in many contexts.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}