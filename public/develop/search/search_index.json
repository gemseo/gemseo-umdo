{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":""},{"location":"#gemseo-umdo","title":"gemseo-umdo","text":""},{"location":"#overview","title":"Overview","text":"<p><code>gemseo-umdo</code> is a plugin of the library GEMSEO, dedicated to multidisciplinary optimization (MDO) under uncertainty.</p>"},{"location":"#mdo-under-uncertainty","title":"MDO under uncertainty","text":"<p>The main goal of <code>gemseo-umdo</code> is to extend GEMSEO to MDO under uncertainty.</p> <p>Given a collection of disciplines, we are interested in solving a problem like</p> \\[ \\begin{align} &amp;\\underset{x\\in\\mathcal{X}}{\\operatorname{minimize}}&amp; &amp; \\mathbb{E}[f(x,U)]+\\kappa\\times\\mathbb{S}[f(x,U)] \\\\ &amp;\\operatorname{subject\\;to} &amp; &amp;\\mathbb{P}[g(x,U)\\geq 0] \\leq \\varepsilon \\end{align} \\] <p>by selecting an MDO formulation to handle the multidisciplinary coupling and an estimation technique to approximate the statistics.</p>"},{"location":"#statistics","title":"Statistics","text":"<p><code>gemseo-umdo</code> also proposes advanced techniques for uncertainty quantification and management (UQ&amp;M). In presence of multilevel simulators, multilevel Monte Carlo (MLMC) sampling can reduce the variance of the statistics estimators. Another variance reduction technique consists of using the outputs of surrogate models as control variates, even moderately correlated with the original models.</p>"},{"location":"#visualization","title":"Visualization","text":"<p>A third facet of <code>gemseo-umdo</code> is the visualization toolbox to display the propagation of the uncertainties through a multidisciplinary system as well as the interaction between the uncertain input variables.</p>"},{"location":"#installation","title":"Installation","text":"<p>Install the latest version with <code>pip install gemseo-umdo</code>.</p> <p>See pip for more information.</p>"},{"location":"#bugs-and-questions","title":"Bugs and questions","text":"<p>Please use the gitlab issue tracker to submit bugs or questions.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>See the contributing section of GEMSEO.</p>"},{"location":"#contributors","title":"Contributors","text":"<ul> <li>Antoine Dechaume</li> <li>Matthias De Lozzo</li> </ul>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#changelog","title":"Changelog","text":"<p>All notable changes of this project will be documented here.</p> <p>The format is based on Keep a Changelog and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#version-300-november-2024","title":"Version 3.0.0 (November 2024)","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Support GEMSEO v6.</li> <li>Support for Python 3.12.</li> <li>The U-MDO formulation PCE creates a polynomial chaos expansion (PCE)   over the uncertain space at each iteration of the optimization loop and uses the coefficients of the PCE   to estimate the following statistics: <code>Mean</code>, <code>StandardDeviation</code>, <code>Margin</code> and <code>Variance</code>.</li> <li>The U-MDO formulation Surrogate creates a surrogate model   over the uncertain space at each iteration of the optimization loop and uses Monte Carlo sampling   to estimate the following statistics: <code>Mean</code>, <code>StandardDeviation</code>, <code>Margin</code>, <code>Probability</code> and <code>Variance</code>.</li> <li>The U-MDO formulations   Sampling and   SequentialSampling   have an option <code>samples_directory_path</code>   to save the samples at each iteration of the algorithm chosen for the execution of the   UDOEScenario   or UMDOScenario.</li> <li>The U-MDO formulation SequentialSampling   has an option <code>estimate_statistics_iteratively</code> (default: <code>True</code>)   to compute the statistics iteratively   and so do not store the samples in a <code>Database</code>.</li> <li>The dictionary argument <code>uncertain_design_variables</code> of   UDOEScenario   and UMDOScenario   can now accept values such as <code>(\"+\", \"u\")</code> and <code>(\"*\", \"u\")</code>   to noise the corresponding key <code>x</code> as <code>x = dv_x + u</code> and <code>x = dv_x * (1 + u)</code>   where <code>x</code> is a discipline input made uncertain by the random variable <code>u</code>.</li> <li>AdditiveNoiser   and   MultiplicativeNoiser   are disciplines to noise a design variable \\(x\\) as \\(X=x+U\\) and \\(X=x(1+U)\\) respectively   where \\(U\\) is a random variable.   BaseNoiser   can be used to create other noising disciplines   and a specific   NoiserFactory   is available.</li> <li>ControlVariate,   a new BaseUMDOFormulation   estimating the statistics with a control variate technique based on Taylor polynomials.</li> </ul>"},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>The default value of the <code>initial_n_samples</code> argument of   SequentialSampling   is 2 instead of 1,   because the default DOE algorithm (<code>\"OT_OPT_LHS\"</code>) requires at least 2 samples.</li> <li><code>gemseo_umdo.scenarios._uscenario._UScenario</code> renamed to <code>gemseo_umdo.scenarios.base_u_scenario.BaseUScenario</code>.</li> <li>API CHANGE: <code>gemseo_umdo.statistics.mlmc.pilots.pilot.MLMCPilot</code> renamed to <code>gemseo_umdo.statistics.mlmc.pilots.base_mlmc_pilot.BaseMLMCPilot</code>.</li> <li>API CHANGE: <code>gemseo_umdo.statistics.mlmc_mlcv.pilots.pilot.MLMCMLCVPilot</code> renamed to <code>gemseo_umdo.statistics.mlmc_mlcv.pilots.base_mlmc_mlcv_pilot.BaseMLMCMLCVPilot</code>.</li> <li>API CHANGE: <code>gemseo_umdo.statistics.pilot.Pilot</code> renamed to <code>gemseo_umdo.statistics.base_pilot.BasePilot</code>.</li> <li>API CHANGE: <code>gemseo_umdo.formulations.formulation.UMDOFormulation</code> renamed to <code>gemseo_umdo.formulations.base_umdo_formulation.BaseUMDOFormulation</code>.</li> <li>API CHANGE: <code>gemseo_umdo.formulations.statistics</code> is now a protected package.</li> <li>API CHANGE: <code>gemseo_umdo.formulations.functions</code> is now a protected package.</li> <li>The BeamConstraints discipline   computed outputs of the form <code>a/(b+eps)</code> where <code>eps</code> was used to avoid division by zero.   Now,   this discipline computes outputs of the form <code>b/a</code>   as <code>a</code> is never zero.</li> </ul>"},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>The U-MDO formulation Sampling   works properly when the option <code>estimate_statistics_iteratively</code>  is <code>True</code>   and the DOE option <code>n_processes</code> is greater than 1.</li> <li>The docstring of the <code>uncertain_design_variables</code> argument of   UDOEScenario   and UMDOScenario   explains that specifying a value such as <code>\"{} + u\"</code> at key <code>\"x\"</code>   assumes that both the uncertain design variable <code>\"x\"</code>   and the uncertain variable <code>\"u\"</code> are scalar variables.</li> <li>The discipline transforming the design variables into uncertain design variables   is placed before the user's disciplines;   by doing so,   the uncertain design variables can be propagated   through the multidisciplinary process   even with MDO formulations that do not ensure the satisfaction of couplings,   such as DisciplinaryOpt.</li> </ul>"},{"location":"changelog/#version-201-january-2024","title":"Version 2.0.1 (January 2024)","text":""},{"location":"changelog/#fixed_1","title":"Fixed","text":"<ul> <li>The U-MDO formulations handle the finite-difference approximation of derivatives.</li> </ul>"},{"location":"changelog/#version-200-december-2023","title":"Version 2.0.0 (December 2023)","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>Support for Python 3.11.</li> <li>A web documentation.</li> <li>The heat equation problem (   HeatEquationConfiguration,   HeatEquationDiscipline,   HeatEquationModel   and HeatEquationUncertainSpace)   to illustrate the algorithms MLMC   and MLMCMLCV.</li> <li>The MLMC and   the MLMCMLCV   algorithms to estimate a statistic of the output of a function   whose input is random.</li> <li>The MonteCarloSampler   to sample vectorized functions.</li> <li>UncertainCouplingGraph   has a new option <code>save</code> (default: <code>True</code>).</li> <li>The U-MDO formulation Sampling   has an option <code>estimate_statistics_iteratively</code> (default: <code>True</code>)   to compute the statistics iteratively   and so do not store the samples in a <code>Database</code>.</li> <li>The package <code>gemseo_umdo.formulations.functions</code> contains the <code>MDOFunction</code>s   used by a UMDOFormulation   to compute the statistics of the objective, constraints and observables.</li> <li>The logs of the UDOEScenario   and UMDOScenario   include the uncertain space.</li> </ul>"},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>Setting the argument <code>n_samples</code>   of the U-MDO formulation Sampling   is mandatory for many DOE algorithms   but optional in the case where   the DOE algorithm does not consider a <code>n_samples</code> argument to generate the samples.</li> <li>The estimator of the <code>Variance</code>   used by the U-MDO formulation Sampling   with <code>estimate_statistics_iteratively=False</code> is now unbiased.</li> <li>API changes:</li> <li>The options of the statistics estimators     are now set at instantiation instead of execution.</li> <li><code>gemseo_umdo.estimators</code> has been renamed to <code>gemseo_umdo.formulations.statistics</code>.</li> <li>The log of the statistics no longer includes design variables and uncertain inputs   (e.g. <code>E[y(x; u)]</code>),   but only uncertain output  (e.g. <code>E[y]</code>) to avoid display problems in large dimensions.</li> </ul>"},{"location":"changelog/#fixed_2","title":"Fixed","text":"<ul> <li>The UDOEScenario   and UMDOScenario   maximize the statistic of the objective   when the argument <code>maximize_objective</code> is set to <code>True</code>.</li> <li>The log of the objective and constraint is now consistent   with the arguments <code>maximize_objective</code> and <code>constraint_name</code>.</li> </ul>"},{"location":"changelog/#removed","title":"Removed","text":"<ul> <li>Support for Python 3.8.</li> </ul>"},{"location":"changelog/#version-111-october-2023","title":"Version 1.1.1 (October 2023)","text":""},{"location":"changelog/#fixed_3","title":"Fixed","text":"<ul> <li>One test was not compatible with GEMSEO 5.1+.</li> </ul>"},{"location":"changelog/#version-110-june-2023","title":"Version 1.1.0 (June 2023)","text":""},{"location":"changelog/#added_2","title":"Added","text":"<ul> <li>The beam problem (Beam,   BeamConstraints,   BeamUncertainSpace   and BeamDesignSpace   to benchmark robust optimization algorithms.</li> <li>TaylorPolynomial,   a new UMDOFormulation   estimating the statistics with Taylor polynomials.</li> <li>SequentialSampling,   a new UMDOFormulation   estimating the statistics with sequential sampling.</li> <li>UncertainCouplingGraph   to visualize the dispersion of the coupling variables.</li> <li>SobolGraph   to visualize the first-, second- and total-order Sobol' indices.</li> <li>The set of SpringMassModel,   SpringMassDiscipline   and SpringMassUncertainSpace   is a use case based on a spring-mass system.</li> </ul>"},{"location":"changelog/#fixed_4","title":"Fixed","text":"<ul> <li>The <code>_UScenario</code> no longer changes the list of disciplines passed by the user.</li> </ul>"},{"location":"changelog/#version-101-january-2023","title":"Version 1.0.1 (January 2023)","text":""},{"location":"changelog/#changed_2","title":"Changed","text":"<ul> <li>API change: the argument <code>statistic_estimation_options</code>   of UMDOFormulation   has been renamed to <code>statistic_estimation_parameters</code>.</li> <li>API change: <code>UMDOFormulation._processed_functions</code> replaces <code>Sampling.processed_functions</code>.</li> </ul>"},{"location":"changelog/#version-100-july-2022","title":"Version 1.0.0 (July 2022)","text":"<p>First release.</p>"},{"location":"credits/","title":"Credits","text":""},{"location":"credits/#exec-1--credits","title":"Credits","text":"<p>The developers thank all the open source libraries making <code>gemseo-umdo</code> possible.</p>"},{"location":"credits/#exec-1--external-dependencies","title":"External Dependencies","text":"<p><code>gemseo-umdo</code> depends on software with compatible licenses that are listed below.</p> Project License <code>Python</code> Python Software License <code>gemseo</code> GNU Lesser General Public License v3 <code>matplotlib</code> Python Software Foundation License <code>numpy</code> BSD License <code>scipy</code> BSD License"},{"location":"credits/#exec-1--external-applications","title":"External applications","text":"<p>Some external applications are used by <code>gemseo-umdo</code>, but not linked with the application, for testing, documentation generation, training or example purposes.</p> Project License <code>black</code> MIT <code>commitizen</code> MIT License <code>covdefaults</code> MIT License <code>griffe-inherited-docstrings</code> ISC <code>insert-license</code> MIT <code>markdown-exec</code> ISC <code>mike</code> BSD-3-Clause <code>mkdocs-bibtex</code> BSD-3-Clause-LBNL <code>mkdocs-gallery</code> BSD 3-Clause <code>mkdocs-gen-files</code> MIT License <code>mkdocs-include-markdown-plugin</code> Apache-2.0 <code>mkdocs-literate-nav</code> MIT License <code>mkdocs-material</code> MIT License <code>mkdocs-section-index</code> MIT License <code>mkdocstrings</code> ISC <code>pre-commit</code> MIT License <code>pygrep-hooks</code> MIT <code>pytest</code> MIT License <code>pytest-cov</code> MIT License <code>pytest-xdist</code> MIT License <code>ruff</code> MIT License <code>setuptools</code> MIT License <code>setuptools-scm</code> MIT License"},{"location":"licenses/","title":"Licenses","text":""},{"location":"licenses/#licenses","title":"Licenses","text":""},{"location":"licenses/#gnu-lgpl-v30","title":"GNU LGPL v3.0","text":"<p>The <code>gemseo-umdo</code> source code is distributed under the GNU LGPL v3.0 license. <pre><code>Copyright 2021 IRT Saint Exup\u00e9ry, https://www.irt-saintexupery.com\n\nThis program is free software; you can redistribute it and/or\nmodify it under the terms of the GNU Lesser General Public\nLicense version 3 as published by the Free Software Foundation.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\nLesser General Public License for more details.\n\nYou should have received a copy of the GNU Lesser General Public License\nalong with this program; if not, write to the Free Software Foundation,\nInc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.\n</code></pre></p>"},{"location":"licenses/#bsd-0-clause","title":"BSD 0-Clause","text":"<p>The <code>gemseo-umdo</code> examples are distributed under the BSD 0-Clause <pre><code>Copyright 2021 IRT Saint Exup\u00e9ry, https://www.irt-saintexupery.com\n\nThis work is licensed under a BSD 0-Clause License.\n\nPermission to use, copy, modify, and/or distribute this software\nfor any purpose with or without fee is hereby granted.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL\nWARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL\nTHE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\nOR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING\nFROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT,\nNEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION\nWITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n</code></pre></p>"},{"location":"licenses/#cc-by-sa-40","title":"CC BY-SA 4.0","text":"<p>The <code>gemseo-umdo</code> documentation is distributed under the CC BY-SA 4.0 license. <pre><code>Copyright 2021 IRT Saint Exup\u00e9ry, https://www.irt-saintexupery.com\n\nThis work is licensed under the Creative Commons Attribution-ShareAlike 4.0\nInternational License. To view a copy of this license, visit\nhttp://creativecommons.org/licenses/by-sa/4.0/ or send a letter to Creative\nCommons, PO Box 1866, Mountain View, CA 94042, USA.\n</code></pre></p>"},{"location":"developer_guide/umdo/","title":"U-MDO","text":""},{"location":"developer_guide/umdo/#mdo-under-uncertainty","title":"MDO under uncertainty","text":"<p>This section describes the design of the disciplines, formulations and scenarios subpackages used to define and solve an MDO problem under uncertainty.</p> <p>Info</p> <p>Open the user guide for general information, e.g. concepts, API, examples, etc.</p>"},{"location":"developer_guide/umdo/#tree-structure","title":"Tree structure","text":"<pre><code>\ud83d\udcc1 gemseo_umdo\n\u251c\u2500\u2500 \ud83d\udcc1 disciplines # Subpackage including noising disciplines\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 additive_noiser.py # Noising discipline adding a random variable to a deterministic one\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 base_noiser.py # Base class for noising disciplines\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 multiplicative_noiser.py # Noising discipline multiplying a deterministic variable by a random one\n\u2502   \u2514\u2500\u2500 \ud83d\udcc4 noiser_factory.py # Factory of noising disciplines\n\u251c\u2500\u2500 \ud83d\udcc1 formulations # Subpackage including U-MDO formulations\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 factory.py # Factory of U-MDO formulations\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 base_umdo_formulation.py # Base class for U-MDO formulations\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 control_variate.py # U-MDO formulation estimating statistics using Taylor-based control variates\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 pce.py # U-MDO formulation estimating statistics using polynomial chaos expansions (PCE)\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 sampling.py # U-MDO formulation estimating statistics using Monte Carlo sampling\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 sequential_sampling.py # U-MDO formulation estimating statistics using Monte Carlo sampling\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 taylor_polynomial.py # U-MDO formulation estimating statistics using Taylor polynomials\n\u2502   \u251c\u2500\u2500 \ud83d\udcc1 _functions # Subpackage of statistic estimation functions to be used with EvaluationProblem\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 base_statistic_function.py # Base class for statistic estimation functions\n\u2502   \u2502   \u251c\u2500\u2500 \ud83d\udcc4 statistic_function_for_a_specific_u_mdo_formulation.py # Statistic estimation functions for a U-MDO formulation\n\u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc4 ...\n\u2502   \u2514\u2500\u2500 \ud83d\udcc1 _statistics # Subpackage of statistic estimators\n\u2502       \u251c\u2500\u2500 \ud83d\udcc4 base_statistic_estimator.py # Base class for statistic estimators\n\u2502       \u251c\u2500\u2500 \ud83d\udcc1 specific_u_mdo_formulation # The subpackage of statistic estimators associated with a specific U-MDO formulation\n\u2502       \u2502   \u251c\u2500\u2500 \ud83d\udcc4 base_sampling_estimator.py # The base class for statistic estimators associated with this U-MDO formulation\n\u2502       \u2502   \u251c\u2500\u2500 \ud83d\udcc4 mean.py # The estimator of the mean associated with this U-MDO formulation\n\u2502       \u2502   \u251c\u2500\u2500 \ud83d\udcc4 variance.py # The estimator of the variance associated with this U-MDO formulation\n\u2502       \u2502   \u2514\u2500\u2500 \ud83d\udcc4 ...\n\u2502       \u2514\u2500\u2500 \ud83d\udcc4 ...\n\u2514\u2500\u2500 \ud83d\udcc1 scenarios # Subpackage including scenarios using U-MDO formulations\n    \u251c\u2500\u2500 \ud83d\udcc4 base_u_scenario.py # Base scenario using a U-MDO formulation\n    \u251c\u2500\u2500 \ud83d\udcc4 udoe_scenario.py # DOE-based scenario using a U-MDO formulation\n    \u2514\u2500\u2500 \ud83d\udcc4 umdo_scenario.py # Optimizer-based scenario using a U-MDO formulation\n</code></pre>"},{"location":"developer_guide/umdo/#class-diagram","title":"Class diagram","text":"<p>A <code>BaseUScenario</code> is a <code>Scenario</code> with an API adapted to the definition of the uncertain space, statistics and the associated estimation techniques.</p> <p>A <code>BaseUScenario</code> is made of</p> <ul> <li>a <code>BaseUMDOFormulation</code>, which is an <code>MDOFormulation</code> depending on a standard <code>MDOFormulation</code>, e.g. <code>MDF</code>,</li> <li>a specific statistics estimation technique,   e.g. sampling,   whose class name corresponds to this technique,   e.g. <code>Sampling</code>.</li> </ul> <p>The standard <code>MDOFormulation</code> is in charge to define the multidisciplinary process for a specific design value and a specific uncertainty value while the estimation technique is in charge to</p> <ol> <li>sample this multidisciplinary process over the uncertain space,</li> <li>estimate the statistics by means of <code>BaseStatisticFunction</code>s    which are particular <code>MDOFunction</code>s    associated with the <code>OptimizationProblem</code> attached to the <code>UMDOFormulation</code>.</li> </ol> <p>A <code>BaseStatisticFunction</code> relies on a basic functor, called <code>BaseStatisticEstimator</code>.</p> <p>So, adding a new U-MDO formulation <code>Foo</code> implies to</p> <ul> <li>subclass <code>BaseUMDOFormulation</code> to <code>Foo</code>,</li> <li>subclass <code>BaseStatisticFunction</code> to <code>StasticFunctionForFoo</code>,</li> <li>subclass <code>BaseStatisticEstimator</code> to <code>BaseFooEstimator</code>,</li> <li>subclass <code>BaseFooEstimator</code> to <code>Mean</code>, <code>Variance</code>, etc.</li> </ul> <pre><code>classDiagram\n\n   BaseUScenario --|&gt; Scenario\n   BaseUScenario &lt;|-- UMDOScenario\n   MDOScenario &lt;|-- UMDOScenario\n\n   class BaseUScenario {\n    +add_constraint()\n    +add_observable()\n    +formulation_name\n    +mdo_formulation\n    +uncertain_space\n   }\n\n   BaseUScenario *-- BaseUMDOFormulation\n   BaseUMDOFormulation &lt;|-- BaseMDOFormulation\n   BaseUMDOFormulation o-- BaseMDOFormulation\n\n   class BaseUMDOFormulation {\n     +add_constraint()\n     +add_observable()\n     +get_expected_dataflow()\n     +get_expected_workflow()\n     +get_top_level_disc()\n     +input_data_to_output_data\n     +mdo_formulation\n     +name\n     +uncertain_space\n     +update_top_level_disciplines()\n   }\n\n   BaseUMDOFormulation o-- ParameterSpace: uncertain space\n   BaseUMDOFormulation \"1\" --&gt; \"n\" BaseStatisticFunction\n   BaseStatisticFunction *-- BaseStatisticEstimator\n\n   BaseUMDOFormulation &lt;|-- Sampling\n   MDOFunction &lt;|-- BaseStatisticFunction\n   BaseStatisticFunction &lt;|-- StatisticFunctionForStandardSampling\n   Sampling \"1\" --&gt; \"n\" StatisticFunctionForStandardSampling\n   StatisticFunctionForStandardSampling *-- BaseSamplingEstimator\n   BaseStatisticEstimator &lt;|-- BaseSamplingEstimator\n   BaseSamplingEstimator &lt;|-- Mean\n\n   BaseUMDOFormulation *-- OptimizationProblem\n   OptimizationProblem \"1\" o-- \"n\" BaseStatisticFunction\n\n   BaseUMDOFormulation \"1\" *-- \"n\" BaseNoiser\n   BaseNoiser --|&gt; MDODiscipline\n\n   &lt;&lt;abstract&gt;&gt; BaseUScenario\n   &lt;&lt;abstract&gt;&gt; BaseMDOFormulation\n   &lt;&lt;abstract&gt;&gt; BaseUMDOFormulation\n   &lt;&lt;abstract&gt;&gt; BaseStatisticFunction\n   &lt;&lt;abstract&gt;&gt; BaseStatisticEstimator\n   &lt;&lt;abstract&gt;&gt; BaseSamplingEstimator\n   &lt;&lt;abstract&gt;&gt; BaseNoiser\n\n   namespace Example {\n    class Sampling\n    class StatisticFunctionForStandardSampling\n    class BaseSamplingEstimator\n    class Mean\n   }\n\n   namespace gemseo {\n     class MDODiscipline\n     class MDOFunction\n     class MDOScenario\n     class ParameterSpace\n     class Scenario\n   }</code></pre>"},{"location":"generated/examples/problems/","title":"Problems","text":""},{"location":"generated/examples/problems/#problems","title":"Problems","text":""},{"location":"generated/examples/problems/#the-beam-problem","title":"The beam problem","text":"<p> Optimization problem. </p> <p> Sobol' sensitivity analysis. </p> <p> Robust optimization problem. </p> <p> Large DOE study. </p> <p> Download all examples in Python source code: problems_python.zip</p> <p> Download all examples in Jupyter notebooks: problems_jupyter.zip</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/problems/beam_model/mg_execution_times/","title":"Computation times","text":"<p>01:27.414 total execution time for generated_examples_problems_beam_model files:</p> <p>+------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_beam_rob_opt (docs/examples/problems/beam_model/plot_beam_rob_opt.py) | 01:13.672 | 0.0 MB | +------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_beam_opt (docs/examples/problems/beam_model/plot_beam_opt.py)             | 00:08.059 | 0.0 MB | +------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_beam_doe (docs/examples/problems/beam_model/plot_beam_doe.py)             | 00:03.770 | 0.0 MB | +------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_beam_sa (docs/examples/problems/beam_model/plot_beam_sa.py)                | 00:01.914 | 0.0 MB | +------------------------------------------------------------------------------------------------------+-----------+--------+</p>"},{"location":"generated/examples/problems/beam_model/plot_beam_doe/","title":"Large DOE study.","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/problems/beam_model/plot_beam_doe/#large-doe-study","title":"Large DOE study.","text":"<p>Sample the weight \\(w(h,t)\\) and the constraints \\(c_{\\text{stress}}(h,t)\\) and \\(c_{\\text{displacement}}(h,t)\\) w.r.t. the height \\(h\\in[500, 800]\\) and the thickness \\(t\\in[2,10]\\).</p> <p>Out:</p> <pre><code>    INFO - 10:51:27:  \n    INFO - 10:51:27: *** Start DOEScenario execution ***\n    INFO - 10:51:27: DOEScenario\n    INFO - 10:51:27:    Disciplines: Beam BeamConstraints\n    INFO - 10:51:27:    MDO formulation: MDF\n    INFO - 10:51:27: Optimization problem:\n    INFO - 10:51:27:    minimize w(h, t)\n    INFO - 10:51:27:    with respect to h, t\n    INFO - 10:51:27:    subject to constraints:\n    INFO - 10:51:27:       c_stress(h, t) &lt;= 1.0\n    INFO - 10:51:27:       c_displ(h, t) &gt;= 1.0\n    INFO - 10:51:27:    over the design space:\n    INFO - 10:51:27:       +------+-------------+-------+-------------+-------+\n    INFO - 10:51:27:       | Name | Lower bound | Value | Upper bound | Type  |\n    INFO - 10:51:27:       +------+-------------+-------+-------------+-------+\n    INFO - 10:51:27:       | h    |     500     |  800  |     800     | float |\n    INFO - 10:51:27:       | t    |      2      |  2.5  |      10     | float |\n    INFO - 10:51:27:       +------+-------------+-------+-------------+-------+\n    INFO - 10:51:27: Solving optimization problem with algorithm PYDOE_FULLFACT:\n    INFO - 10:51:27:      1%|          | 1/100 [00:00&lt;00:00, 132.20 it/sec, obj=55.8]\n    INFO - 10:51:27:      2%|\u258f         | 2/100 [00:00&lt;00:00, 223.88 it/sec, obj=57.6]\n    INFO - 10:51:27:      3%|\u258e         | 3/100 [00:00&lt;00:00, 297.41 it/sec, obj=59.5]\n    INFO - 10:51:27:      4%|\u258d         | 4/100 [00:00&lt;00:00, 355.91 it/sec, obj=61.4]\n    INFO - 10:51:27:      5%|\u258c         | 5/100 [00:00&lt;00:00, 404.57 it/sec, obj=63.2]\n    INFO - 10:51:27:      6%|\u258c         | 6/100 [00:00&lt;00:00, 444.78 it/sec, obj=65.1]\n    INFO - 10:51:27:      7%|\u258b         | 7/100 [00:00&lt;00:00, 480.16 it/sec, obj=67]\n    INFO - 10:51:27:      8%|\u258a         | 8/100 [00:00&lt;00:00, 508.80 it/sec, obj=68.8]\n    INFO - 10:51:27:      9%|\u2589         | 9/100 [00:00&lt;00:00, 535.23 it/sec, obj=70.7]\n    INFO - 10:51:27:     10%|\u2588         | 10/100 [00:00&lt;00:00, 558.58 it/sec, obj=72.6]\n    INFO - 10:51:27:     11%|\u2588         | 11/100 [00:00&lt;00:00, 579.40 it/sec, obj=80.4]\n    INFO - 10:51:27:     12%|\u2588\u258f        | 12/100 [00:00&lt;00:00, 597.90 it/sec, obj=83.1]\n    INFO - 10:51:27:     13%|\u2588\u258e        | 13/100 [00:00&lt;00:00, 614.70 it/sec, obj=85.8]\n    INFO - 10:51:27:     14%|\u2588\u258d        | 14/100 [00:00&lt;00:00, 629.98 it/sec, obj=88.5]\n    INFO - 10:51:27:     15%|\u2588\u258c        | 15/100 [00:00&lt;00:00, 643.52 it/sec, obj=91.2]\n    INFO - 10:51:27:     16%|\u2588\u258c        | 16/100 [00:00&lt;00:00, 655.73 it/sec, obj=93.9]\n    INFO - 10:51:27:     17%|\u2588\u258b        | 17/100 [00:00&lt;00:00, 666.92 it/sec, obj=96.6]\n    INFO - 10:51:27:     18%|\u2588\u258a        | 18/100 [00:00&lt;00:00, 677.41 it/sec, obj=99.3]\n    INFO - 10:51:27:     19%|\u2588\u2589        | 19/100 [00:00&lt;00:00, 684.18 it/sec, obj=102]\n    INFO - 10:51:27:     20%|\u2588\u2588        | 20/100 [00:00&lt;00:00, 692.88 it/sec, obj=105]\n    INFO - 10:51:27:     21%|\u2588\u2588        | 21/100 [00:00&lt;00:00, 701.21 it/sec, obj=105]\n    INFO - 10:51:27:     22%|\u2588\u2588\u258f       | 22/100 [00:00&lt;00:00, 708.42 it/sec, obj=109]\n    INFO - 10:51:27:     23%|\u2588\u2588\u258e       | 23/100 [00:00&lt;00:00, 715.60 it/sec, obj=112]\n    INFO - 10:51:27:     24%|\u2588\u2588\u258d       | 24/100 [00:00&lt;00:00, 722.21 it/sec, obj=116]\n    INFO - 10:51:27:     25%|\u2588\u2588\u258c       | 25/100 [00:00&lt;00:00, 728.47 it/sec, obj=119]\n    INFO - 10:51:27:     26%|\u2588\u2588\u258c       | 26/100 [00:00&lt;00:00, 734.51 it/sec, obj=123]\n    INFO - 10:51:27:     27%|\u2588\u2588\u258b       | 27/100 [00:00&lt;00:00, 739.89 it/sec, obj=126]\n    INFO - 10:51:27:     28%|\u2588\u2588\u258a       | 28/100 [00:00&lt;00:00, 743.18 it/sec, obj=130]\n    INFO - 10:51:27:     29%|\u2588\u2588\u2589       | 29/100 [00:00&lt;00:00, 746.57 it/sec, obj=133]\n    INFO - 10:51:27:     30%|\u2588\u2588\u2588       | 30/100 [00:00&lt;00:00, 751.22 it/sec, obj=137]\n    INFO - 10:51:27:     31%|\u2588\u2588\u2588       | 31/100 [00:00&lt;00:00, 755.20 it/sec, obj=129]\n    INFO - 10:51:27:     32%|\u2588\u2588\u2588\u258f      | 32/100 [00:00&lt;00:00, 759.32 it/sec, obj=134]\n    INFO - 10:51:27:     33%|\u2588\u2588\u2588\u258e      | 33/100 [00:00&lt;00:00, 762.76 it/sec, obj=138]\n    INFO - 10:51:27:     34%|\u2588\u2588\u2588\u258d      | 34/100 [00:00&lt;00:00, 765.36 it/sec, obj=143]\n    INFO - 10:51:27:     35%|\u2588\u2588\u2588\u258c      | 35/100 [00:00&lt;00:00, 768.77 it/sec, obj=147]\n    INFO - 10:51:27:     36%|\u2588\u2588\u2588\u258c      | 36/100 [00:00&lt;00:00, 771.32 it/sec, obj=151]\n    INFO - 10:51:27:     37%|\u2588\u2588\u2588\u258b      | 37/100 [00:00&lt;00:00, 774.61 it/sec, obj=156]\n    INFO - 10:51:27:     38%|\u2588\u2588\u2588\u258a      | 38/100 [00:00&lt;00:00, 776.60 it/sec, obj=160]\n    INFO - 10:51:27:     39%|\u2588\u2588\u2588\u2589      | 39/100 [00:00&lt;00:00, 779.36 it/sec, obj=164]\n    INFO - 10:51:27:     40%|\u2588\u2588\u2588\u2588      | 40/100 [00:00&lt;00:00, 781.81 it/sec, obj=169]\n    INFO - 10:51:27:     41%|\u2588\u2588\u2588\u2588      | 41/100 [00:00&lt;00:00, 784.26 it/sec, obj=154]\n    INFO - 10:51:27:     42%|\u2588\u2588\u2588\u2588\u258f     | 42/100 [00:00&lt;00:00, 786.63 it/sec, obj=159]\n    INFO - 10:51:27:     43%|\u2588\u2588\u2588\u2588\u258e     | 43/100 [00:00&lt;00:00, 789.19 it/sec, obj=164]\n    INFO - 10:51:27:     44%|\u2588\u2588\u2588\u2588\u258d     | 44/100 [00:00&lt;00:00, 791.77 it/sec, obj=169]\n    INFO - 10:51:27:     45%|\u2588\u2588\u2588\u2588\u258c     | 45/100 [00:00&lt;00:00, 793.74 it/sec, obj=175]\n    INFO - 10:51:27:     46%|\u2588\u2588\u2588\u2588\u258c     | 46/100 [00:00&lt;00:00, 795.60 it/sec, obj=180]\n    INFO - 10:51:27:     47%|\u2588\u2588\u2588\u2588\u258b     | 47/100 [00:00&lt;00:00, 796.10 it/sec, obj=185]\n    INFO - 10:51:27:     48%|\u2588\u2588\u2588\u2588\u258a     | 48/100 [00:00&lt;00:00, 797.91 it/sec, obj=190]\n    INFO - 10:51:27:     49%|\u2588\u2588\u2588\u2588\u2589     | 49/100 [00:00&lt;00:00, 798.46 it/sec, obj=195]\n    INFO - 10:51:27:     50%|\u2588\u2588\u2588\u2588\u2588     | 50/100 [00:00&lt;00:00, 800.31 it/sec, obj=200]\n    INFO - 10:51:27:     51%|\u2588\u2588\u2588\u2588\u2588     | 51/100 [00:00&lt;00:00, 802.22 it/sec, obj=178]\n    INFO - 10:51:27:     52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 52/100 [00:00&lt;00:00, 803.71 it/sec, obj=184]\n    INFO - 10:51:27:     53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 53/100 [00:00&lt;00:00, 805.50 it/sec, obj=190]\n    INFO - 10:51:27:     54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 54/100 [00:00&lt;00:00, 807.31 it/sec, obj=196]\n    INFO - 10:51:27:     55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 55/100 [00:00&lt;00:00, 809.03 it/sec, obj=202]\n    INFO - 10:51:27:     56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 56/100 [00:00&lt;00:00, 810.54 it/sec, obj=208]\n    INFO - 10:51:27:     57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 57/100 [00:00&lt;00:00, 812.10 it/sec, obj=214]\n    INFO - 10:51:27:     58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 58/100 [00:00&lt;00:00, 811.99 it/sec, obj=220]\n    INFO - 10:51:27:     59%|\u2588\u2588\u2588\u2588\u2588\u2589    | 59/100 [00:00&lt;00:00, 813.27 it/sec, obj=226]\n    INFO - 10:51:27:     60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 60/100 [00:00&lt;00:00, 814.39 it/sec, obj=232]\n    INFO - 10:51:27:     61%|\u2588\u2588\u2588\u2588\u2588\u2588    | 61/100 [00:00&lt;00:00, 815.75 it/sec, obj=202]\n    INFO - 10:51:27:     62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 62/100 [00:00&lt;00:00, 817.18 it/sec, obj=209]\n    INFO - 10:51:27:     63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 63/100 [00:00&lt;00:00, 818.73 it/sec, obj=216]\n    INFO - 10:51:27:     64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 64/100 [00:00&lt;00:00, 820.15 it/sec, obj=223]\n    INFO - 10:51:27:     65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 65/100 [00:00&lt;00:00, 821.14 it/sec, obj=230]\n    INFO - 10:51:27:     66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 66/100 [00:00&lt;00:00, 822.37 it/sec, obj=237]\n    INFO - 10:51:27:     67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 67/100 [00:00&lt;00:00, 823.47 it/sec, obj=243]\n    INFO - 10:51:27:     68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 68/100 [00:00&lt;00:00, 824.76 it/sec, obj=250]\n    INFO - 10:51:27:     69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 69/100 [00:00&lt;00:00, 826.12 it/sec, obj=257]\n    INFO - 10:51:27:     70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 70/100 [00:00&lt;00:00, 827.26 it/sec, obj=264]\n    INFO - 10:51:27:     71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 71/100 [00:00&lt;00:00, 828.38 it/sec, obj=226]\n    INFO - 10:51:27:     72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 72/100 [00:00&lt;00:00, 829.58 it/sec, obj=234]\n    INFO - 10:51:27:     73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 73/100 [00:00&lt;00:00, 830.66 it/sec, obj=242]\n    INFO - 10:51:27:     74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 74/100 [00:00&lt;00:00, 831.54 it/sec, obj=249]\n    INFO - 10:51:27:     75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 75/100 [00:00&lt;00:00, 832.18 it/sec, obj=257]\n    INFO - 10:51:27:     76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 76/100 [00:00&lt;00:00, 832.80 it/sec, obj=265]\n    INFO - 10:51:27:     77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 77/100 [00:00&lt;00:00, 833.69 it/sec, obj=272]\n    INFO - 10:51:27:     78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 78/100 [00:00&lt;00:00, 834.73 it/sec, obj=280]\n    INFO - 10:51:27:     79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 79/100 [00:00&lt;00:00, 835.82 it/sec, obj=288]\n    INFO - 10:51:27:     80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 80/100 [00:00&lt;00:00, 836.88 it/sec, obj=296]\n    INFO - 10:51:27:     81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 81/100 [00:00&lt;00:00, 837.40 it/sec, obj=250]\n    INFO - 10:51:27:     82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 82/100 [00:00&lt;00:00, 838.31 it/sec, obj=259]\n    INFO - 10:51:27:     83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 83/100 [00:00&lt;00:00, 839.19 it/sec, obj=267]\n    INFO - 10:51:27:     84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 84/100 [00:00&lt;00:00, 840.06 it/sec, obj=276]\n    INFO - 10:51:27:     85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 85/100 [00:00&lt;00:00, 841.01 it/sec, obj=284]\n    INFO - 10:51:27:     86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 86/100 [00:00&lt;00:00, 841.87 it/sec, obj=293]\n    INFO - 10:51:27:     87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 87/100 [00:00&lt;00:00, 842.74 it/sec, obj=301]\n    INFO - 10:51:27:     88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 88/100 [00:00&lt;00:00, 843.47 it/sec, obj=310]\n    INFO - 10:51:28:     89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 89/100 [00:00&lt;00:00, 844.06 it/sec, obj=318]\n    INFO - 10:51:28:     90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 90/100 [00:00&lt;00:00, 844.80 it/sec, obj=327]\n    INFO - 10:51:28:     91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 91/100 [00:00&lt;00:00, 845.47 it/sec, obj=274]\n    INFO - 10:51:28:     92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 92/100 [00:00&lt;00:00, 846.09 it/sec, obj=284]\n    INFO - 10:51:28:     93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 93/100 [00:00&lt;00:00, 846.78 it/sec, obj=293]\n    INFO - 10:51:28:     94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 94/100 [00:00&lt;00:00, 847.26 it/sec, obj=302]\n    INFO - 10:51:28:     95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 95/100 [00:00&lt;00:00, 847.58 it/sec, obj=312]\n    INFO - 10:51:28:     96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 96/100 [00:00&lt;00:00, 848.21 it/sec, obj=321]\n    INFO - 10:51:28:     97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 97/100 [00:00&lt;00:00, 848.68 it/sec, obj=330]\n    INFO - 10:51:28:     98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 98/100 [00:00&lt;00:00, 849.37 it/sec, obj=340]\n    INFO - 10:51:28:     99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 99/100 [00:00&lt;00:00, 850.00 it/sec, obj=349]\n    INFO - 10:51:28:    100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:00&lt;00:00, 850.77 it/sec, obj=358]\n    INFO - 10:51:28: Optimization result:\n    INFO - 10:51:28:    Optimizer info:\n    INFO - 10:51:28:       Status: None\n    INFO - 10:51:28:       Message: None\n    INFO - 10:51:28:       Number of calls to the objective function by the optimizer: 100\n    INFO - 10:51:28:    Solution:\n    INFO - 10:51:28:       The solution is feasible.\n    INFO - 10:51:28:       Objective: 257.1326419753086\n    INFO - 10:51:28:       Standardized constraints:\n    INFO - 10:51:28:          -[c_displ-1.0] = [-0.01235799 -0.01235799 -0.01235799 -0.00782042 -0.00782042 -0.00782042\n    INFO - 10:51:28:  -0.01235799 -0.01235799 -0.01235799]\n    INFO - 10:51:28:          [c_stress-1.0] = [-0.05840978 -0.06171919 -0.05840978 -0.8696619  -1.         -0.8696619\n    INFO - 10:51:28:  -0.05840978 -0.06171919 -0.05840978]\n    INFO - 10:51:28:       Design space:\n    INFO - 10:51:28:          +------+-------------+-------------------+-------------+-------+\n    INFO - 10:51:28:          | Name | Lower bound |       Value       | Upper bound | Type  |\n    INFO - 10:51:28:          +------+-------------+-------------------+-------------+-------+\n    INFO - 10:51:28:          | h    |     500     | 633.3333333333333 |     800     | float |\n    INFO - 10:51:28:          | t    |      2      | 8.222222222222221 |      10     | float |\n    INFO - 10:51:28:          +------+-------------+-------------------+-------------+-------+\n    INFO - 10:51:28: *** End DOEScenario execution (time: 0:00:00.122113) ***\n</code></pre> <p></p> <pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.post.dataset.zvsxy import ZvsXY\nfrom gemseo.scenarios.doe_scenario import DOEScenario\n\nfrom gemseo_umdo.use_cases.beam_model.constraints import BeamConstraints\nfrom gemseo_umdo.use_cases.beam_model.design_space import BeamDesignSpace\nfrom gemseo_umdo.use_cases.beam_model.discipline import Beam\n\nconfigure_logger()\n\ndisciplines = [Beam(), BeamConstraints()]\n\ndesign_space = BeamDesignSpace()\n\nscenario = DOEScenario(disciplines, \"w\", design_space, formulation_name=\"MDF\")\nscenario.add_constraint(\"c_stress\", constraint_type=\"ineq\", value=1.0)\nscenario.add_constraint(\"c_displ\", constraint_type=\"ineq\", positive=True, value=1.0)\nscenario.execute(algo_name=\"PYDOE_FULLFACT\", n_samples=10**2)\n\ndataset = scenario.formulation.optimization_problem.to_dataset()\nZvsXY(dataset, \"h\", \"t\", \"w\").execute(save=True, show=False, file_name=\"w\")\nfor constraint_name in [\"-[c_displ-1.0]\", \"[c_stress-1.0]\"]:\n    for z_component in range(9):\n        ZvsXY(dataset, \"h\", \"t\", (constraint_name, z_component)).execute(\n            save=False,\n            show=True,\n        )\n</code></pre> <p>Total running time of the script: ( 0 minutes  3.770 seconds)</p> <p> Download Python source code: plot_beam_doe.py</p> <p> Download Jupyter notebook: plot_beam_doe.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/problems/beam_model/plot_beam_opt/","title":"Optimization problem.","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/problems/beam_model/plot_beam_opt/#optimization-problem","title":"Optimization problem.","text":"<p>Minimize the weight \\(w(h,t)\\) w.r.t. the height \\(h\\in[500, 800]\\) and the thickness \\(t\\in[2,10]\\) while satisfying \\(c_{\\text{stress}}(h,t)\\geq 1.0\\) and \\(c_{\\text{displacement}}(h,t)\\leq 1.0\\).</p> <p>Out:</p> <pre><code>/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/gemseo/third_party/prettytable/prettytable.py:73: DeprecationWarning: invalid escape sequence \\[\n  _re = re.compile(\"\\033\\[[0-9;]*m\")\n/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/gemseo/third_party/prettytable/prettytable.py:1291: DeprecationWarning: invalid escape sequence \\{\n  self.vertical_char = random.choice(\"~!@#$%^&amp;*()_+|-=\\{}[];':\\\",./;&lt;&gt;?\")\n/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/gemseo/third_party/prettytable/prettytable.py:1292: DeprecationWarning: invalid escape sequence \\{\n  self.horizontal_char = random.choice(\"~!@#$%^&amp;*()_+|-=\\{}[];':\\\",./;&lt;&gt;?\")\n/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/gemseo/third_party/prettytable/prettytable.py:1293: DeprecationWarning: invalid escape sequence \\{\n  self.junction_char = random.choice(\"~!@#$%^&amp;*()_+|-=\\{}[];':\\\",./;&lt;&gt;?\")\n/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n  backends.update(_get_backends(\"networkx.backends\"))\n    INFO - 10:50:09:  \n    INFO - 10:50:09: *** Start MDOScenario execution ***\n    INFO - 10:50:09: MDOScenario\n    INFO - 10:50:09:    Disciplines: Beam BeamConstraints\n    INFO - 10:50:09:    MDO formulation: MDF\n    INFO - 10:50:09: Optimization problem:\n    INFO - 10:50:09:    minimize w(h, t)\n    INFO - 10:50:09:    with respect to h, t\n    INFO - 10:50:09:    subject to constraints:\n    INFO - 10:50:09:       c_stress(h, t) &lt;= 1.0\n    INFO - 10:50:09:       c_displ(h, t) &gt;= 1.0\n    INFO - 10:50:09:    over the design space:\n    INFO - 10:50:09:       +------+-------------+-------+-------------+-------+\n    INFO - 10:50:09:       | Name | Lower bound | Value | Upper bound | Type  |\n    INFO - 10:50:09:       +------+-------------+-------+-------------+-------+\n    INFO - 10:50:09:       | h    |     500     |  800  |     800     | float |\n    INFO - 10:50:09:       | t    |      2      |  2.5  |      10     | float |\n    INFO - 10:50:09:       +------+-------------+-------+-------------+-------+\n    INFO - 10:50:09: Solving optimization problem with algorithm NLOPT_COBYLA:\n    INFO - 10:50:09:      1%|          | 6/1000 [00:00&lt;00:03, 327.62 it/sec, obj=182]\n    INFO - 10:50:09:      1%|          | 7/1000 [00:00&lt;00:02, 342.87 it/sec, obj=211]\n    INFO - 10:50:09:      1%|          | 8/1000 [00:00&lt;00:02, 357.08 it/sec, obj=225]\n    INFO - 10:50:09:      1%|          | 9/1000 [00:00&lt;00:02, 370.65 it/sec, obj=222]\n    INFO - 10:50:09:      1%|          | 10/1000 [00:00&lt;00:02, 381.47 it/sec, obj=220]\n    INFO - 10:50:09:      1%|          | 11/1000 [00:00&lt;00:02, 391.55 it/sec, obj=229]\n    INFO - 10:50:09:      1%|          | 12/1000 [00:00&lt;00:02, 400.71 it/sec, obj=228]\n    INFO - 10:50:09:      1%|\u258f         | 13/1000 [00:00&lt;00:02, 408.91 it/sec, obj=229]\n    INFO - 10:50:09:      1%|\u258f         | 14/1000 [00:00&lt;00:02, 416.25 it/sec, obj=229]\n    INFO - 10:50:10:      2%|\u258f         | 15/1000 [00:00&lt;00:02, 422.60 it/sec, obj=229]\n    INFO - 10:50:10:      2%|\u258f         | 16/1000 [00:00&lt;00:02, 428.08 it/sec, obj=229]\n    INFO - 10:50:10:      2%|\u258f         | 17/1000 [00:00&lt;00:02, 433.08 it/sec, obj=229]\n    INFO - 10:50:10:      2%|\u258f         | 18/1000 [00:00&lt;00:02, 433.32 it/sec, obj=229]\n    INFO - 10:50:10:      2%|\u258f         | 19/1000 [00:00&lt;00:02, 434.90 it/sec, obj=229]\n    INFO - 10:50:10:      2%|\u258f         | 20/1000 [00:00&lt;00:02, 439.30 it/sec, obj=229]\n    INFO - 10:50:10:      2%|\u258f         | 21/1000 [00:00&lt;00:02, 443.06 it/sec, obj=229]\n    INFO - 10:50:10:      2%|\u258f         | 22/1000 [00:00&lt;00:02, 446.14 it/sec, obj=229]\n    INFO - 10:50:10:      2%|\u258f         | 23/1000 [00:00&lt;00:02, 448.13 it/sec, obj=229]\n    INFO - 10:50:10:      2%|\u258f         | 24/1000 [00:00&lt;00:02, 450.84 it/sec, obj=229]\n    INFO - 10:50:10:      2%|\u258e         | 25/1000 [00:00&lt;00:02, 453.43 it/sec, obj=229]\n    INFO - 10:50:10:      3%|\u258e         | 26/1000 [00:00&lt;00:02, 453.29 it/sec, obj=229]\n    INFO - 10:50:10:      3%|\u258e         | 27/1000 [00:00&lt;00:02, 453.62 it/sec, obj=229]\n    INFO - 10:50:10:      3%|\u258e         | 28/1000 [00:00&lt;00:02, 453.16 it/sec, obj=229]\n    INFO - 10:50:10:      3%|\u258e         | 29/1000 [00:00&lt;00:02, 453.30 it/sec, obj=229]\n    INFO - 10:50:10:      3%|\u258e         | 30/1000 [00:00&lt;00:02, 453.46 it/sec, obj=229]\n    INFO - 10:50:10:      3%|\u258e         | 31/1000 [00:00&lt;00:02, 453.76 it/sec, obj=229]\n    INFO - 10:50:10:      3%|\u258e         | 32/1000 [00:00&lt;00:02, 454.10 it/sec, obj=229]\n    INFO - 10:50:10:      3%|\u258e         | 33/1000 [00:00&lt;00:02, 452.40 it/sec, obj=229]\n    INFO - 10:50:10:      3%|\u258e         | 34/1000 [00:00&lt;00:02, 452.41 it/sec, obj=229]\n    INFO - 10:50:10:      4%|\u258e         | 35/1000 [00:00&lt;00:02, 451.98 it/sec, obj=229]\n    INFO - 10:50:10:      4%|\u258e         | 36/1000 [00:00&lt;00:02, 451.55 it/sec, obj=229]\n    INFO - 10:50:10:      4%|\u258e         | 37/1000 [00:00&lt;00:02, 451.33 it/sec, obj=229]\n    INFO - 10:50:10:      4%|\u258d         | 38/1000 [00:00&lt;00:02, 451.26 it/sec, obj=229]\n    INFO - 10:50:10:      4%|\u258d         | 39/1000 [00:00&lt;00:02, 451.43 it/sec, obj=229]\n    INFO - 10:50:10:      4%|\u258d         | 40/1000 [00:00&lt;00:02, 451.46 it/sec, obj=229]\n    INFO - 10:50:10:      4%|\u258d         | 41/1000 [00:00&lt;00:02, 451.58 it/sec, obj=229]\n    INFO - 10:50:10: Optimization result:\n    INFO - 10:50:10:    Optimizer info:\n    INFO - 10:50:10:       Status: None\n    INFO - 10:50:10:       Message: Successive iterates of the objective function are closer than ftol_rel or ftol_abs. GEMSEO stopped the driver.\n    INFO - 10:50:10:       Number of calls to the objective function by the optimizer: 42\n    INFO - 10:50:10:    Solution:\n    INFO - 10:50:10:       The solution is feasible.\n    INFO - 10:50:10:       Objective: 229.1109776763463\n    INFO - 10:50:10:       Standardized constraints:\n    INFO - 10:50:10:          -[c_displ-1.0] = [-5.19123398e-03 -5.19123398e-03 -5.19123398e-03 -3.51346551e-05\n    INFO - 10:50:10:  -3.51346551e-05 -3.51346551e-05 -5.19123398e-03 -5.19123398e-03\n    INFO - 10:50:10:  -5.19123398e-03]\n    INFO - 10:50:10:          [c_stress-1.0] = [ 3.02343028e-05 -3.52038986e-03  3.02343028e-05 -8.57307483e-01\n    INFO - 10:50:10:  -1.00000000e+00 -8.57307483e-01  3.02343028e-05 -3.52038986e-03\n    INFO - 10:50:10:   3.02343028e-05]\n    INFO - 10:50:10:       Design space:\n    INFO - 10:50:10:          +------+-------------+-------------------+-------------+-------+\n    INFO - 10:50:10:          | Name | Lower bound |       Value       | Upper bound | Type  |\n    INFO - 10:50:10:          +------+-------------+-------------------+-------------+-------+\n    INFO - 10:50:10:          | h    |     500     | 677.8534696587071 |     800     | float |\n    INFO - 10:50:10:          | t    |      2      | 7.030927890734481 |      10     | float |\n    INFO - 10:50:10:          +------+-------------+-------------------+-------------+-------+\n    INFO - 10:50:10: *** End MDOScenario execution (time: 0:00:00.096648) ***\n\n&lt;gemseo.post.opt_history_view.OptHistoryView object at 0x78c12025e1f0&gt;\n</code></pre> <p></p> <pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.scenarios.mdo_scenario import MDOScenario\n\nfrom gemseo_umdo.use_cases.beam_model.constraints import BeamConstraints\nfrom gemseo_umdo.use_cases.beam_model.design_space import BeamDesignSpace\nfrom gemseo_umdo.use_cases.beam_model.discipline import Beam\n\nconfigure_logger()\n\ndisciplines = [Beam(), BeamConstraints()]\n\ndesign_space = BeamDesignSpace()\n\nscenario = MDOScenario(disciplines, \"w\", design_space, formulation_name=\"MDF\")\nscenario.add_constraint(\"c_stress\", constraint_type=\"ineq\", value=1.0)\nscenario.add_constraint(\"c_displ\", constraint_type=\"ineq\", positive=True, value=1.0)\nscenario.execute(algo_name=\"NLOPT_COBYLA\", max_iter=1000)\n\nscenario.post_process(post_name=\"OptHistoryView\", save=False, show=True)\n</code></pre> <p>Total running time of the script: ( 0 minutes  8.059 seconds)</p> <p> Download Python source code: plot_beam_opt.py</p> <p> Download Jupyter notebook: plot_beam_opt.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/problems/beam_model/plot_beam_rob_opt/","title":"Robust optimization problem.","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/problems/beam_model/plot_beam_rob_opt/#robust-optimization-problem","title":"Robust optimization problem.","text":"<p>Minimize the expectation of the weight \\(w(h,t)\\) w.r.t. the height \\(h\\in[500, 800]\\) and the thickness \\(t\\in[2,10]\\) while satisfying \\(c_{\\text{stress}}(h,t)\\geq 1.0\\) and \\(c_{\\text{displacement}}(h,t)\\leq 1.0\\) with probability 90\\% where \\(F\\), \\(E\\) and \\(\\sigma_{\\text{all}}\\) are random variables defined by <code>BeamUncertainSpace</code>.</p> <p>Out:</p> <pre><code>/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/pydantic/main.py:209: DeprecationWarning: Conversion of an array with ndim &gt; 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n    INFO - 10:50:14:  \n    INFO - 10:50:14: *** Start UMDOScenario execution ***\n    INFO - 10:50:14: UMDOScenario\n    INFO - 10:50:14:    Disciplines: Beam BeamConstraints\n    INFO - 10:50:14:    Formulation:\n    INFO - 10:50:14:       MDO formulation: MDF\n    INFO - 10:50:14:       Statistic estimation: Sampling\n    INFO - 10:50:14:    Uncertain space:\n    INFO - 10:50:14:       +-----------+-----------------------------------------------+\n    INFO - 10:50:14:       |    Name   |                  Distribution                 |\n    INFO - 10:50:14:       +-----------+-----------------------------------------------+\n    INFO - 10:50:14:       |     F     | Normal(mu=-200000.0, sigma=6666.666666666667) |\n    INFO - 10:50:14:       |     E     |        Normal(mu=73500.0, sigma=1225.0)       |\n    INFO - 10:50:14:       | sigma_all |          Normal(mu=300.0, sigma=5.0)          |\n    INFO - 10:50:14:       +-----------+-----------------------------------------------+\n    INFO - 10:50:14: Optimization problem:\n    INFO - 10:50:14:    minimize E[w]\n    INFO - 10:50:14:    with respect to h, t\n    INFO - 10:50:14:    subject to constraints:\n    INFO - 10:50:14:       P[c_stress &lt;= 1.0] &gt;= 0.9\n    INFO - 10:50:14:       P[c_displ &gt;= 1.0] &gt;= 0.9\n    INFO - 10:50:14:    over the design space:\n    INFO - 10:50:14:       +------+-------------+-------+-------------+-------+\n    INFO - 10:50:14:       | Name | Lower bound | Value | Upper bound | Type  |\n    INFO - 10:50:14:       +------+-------------+-------+-------------+-------+\n    INFO - 10:50:14:       | h    |     500     |  800  |     800     | float |\n    INFO - 10:50:14:       | t    |      2      |  2.5  |      10     | float |\n    INFO - 10:50:14:       +------+-------------+-------+-------------+-------+\n    INFO - 10:50:14: Solving optimization problem with algorithm NLOPT_COBYLA:\n    INFO - 10:50:14:      3%|\u258e         | 1/30 [00:00&lt;00:06,  4.43 it/sec, obj=90.6]\n    INFO - 10:50:15:      7%|\u258b         | 2/30 [00:00&lt;00:13,  2.09 it/sec, obj=85.4]\n    INFO - 10:50:15:     10%|\u2588         | 3/30 [00:01&lt;00:16,  1.66 it/sec, obj=153]\n    INFO - 10:50:16:     13%|\u2588\u258e        | 4/30 [00:02&lt;00:17,  1.44 it/sec, obj=102]\n    INFO - 10:50:17:     17%|\u2588\u258b        | 5/30 [00:03&lt;00:19,  1.30 it/sec, obj=102]\n    INFO - 10:50:19:     20%|\u2588\u2588        | 6/30 [00:05&lt;00:20,  1.19 it/sec, obj=68.3]\n    INFO - 10:50:20:     23%|\u2588\u2588\u258e       | 7/30 [00:06&lt;00:20,  1.10 it/sec, obj=68.4]\n    INFO - 10:50:21:     27%|\u2588\u2588\u258b       | 8/30 [00:07&lt;00:21,  1.03 it/sec, obj=68.5]\n    INFO - 10:50:23:     30%|\u2588\u2588\u2588       | 9/30 [00:09&lt;00:22, 56.31 it/min, obj=67.3]\n    INFO - 10:50:25:     33%|\u2588\u2588\u2588\u258e      | 10/30 [00:11&lt;00:22, 53.13 it/min, obj=69.1]\n    INFO - 10:50:27:     37%|\u2588\u2588\u2588\u258b      | 11/30 [00:13&lt;00:22, 50.39 it/min, obj=67.8]\n    INFO - 10:50:29:     40%|\u2588\u2588\u2588\u2588      | 12/30 [00:15&lt;00:22, 47.89 it/min, obj=68]\n    INFO - 10:50:31:     43%|\u2588\u2588\u2588\u2588\u258e     | 13/30 [00:17&lt;00:22, 45.66 it/min, obj=67.4]\n    INFO - 10:50:33:     47%|\u2588\u2588\u2588\u2588\u258b     | 14/30 [00:19&lt;00:22, 43.62 it/min, obj=70]\n    INFO - 10:50:35:     50%|\u2588\u2588\u2588\u2588\u2588     | 15/30 [00:21&lt;00:21, 41.79 it/min, obj=67.4]\n    INFO - 10:50:37:     53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 16/30 [00:23&lt;00:20, 40.13 it/min, obj=67.4]\n    INFO - 10:50:40:     57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 17/30 [00:26&lt;00:20, 38.57 it/min, obj=67.4]\n    INFO - 10:50:43:     60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 18/30 [00:29&lt;00:19, 37.13 it/min, obj=67.3]\n    INFO - 10:50:45:     63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 19/30 [00:31&lt;00:18, 35.82 it/min, obj=67.4]\n    INFO - 10:50:48:     67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 20/30 [00:34&lt;00:17, 34.60 it/min, obj=67.4]\n    INFO - 10:50:51:     70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 21/30 [00:37&lt;00:16, 33.38 it/min, obj=67.6]\n    INFO - 10:50:54:     73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 22/30 [00:40&lt;00:14, 32.29 it/min, obj=67.4]\n    INFO - 10:50:58:     77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 23/30 [00:44&lt;00:13, 31.29 it/min, obj=67.4]\n    INFO - 10:51:01:     80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 24/30 [00:47&lt;00:11, 30.36 it/min, obj=67.4]\n    INFO - 10:51:04:     83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 25/30 [00:50&lt;00:10, 29.47 it/min, obj=67.3]\n    INFO - 10:51:08:     87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 26/30 [00:54&lt;00:08, 28.62 it/min, obj=67.4]\n    INFO - 10:51:12:     90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 27/30 [00:58&lt;00:06, 27.83 it/min, obj=67.3]\n    INFO - 10:51:16:     93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 28/30 [01:02&lt;00:04, 27.08 it/min, obj=67.3]\n    INFO - 10:51:20:     97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 29/30 [01:05&lt;00:02, 26.37 it/min, obj=67.3]\n    INFO - 10:51:24:    100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [01:10&lt;00:00, 25.70 it/min, obj=67.2]\n WARNING - 10:51:26: Optimization found no feasible point; the least infeasible point is selected.\n    INFO - 10:51:26: Optimization result:\n    INFO - 10:51:26:    Optimizer info:\n    INFO - 10:51:26:       Status: None\n    INFO - 10:51:26:       Message: Maximum number of iterations reached. GEMSEO stopped the driver.\n    INFO - 10:51:26:       Number of calls to the objective function by the optimizer: 32\n    INFO - 10:51:26:    Solution:\n WARNING - 10:51:26:       The solution is not feasible.\n    INFO - 10:51:26:       Objective: 68.3457212077113\n    INFO - 10:51:26:       Standardized constraints:\n    INFO - 10:51:26:          -[P[c_displ &gt;= 1.0]-0.9] = [-0.1 -0.1 -0.1 -0.1 -0.1 -0.1 -0.1 -0.1 -0.1]\n    INFO - 10:51:26:          -[P[c_stress &lt;= 1.0]-0.9] = [ 0.9  0.9  0.9 -0.1 -0.1 -0.1  0.9  0.9  0.9]\n    INFO - 10:51:26:       Design space:\n    INFO - 10:51:26:          +------+-------------+-------------------+-------------+-------+\n    INFO - 10:51:26:          | Name | Lower bound |       Value       | Upper bound | Type  |\n    INFO - 10:51:26:          +------+-------------+-------------------+-------------+-------+\n    INFO - 10:51:26:          | h    |     500     | 723.5529176109274 |     800     | float |\n    INFO - 10:51:26:          | t    |      2      | 2.001491324450939 |      10     | float |\n    INFO - 10:51:26:          +------+-------------+-------------------+-------------+-------+\n    INFO - 10:51:26: *** End UMDOScenario execution (time: 0:01:12.845955) ***\n WARNING - 10:51:26: Optimization found no feasible point; the least infeasible point is selected.\n WARNING - 10:51:27: Optimization found no feasible point; the least infeasible point is selected.\n\n&lt;gemseo.post.opt_history_view.OptHistoryView object at 0x78c11d315040&gt;\n</code></pre> <p></p> <pre><code>from __future__ import annotations\n\nfrom gemseo import configure\nfrom gemseo import configure_logger\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\nfrom gemseo_umdo.use_cases.beam_model.constraints import BeamConstraints\nfrom gemseo_umdo.use_cases.beam_model.design_space import BeamDesignSpace\nfrom gemseo_umdo.use_cases.beam_model.discipline import Beam\nfrom gemseo_umdo.use_cases.beam_model.uncertain_space import BeamUncertainSpace\n\nconfigure()\nconfigure_logger()\n\nscenario = UMDOScenario(\n    [Beam(), BeamConstraints()],\n    \"w\",\n    BeamDesignSpace(),\n    BeamUncertainSpace(uniform=False),\n    \"Mean\",\n    formulation_name=\"MDF\",\n    statistic_estimation=\"Sampling\",\n    statistic_estimation_parameters={\"n_samples\": 200},\n)\nscenario.add_constraint(\n    \"c_stress\", \"Probability\", greater=False, threshold=1.0, positive=True, value=0.9\n)\nscenario.add_constraint(\n    \"c_displ\", \"Probability\", greater=True, threshold=1.0, positive=True, value=0.9\n)\nscenario.execute(algo_name=\"NLOPT_COBYLA\", max_iter=30)\n\nscenario.post_process(post_name=\"OptHistoryView\", save=False, show=True)\n</code></pre> <p>Total running time of the script: ( 1 minutes  13.672 seconds)</p> <p> Download Python source code: plot_beam_rob_opt.py</p> <p> Download Jupyter notebook: plot_beam_rob_opt.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/problems/beam_model/plot_beam_sa/","title":"Sobol' sensitivity analysis.","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/problems/beam_model/plot_beam_sa/#sobol-sensitivity-analysis","title":"Sobol' sensitivity analysis.","text":"<p>Compute and plot the total Sobol' indices for the field constraints \\(c_{\\text{stress}}\\) and \\(c_{\\text{displacement}}\\) where \\(F\\), \\(E\\) and \\(\\sigma_{\\text{all}}\\) are random variables defined by <code>BeamUncertainSpace</code>.</p> <p>Out:</p> <pre><code>/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/pydantic/main.py:209: DeprecationWarning: Conversion of an array with ndim &gt; 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n WARNING - 10:50:11: No coupling in MDA, switching chain_linearize to True.\n    INFO - 10:50:11:  \n    INFO - 10:50:11: *** Start SobolAnalysisSamplingPhase execution ***\n    INFO - 10:50:11: SobolAnalysisSamplingPhase\n    INFO - 10:50:11:    Disciplines: MDOChain\n    INFO - 10:50:11:    MDO formulation: MDF\n    INFO - 10:50:11: Running the algorithm OT_SOBOL_INDICES:\n    INFO - 10:50:11:      1%|          | 3/496 [00:00&lt;00:01, 276.38 it/sec]\n    INFO - 10:50:11:      1%|          | 4/496 [00:00&lt;00:01, 326.27 it/sec]\n    INFO - 10:50:11:      1%|          | 5/496 [00:00&lt;00:01, 366.67 it/sec]\n    INFO - 10:50:11:      1%|          | 6/496 [00:00&lt;00:01, 400.36 it/sec]\n    INFO - 10:50:11:      1%|\u258f         | 7/496 [00:00&lt;00:01, 427.79 it/sec]\n    INFO - 10:50:11:      2%|\u258f         | 8/496 [00:00&lt;00:01, 450.85 it/sec]\n    INFO - 10:50:11:      2%|\u258f         | 9/496 [00:00&lt;00:01, 471.02 it/sec]\n    INFO - 10:50:11:      2%|\u258f         | 10/496 [00:00&lt;00:00, 487.68 it/sec]\n    INFO - 10:50:11:      2%|\u258f         | 11/496 [00:00&lt;00:00, 502.26 it/sec]\n    INFO - 10:50:12:      2%|\u258f         | 12/496 [00:00&lt;00:00, 515.28 it/sec]\n    INFO - 10:50:12:      3%|\u258e         | 13/496 [00:00&lt;00:00, 527.19 it/sec]\n    INFO - 10:50:12:      3%|\u258e         | 14/496 [00:00&lt;00:00, 538.39 it/sec]\n    INFO - 10:50:12:      3%|\u258e         | 15/496 [00:00&lt;00:00, 548.18 it/sec]\n    INFO - 10:50:12:      3%|\u258e         | 16/496 [00:00&lt;00:00, 556.26 it/sec]\n    INFO - 10:50:12:      3%|\u258e         | 17/496 [00:00&lt;00:00, 564.60 it/sec]\n    INFO - 10:50:12:      4%|\u258e         | 18/496 [00:00&lt;00:00, 571.73 it/sec]\n    INFO - 10:50:12:      4%|\u258d         | 19/496 [00:00&lt;00:00, 578.77 it/sec]\n    INFO - 10:50:12:      4%|\u258d         | 20/496 [00:00&lt;00:00, 584.96 it/sec]\n    INFO - 10:50:12:      4%|\u258d         | 21/496 [00:00&lt;00:00, 590.25 it/sec]\n    INFO - 10:50:12:      4%|\u258d         | 22/496 [00:00&lt;00:00, 595.93 it/sec]\n    INFO - 10:50:12:      5%|\u258d         | 23/496 [00:00&lt;00:00, 601.02 it/sec]\n    INFO - 10:50:12:      5%|\u258d         | 24/496 [00:00&lt;00:00, 605.63 it/sec]\n    INFO - 10:50:12:      5%|\u258c         | 25/496 [00:00&lt;00:00, 610.13 it/sec]\n    INFO - 10:50:12:      5%|\u258c         | 26/496 [00:00&lt;00:00, 614.37 it/sec]\n    INFO - 10:50:12:      5%|\u258c         | 27/496 [00:00&lt;00:00, 618.20 it/sec]\n    INFO - 10:50:12:      6%|\u258c         | 28/496 [00:00&lt;00:00, 621.93 it/sec]\n    INFO - 10:50:12:      6%|\u258c         | 29/496 [00:00&lt;00:00, 625.33 it/sec]\n    INFO - 10:50:12:      6%|\u258c         | 30/496 [00:00&lt;00:00, 628.39 it/sec]\n    INFO - 10:50:12:      6%|\u258b         | 31/496 [00:00&lt;00:00, 631.37 it/sec]\n    INFO - 10:50:12:      6%|\u258b         | 32/496 [00:00&lt;00:00, 633.99 it/sec]\n    INFO - 10:50:12:      7%|\u258b         | 33/496 [00:00&lt;00:00, 636.79 it/sec]\n    INFO - 10:50:12:      7%|\u258b         | 34/496 [00:00&lt;00:00, 639.58 it/sec]\n    INFO - 10:50:12:      7%|\u258b         | 35/496 [00:00&lt;00:00, 641.44 it/sec]\n    INFO - 10:50:12:      7%|\u258b         | 36/496 [00:00&lt;00:00, 643.93 it/sec]\n    INFO - 10:50:12:      7%|\u258b         | 37/496 [00:00&lt;00:00, 646.22 it/sec]\n    INFO - 10:50:12:      8%|\u258a         | 38/496 [00:00&lt;00:00, 648.04 it/sec]\n    INFO - 10:50:12:      8%|\u258a         | 39/496 [00:00&lt;00:00, 650.22 it/sec]\n    INFO - 10:50:12:      8%|\u258a         | 40/496 [00:00&lt;00:00, 652.18 it/sec]\n    INFO - 10:50:12:      8%|\u258a         | 41/496 [00:00&lt;00:00, 654.05 it/sec]\n    INFO - 10:50:12:      8%|\u258a         | 42/496 [00:00&lt;00:00, 654.97 it/sec]\n    INFO - 10:50:12:      9%|\u258a         | 43/496 [00:00&lt;00:00, 655.67 it/sec]\n    INFO - 10:50:12:      9%|\u2589         | 44/496 [00:00&lt;00:00, 657.30 it/sec]\n    INFO - 10:50:12:      9%|\u2589         | 45/496 [00:00&lt;00:00, 658.65 it/sec]\n    INFO - 10:50:12:      9%|\u2589         | 46/496 [00:00&lt;00:00, 660.16 it/sec]\n    INFO - 10:50:12:      9%|\u2589         | 47/496 [00:00&lt;00:00, 661.80 it/sec]\n    INFO - 10:50:12:     10%|\u2589         | 48/496 [00:00&lt;00:00, 663.10 it/sec]\n    INFO - 10:50:12:     10%|\u2589         | 49/496 [00:00&lt;00:00, 663.91 it/sec]\n    INFO - 10:50:12:     10%|\u2588         | 50/496 [00:00&lt;00:00, 665.27 it/sec]\n    INFO - 10:50:12:     10%|\u2588         | 51/496 [00:00&lt;00:00, 666.44 it/sec]\n    INFO - 10:50:12:     10%|\u2588         | 52/496 [00:00&lt;00:00, 667.82 it/sec]\n    INFO - 10:50:12:     11%|\u2588         | 53/496 [00:00&lt;00:00, 668.43 it/sec]\n    INFO - 10:50:12:     11%|\u2588         | 54/496 [00:00&lt;00:00, 669.48 it/sec]\n    INFO - 10:50:12:     11%|\u2588         | 55/496 [00:00&lt;00:00, 670.68 it/sec]\n    INFO - 10:50:12:     11%|\u2588\u258f        | 56/496 [00:00&lt;00:00, 671.75 it/sec]\n    INFO - 10:50:12:     11%|\u2588\u258f        | 57/496 [00:00&lt;00:00, 672.75 it/sec]\n    INFO - 10:50:12:     12%|\u2588\u258f        | 58/496 [00:00&lt;00:00, 673.90 it/sec]\n    INFO - 10:50:12:     12%|\u2588\u258f        | 59/496 [00:00&lt;00:00, 674.86 it/sec]\n    INFO - 10:50:12:     12%|\u2588\u258f        | 60/496 [00:00&lt;00:00, 675.61 it/sec]\n    INFO - 10:50:12:     12%|\u2588\u258f        | 61/496 [00:00&lt;00:00, 676.67 it/sec]\n    INFO - 10:50:12:     12%|\u2588\u258e        | 62/496 [00:00&lt;00:00, 677.38 it/sec]\n    INFO - 10:50:12:     13%|\u2588\u258e        | 63/496 [00:00&lt;00:00, 678.40 it/sec]\n    INFO - 10:50:12:     13%|\u2588\u258e        | 64/496 [00:00&lt;00:00, 679.31 it/sec]\n    INFO - 10:50:12:     13%|\u2588\u258e        | 65/496 [00:00&lt;00:00, 679.99 it/sec]\n    INFO - 10:50:12:     13%|\u2588\u258e        | 66/496 [00:00&lt;00:00, 680.78 it/sec]\n    INFO - 10:50:12:     14%|\u2588\u258e        | 67/496 [00:00&lt;00:00, 681.54 it/sec]\n    INFO - 10:50:12:     14%|\u2588\u258e        | 68/496 [00:00&lt;00:00, 682.28 it/sec]\n    INFO - 10:50:12:     14%|\u2588\u258d        | 69/496 [00:00&lt;00:00, 683.00 it/sec]\n    INFO - 10:50:12:     14%|\u2588\u258d        | 70/496 [00:00&lt;00:00, 683.79 it/sec]\n    INFO - 10:50:12:     14%|\u2588\u258d        | 71/496 [00:00&lt;00:00, 684.51 it/sec]\n    INFO - 10:50:12:     15%|\u2588\u258d        | 72/496 [00:00&lt;00:00, 685.38 it/sec]\n    INFO - 10:50:12:     15%|\u2588\u258d        | 73/496 [00:00&lt;00:00, 686.14 it/sec]\n    INFO - 10:50:12:     15%|\u2588\u258d        | 74/496 [00:00&lt;00:00, 686.77 it/sec]\n    INFO - 10:50:12:     15%|\u2588\u258c        | 75/496 [00:00&lt;00:00, 687.38 it/sec]\n    INFO - 10:50:12:     15%|\u2588\u258c        | 76/496 [00:00&lt;00:00, 687.90 it/sec]\n    INFO - 10:50:12:     16%|\u2588\u258c        | 77/496 [00:00&lt;00:00, 688.68 it/sec]\n    INFO - 10:50:12:     16%|\u2588\u258c        | 78/496 [00:00&lt;00:00, 689.43 it/sec]\n    INFO - 10:50:12:     16%|\u2588\u258c        | 79/496 [00:00&lt;00:00, 689.96 it/sec]\n    INFO - 10:50:12:     16%|\u2588\u258c        | 80/496 [00:00&lt;00:00, 690.60 it/sec]\n    INFO - 10:50:12:     16%|\u2588\u258b        | 81/496 [00:00&lt;00:00, 691.27 it/sec]\n    INFO - 10:50:12:     17%|\u2588\u258b        | 82/496 [00:00&lt;00:00, 691.76 it/sec]\n    INFO - 10:50:12:     17%|\u2588\u258b        | 83/496 [00:00&lt;00:00, 692.41 it/sec]\n    INFO - 10:50:12:     17%|\u2588\u258b        | 84/496 [00:00&lt;00:00, 692.54 it/sec]\n    INFO - 10:50:12:     17%|\u2588\u258b        | 85/496 [00:00&lt;00:00, 693.03 it/sec]\n    INFO - 10:50:12:     17%|\u2588\u258b        | 86/496 [00:00&lt;00:00, 693.63 it/sec]\n    INFO - 10:50:12:     18%|\u2588\u258a        | 87/496 [00:00&lt;00:00, 694.18 it/sec]\n    INFO - 10:50:12:     18%|\u2588\u258a        | 88/496 [00:00&lt;00:00, 694.57 it/sec]\n    INFO - 10:50:12:     18%|\u2588\u258a        | 89/496 [00:00&lt;00:00, 695.11 it/sec]\n    INFO - 10:50:12:     18%|\u2588\u258a        | 90/496 [00:00&lt;00:00, 695.51 it/sec]\n    INFO - 10:50:12:     18%|\u2588\u258a        | 91/496 [00:00&lt;00:00, 695.98 it/sec]\n    INFO - 10:50:12:     19%|\u2588\u258a        | 92/496 [00:00&lt;00:00, 696.48 it/sec]\n    INFO - 10:50:12:     19%|\u2588\u2589        | 93/496 [00:00&lt;00:00, 696.76 it/sec]\n    INFO - 10:50:12:     19%|\u2588\u2589        | 94/496 [00:00&lt;00:00, 697.18 it/sec]\n    INFO - 10:50:12:     19%|\u2588\u2589        | 95/496 [00:00&lt;00:00, 697.72 it/sec]\n    INFO - 10:50:12:     19%|\u2588\u2589        | 96/496 [00:00&lt;00:00, 698.12 it/sec]\n    INFO - 10:50:12:     20%|\u2588\u2589        | 97/496 [00:00&lt;00:00, 698.30 it/sec]\n    INFO - 10:50:12:     20%|\u2588\u2589        | 98/496 [00:00&lt;00:00, 698.52 it/sec]\n    INFO - 10:50:12:     20%|\u2588\u2589        | 99/496 [00:00&lt;00:00, 698.83 it/sec]\n    INFO - 10:50:12:     20%|\u2588\u2588        | 100/496 [00:00&lt;00:00, 699.33 it/sec]\n    INFO - 10:50:12:     20%|\u2588\u2588        | 101/496 [00:00&lt;00:00, 699.77 it/sec]\n    INFO - 10:50:12:     21%|\u2588\u2588        | 102/496 [00:00&lt;00:00, 700.11 it/sec]\n    INFO - 10:50:12:     21%|\u2588\u2588        | 103/496 [00:00&lt;00:00, 700.60 it/sec]\n    INFO - 10:50:12:     21%|\u2588\u2588        | 104/496 [00:00&lt;00:00, 700.90 it/sec]\n    INFO - 10:50:12:     21%|\u2588\u2588        | 105/496 [00:00&lt;00:00, 701.21 it/sec]\n    INFO - 10:50:12:     21%|\u2588\u2588\u258f       | 106/496 [00:00&lt;00:00, 701.59 it/sec]\n    INFO - 10:50:12:     22%|\u2588\u2588\u258f       | 107/496 [00:00&lt;00:00, 701.92 it/sec]\n    INFO - 10:50:12:     22%|\u2588\u2588\u258f       | 108/496 [00:00&lt;00:00, 702.15 it/sec]\n    INFO - 10:50:12:     22%|\u2588\u2588\u258f       | 109/496 [00:00&lt;00:00, 702.53 it/sec]\n    INFO - 10:50:12:     22%|\u2588\u2588\u258f       | 110/496 [00:00&lt;00:00, 702.73 it/sec]\n    INFO - 10:50:12:     22%|\u2588\u2588\u258f       | 111/496 [00:00&lt;00:00, 703.06 it/sec]\n    INFO - 10:50:12:     23%|\u2588\u2588\u258e       | 112/496 [00:00&lt;00:00, 703.41 it/sec]\n    INFO - 10:50:12:     23%|\u2588\u2588\u258e       | 113/496 [00:00&lt;00:00, 703.65 it/sec]\n    INFO - 10:50:12:     23%|\u2588\u2588\u258e       | 114/496 [00:00&lt;00:00, 704.02 it/sec]\n    INFO - 10:50:12:     23%|\u2588\u2588\u258e       | 115/496 [00:00&lt;00:00, 704.27 it/sec]\n    INFO - 10:50:12:     23%|\u2588\u2588\u258e       | 116/496 [00:00&lt;00:00, 704.55 it/sec]\n    INFO - 10:50:12:     24%|\u2588\u2588\u258e       | 117/496 [00:00&lt;00:00, 704.90 it/sec]\n    INFO - 10:50:12:     24%|\u2588\u2588\u258d       | 118/496 [00:00&lt;00:00, 705.23 it/sec]\n    INFO - 10:50:12:     24%|\u2588\u2588\u258d       | 119/496 [00:00&lt;00:00, 705.37 it/sec]\n    INFO - 10:50:12:     24%|\u2588\u2588\u258d       | 120/496 [00:00&lt;00:00, 705.71 it/sec]\n    INFO - 10:50:12:     24%|\u2588\u2588\u258d       | 121/496 [00:00&lt;00:00, 705.96 it/sec]\n    INFO - 10:50:12:     25%|\u2588\u2588\u258d       | 122/496 [00:00&lt;00:00, 706.18 it/sec]\n    INFO - 10:50:12:     25%|\u2588\u2588\u258d       | 123/496 [00:00&lt;00:00, 706.53 it/sec]\n    INFO - 10:50:12:     25%|\u2588\u2588\u258c       | 124/496 [00:00&lt;00:00, 706.74 it/sec]\n    INFO - 10:50:12:     25%|\u2588\u2588\u258c       | 125/496 [00:00&lt;00:00, 707.08 it/sec]\n    INFO - 10:50:12:     25%|\u2588\u2588\u258c       | 126/496 [00:00&lt;00:00, 707.39 it/sec]\n    INFO - 10:50:12:     26%|\u2588\u2588\u258c       | 127/496 [00:00&lt;00:00, 707.63 it/sec]\n    INFO - 10:50:12:     26%|\u2588\u2588\u258c       | 128/496 [00:00&lt;00:00, 707.71 it/sec]\n    INFO - 10:50:12:     26%|\u2588\u2588\u258c       | 129/496 [00:00&lt;00:00, 707.98 it/sec]\n    INFO - 10:50:12:     26%|\u2588\u2588\u258c       | 130/496 [00:00&lt;00:00, 708.20 it/sec]\n    INFO - 10:50:12:     26%|\u2588\u2588\u258b       | 131/496 [00:00&lt;00:00, 708.50 it/sec]\n    INFO - 10:50:12:     27%|\u2588\u2588\u258b       | 132/496 [00:00&lt;00:00, 708.72 it/sec]\n    INFO - 10:50:12:     27%|\u2588\u2588\u258b       | 133/496 [00:00&lt;00:00, 708.93 it/sec]\n    INFO - 10:50:12:     27%|\u2588\u2588\u258b       | 134/496 [00:00&lt;00:00, 709.09 it/sec]\n    INFO - 10:50:12:     27%|\u2588\u2588\u258b       | 135/496 [00:00&lt;00:00, 709.24 it/sec]\n    INFO - 10:50:12:     27%|\u2588\u2588\u258b       | 136/496 [00:00&lt;00:00, 709.40 it/sec]\n    INFO - 10:50:12:     28%|\u2588\u2588\u258a       | 137/496 [00:00&lt;00:00, 709.69 it/sec]\n    INFO - 10:50:12:     28%|\u2588\u2588\u258a       | 138/496 [00:00&lt;00:00, 709.91 it/sec]\n    INFO - 10:50:12:     28%|\u2588\u2588\u258a       | 139/496 [00:00&lt;00:00, 710.03 it/sec]\n    INFO - 10:50:12:     28%|\u2588\u2588\u258a       | 140/496 [00:00&lt;00:00, 710.28 it/sec]\n    INFO - 10:50:12:     28%|\u2588\u2588\u258a       | 141/496 [00:00&lt;00:00, 710.41 it/sec]\n    INFO - 10:50:12:     29%|\u2588\u2588\u258a       | 142/496 [00:00&lt;00:00, 710.70 it/sec]\n    INFO - 10:50:12:     29%|\u2588\u2588\u2589       | 143/496 [00:00&lt;00:00, 710.95 it/sec]\n    INFO - 10:50:12:     29%|\u2588\u2588\u2589       | 144/496 [00:00&lt;00:00, 710.81 it/sec]\n    INFO - 10:50:12:     29%|\u2588\u2588\u2589       | 145/496 [00:00&lt;00:00, 708.35 it/sec]\n    INFO - 10:50:12:     29%|\u2588\u2588\u2589       | 146/496 [00:00&lt;00:00, 707.07 it/sec]\n    INFO - 10:50:12:     30%|\u2588\u2588\u2589       | 147/496 [00:00&lt;00:00, 706.76 it/sec]\n    INFO - 10:50:12:     30%|\u2588\u2588\u2589       | 148/496 [00:00&lt;00:00, 706.54 it/sec]\n    INFO - 10:50:12:     30%|\u2588\u2588\u2588       | 149/496 [00:00&lt;00:00, 706.58 it/sec]\n    INFO - 10:50:12:     30%|\u2588\u2588\u2588       | 150/496 [00:00&lt;00:00, 706.72 it/sec]\n    INFO - 10:50:12:     30%|\u2588\u2588\u2588       | 151/496 [00:00&lt;00:00, 706.87 it/sec]\n    INFO - 10:50:12:     31%|\u2588\u2588\u2588       | 152/496 [00:00&lt;00:00, 707.07 it/sec]\n    INFO - 10:50:12:     31%|\u2588\u2588\u2588       | 153/496 [00:00&lt;00:00, 707.24 it/sec]\n    INFO - 10:50:12:     31%|\u2588\u2588\u2588       | 154/496 [00:00&lt;00:00, 707.34 it/sec]\n    INFO - 10:50:12:     31%|\u2588\u2588\u2588\u258f      | 155/496 [00:00&lt;00:00, 707.53 it/sec]\n    INFO - 10:50:12:     31%|\u2588\u2588\u2588\u258f      | 156/496 [00:00&lt;00:00, 707.65 it/sec]\n    INFO - 10:50:12:     32%|\u2588\u2588\u2588\u258f      | 157/496 [00:00&lt;00:00, 707.85 it/sec]\n    INFO - 10:50:12:     32%|\u2588\u2588\u2588\u258f      | 158/496 [00:00&lt;00:00, 708.08 it/sec]\n    INFO - 10:50:12:     32%|\u2588\u2588\u2588\u258f      | 159/496 [00:00&lt;00:00, 708.23 it/sec]\n    INFO - 10:50:12:     32%|\u2588\u2588\u2588\u258f      | 160/496 [00:00&lt;00:00, 708.44 it/sec]\n    INFO - 10:50:12:     32%|\u2588\u2588\u2588\u258f      | 161/496 [00:00&lt;00:00, 708.67 it/sec]\n    INFO - 10:50:12:     33%|\u2588\u2588\u2588\u258e      | 162/496 [00:00&lt;00:00, 708.75 it/sec]\n    INFO - 10:50:12:     33%|\u2588\u2588\u2588\u258e      | 163/496 [00:00&lt;00:00, 708.98 it/sec]\n    INFO - 10:50:12:     33%|\u2588\u2588\u2588\u258e      | 164/496 [00:00&lt;00:00, 709.15 it/sec]\n    INFO - 10:50:12:     33%|\u2588\u2588\u2588\u258e      | 165/496 [00:00&lt;00:00, 709.30 it/sec]\n    INFO - 10:50:12:     33%|\u2588\u2588\u2588\u258e      | 166/496 [00:00&lt;00:00, 709.50 it/sec]\n    INFO - 10:50:12:     34%|\u2588\u2588\u2588\u258e      | 167/496 [00:00&lt;00:00, 709.68 it/sec]\n    INFO - 10:50:12:     34%|\u2588\u2588\u2588\u258d      | 168/496 [00:00&lt;00:00, 709.82 it/sec]\n    INFO - 10:50:12:     34%|\u2588\u2588\u2588\u258d      | 169/496 [00:00&lt;00:00, 710.05 it/sec]\n    INFO - 10:50:12:     34%|\u2588\u2588\u2588\u258d      | 170/496 [00:00&lt;00:00, 710.25 it/sec]\n    INFO - 10:50:12:     34%|\u2588\u2588\u2588\u258d      | 171/496 [00:00&lt;00:00, 710.37 it/sec]\n    INFO - 10:50:12:     35%|\u2588\u2588\u2588\u258d      | 172/496 [00:00&lt;00:00, 710.58 it/sec]\n    INFO - 10:50:12:     35%|\u2588\u2588\u2588\u258d      | 173/496 [00:00&lt;00:00, 710.69 it/sec]\n    INFO - 10:50:12:     35%|\u2588\u2588\u2588\u258c      | 174/496 [00:00&lt;00:00, 710.89 it/sec]\n    INFO - 10:50:12:     35%|\u2588\u2588\u2588\u258c      | 175/496 [00:00&lt;00:00, 711.09 it/sec]\n    INFO - 10:50:12:     35%|\u2588\u2588\u2588\u258c      | 176/496 [00:00&lt;00:00, 711.17 it/sec]\n    INFO - 10:50:12:     36%|\u2588\u2588\u2588\u258c      | 177/496 [00:00&lt;00:00, 711.27 it/sec]\n    INFO - 10:50:12:     36%|\u2588\u2588\u2588\u258c      | 178/496 [00:00&lt;00:00, 711.44 it/sec]\n    INFO - 10:50:12:     36%|\u2588\u2588\u2588\u258c      | 179/496 [00:00&lt;00:00, 711.53 it/sec]\n    INFO - 10:50:12:     36%|\u2588\u2588\u2588\u258b      | 180/496 [00:00&lt;00:00, 711.71 it/sec]\n    INFO - 10:50:12:     36%|\u2588\u2588\u2588\u258b      | 181/496 [00:00&lt;00:00, 711.87 it/sec]\n    INFO - 10:50:12:     37%|\u2588\u2588\u2588\u258b      | 182/496 [00:00&lt;00:00, 711.97 it/sec]\n    INFO - 10:50:12:     37%|\u2588\u2588\u2588\u258b      | 183/496 [00:00&lt;00:00, 712.18 it/sec]\n    INFO - 10:50:12:     37%|\u2588\u2588\u2588\u258b      | 184/496 [00:00&lt;00:00, 712.32 it/sec]\n    INFO - 10:50:12:     37%|\u2588\u2588\u2588\u258b      | 185/496 [00:00&lt;00:00, 712.41 it/sec]\n    INFO - 10:50:12:     38%|\u2588\u2588\u2588\u258a      | 186/496 [00:00&lt;00:00, 712.56 it/sec]\n    INFO - 10:50:12:     38%|\u2588\u2588\u2588\u258a      | 187/496 [00:00&lt;00:00, 712.72 it/sec]\n    INFO - 10:50:12:     38%|\u2588\u2588\u2588\u258a      | 188/496 [00:00&lt;00:00, 712.82 it/sec]\n    INFO - 10:50:12:     38%|\u2588\u2588\u2588\u258a      | 189/496 [00:00&lt;00:00, 712.95 it/sec]\n    INFO - 10:50:12:     38%|\u2588\u2588\u2588\u258a      | 190/496 [00:00&lt;00:00, 712.97 it/sec]\n    INFO - 10:50:12:     39%|\u2588\u2588\u2588\u258a      | 191/496 [00:00&lt;00:00, 712.30 it/sec]\n    INFO - 10:50:12:     39%|\u2588\u2588\u2588\u258a      | 192/496 [00:00&lt;00:00, 711.89 it/sec]\n    INFO - 10:50:12:     39%|\u2588\u2588\u2588\u2589      | 193/496 [00:00&lt;00:00, 711.93 it/sec]\n    INFO - 10:50:12:     39%|\u2588\u2588\u2588\u2589      | 194/496 [00:00&lt;00:00, 711.98 it/sec]\n    INFO - 10:50:12:     39%|\u2588\u2588\u2588\u2589      | 195/496 [00:00&lt;00:00, 712.15 it/sec]\n    INFO - 10:50:12:     40%|\u2588\u2588\u2588\u2589      | 196/496 [00:00&lt;00:00, 712.34 it/sec]\n    INFO - 10:50:12:     40%|\u2588\u2588\u2588\u2589      | 197/496 [00:00&lt;00:00, 712.35 it/sec]\n    INFO - 10:50:12:     40%|\u2588\u2588\u2588\u2589      | 198/496 [00:00&lt;00:00, 712.51 it/sec]\n    INFO - 10:50:12:     40%|\u2588\u2588\u2588\u2588      | 199/496 [00:00&lt;00:00, 712.67 it/sec]\n    INFO - 10:50:12:     40%|\u2588\u2588\u2588\u2588      | 200/496 [00:00&lt;00:00, 712.77 it/sec]\n    INFO - 10:50:12:     41%|\u2588\u2588\u2588\u2588      | 201/496 [00:00&lt;00:00, 712.89 it/sec]\n    INFO - 10:50:12:     41%|\u2588\u2588\u2588\u2588      | 202/496 [00:00&lt;00:00, 712.98 it/sec]\n    INFO - 10:50:12:     41%|\u2588\u2588\u2588\u2588      | 203/496 [00:00&lt;00:00, 712.84 it/sec]\n    INFO - 10:50:12:     41%|\u2588\u2588\u2588\u2588      | 204/496 [00:00&lt;00:00, 712.96 it/sec]\n    INFO - 10:50:12:     41%|\u2588\u2588\u2588\u2588\u258f     | 205/496 [00:00&lt;00:00, 713.02 it/sec]\n    INFO - 10:50:12:     42%|\u2588\u2588\u2588\u2588\u258f     | 206/496 [00:00&lt;00:00, 713.13 it/sec]\n    INFO - 10:50:12:     42%|\u2588\u2588\u2588\u2588\u258f     | 207/496 [00:00&lt;00:00, 713.23 it/sec]\n    INFO - 10:50:12:     42%|\u2588\u2588\u2588\u2588\u258f     | 208/496 [00:00&lt;00:00, 713.34 it/sec]\n    INFO - 10:50:12:     42%|\u2588\u2588\u2588\u2588\u258f     | 209/496 [00:00&lt;00:00, 713.50 it/sec]\n    INFO - 10:50:12:     42%|\u2588\u2588\u2588\u2588\u258f     | 210/496 [00:00&lt;00:00, 713.64 it/sec]\n    INFO - 10:50:12:     43%|\u2588\u2588\u2588\u2588\u258e     | 211/496 [00:00&lt;00:00, 713.74 it/sec]\n    INFO - 10:50:12:     43%|\u2588\u2588\u2588\u2588\u258e     | 212/496 [00:00&lt;00:00, 713.91 it/sec]\n    INFO - 10:50:12:     43%|\u2588\u2588\u2588\u2588\u258e     | 213/496 [00:00&lt;00:00, 714.05 it/sec]\n    INFO - 10:50:12:     43%|\u2588\u2588\u2588\u2588\u258e     | 214/496 [00:00&lt;00:00, 714.15 it/sec]\n    INFO - 10:50:12:     43%|\u2588\u2588\u2588\u2588\u258e     | 215/496 [00:00&lt;00:00, 714.31 it/sec]\n    INFO - 10:50:12:     44%|\u2588\u2588\u2588\u2588\u258e     | 216/496 [00:00&lt;00:00, 714.45 it/sec]\n    INFO - 10:50:12:     44%|\u2588\u2588\u2588\u2588\u258d     | 217/496 [00:00&lt;00:00, 714.54 it/sec]\n    INFO - 10:50:12:     44%|\u2588\u2588\u2588\u2588\u258d     | 218/496 [00:00&lt;00:00, 714.66 it/sec]\n    INFO - 10:50:12:     44%|\u2588\u2588\u2588\u2588\u258d     | 219/496 [00:00&lt;00:00, 714.79 it/sec]\n    INFO - 10:50:12:     44%|\u2588\u2588\u2588\u2588\u258d     | 220/496 [00:00&lt;00:00, 714.90 it/sec]\n    INFO - 10:50:12:     45%|\u2588\u2588\u2588\u2588\u258d     | 221/496 [00:00&lt;00:00, 715.02 it/sec]\n    INFO - 10:50:12:     45%|\u2588\u2588\u2588\u2588\u258d     | 222/496 [00:00&lt;00:00, 715.05 it/sec]\n    INFO - 10:50:12:     45%|\u2588\u2588\u2588\u2588\u258d     | 223/496 [00:00&lt;00:00, 715.21 it/sec]\n    INFO - 10:50:12:     45%|\u2588\u2588\u2588\u2588\u258c     | 224/496 [00:00&lt;00:00, 715.38 it/sec]\n    INFO - 10:50:12:     45%|\u2588\u2588\u2588\u2588\u258c     | 225/496 [00:00&lt;00:00, 715.18 it/sec]\n    INFO - 10:50:12:     46%|\u2588\u2588\u2588\u2588\u258c     | 226/496 [00:00&lt;00:00, 714.86 it/sec]\n    INFO - 10:50:12:     46%|\u2588\u2588\u2588\u2588\u258c     | 227/496 [00:00&lt;00:00, 714.86 it/sec]\n    INFO - 10:50:12:     46%|\u2588\u2588\u2588\u2588\u258c     | 228/496 [00:00&lt;00:00, 714.97 it/sec]\n    INFO - 10:50:12:     46%|\u2588\u2588\u2588\u2588\u258c     | 229/496 [00:00&lt;00:00, 715.05 it/sec]\n    INFO - 10:50:12:     46%|\u2588\u2588\u2588\u2588\u258b     | 230/496 [00:00&lt;00:00, 715.16 it/sec]\n    INFO - 10:50:12:     47%|\u2588\u2588\u2588\u2588\u258b     | 231/496 [00:00&lt;00:00, 715.32 it/sec]\n    INFO - 10:50:12:     47%|\u2588\u2588\u2588\u2588\u258b     | 232/496 [00:00&lt;00:00, 715.48 it/sec]\n    INFO - 10:50:12:     47%|\u2588\u2588\u2588\u2588\u258b     | 233/496 [00:00&lt;00:00, 715.53 it/sec]\n    INFO - 10:50:12:     47%|\u2588\u2588\u2588\u2588\u258b     | 234/496 [00:00&lt;00:00, 715.69 it/sec]\n    INFO - 10:50:12:     47%|\u2588\u2588\u2588\u2588\u258b     | 235/496 [00:00&lt;00:00, 715.77 it/sec]\n    INFO - 10:50:12:     48%|\u2588\u2588\u2588\u2588\u258a     | 236/496 [00:00&lt;00:00, 715.85 it/sec]\n    INFO - 10:50:12:     48%|\u2588\u2588\u2588\u2588\u258a     | 237/496 [00:00&lt;00:00, 715.95 it/sec]\n    INFO - 10:50:12:     48%|\u2588\u2588\u2588\u2588\u258a     | 238/496 [00:00&lt;00:00, 716.03 it/sec]\n    INFO - 10:50:12:     48%|\u2588\u2588\u2588\u2588\u258a     | 239/496 [00:00&lt;00:00, 716.10 it/sec]\n    INFO - 10:50:12:     48%|\u2588\u2588\u2588\u2588\u258a     | 240/496 [00:00&lt;00:00, 716.19 it/sec]\n    INFO - 10:50:12:     49%|\u2588\u2588\u2588\u2588\u258a     | 241/496 [00:00&lt;00:00, 716.17 it/sec]\n    INFO - 10:50:12:     49%|\u2588\u2588\u2588\u2588\u2589     | 242/496 [00:00&lt;00:00, 716.26 it/sec]\n    INFO - 10:50:12:     49%|\u2588\u2588\u2588\u2588\u2589     | 243/496 [00:00&lt;00:00, 716.37 it/sec]\n    INFO - 10:50:12:     49%|\u2588\u2588\u2588\u2588\u2589     | 244/496 [00:00&lt;00:00, 716.45 it/sec]\n    INFO - 10:50:12:     49%|\u2588\u2588\u2588\u2588\u2589     | 245/496 [00:00&lt;00:00, 716.56 it/sec]\n    INFO - 10:50:12:     50%|\u2588\u2588\u2588\u2588\u2589     | 246/496 [00:00&lt;00:00, 716.64 it/sec]\n    INFO - 10:50:12:     50%|\u2588\u2588\u2588\u2588\u2589     | 247/496 [00:00&lt;00:00, 716.68 it/sec]\n    INFO - 10:50:12:     50%|\u2588\u2588\u2588\u2588\u2588     | 248/496 [00:00&lt;00:00, 716.70 it/sec]\n    INFO - 10:50:12:     50%|\u2588\u2588\u2588\u2588\u2588     | 249/496 [00:00&lt;00:00, 716.70 it/sec]\n    INFO - 10:50:12:     50%|\u2588\u2588\u2588\u2588\u2588     | 250/496 [00:00&lt;00:00, 716.76 it/sec]\n    INFO - 10:50:12:     51%|\u2588\u2588\u2588\u2588\u2588     | 251/496 [00:00&lt;00:00, 716.86 it/sec]\n    INFO - 10:50:12:     51%|\u2588\u2588\u2588\u2588\u2588     | 252/496 [00:00&lt;00:00, 716.86 it/sec]\n    INFO - 10:50:12:     51%|\u2588\u2588\u2588\u2588\u2588     | 253/496 [00:00&lt;00:00, 716.96 it/sec]\n    INFO - 10:50:12:     51%|\u2588\u2588\u2588\u2588\u2588     | 254/496 [00:00&lt;00:00, 717.05 it/sec]\n    INFO - 10:50:12:     51%|\u2588\u2588\u2588\u2588\u2588\u258f    | 255/496 [00:00&lt;00:00, 717.08 it/sec]\n    INFO - 10:50:12:     52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 256/496 [00:00&lt;00:00, 717.13 it/sec]\n    INFO - 10:50:12:     52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 257/496 [00:00&lt;00:00, 717.22 it/sec]\n    INFO - 10:50:12:     52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 258/496 [00:00&lt;00:00, 717.27 it/sec]\n    INFO - 10:50:12:     52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 259/496 [00:00&lt;00:00, 717.11 it/sec]\n    INFO - 10:50:12:     52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 260/496 [00:00&lt;00:00, 717.02 it/sec]\n    INFO - 10:50:12:     53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 261/496 [00:00&lt;00:00, 717.01 it/sec]\n    INFO - 10:50:12:     53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 262/496 [00:00&lt;00:00, 717.06 it/sec]\n    INFO - 10:50:12:     53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 263/496 [00:00&lt;00:00, 717.10 it/sec]\n    INFO - 10:50:12:     53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 264/496 [00:00&lt;00:00, 717.14 it/sec]\n    INFO - 10:50:12:     53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 265/496 [00:00&lt;00:00, 717.16 it/sec]\n    INFO - 10:50:12:     54%|\u2588\u2588\u2588\u2588\u2588\u258e    | 266/496 [00:00&lt;00:00, 717.25 it/sec]\n    INFO - 10:50:12:     54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 267/496 [00:00&lt;00:00, 717.34 it/sec]\n    INFO - 10:50:12:     54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 268/496 [00:00&lt;00:00, 717.34 it/sec]\n    INFO - 10:50:12:     54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 269/496 [00:00&lt;00:00, 717.44 it/sec]\n    INFO - 10:50:12:     54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 270/496 [00:00&lt;00:00, 717.49 it/sec]\n    INFO - 10:50:12:     55%|\u2588\u2588\u2588\u2588\u2588\u258d    | 271/496 [00:00&lt;00:00, 717.54 it/sec]\n    INFO - 10:50:12:     55%|\u2588\u2588\u2588\u2588\u2588\u258d    | 272/496 [00:00&lt;00:00, 717.63 it/sec]\n    INFO - 10:50:12:     55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 273/496 [00:00&lt;00:00, 717.72 it/sec]\n    INFO - 10:50:12:     55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 274/496 [00:00&lt;00:00, 717.75 it/sec]\n    INFO - 10:50:12:     55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 275/496 [00:00&lt;00:00, 717.86 it/sec]\n    INFO - 10:50:12:     56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 276/496 [00:00&lt;00:00, 717.89 it/sec]\n    INFO - 10:50:12:     56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 277/496 [00:00&lt;00:00, 717.98 it/sec]\n    INFO - 10:50:12:     56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 278/496 [00:00&lt;00:00, 716.12 it/sec]\n    INFO - 10:50:12:     56%|\u2588\u2588\u2588\u2588\u2588\u258b    | 279/496 [00:00&lt;00:00, 716.15 it/sec]\n    INFO - 10:50:12:     56%|\u2588\u2588\u2588\u2588\u2588\u258b    | 280/496 [00:00&lt;00:00, 716.21 it/sec]\n    INFO - 10:50:12:     57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 281/496 [00:00&lt;00:00, 716.29 it/sec]\n    INFO - 10:50:12:     57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 282/496 [00:00&lt;00:00, 716.35 it/sec]\n    INFO - 10:50:12:     57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 283/496 [00:00&lt;00:00, 716.23 it/sec]\n    INFO - 10:50:12:     57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 284/496 [00:00&lt;00:00, 716.24 it/sec]\n    INFO - 10:50:12:     57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 285/496 [00:00&lt;00:00, 716.34 it/sec]\n    INFO - 10:50:12:     58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 286/496 [00:00&lt;00:00, 716.42 it/sec]\n    INFO - 10:50:12:     58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 287/496 [00:00&lt;00:00, 716.46 it/sec]\n    INFO - 10:50:12:     58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 288/496 [00:00&lt;00:00, 716.55 it/sec]\n    INFO - 10:50:12:     58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 289/496 [00:00&lt;00:00, 716.61 it/sec]\n    INFO - 10:50:12:     58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 290/496 [00:00&lt;00:00, 716.66 it/sec]\n    INFO - 10:50:12:     59%|\u2588\u2588\u2588\u2588\u2588\u258a    | 291/496 [00:00&lt;00:00, 716.75 it/sec]\n    INFO - 10:50:12:     59%|\u2588\u2588\u2588\u2588\u2588\u2589    | 292/496 [00:00&lt;00:00, 716.78 it/sec]\n    INFO - 10:50:12:     59%|\u2588\u2588\u2588\u2588\u2588\u2589    | 293/496 [00:00&lt;00:00, 716.76 it/sec]\n    INFO - 10:50:12:     59%|\u2588\u2588\u2588\u2588\u2588\u2589    | 294/496 [00:00&lt;00:00, 716.84 it/sec]\n    INFO - 10:50:12:     59%|\u2588\u2588\u2588\u2588\u2588\u2589    | 295/496 [00:00&lt;00:00, 716.85 it/sec]\n    INFO - 10:50:12:     60%|\u2588\u2588\u2588\u2588\u2588\u2589    | 296/496 [00:00&lt;00:00, 716.93 it/sec]\n    INFO - 10:50:12:     60%|\u2588\u2588\u2588\u2588\u2588\u2589    | 297/496 [00:00&lt;00:00, 717.01 it/sec]\n    INFO - 10:50:12:     60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 298/496 [00:00&lt;00:00, 717.05 it/sec]\n    INFO - 10:50:12:     60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 299/496 [00:00&lt;00:00, 717.12 it/sec]\n    INFO - 10:50:12:     60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 300/496 [00:00&lt;00:00, 717.18 it/sec]\n    INFO - 10:50:12:     61%|\u2588\u2588\u2588\u2588\u2588\u2588    | 301/496 [00:00&lt;00:00, 717.19 it/sec]\n    INFO - 10:50:12:     61%|\u2588\u2588\u2588\u2588\u2588\u2588    | 302/496 [00:00&lt;00:00, 717.27 it/sec]\n    INFO - 10:50:12:     61%|\u2588\u2588\u2588\u2588\u2588\u2588    | 303/496 [00:00&lt;00:00, 717.33 it/sec]\n    INFO - 10:50:12:     61%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 304/496 [00:00&lt;00:00, 717.36 it/sec]\n    INFO - 10:50:12:     61%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 305/496 [00:00&lt;00:00, 717.43 it/sec]\n    INFO - 10:50:12:     62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 306/496 [00:00&lt;00:00, 717.41 it/sec]\n    INFO - 10:50:12:     62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 307/496 [00:00&lt;00:00, 717.49 it/sec]\n    INFO - 10:50:12:     62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 308/496 [00:00&lt;00:00, 717.52 it/sec]\n    INFO - 10:50:12:     62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 309/496 [00:00&lt;00:00, 717.55 it/sec]\n    INFO - 10:50:12:     62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 310/496 [00:00&lt;00:00, 717.62 it/sec]\n    INFO - 10:50:12:     63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 311/496 [00:00&lt;00:00, 717.67 it/sec]\n    INFO - 10:50:12:     63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 312/496 [00:00&lt;00:00, 717.70 it/sec]\n    INFO - 10:50:12:     63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 313/496 [00:00&lt;00:00, 717.75 it/sec]\n    INFO - 10:50:12:     63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 314/496 [00:00&lt;00:00, 717.79 it/sec]\n    INFO - 10:50:12:     64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 315/496 [00:00&lt;00:00, 717.86 it/sec]\n    INFO - 10:50:12:     64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 316/496 [00:00&lt;00:00, 717.95 it/sec]\n    INFO - 10:50:12:     64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 317/496 [00:00&lt;00:00, 717.96 it/sec]\n    INFO - 10:50:12:     64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 318/496 [00:00&lt;00:00, 718.03 it/sec]\n    INFO - 10:50:12:     64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 319/496 [00:00&lt;00:00, 718.08 it/sec]\n    INFO - 10:50:12:     65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 320/496 [00:00&lt;00:00, 718.13 it/sec]\n    INFO - 10:50:12:     65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 321/496 [00:00&lt;00:00, 718.21 it/sec]\n    INFO - 10:50:12:     65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 322/496 [00:00&lt;00:00, 718.23 it/sec]\n    INFO - 10:50:12:     65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 323/496 [00:00&lt;00:00, 718.26 it/sec]\n    INFO - 10:50:12:     65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 324/496 [00:00&lt;00:00, 718.33 it/sec]\n    INFO - 10:50:12:     66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 325/496 [00:00&lt;00:00, 718.40 it/sec]\n    INFO - 10:50:12:     66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 326/496 [00:00&lt;00:00, 718.42 it/sec]\n    INFO - 10:50:12:     66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 327/496 [00:00&lt;00:00, 718.45 it/sec]\n    INFO - 10:50:12:     66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 328/496 [00:00&lt;00:00, 718.47 it/sec]\n    INFO - 10:50:12:     66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 329/496 [00:00&lt;00:00, 718.54 it/sec]\n    INFO - 10:50:12:     67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 330/496 [00:00&lt;00:00, 718.59 it/sec]\n    INFO - 10:50:12:     67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 331/496 [00:00&lt;00:00, 718.62 it/sec]\n    INFO - 10:50:12:     67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 332/496 [00:00&lt;00:00, 718.66 it/sec]\n    INFO - 10:50:12:     67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 333/496 [00:00&lt;00:00, 718.71 it/sec]\n    INFO - 10:50:12:     67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 334/496 [00:00&lt;00:00, 718.75 it/sec]\n    INFO - 10:50:12:     68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 335/496 [00:00&lt;00:00, 718.80 it/sec]\n    INFO - 10:50:12:     68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 336/496 [00:00&lt;00:00, 718.81 it/sec]\n    INFO - 10:50:12:     68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 337/496 [00:00&lt;00:00, 718.80 it/sec]\n    INFO - 10:50:12:     68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 338/496 [00:00&lt;00:00, 718.84 it/sec]\n    INFO - 10:50:12:     68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 339/496 [00:00&lt;00:00, 718.85 it/sec]\n    INFO - 10:50:12:     69%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 340/496 [00:00&lt;00:00, 718.84 it/sec]\n    INFO - 10:50:12:     69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 341/496 [00:00&lt;00:00, 718.85 it/sec]\n    INFO - 10:50:12:     69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 342/496 [00:00&lt;00:00, 718.78 it/sec]\n    INFO - 10:50:12:     69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 343/496 [00:00&lt;00:00, 718.82 it/sec]\n    INFO - 10:50:12:     69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 344/496 [00:00&lt;00:00, 718.82 it/sec]\n    INFO - 10:50:12:     70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 345/496 [00:00&lt;00:00, 718.85 it/sec]\n    INFO - 10:50:12:     70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 346/496 [00:00&lt;00:00, 718.87 it/sec]\n    INFO - 10:50:12:     70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 347/496 [00:00&lt;00:00, 718.89 it/sec]\n    INFO - 10:50:12:     70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 348/496 [00:00&lt;00:00, 718.94 it/sec]\n    INFO - 10:50:12:     70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 349/496 [00:00&lt;00:00, 718.94 it/sec]\n    INFO - 10:50:12:     71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 350/496 [00:00&lt;00:00, 718.96 it/sec]\n    INFO - 10:50:12:     71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 351/496 [00:00&lt;00:00, 718.94 it/sec]\n    INFO - 10:50:12:     71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 352/496 [00:00&lt;00:00, 718.95 it/sec]\n    INFO - 10:50:12:     71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 353/496 [00:00&lt;00:00, 718.88 it/sec]\n    INFO - 10:50:12:     71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 354/496 [00:00&lt;00:00, 718.93 it/sec]\n    INFO - 10:50:12:     72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 355/496 [00:00&lt;00:00, 718.97 it/sec]\n    INFO - 10:50:12:     72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 356/496 [00:00&lt;00:00, 719.04 it/sec]\n    INFO - 10:50:12:     72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 357/496 [00:00&lt;00:00, 719.05 it/sec]\n    INFO - 10:50:12:     72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 358/496 [00:00&lt;00:00, 719.10 it/sec]\n    INFO - 10:50:12:     72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 359/496 [00:00&lt;00:00, 719.12 it/sec]\n    INFO - 10:50:12:     73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 360/496 [00:00&lt;00:00, 719.13 it/sec]\n    INFO - 10:50:12:     73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 361/496 [00:00&lt;00:00, 719.18 it/sec]\n    INFO - 10:50:12:     73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 362/496 [00:00&lt;00:00, 719.23 it/sec]\n    INFO - 10:50:12:     73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 363/496 [00:00&lt;00:00, 719.24 it/sec]\n    INFO - 10:50:12:     73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 364/496 [00:00&lt;00:00, 719.30 it/sec]\n    INFO - 10:50:12:     74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 365/496 [00:00&lt;00:00, 719.35 it/sec]\n    INFO - 10:50:12:     74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 366/496 [00:00&lt;00:00, 719.34 it/sec]\n    INFO - 10:50:12:     74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 367/496 [00:00&lt;00:00, 719.42 it/sec]\n    INFO - 10:50:12:     74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 368/496 [00:00&lt;00:00, 719.43 it/sec]\n    INFO - 10:50:12:     74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 369/496 [00:00&lt;00:00, 719.47 it/sec]\n    INFO - 10:50:12:     75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 370/496 [00:00&lt;00:00, 719.52 it/sec]\n    INFO - 10:50:12:     75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 371/496 [00:00&lt;00:00, 719.55 it/sec]\n    INFO - 10:50:12:     75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 372/496 [00:00&lt;00:00, 719.60 it/sec]\n    INFO - 10:50:12:     75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 373/496 [00:00&lt;00:00, 719.58 it/sec]\n    INFO - 10:50:12:     75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 374/496 [00:00&lt;00:00, 719.61 it/sec]\n    INFO - 10:50:12:     76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 375/496 [00:00&lt;00:00, 719.67 it/sec]\n    INFO - 10:50:12:     76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 376/496 [00:00&lt;00:00, 719.64 it/sec]\n    INFO - 10:50:12:     76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 377/496 [00:00&lt;00:00, 719.68 it/sec]\n    INFO - 10:50:12:     76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 378/496 [00:00&lt;00:00, 719.68 it/sec]\n    INFO - 10:50:12:     76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 379/496 [00:00&lt;00:00, 719.71 it/sec]\n    INFO - 10:50:12:     77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 380/496 [00:00&lt;00:00, 719.74 it/sec]\n    INFO - 10:50:12:     77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 381/496 [00:00&lt;00:00, 719.77 it/sec]\n    INFO - 10:50:12:     77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 382/496 [00:00&lt;00:00, 719.80 it/sec]\n    INFO - 10:50:12:     77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 383/496 [00:00&lt;00:00, 719.84 it/sec]\n    INFO - 10:50:12:     77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 384/496 [00:00&lt;00:00, 719.86 it/sec]\n    INFO - 10:50:12:     78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 385/496 [00:00&lt;00:00, 719.91 it/sec]\n    INFO - 10:50:12:     78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 386/496 [00:00&lt;00:00, 719.96 it/sec]\n    INFO - 10:50:12:     78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 387/496 [00:00&lt;00:00, 719.97 it/sec]\n    INFO - 10:50:12:     78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 388/496 [00:00&lt;00:00, 720.02 it/sec]\n    INFO - 10:50:12:     78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 389/496 [00:00&lt;00:00, 720.06 it/sec]\n    INFO - 10:50:12:     79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 390/496 [00:00&lt;00:00, 720.07 it/sec]\n    INFO - 10:50:12:     79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 391/496 [00:00&lt;00:00, 720.11 it/sec]\n    INFO - 10:50:12:     79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 392/496 [00:00&lt;00:00, 720.12 it/sec]\n    INFO - 10:50:12:     79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 393/496 [00:00&lt;00:00, 720.10 it/sec]\n    INFO - 10:50:12:     79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 394/496 [00:00&lt;00:00, 720.16 it/sec]\n    INFO - 10:50:12:     80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 395/496 [00:00&lt;00:00, 720.14 it/sec]\n    INFO - 10:50:12:     80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 396/496 [00:00&lt;00:00, 720.19 it/sec]\n    INFO - 10:50:12:     80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 397/496 [00:00&lt;00:00, 720.22 it/sec]\n    INFO - 10:50:12:     80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 398/496 [00:00&lt;00:00, 720.25 it/sec]\n    INFO - 10:50:12:     80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 399/496 [00:00&lt;00:00, 720.30 it/sec]\n    INFO - 10:50:12:     81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 400/496 [00:00&lt;00:00, 720.35 it/sec]\n    INFO - 10:50:12:     81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 401/496 [00:00&lt;00:00, 720.34 it/sec]\n    INFO - 10:50:12:     81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 402/496 [00:00&lt;00:00, 720.39 it/sec]\n    INFO - 10:50:12:     81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 403/496 [00:00&lt;00:00, 720.43 it/sec]\n    INFO - 10:50:12:     81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 404/496 [00:00&lt;00:00, 720.45 it/sec]\n    INFO - 10:50:12:     82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 405/496 [00:00&lt;00:00, 720.52 it/sec]\n    INFO - 10:50:12:     82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 406/496 [00:00&lt;00:00, 720.31 it/sec]\n    INFO - 10:50:12:     82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 407/496 [00:00&lt;00:00, 719.60 it/sec]\n    INFO - 10:50:12:     82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 408/496 [00:00&lt;00:00, 719.57 it/sec]\n    INFO - 10:50:12:     82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 409/496 [00:00&lt;00:00, 719.50 it/sec]\n    INFO - 10:50:12:     83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 410/496 [00:00&lt;00:00, 719.54 it/sec]\n    INFO - 10:50:12:     83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 411/496 [00:00&lt;00:00, 719.60 it/sec]\n    INFO - 10:50:12:     83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 412/496 [00:00&lt;00:00, 719.60 it/sec]\n    INFO - 10:50:12:     83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 413/496 [00:00&lt;00:00, 719.60 it/sec]\n    INFO - 10:50:12:     83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 414/496 [00:00&lt;00:00, 719.64 it/sec]\n    INFO - 10:50:12:     84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 415/496 [00:00&lt;00:00, 719.66 it/sec]\n    INFO - 10:50:12:     84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 416/496 [00:00&lt;00:00, 719.73 it/sec]\n    INFO - 10:50:12:     84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 417/496 [00:00&lt;00:00, 719.79 it/sec]\n    INFO - 10:50:12:     84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 418/496 [00:00&lt;00:00, 719.82 it/sec]\n    INFO - 10:50:12:     84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 419/496 [00:00&lt;00:00, 719.89 it/sec]\n    INFO - 10:50:12:     85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 420/496 [00:00&lt;00:00, 719.93 it/sec]\n    INFO - 10:50:12:     85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 421/496 [00:00&lt;00:00, 719.91 it/sec]\n    INFO - 10:50:12:     85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 422/496 [00:00&lt;00:00, 719.95 it/sec]\n    INFO - 10:50:12:     85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 423/496 [00:00&lt;00:00, 719.95 it/sec]\n    INFO - 10:50:12:     85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 424/496 [00:00&lt;00:00, 719.97 it/sec]\n    INFO - 10:50:12:     86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 425/496 [00:00&lt;00:00, 719.99 it/sec]\n    INFO - 10:50:12:     86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 426/496 [00:00&lt;00:00, 720.01 it/sec]\n    INFO - 10:50:12:     86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 427/496 [00:00&lt;00:00, 720.06 it/sec]\n    INFO - 10:50:12:     86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 428/496 [00:00&lt;00:00, 719.97 it/sec]\n    INFO - 10:50:12:     86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 429/496 [00:00&lt;00:00, 720.02 it/sec]\n    INFO - 10:50:12:     87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 430/496 [00:00&lt;00:00, 720.09 it/sec]\n    INFO - 10:50:12:     87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 431/496 [00:00&lt;00:00, 720.08 it/sec]\n    INFO - 10:50:12:     87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 432/496 [00:00&lt;00:00, 720.06 it/sec]\n    INFO - 10:50:12:     87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 433/496 [00:00&lt;00:00, 720.08 it/sec]\n    INFO - 10:50:12:     88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 434/496 [00:00&lt;00:00, 720.08 it/sec]\n    INFO - 10:50:12:     88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 435/496 [00:00&lt;00:00, 720.10 it/sec]\n    INFO - 10:50:12:     88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 436/496 [00:00&lt;00:00, 720.10 it/sec]\n    INFO - 10:50:12:     88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 437/496 [00:00&lt;00:00, 720.11 it/sec]\n    INFO - 10:50:12:     88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 438/496 [00:00&lt;00:00, 720.10 it/sec]\n    INFO - 10:50:12:     89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 439/496 [00:00&lt;00:00, 720.12 it/sec]\n    INFO - 10:50:12:     89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 440/496 [00:00&lt;00:00, 720.16 it/sec]\n    INFO - 10:50:12:     89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 441/496 [00:00&lt;00:00, 720.19 it/sec]\n    INFO - 10:50:12:     89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 442/496 [00:00&lt;00:00, 720.22 it/sec]\n    INFO - 10:50:12:     89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 443/496 [00:00&lt;00:00, 720.27 it/sec]\n    INFO - 10:50:12:     90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 444/496 [00:00&lt;00:00, 720.31 it/sec]\n    INFO - 10:50:12:     90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 445/496 [00:00&lt;00:00, 720.30 it/sec]\n    INFO - 10:50:12:     90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 446/496 [00:00&lt;00:00, 720.34 it/sec]\n    INFO - 10:50:12:     90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 447/496 [00:00&lt;00:00, 720.35 it/sec]\n    INFO - 10:50:12:     90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 448/496 [00:00&lt;00:00, 720.36 it/sec]\n    INFO - 10:50:12:     91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 449/496 [00:00&lt;00:00, 720.40 it/sec]\n    INFO - 10:50:12:     91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 450/496 [00:00&lt;00:00, 720.41 it/sec]\n    INFO - 10:50:12:     91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 451/496 [00:00&lt;00:00, 720.45 it/sec]\n    INFO - 10:50:12:     91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 452/496 [00:00&lt;00:00, 720.49 it/sec]\n    INFO - 10:50:12:     91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 453/496 [00:00&lt;00:00, 720.47 it/sec]\n    INFO - 10:50:12:     92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 454/496 [00:00&lt;00:00, 720.50 it/sec]\n    INFO - 10:50:12:     92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 455/496 [00:00&lt;00:00, 720.43 it/sec]\n    INFO - 10:50:12:     92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 456/496 [00:00&lt;00:00, 720.41 it/sec]\n    INFO - 10:50:12:     92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 457/496 [00:00&lt;00:00, 720.43 it/sec]\n    INFO - 10:50:12:     92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 458/496 [00:00&lt;00:00, 720.42 it/sec]\n    INFO - 10:50:12:     93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 459/496 [00:00&lt;00:00, 720.46 it/sec]\n    INFO - 10:50:12:     93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 460/496 [00:00&lt;00:00, 720.47 it/sec]\n    INFO - 10:50:12:     93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 461/496 [00:00&lt;00:00, 720.52 it/sec]\n    INFO - 10:50:12:     93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 462/496 [00:00&lt;00:00, 720.57 it/sec]\n    INFO - 10:50:12:     93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 463/496 [00:00&lt;00:00, 720.58 it/sec]\n    INFO - 10:50:12:     94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 464/496 [00:00&lt;00:00, 720.62 it/sec]\n    INFO - 10:50:12:     94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 465/496 [00:00&lt;00:00, 720.63 it/sec]\n    INFO - 10:50:12:     94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 466/496 [00:00&lt;00:00, 720.64 it/sec]\n    INFO - 10:50:12:     94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 467/496 [00:00&lt;00:00, 720.69 it/sec]\n    INFO - 10:50:12:     94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 468/496 [00:00&lt;00:00, 720.69 it/sec]\n    INFO - 10:50:12:     95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 469/496 [00:00&lt;00:00, 720.69 it/sec]\n    INFO - 10:50:12:     95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 470/496 [00:00&lt;00:00, 720.74 it/sec]\n    INFO - 10:50:12:     95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 471/496 [00:00&lt;00:00, 720.74 it/sec]\n    INFO - 10:50:12:     95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 472/496 [00:00&lt;00:00, 720.78 it/sec]\n    INFO - 10:50:12:     95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 473/496 [00:00&lt;00:00, 720.79 it/sec]\n    INFO - 10:50:12:     96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 474/496 [00:00&lt;00:00, 720.82 it/sec]\n    INFO - 10:50:12:     96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 475/496 [00:00&lt;00:00, 720.85 it/sec]\n    INFO - 10:50:12:     96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 476/496 [00:00&lt;00:00, 720.87 it/sec]\n    INFO - 10:50:12:     96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 477/496 [00:00&lt;00:00, 720.90 it/sec]\n    INFO - 10:50:12:     96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 478/496 [00:00&lt;00:00, 720.95 it/sec]\n    INFO - 10:50:12:     97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 479/496 [00:00&lt;00:00, 721.00 it/sec]\n    INFO - 10:50:12:     97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 480/496 [00:00&lt;00:00, 720.97 it/sec]\n    INFO - 10:50:12:     97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 481/496 [00:00&lt;00:00, 720.91 it/sec]\n    INFO - 10:50:12:     97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 482/496 [00:00&lt;00:00, 720.87 it/sec]\n    INFO - 10:50:12:     97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 483/496 [00:00&lt;00:00, 720.91 it/sec]\n    INFO - 10:50:12:     98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 484/496 [00:00&lt;00:00, 720.93 it/sec]\n    INFO - 10:50:12:     98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 485/496 [00:00&lt;00:00, 720.94 it/sec]\n    INFO - 10:50:12:     98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 486/496 [00:00&lt;00:00, 720.99 it/sec]\n    INFO - 10:50:12:     98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 487/496 [00:00&lt;00:00, 720.99 it/sec]\n    INFO - 10:50:12:     98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 488/496 [00:00&lt;00:00, 721.04 it/sec]\n    INFO - 10:50:12:     99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 489/496 [00:00&lt;00:00, 721.08 it/sec]\n    INFO - 10:50:12:     99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 490/496 [00:00&lt;00:00, 721.11 it/sec]\n    INFO - 10:50:12:     99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 491/496 [00:00&lt;00:00, 721.12 it/sec]\n    INFO - 10:50:12:     99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 492/496 [00:00&lt;00:00, 721.17 it/sec]\n    INFO - 10:50:12:     99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 493/496 [00:00&lt;00:00, 721.20 it/sec]\n    INFO - 10:50:12:    100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 494/496 [00:00&lt;00:00, 721.25 it/sec]\n    INFO - 10:50:12:    100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 495/496 [00:00&lt;00:00, 721.28 it/sec]\n    INFO - 10:50:12:    100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 496/496 [00:00&lt;00:00, 721.26 it/sec]\n    INFO - 10:50:12: *** End SobolAnalysisSamplingPhase execution (time: 0:00:00.700648) ***\n\n&lt;gemseo.post.dataset.surfaces.Surfaces object at 0x78c11d315ac0&gt;\n</code></pre> <p></p> <pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.core.chains.chain import MDOChain\nfrom gemseo.uncertainty.sensitivity.sobol_analysis import SobolAnalysis\n\nfrom gemseo_umdo.use_cases.beam_model.constraints import BeamConstraints\nfrom gemseo_umdo.use_cases.beam_model.discipline import Beam\nfrom gemseo_umdo.use_cases.beam_model.uncertain_space import BeamUncertainSpace\n\nconfigure_logger()\n\nuncertain_space = BeamUncertainSpace()\n\nn_y = n_z = 10\n\nmdo_chain = MDOChain([Beam(n_y=n_y, n_z=n_z), BeamConstraints()])\n\nsobol = SobolAnalysis()\nsobol.compute_samples(\n    [mdo_chain], uncertain_space, 500, output_names=[\"c_displ\", \"c_stress\"]\n)\nmesh = mdo_chain.disciplines[0].io.data[\"yz_grid\"].reshape((-1, 2))\nsobol.main_method = \"total\"\nsobol.compute_indices()\nsobol.plot_field(\"c_displ\", mesh=mesh, save=False, show=True)\nsobol.plot_field(\"c_stress\", mesh=mesh, save=False, show=True)\n</code></pre> <p>Total running time of the script: ( 0 minutes  1.914 seconds)</p> <p> Download Python source code: plot_beam_sa.py</p> <p> Download Jupyter notebook: plot_beam_sa.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/","title":"MDO under uncertainty","text":""},{"location":"generated/examples/umdo/#mdo-under-uncertainty","title":"MDO under uncertainty","text":"<p>These examples show how to use the different U-MDO formulations presented in the user guide by considering toy functions and state-of-the-art use cases.</p>"},{"location":"generated/examples/umdo/#using-control-variates","title":"... using control variates","text":"<p>The statistics are estimated using the control variates technique where the control variates are based on Taylor polynomials of the quantities of interest.</p> <p>Read more in the user guide.</p> <p> A quadratic mono-disciplinary problem </p> <p> The Rosenbrock mono-disciplinary problem </p> <p> The Sellar's MDO problem </p>"},{"location":"generated/examples/umdo/#miscellaneous","title":"Miscellaneous","text":"<p> DOE </p> <p> Sampling with repetitions </p> <p> Control variate vs Sampling </p>"},{"location":"generated/examples/umdo/#using-polynomial-chaos-expansions-pces","title":"... using polynomial chaos expansions (PCEs)","text":"<p>The statistics are estimated using a PCE built over the uncertain space.</p> <p>Read more in the user guide.</p> <p> A quadratic mono-disciplinary problem </p>"},{"location":"generated/examples/umdo/#using-sampling","title":"... using sampling","text":"<p>The statistics are estimated using crude Monte Carlo sampling.</p> <p>Read more in the user guide</p> <p> A quadratic mono-disciplinary problem </p> <p> The Rosenbrock mono-disciplinary problem </p> <p> The Sellar's MDO problem </p> <p> The Sobieski's SSBJ MDO problem </p>"},{"location":"generated/examples/umdo/#using-sequential-sampling","title":"... using sequential sampling","text":"<p>The statistics are estimated using crude Monte Carlo sampling by increasing the sample size sequentially as the optimisation process progresses.</p> <p>Read more in the user guide.</p> <p> A quadratic mono-disciplinary problem </p>"},{"location":"generated/examples/umdo/#using-surrogate-models","title":"... using surrogate models","text":"<p>The statistics are estimated using a surrogate model built over the uncertain space.</p> <p>Read more in the user guide.</p> <p> A quadratic mono-disciplinary problem </p>"},{"location":"generated/examples/umdo/#using-taylor-polynomials","title":"... using Taylor polynomials","text":"<p>The statistics are estimated using Taylor polynomials of the quantities of interest.</p> <p>Read more in the user guide.</p> <p> A quadratic mono-disciplinary problem </p> <p> The Sellar's MDO problem </p> <p> The Sobieski's SSBJ MDO problem </p> <p> Download all examples in Python source code: umdo_python.zip</p> <p> Download all examples in Jupyter notebooks: umdo_jupyter.zip</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/control_variate/cv_sellar/","title":"The Sellar's MDO problem","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/control_variate/cv_sellar/#the-sellars-mdo-problem","title":"The Sellar's MDO problem","text":"<p>In this example, we consider the Sellar's MDO problem under uncertainty</p> \\[\\min_{x,z_1,x_2} \\mathbb{E}[f(x,z_2,y_1,y_2)]\\] <p>over the design space \\([0,10]\\times[-10,10]\\times[0,10]\\) and under the inequality constraints</p> \\[\\mathbb{E}[c_1(y_1)]+3\\mathbb{S}[c_1(y_1)] \\leq 0\\] <p>and</p> \\[\\mathbb{E}[c_2(y_2)]+3\\mathbb{S}[c_2(y_2)] \\leq 0,\\] <p>where</p> <ul> <li>\\(\\mathbb{E}\\) is the expectation operator,</li> <li>\\(\\mathbb{S}\\) is the standard deviation operators,</li> <li>\\(f(x,z_2) = x^2 + z_2 + y_1^2 + \\exp(-y_2)\\) is the objective function,</li> <li>\\(c_1(y_1) = 3.16 - y_1^2\\) is the first constraint function,</li> <li>\\(c_2(y_2) = y_2 - 24.0\\) is the second constraint function,</li> <li>\\(y_1 = \\sqrt{z_1^2 + z_2 + x - ay_2}\\) is the first coupling equation,</li> <li>\\(y_2 = \\frac{\\log(1+\\exp(10y_1))}{5} - y_1 - \\frac{\\log(2)}{5} + z_1 + z_2\\)   is the second coupling equation,</li> <li>\\(a\\) is a random variable distributed   according to the triangular distribution \\(\\mathcal{T}(0.1,0.2,0.3)\\).</li> </ul> <pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nconfigure_logger()\n</code></pre> <p>Firstly, we create one discipline per couping equation and a system discipline to compute the objective and constraints:</p> <pre><code>system = AnalyticDiscipline({\n    \"obj\": \"x**2 + z2 + y1**2 + exp(-y2)\",\n    \"c1\": \"3.16 - y1 ** 2\",\n    \"c2\": \"y2 - 24.0\",\n})\ndisc1 = AnalyticDiscipline({\"y1\": \"(z1**2 + z2 + x - a*y2)**0.5\"})\ndisc2 = AnalyticDiscipline({\"y2\": \"2/10*log(1+exp(10*y1))-y1-2/10*log(2) + z1 + z2\"})\n</code></pre> <p>as well as the design space:</p> <pre><code>design_space = DesignSpace()\ndesign_space.add_variable(\"x\", 1, lower_bound=0.0, upper_bound=10.0, value=1.0)\ndesign_space.add_variable(\"z1\", 1, lower_bound=-10.0, upper_bound=10.0, value=4.0)\ndesign_space.add_variable(\"z2\", 1, lower_bound=0.0, upper_bound=10.0, value=3.0)\n</code></pre> <p>Secondly, we define the uncertain space:</p> <pre><code>uncertain_space = ParameterSpace()\n</code></pre> <p>with an uncertainty over the constant <code>\"a\"</code>:</p> <pre><code>uncertain_space.add_random_variable(\n    \"a\", \"OTTriangularDistribution\", minimum=0.1, maximum=0.3, mode=0.2\n)\n</code></pre> <p>Then, we define a UMDOScenario to minimize the statistic \\(\\mathbb{E}[f(x,z_2,y_1,y_2)]\\) estimated using a control variates technique based on Taylor polynomials and 50 samples at each iteration of the optimization loop:</p> <pre><code>scenario = UMDOScenario(\n    [system, disc1, disc2],\n    \"obj\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    formulation_name=\"MDF\",\n    statistic_estimation=\"ControlVariate\",\n    statistic_estimation_parameters={\"n_samples\": 100},\n)\n</code></pre> <p>while satisfying the constraints \\(\\mathbb{E}[c_1(y_1)]+3\\mathbb{S}[c_1(y_1)] \\leq 0\\) and \\(\\mathbb{E}[c_2(y_2)]+3\\mathbb{S}[c_2(y_2)] \\leq 0\\):</p> <pre><code>scenario.add_constraint(\"c1\", \"Margin\", factor=3.0)\nscenario.add_constraint(\"c2\", \"Margin\", factor=3.0)\n</code></pre> <p>We execute this scenario using the gradient-free optimizer COBYLA:</p> <pre><code>scenario.execute(algo_name=\"NLOPT_COBYLA\", max_iter=200)\n</code></pre> <p>and plot the optimization history:</p> <pre><code>scenario.post_process(post_name=\"OptHistoryView\", save=True, show=False)\n</code></pre> <p>Lastly, we can compare the numerical solution of this Sellar's MDO problem under uncertainty</p> <pre><code>result = scenario.optimization_result\n(result.x_opt, result.constraint_values, result.f_opt)\n</code></pre> <p>to the solution of the Sellar's MDO problem without uncertainty, namely \\((x^*,c^*,f^*)=([0, 1.77, 0], [0, -20.58], 3.19)\\).</p> <p>Total running time of the script: ( 0 minutes  0.000 seconds)</p> <p> Download Python source code: cv_sellar.py</p> <p> Download Jupyter notebook: cv_sellar.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/control_variate/mg_execution_times/","title":"Computation times","text":"<p>00:02.971 total execution time for generated_examples_umdo_control_variate files:</p> <p>+----------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_cv_rosenbrock (docs/examples/umdo/control_variate/plot_cv_rosenbrock.py) | 00:02.172 | 0.0 MB | +----------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_cv_quadratic (docs/examples/umdo/control_variate/plot_cv_quadratic.py)    | 00:00.799 | 0.0 MB | +----------------------------------------------------------------------------------------------------------+-----------+--------+ | cv_sellar (docs/examples/umdo/control_variate/cv_sellar.py)                            | 00:00.000 | 0.0 MB | +----------------------------------------------------------------------------------------------------------+-----------+--------+</p>"},{"location":"generated/examples/umdo/control_variate/plot_cv_quadratic/","title":"A quadratic mono-disciplinary problem","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/control_variate/plot_cv_quadratic/#a-quadratic-mono-disciplinary-problem","title":"A quadratic mono-disciplinary problem","text":"<p>In this example, we consider the quadratic mono-disciplinary optimization problem</p> \\[\\min_{x\\in[-1,1]} \\mathbb{E}[(x+U)^2]\\] <p>where \\(U\\sim\\mathcal{N}(0,1)\\) is a standard Gaussian variable and \\(\\mathbb{E}\\) is the expectation operator.</p> <p>The objective can be rewritten as \\(x^2+1\\) and then the solution is obvious, namely</p> \\[(x^*,\\mathbb{E}[(x^*+U)^2])=(0,1).\\] <p>In the following, we will call \\(f\\) the function computing \\((x+U)^2\\) given \\(x\\) and \\(U\\).</p> <pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nconfigure_logger()\n</code></pre> <p>Out:</p> <pre><code>&lt;RootLogger root (INFO)&gt;\n</code></pre> <p>Firstly, we define an AnalyticDiscipline implementing the function \\(f\\):</p> <pre><code>discipline = AnalyticDiscipline({\"y\": \"(x+u)**2\"}, name=\"f\")\n</code></pre> <p>as well as the design space:</p> <pre><code>design_space = DesignSpace()\ndesign_space.add_variable(\"x\", lower_bound=-1, upper_bound=1.0, value=0.5)\n</code></pre> <p>and the uncertain space:</p> <pre><code>uncertain_space = ParameterSpace()\nuncertain_space.add_random_variable(\"u\", \"OTNormalDistribution\")\n</code></pre> <p>Out:</p> <pre><code>/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/pydantic/main.py:209: DeprecationWarning: Conversion of an array with ndim &gt; 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n</code></pre> <p>Then, we define a UMDOScenario to minimize the statistic \\(\\mathbb{E}[(x+U)^2]\\) estimated using a control variates technique based on Taylor polynomials and 50 samples at each iteration of the optimization loop:</p> <pre><code>scenario = UMDOScenario(\n    [discipline],\n    \"y\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    formulation_name=\"DisciplinaryOpt\",\n    statistic_estimation=\"ControlVariate\",\n    statistic_estimation_parameters={\"n_samples\": 25},\n)\n</code></pre> <p>We execute this scenario using the gradient-free optimizer COBYLA:</p> <pre><code>scenario.execute(algo_name=\"NLOPT_COBYLA\", max_iter=100)\n</code></pre> <p>Out:</p> <pre><code>    INFO - 10:51:32:  \n    INFO - 10:51:32: *** Start UMDOScenario execution ***\n    INFO - 10:51:32: UMDOScenario\n    INFO - 10:51:32:    Disciplines: f\n    INFO - 10:51:32:    Formulation:\n    INFO - 10:51:32:       MDO formulation: DisciplinaryOpt\n    INFO - 10:51:32:       Statistic estimation: ControlVariate\n    INFO - 10:51:32:    Uncertain space:\n    INFO - 10:51:32:       +------+---------------------------+\n    INFO - 10:51:32:       | Name |        Distribution       |\n    INFO - 10:51:32:       +------+---------------------------+\n    INFO - 10:51:32:       |  u   | Normal(mu=0.0, sigma=1.0) |\n    INFO - 10:51:32:       +------+---------------------------+\n    INFO - 10:51:32: Optimization problem:\n    INFO - 10:51:32:    minimize E[y]\n    INFO - 10:51:32:    with respect to x\n    INFO - 10:51:32:    over the design space:\n    INFO - 10:51:32:       +------+-------------+-------+-------------+-------+\n    INFO - 10:51:32:       | Name | Lower bound | Value | Upper bound | Type  |\n    INFO - 10:51:32:       +------+-------------+-------+-------------+-------+\n    INFO - 10:51:32:       | x    |      -1     |  0.5  |      1      | float |\n    INFO - 10:51:32:       +------+-------------+-------+-------------+-------+\n    INFO - 10:51:32: Solving optimization problem with algorithm NLOPT_COBYLA:\n    INFO - 10:51:32:      1%|          | 1/100 [00:00&lt;00:01, 87.93 it/sec, obj=1.25]\n    INFO - 10:51:32:      2%|\u258f         | 2/100 [00:00&lt;00:01, 96.85 it/sec, obj=2]\n    INFO - 10:51:32:      3%|\u258e         | 3/100 [00:00&lt;00:00, 100.54 it/sec, obj=1.01]\n    INFO - 10:51:32:      4%|\u258d         | 4/100 [00:00&lt;00:00, 102.12 it/sec, obj=1.25]\n    INFO - 10:51:32:      5%|\u258c         | 5/100 [00:00&lt;00:00, 103.35 it/sec, obj=1.07]\n    INFO - 10:51:32:      6%|\u258c         | 6/100 [00:00&lt;00:00, 104.24 it/sec, obj=1.02]\n    INFO - 10:51:32:      7%|\u258b         | 7/100 [00:00&lt;00:00, 104.96 it/sec, obj=1.01]\n    INFO - 10:51:32:      8%|\u258a         | 8/100 [00:00&lt;00:00, 105.65 it/sec, obj=1]\n    INFO - 10:51:32:      9%|\u2589         | 9/100 [00:00&lt;00:00, 106.09 it/sec, obj=1.01]\n    INFO - 10:51:32:     10%|\u2588         | 10/100 [00:00&lt;00:00, 106.16 it/sec, obj=1.01]\n    INFO - 10:51:32:     11%|\u2588         | 11/100 [00:00&lt;00:00, 106.03 it/sec, obj=1]\n    INFO - 10:51:32:     12%|\u2588\u258f        | 12/100 [00:00&lt;00:00, 105.98 it/sec, obj=1]\n    INFO - 10:51:32:     13%|\u2588\u258e        | 13/100 [00:00&lt;00:00, 106.13 it/sec, obj=1]\n    INFO - 10:51:32:     14%|\u2588\u258d        | 14/100 [00:00&lt;00:00, 106.24 it/sec, obj=1]\n    INFO - 10:51:32:     15%|\u2588\u258c        | 15/100 [00:00&lt;00:00, 106.42 it/sec, obj=1]\n    INFO - 10:51:32:     16%|\u2588\u258c        | 16/100 [00:00&lt;00:00, 106.53 it/sec, obj=1]\n    INFO - 10:51:32:     17%|\u2588\u258b        | 17/100 [00:00&lt;00:00, 106.66 it/sec, obj=1]\n    INFO - 10:51:32:     18%|\u2588\u258a        | 18/100 [00:00&lt;00:00, 105.62 it/sec, obj=1]\n    INFO - 10:51:32:     19%|\u2588\u2589        | 19/100 [00:00&lt;00:00, 105.39 it/sec, obj=1]\n    INFO - 10:51:32:     20%|\u2588\u2588        | 20/100 [00:00&lt;00:00, 105.58 it/sec, obj=1]\n    INFO - 10:51:32:     21%|\u2588\u2588        | 21/100 [00:00&lt;00:00, 105.80 it/sec, obj=1]\n    INFO - 10:51:32:     22%|\u2588\u2588\u258f       | 22/100 [00:00&lt;00:00, 105.89 it/sec, obj=1]\n    INFO - 10:51:32: Optimization result:\n    INFO - 10:51:32:    Optimizer info:\n    INFO - 10:51:32:       Status: None\n    INFO - 10:51:32:       Message: Successive iterates of the objective function are closer than ftol_rel or ftol_abs. GEMSEO stopped the driver.\n    INFO - 10:51:32:       Number of calls to the objective function by the optimizer: 29\n    INFO - 10:51:32:    Solution:\n    INFO - 10:51:32:       Objective: 1.0035199933459258\n    INFO - 10:51:32:       Design space:\n    INFO - 10:51:32:          +------+-------------+-----------------+-------------+-------+\n    INFO - 10:51:32:          | Name | Lower bound |      Value      | Upper bound | Type  |\n    INFO - 10:51:32:          +------+-------------+-----------------+-------------+-------+\n    INFO - 10:51:32:          | x    |      -1     | 6.103515625e-05 |      1      | float |\n    INFO - 10:51:32:          +------+-------------+-----------------+-------------+-------+\n    INFO - 10:51:32: *** End UMDOScenario execution (time: 0:00:00.210805) ***\n</code></pre> <p>and plot the optimization history:</p> <pre><code>scenario.post_process(post_name=\"OptHistoryView\", save=False, show=True)\n</code></pre> <p>Out:</p> <pre><code>&lt;gemseo.post.opt_history_view.OptHistoryView object at 0x78c1567242e0&gt;\n</code></pre> <p>Notice that the numerical solution</p> <pre><code>(scenario.optimization_result.x_opt[0], scenario.optimization_result.f_opt)\n</code></pre> <p>Out:</p> <pre><code>(6.103515625e-05, 1.0035199933459258)\n</code></pre> <p>is close to the theoretical solution \\((x^*,\\mathbb{E}[(x^*+U)^2])=(0,1)\\).</p> <p>Total running time of the script: ( 0 minutes  0.799 seconds)</p> <p> Download Python source code: plot_cv_quadratic.py</p> <p> Download Jupyter notebook: plot_cv_quadratic.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/control_variate/plot_cv_rosenbrock/","title":"The Rosenbrock mono-disciplinary problem","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/control_variate/plot_cv_rosenbrock/#the-rosenbrock-mono-disciplinary-problem","title":"The Rosenbrock mono-disciplinary problem","text":"<p>In this example, we consider the Rosenbrock mono-disciplinary optimization problem</p> \\[\\min_{x,y\\in[-2,2]} \\mathbb{E}[(U-x)^2+100(y-x^2)^2]\\] <p>where \\(U\\sim\\mathcal{N}(0,0.0025)\\) is a Gaussian variable and \\(\\mathbb{E}\\) is the expectation operator.</p> <p>In the following, we will call \\(f\\) the function computing \\((U-x)^2+100(y-x^2)^2\\) given \\(x\\), \\(y\\) and \\(U\\).</p> <pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nconfigure_logger()\n</code></pre> <p>Out:</p> <pre><code>&lt;RootLogger root (INFO)&gt;\n</code></pre> <p>Firstly, we define the discipline implementing the Rosenbrock function \\(f\\):</p> <pre><code>discipline = AnalyticDiscipline({\"z\": \"(u-x)**2+100*(y-x**2)**2\"}, name=\"Rosenbrock\")\n</code></pre> <p>where \\(x,y\\) belongs to the interval \\([-2,2]\\):</p> <pre><code>design_space = DesignSpace()\ndesign_space.add_variable(\"x\", lower_bound=-2, upper_bound=2.0, value=-2.0)\ndesign_space.add_variable(\"y\", lower_bound=-2, upper_bound=2.0, value=-2.0)\n</code></pre> <p>and \\(U\\) is a Gaussian variable with unit mean and standard deviation equal to 0.05:</p> <pre><code>uncertain_space = ParameterSpace()\nuncertain_space.add_random_variable(\"u\", \"OTNormalDistribution\", mu=1.0, sigma=0.05)\n</code></pre> <p>Out:</p> <pre><code>/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/pydantic/main.py:209: DeprecationWarning: Conversion of an array with ndim &gt; 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n</code></pre> <p>Then, we define a UMDOScenario to minimize the statistic \\(\\mathbb{E}[(U-x)^2+100(y-x^2)^2]\\) estimated using a control variates technique based on Taylor polynomials and 50 samples at each iteration of the optimization loop:</p> <pre><code>scenario = UMDOScenario(\n    [discipline],\n    \"z\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    formulation_name=\"DisciplinaryOpt\",\n    statistic_estimation=\"ControlVariate\",\n    statistic_estimation_parameters={\"n_samples\": 30},\n)\n</code></pre> <p>We execute it with the gradient-based optimizer SLSQP:</p> <p>Warning</p> <p>The implementation of statistic estimators do not allow for the moment to use analytical derivatives. Please use finite differences or complex step to approximate the gradients.</p> <pre><code>scenario.set_differentiation_method(\"finite_differences\")\nscenario.execute(algo_name=\"NLOPT_SLSQP\", max_iter=100)\n</code></pre> <p>Out:</p> <pre><code>    INFO - 10:51:32:  \n    INFO - 10:51:32: *** Start UMDOScenario execution ***\n    INFO - 10:51:32: UMDOScenario\n    INFO - 10:51:32:    Disciplines: Rosenbrock\n    INFO - 10:51:32:    Formulation:\n    INFO - 10:51:32:       MDO formulation: DisciplinaryOpt\n    INFO - 10:51:32:       Statistic estimation: ControlVariate\n    INFO - 10:51:32:    Uncertain space:\n    INFO - 10:51:32:       +------+----------------------------+\n    INFO - 10:51:32:       | Name |        Distribution        |\n    INFO - 10:51:32:       +------+----------------------------+\n    INFO - 10:51:32:       |  u   | Normal(mu=1.0, sigma=0.05) |\n    INFO - 10:51:32:       +------+----------------------------+\n    INFO - 10:51:32: Optimization problem:\n    INFO - 10:51:32:    minimize E[z]\n    INFO - 10:51:32:    with respect to x, y\n    INFO - 10:51:32:    over the design space:\n    INFO - 10:51:32:       +------+-------------+-------+-------------+-------+\n    INFO - 10:51:32:       | Name | Lower bound | Value | Upper bound | Type  |\n    INFO - 10:51:32:       +------+-------------+-------+-------------+-------+\n    INFO - 10:51:32:       | x    |      -2     |   -2  |      2      | float |\n    INFO - 10:51:32:       | y    |      -2     |   -2  |      2      | float |\n    INFO - 10:51:32:       +------+-------------+-------+-------------+-------+\n    INFO - 10:51:32: Solving optimization problem with algorithm NLOPT_SLSQP:\n    INFO - 10:51:32:      1%|          | 1/100 [00:00&lt;00:01, 73.36 it/sec, obj=3.61e+3]\n    INFO - 10:51:33:      2%|\u258f         | 2/100 [00:00&lt;00:05, 18.32 it/sec, obj=401]\n    INFO - 10:51:33:      3%|\u258e         | 3/100 [00:00&lt;00:04, 19.95 it/sec, obj=152]\n    INFO - 10:51:33:      4%|\u258d         | 4/100 [00:00&lt;00:04, 23.36 it/sec, obj=411]\n    INFO - 10:51:33:      5%|\u258c         | 5/100 [00:00&lt;00:03, 29.17 it/sec, obj=14]\n    INFO - 10:51:33:      6%|\u258c         | 6/100 [00:00&lt;00:03, 24.30 it/sec, obj=618]\n    INFO - 10:51:33:      7%|\u258b         | 7/100 [00:00&lt;00:03, 28.33 it/sec, obj=5.18]\n    INFO - 10:51:33:      8%|\u258a         | 8/100 [00:00&lt;00:03, 24.80 it/sec, obj=87.2]\n    INFO - 10:51:33:      9%|\u2589         | 9/100 [00:00&lt;00:03, 27.88 it/sec, obj=2.15]\n    INFO - 10:51:33:     10%|\u2588         | 10/100 [00:00&lt;00:03, 25.15 it/sec, obj=4.06]\n    INFO - 10:51:33:     11%|\u2588         | 11/100 [00:00&lt;00:03, 27.65 it/sec, obj=0.695]\n    INFO - 10:51:33:     12%|\u2588\u258f        | 12/100 [00:00&lt;00:03, 24.39 it/sec, obj=0.654]\n    INFO - 10:51:33:     13%|\u2588\u258e        | 13/100 [00:00&lt;00:03, 24.39 it/sec, obj=0.643]\n    INFO - 10:51:33:     14%|\u2588\u258d        | 14/100 [00:00&lt;00:03, 24.35 it/sec, obj=0.639]\n    INFO - 10:51:33:     15%|\u2588\u258c        | 15/100 [00:00&lt;00:03, 24.26 it/sec, obj=0.611]\n    INFO - 10:51:33:     16%|\u2588\u258c        | 16/100 [00:00&lt;00:03, 24.26 it/sec, obj=0.452]\n    INFO - 10:51:33:     17%|\u2588\u258b        | 17/100 [00:00&lt;00:03, 25.00 it/sec, obj=22.1]\n    INFO - 10:51:33:     18%|\u2588\u258a        | 18/100 [00:00&lt;00:03, 26.46 it/sec, obj=0.382]\n    INFO - 10:51:33:     19%|\u2588\u2589        | 19/100 [00:00&lt;00:03, 25.17 it/sec, obj=0.38]\n    INFO - 10:51:33:     20%|\u2588\u2588        | 20/100 [00:00&lt;00:03, 26.48 it/sec, obj=0.355]\n    INFO - 10:51:33:     21%|\u2588\u2588        | 21/100 [00:00&lt;00:03, 24.72 it/sec, obj=0.324]\n    INFO - 10:51:33:     22%|\u2588\u2588\u258f       | 22/100 [00:00&lt;00:03, 24.68 it/sec, obj=0.203]\n    INFO - 10:51:33:     23%|\u2588\u2588\u258e       | 23/100 [00:00&lt;00:03, 24.65 it/sec, obj=0.144]\n    INFO - 10:51:33:     24%|\u2588\u2588\u258d       | 24/100 [00:00&lt;00:03, 24.63 it/sec, obj=0.0759]\n    INFO - 10:51:33:     25%|\u2588\u2588\u258c       | 25/100 [00:00&lt;00:02, 25.10 it/sec, obj=2.29]\n    INFO - 10:51:33:     26%|\u2588\u2588\u258c       | 26/100 [00:00&lt;00:02, 26.10 it/sec, obj=0.0555]\n    INFO - 10:51:34:     27%|\u2588\u2588\u258b       | 27/100 [00:01&lt;00:02, 25.19 it/sec, obj=0.137]\n    INFO - 10:51:34:     28%|\u2588\u2588\u258a       | 28/100 [00:01&lt;00:02, 26.12 it/sec, obj=0.0434]\n    INFO - 10:51:34:     29%|\u2588\u2588\u2589       | 29/100 [00:01&lt;00:02, 24.88 it/sec, obj=0.0377]\n    INFO - 10:51:34:     30%|\u2588\u2588\u2588       | 30/100 [00:01&lt;00:02, 24.89 it/sec, obj=0.029]\n    INFO - 10:51:34:     31%|\u2588\u2588\u2588       | 31/100 [00:01&lt;00:02, 24.84 it/sec, obj=0.0205]\n    INFO - 10:51:34:     32%|\u2588\u2588\u2588\u258f      | 32/100 [00:01&lt;00:02, 24.80 it/sec, obj=0.00924]\n    INFO - 10:51:34:     33%|\u2588\u2588\u2588\u258e      | 33/100 [00:01&lt;00:02, 24.80 it/sec, obj=0.00572]\n    INFO - 10:51:34:     34%|\u2588\u2588\u2588\u258d      | 34/100 [00:01&lt;00:02, 24.80 it/sec, obj=0.00318]\n    INFO - 10:51:34:     35%|\u2588\u2588\u2588\u258c      | 35/100 [00:01&lt;00:02, 24.80 it/sec, obj=0.00248]\n    INFO - 10:51:34:     36%|\u2588\u2588\u2588\u258c      | 36/100 [00:01&lt;00:02, 24.77 it/sec, obj=0.00236]\n    INFO - 10:51:34:     37%|\u2588\u2588\u2588\u258b      | 37/100 [00:01&lt;00:02, 24.76 it/sec, obj=0.00236]\n    INFO - 10:51:34:     38%|\u2588\u2588\u2588\u258a      | 38/100 [00:01&lt;00:02, 24.76 it/sec, obj=0.00236]\n    INFO - 10:51:34:     39%|\u2588\u2588\u2588\u2589      | 39/100 [00:01&lt;00:02, 25.06 it/sec, obj=0.00236]\n    INFO - 10:51:34:     40%|\u2588\u2588\u2588\u2588      | 40/100 [00:01&lt;00:02, 25.70 it/sec, obj=0.00236]\n    INFO - 10:51:34:     41%|\u2588\u2588\u2588\u2588      | 41/100 [00:01&lt;00:02, 26.17 it/sec, obj=0.00236]\n    INFO - 10:51:34:     42%|\u2588\u2588\u2588\u2588\u258f     | 42/100 [00:01&lt;00:02, 26.63 it/sec, obj=0.00236]\n    INFO - 10:51:34:     43%|\u2588\u2588\u2588\u2588\u258e     | 43/100 [00:01&lt;00:02, 27.08 it/sec, obj=0.00236]\n    INFO - 10:51:34:     44%|\u2588\u2588\u2588\u2588\u258d     | 44/100 [00:01&lt;00:02, 27.53 it/sec, obj=0.00236]\n    INFO - 10:51:34:     45%|\u2588\u2588\u2588\u2588\u258c     | 45/100 [00:01&lt;00:01, 27.97 it/sec, obj=0.00236]\n    INFO - 10:51:34: Optimization result:\n    INFO - 10:51:34:    Optimizer info:\n    INFO - 10:51:34:       Status: None\n    INFO - 10:51:34:       Message: Successive iterates of the objective function are closer than ftol_rel or ftol_abs. GEMSEO stopped the driver.\n    INFO - 10:51:34:       Number of calls to the objective function by the optimizer: 54\n    INFO - 10:51:34:    Solution:\n    INFO - 10:51:34:       Objective: 0.0023555040384618457\n    INFO - 10:51:34:       Design space:\n    INFO - 10:51:34:          +------+-------------+--------------------+-------------+-------+\n    INFO - 10:51:34:          | Name | Lower bound |       Value        | Upper bound | Type  |\n    INFO - 10:51:34:          +------+-------------+--------------------+-------------+-------+\n    INFO - 10:51:34:          | x    |      -2     | 0.998850734908769  |      2      | float |\n    INFO - 10:51:34:          | y    |      -2     | 0.9976950782901226 |      2      | float |\n    INFO - 10:51:34:          +------+-------------+--------------------+-------------+-------+\n    INFO - 10:51:34: *** End UMDOScenario execution (time: 0:00:01.627014) ***\n</code></pre> <p>and plot the optimization history:</p> <pre><code>scenario.post_process(post_name=\"OptHistoryView\", save=False, show=True)\n</code></pre> <p>Out:</p> <pre><code>&lt;gemseo.post.opt_history_view.OptHistoryView object at 0x78c11d28d7f0&gt;\n</code></pre> <p>Lastly, we can compare the numerical solution of this Rosenbrock problem under uncertainty</p> <pre><code>(scenario.optimization_result.x_opt, scenario.optimization_result.f_opt)\n</code></pre> <p>Out:</p> <pre><code>(array([0.99885073, 0.99769508]), 0.0023555040384618457)\n</code></pre> <p>to the solution of the Rosenbrock problem without uncertainty, namely \\((x^*,f^*)=([1, 1], 0)\\).</p> <p>Total running time of the script: ( 0 minutes  2.172 seconds)</p> <p> Download Python source code: plot_cv_rosenbrock.py</p> <p> Download Jupyter notebook: plot_cv_rosenbrock.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/misc/comparison/","title":"Control variate vs Sampling","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/misc/comparison/#control-variate-vs-sampling","title":"Control variate vs Sampling","text":"<pre><code>from __future__ import annotations\n\nimport numpy as np\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\nfrom gemseo.utils.string_tools import MultiLineString\nfrom matplotlib import pyplot as plt\nfrom numpy import array\nfrom numpy import ndarray\nfrom numpy import quantile\nfrom scipy.spatial.distance import cdist\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n</code></pre> <p>Firstly, we define an AnalyticDiscipline implementing a random version of the Rosenbrock function \\(f(x,y,U)=(U-x)^2+100(y-x^2)^2\\):</p> <pre><code>discipline = AnalyticDiscipline({\"z\": \"(a-x)**2+100*(y-x**2)**2\"}, name=\"Rosenbrock\")\n</code></pre> <p>where \\(x,y\\) belongs to the interval \\([-2,2]\\):</p> <pre><code>design_space = DesignSpace()\ndesign_space.add_variable(\"x\", lower_bound=-2, upper_bound=2.0, value=-2.0)\ndesign_space.add_variable(\"y\", lower_bound=-2, upper_bound=2.0, value=-2.0)\n</code></pre> <p>and \\(U\\) is a Gaussian variable with unit mean and standard deviation equal to 0.05:</p> <pre><code>uncertain_space = ParameterSpace()\nuncertain_space.add_random_variable(\"a\", \"OTNormalDistribution\", mu=1.0, sigma=0.05)\n</code></pre> <p>Then, we want to build a UMDOScenario to minimize a sampling-based estimation of the expectation \\(\\mathbb{E}[Y]\\) where \\(Y=f(x,y,U)\\): For that, we compare an approach based on crude Monte Carlo and an approach based on a linearized model as control variate and repeat it 20 times to get statistics on the results:</p> <pre><code>method_to_x_opt = {\"Sampling\": [], \"ControlVariate\": []}\nfor i in range(20):\n    for method in [\"Sampling\", \"ControlVariate\"]:\n        scenario = UMDOScenario(\n            [discipline],\n            \"z\",\n            design_space,\n            uncertain_space,\n            \"Mean\",\n            formulation_name=\"DisciplinaryOpt\",\n            statistic_estimation=method,\n            statistic_estimation_parameters={\n                \"algo\": \"OT_MONTE_CARLO\",\n                \"n_samples\": 10,\n                \"seed\": i + 1,\n            },\n        )\n        scenario.set_differentiation_method(\"finite_differences\")\n        scenario.execute(algo_name=\"NLOPT_SLSQP\", max_iter=100)\n        method_to_x_opt[method].append(scenario.optimization_result.x_opt.tolist())\n</code></pre> <p>Lastly, we print and plot the comparison in terms of distance to the theoretical solution \\(x^*=(1,1)\\):</p> <pre><code>def ecdf(data: ndarray) -&gt; tuple[ndarray, ndarray]:\n    \"\"\"Empirical cumulative distribution function.\n\n    Args:\n        data: The data.\n\n    Returns:\n        The quantiles and the cumulative probabilities.\n    \"\"\"\n    quantiles, counts = np.unique(data, return_counts=True)\n    return quantiles, np.cumsum(counts).astype(np.double) / data.size\n\n\ncomparison = MultiLineString()\nfor index, method in enumerate([\"Sampling\", \"ControlVariate\"]):\n    distances_to_one = cdist(array(method_to_x_opt[method]), array([[1.0, 1.0]]))\n    x, y = ecdf(abs(distances_to_one))\n    plt.plot(x, y, \"-\" * index, label=method)\n    comparison.add(method)\n    comparison.indent()\n    comparison.add(f\"Mean: {distances_to_one.mean():.2e}\")\n    comparison.add(f\"Standard deviation: {distances_to_one.std():.2e}\")\n    comparison.add(f\"0.05-quantile: {quantile(distances_to_one, 0.05):.2e}\")\n    comparison.add(f\"0.95-quantile: {quantile(distances_to_one, 0.95):.2e}\")\n    comparison.dedent()\n\nprint(comparison)\n\nplt.xlabel(\"Distance to the theoretical solution x=(1,1)\")\nplt.ylabel(\"Cumulative distribution function\")\nplt.legend()\nplt.show()\n</code></pre> <p>Total running time of the script: ( 0 minutes  0.000 seconds)</p> <p> Download Python source code: comparison.py</p> <p> Download Jupyter notebook: comparison.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/misc/sellar_sampling_opt_repetitions/","title":"Sampling with repetitions","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/misc/sellar_sampling_opt_repetitions/#sampling-with-repetitions","title":"Sampling with repetitions","text":"<pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\nfrom matplotlib import pyplot as plt\nfrom numpy import load\nfrom numpy import save\nfrom numpy import stack\nfrom numpy import vstack\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nconfigure_logger()\n</code></pre> <p>Firstly, we instantiate the disciplines of the Sellar problem:</p> <pre><code>system = AnalyticDiscipline({\n    \"obj\": \"x**2 + z2 + y1**2 + exp(-y2)\",\n    \"c1\": \"3.16 - y1 ** 2\",\n    \"c2\": \"y2 - 24.0\",\n})\ndisc1 = AnalyticDiscipline({\"y1\": \"(z1**2 + z2 + x - a*y2)**0.5\"})\ndisc2 = AnalyticDiscipline({\"y2\": \"2/10*log(1+exp(10*y1))-y1-2/10*log(2) + z1 + z2\"})\n</code></pre> <p>as well as a function to instantiate the design space:</p> <pre><code>def create_design_space() -&gt; DesignSpace:\n    \"\"\"Create the design space for the Sellar problem.\"\"\"\n    design_space = DesignSpace()\n    design_space.add_variable(\"x\", 1, lower_bound=0.0, upper_bound=10.0, value=1.0)\n    design_space.add_variable(\"z1\", 1, lower_bound=-10, upper_bound=10.0, value=4.0)\n    design_space.add_variable(\"z2\", 1, lower_bound=0.0, upper_bound=10.0, value=3.0)\n    return design_space\n</code></pre> <p>Secondly, we define the uncertain space:</p> <pre><code>uncertain_space = ParameterSpace()\n</code></pre> <p>with an uncertainty over the constant <code>\"a\"</code>:</p> <pre><code>uncertain_space.add_random_variable(\n    \"a\", \"OTTriangularDistribution\", minimum=0.1, maximum=0.3, mode=0.2\n)\n</code></pre> <p>Then, we build 10 UMDOScenario to minimize a sampling-based estimation of the expectation \\(\\mathbb{E}[obj]\\) and store the history of the design values:</p> <pre><code>x_hist = []\nfor i in range(10):\n    print(i)\n    scenario = UMDOScenario(\n        [system, disc1, disc2],\n        \"obj\",\n        create_design_space(),\n        uncertain_space,\n        \"Mean\",\n        formulation_name=\"MDF\",\n        statistic_estimation=\"Sampling\",\n        statistic_estimation_parameters={\n            \"algo\": \"OT_LHS\",\n            \"n_samples\": 100,\n            \"seed\": i + 1,\n        },\n    )\n    scenario.add_constraint(\"c1\", \"Margin\", factor=3.0)\n    scenario.add_constraint(\"c2\", \"Margin\", factor=3.0)\n    scenario.execute(algo_name=\"NLOPT_COBYLA\", max_iter=100)\n    x_hist.append(\n        vstack(scenario.formulation.optimization_problem.database.get_x_vect_history())\n    )\n</code></pre> <p>Lastly, we plot the variability of the optimization history with boxplots:</p> <pre><code>print(x_hist)\nx_hist = stack(x_hist)\nsave(\"x_hist.npy\", x_hist)\nx_hist = load(\"x_hist.npy\")\nplt.boxplot(x_hist[:, :, 0])\nplt.savefig(\"hist.png\")\n</code></pre> <p>Total running time of the script: ( 0 minutes  0.000 seconds)</p> <p> Download Python source code: sellar_sampling_opt_repetitions.py</p> <p> Download Jupyter notebook: sellar_sampling_opt_repetitions.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/misc/udoe_quadratic/","title":"DOE","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/misc/udoe_quadratic/#doe","title":"DOE","text":"<pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\n\nfrom gemseo_umdo.scenarios.udoe_scenario import UDOEScenario\n\nconfigure_logger()\n</code></pre> <p>Firstly, we define an AnalyticDiscipline implementing the random function \\(f(x,U)=(x+U)^2\\):</p> <pre><code>discipline = AnalyticDiscipline({\"y\": \"(x+u)**2\"}, name=\"quadratic_function\")\n</code></pre> <p>where \\(x\\) belongs to the interval \\([-1,1]\\):</p> <pre><code>design_space = DesignSpace()\ndesign_space.add_variable(\"x\", lower_bound=-1, upper_bound=1.0, value=0.5)\n</code></pre> <p>and \\(U\\) is a standard Gaussian variable:</p> <pre><code>uncertain_space = ParameterSpace()\nuncertain_space.add_random_variable(\"u\", \"OTNormalDistribution\")\n</code></pre> <p>Then, we build a UDOEScenario to minimize a sampling-based estimation of the expectation \\(\\mathbb{E}[Y]\\) where \\(Y=f(x,U)\\):</p> <pre><code>scenario = UDOEScenario(\n    [discipline],\n    \"y\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    formulation_name=\"DisciplinaryOpt\",\n    statistic_estimation=\"Sampling\",\n    statistic_estimation_parameters={\"n_samples\": 100},\n)\n</code></pre> <p>We execute it with a full-factorial design of experiments:</p> <pre><code>scenario.execute(algo_name=\"PYDOE_FULLFACT\", n_samples=100)\n</code></pre> <p>and plot the history:</p> <pre><code>scenario.post_process(post_name=\"OptHistoryView\", save=True, show=True)\n</code></pre> <p>Notice that the numerical solution is close to \\((x^*,f^*)=(0,1)\\) as expected from the expression of the statistic: \\(\\mathbb{E}[Y]=\\mathbb{E}[(x+U)^2]=x^2+1\\).</p> <p>Total running time of the script: ( 0 minutes  0.000 seconds)</p> <p> Download Python source code: udoe_quadratic.py</p> <p> Download Jupyter notebook: udoe_quadratic.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/pce/mg_execution_times/","title":"Computation times","text":"<p>00:01.293 total execution time for generated_examples_umdo_pce files:</p> <p>+----------------------------------------------------------------------------------------------+-----------+--------+ | plot_pce_quadratic (docs/examples/umdo/pce/plot_pce_quadratic.py) | 00:01.293 | 0.0 MB | +----------------------------------------------------------------------------------------------+-----------+--------+</p>"},{"location":"generated/examples/umdo/pce/plot_pce_quadratic/","title":"A quadratic mono-disciplinary problem","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/pce/plot_pce_quadratic/#a-quadratic-mono-disciplinary-problem","title":"A quadratic mono-disciplinary problem","text":"<p>In this example, we consider the quadratic mono-disciplinary optimization problem</p> \\[\\min_{x\\in[-1,1]} \\mathbb{E}[(x+U)^2]\\] <p>where \\(U\\sim\\mathcal{N}(0,1)\\) is a standard Gaussian variable and \\(\\mathbb{E}\\) is the expectation operator.</p> <p>The objective can be rewritten as \\(x^2+1\\) and then the solution is obvious, namely</p> \\[(x^*,\\mathbb{E}[(x^*+U)^2])=(0,1).\\] <p>In the following, we will call \\(f\\) the function computing \\((x+U)^2\\) given \\(x\\) and \\(U\\).</p> <pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nconfigure_logger()\n</code></pre> <p>Out:</p> <pre><code>&lt;RootLogger root (INFO)&gt;\n</code></pre> <p>Firstly, we define an AnalyticDiscipline implementing the function \\(f\\):</p> <pre><code>discipline = AnalyticDiscipline({\"y\": \"(x+u)**2\"}, name=\"f\")\n</code></pre> <p>as well as the design space:</p> <pre><code>design_space = DesignSpace()\ndesign_space.add_variable(\"x\", lower_bound=-1, upper_bound=1.0, value=0.5)\n</code></pre> <p>and the uncertain space:</p> <pre><code>uncertain_space = ParameterSpace()\nuncertain_space.add_random_variable(\"u\", \"OTNormalDistribution\")\n</code></pre> <p>Out:</p> <pre><code>/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/pydantic/main.py:209: DeprecationWarning: Conversion of an array with ndim &gt; 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n</code></pre> <p>Then, we define a UMDOScenario to minimize the statistic \\(\\mathbb{E}[(x+U)^2]\\) estimated using a polynomial chaos expansion (PCE) trained from 20 samples at each iteration of the optimization loop:</p> <pre><code>scenario = UMDOScenario(\n    [discipline],\n    \"y\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    formulation_name=\"DisciplinaryOpt\",\n    statistic_estimation=\"PCE\",\n    statistic_estimation_parameters={\"doe_n_samples\": 20},\n)\n</code></pre> <p>We execute this scenario using the gradient-free optimizer COBYLA:</p> <pre><code>scenario.execute(algo_name=\"NLOPT_COBYLA\", max_iter=100)\n</code></pre> <p>Out:</p> <pre><code>    INFO - 10:51:37:  \n    INFO - 10:51:37: *** Start UMDOScenario execution ***\n    INFO - 10:51:37: UMDOScenario\n    INFO - 10:51:37:    Disciplines: f\n    INFO - 10:51:37:    Formulation:\n    INFO - 10:51:37:       MDO formulation: DisciplinaryOpt\n    INFO - 10:51:37:       Statistic estimation: PCE\n    INFO - 10:51:37:    Uncertain space:\n    INFO - 10:51:37:       +------+---------------------------+\n    INFO - 10:51:37:       | Name |        Distribution       |\n    INFO - 10:51:37:       +------+---------------------------+\n    INFO - 10:51:37:       |  u   | Normal(mu=0.0, sigma=1.0) |\n    INFO - 10:51:37:       +------+---------------------------+\n    INFO - 10:51:37: Optimization problem:\n    INFO - 10:51:37:    minimize E[y]\n    INFO - 10:51:37:    with respect to x\n    INFO - 10:51:37:    over the design space:\n    INFO - 10:51:37:       +------+-------------+-------+-------------+-------+\n    INFO - 10:51:37:       | Name | Lower bound | Value | Upper bound | Type  |\n    INFO - 10:51:37:       +------+-------------+-------+-------------+-------+\n    INFO - 10:51:37:       | x    |      -1     |  0.5  |      1      | float |\n    INFO - 10:51:37:       +------+-------------+-------+-------------+-------+\n    INFO - 10:51:37: Solving optimization problem with algorithm NLOPT_COBYLA:\n    INFO - 10:51:37:         R2Measure\n    INFO - 10:51:37:             y[0]: 1.0&gt;=0.9 (train) - 1.0&gt;=0.8 (test)\n    INFO - 10:51:37:      1%|          | 1/100 [00:00&lt;00:05, 19.70 it/sec, obj=1.25]\n    INFO - 10:51:37:         R2Measure\n    INFO - 10:51:37:             y[0]: 1.0&gt;=0.9 (train) - 1.0&gt;=0.8 (test)\n    INFO - 10:51:37:      2%|\u258f         | 2/100 [00:00&lt;00:04, 21.63 it/sec, obj=2]\n    INFO - 10:51:37:         R2Measure\n    INFO - 10:51:37:             y[0]: 1.0&gt;=0.9 (train) - 1.0&gt;=0.8 (test)\n    INFO - 10:51:37:      3%|\u258e         | 3/100 [00:00&lt;00:04, 22.26 it/sec, obj=1]\n    INFO - 10:51:37:         R2Measure\n    INFO - 10:51:37:             y[0]: 1.0&gt;=0.9 (train) - 1.0&gt;=0.8 (test)\n    INFO - 10:51:37:      4%|\u258d         | 4/100 [00:00&lt;00:04, 22.46 it/sec, obj=1.25]\n    INFO - 10:51:37:         R2Measure\n    INFO - 10:51:37:             y[0]: 1.0&gt;=0.9 (train) - 1.0&gt;=0.8 (test)\n    INFO - 10:51:37:      5%|\u258c         | 5/100 [00:00&lt;00:04, 22.36 it/sec, obj=1.06]\n    INFO - 10:51:37:         R2Measure\n    INFO - 10:51:37:             y[0]: 1.0&gt;=0.9 (train) - 1.0&gt;=0.8 (test)\n    INFO - 10:51:37:      6%|\u258c         | 6/100 [00:00&lt;00:04, 22.48 it/sec, obj=1.02]\n    INFO - 10:51:37:         R2Measure\n    INFO - 10:51:37:             y[0]: 1.0&gt;=0.9 (train) - 1.0&gt;=0.8 (test)\n    INFO - 10:51:37:      7%|\u258b         | 7/100 [00:00&lt;00:04, 22.58 it/sec, obj=1]\n    INFO - 10:51:37:         R2Measure\n    INFO - 10:51:37:             y[0]: 1.0&gt;=0.9 (train) - 1.0&gt;=0.8 (test)\n    INFO - 10:51:37:      8%|\u258a         | 8/100 [00:00&lt;00:04, 22.65 it/sec, obj=1]\n    INFO - 10:51:37:         R2Measure\n    INFO - 10:51:37:             y[0]: 1.0&gt;=0.9 (train) - 1.0&gt;=0.8 (test)\n    INFO - 10:51:37:      9%|\u2589         | 9/100 [00:00&lt;00:04, 22.70 it/sec, obj=1]\n    INFO - 10:51:37:         R2Measure\n    INFO - 10:51:37:             y[0]: 1.0&gt;=0.9 (train) - 1.0&gt;=0.8 (test)\n    INFO - 10:51:37:     10%|\u2588         | 10/100 [00:00&lt;00:03, 22.78 it/sec, obj=1]\n    INFO - 10:51:37:         R2Measure\n    INFO - 10:51:37:             y[0]: 1.0&gt;=0.9 (train) - 1.0&gt;=0.8 (test)\n    INFO - 10:51:37:     11%|\u2588         | 11/100 [00:00&lt;00:03, 22.85 it/sec, obj=1]\n    INFO - 10:51:37:         R2Measure\n    INFO - 10:51:37:             y[0]: 1.0&gt;=0.9 (train) - 1.0&gt;=0.8 (test)\n    INFO - 10:51:37:     12%|\u2588\u258f        | 12/100 [00:00&lt;00:03, 22.88 it/sec, obj=1]\n    INFO - 10:51:37:         R2Measure\n    INFO - 10:51:37:             y[0]: 1.0&gt;=0.9 (train) - 1.0&gt;=0.8 (test)\n    INFO - 10:51:37:     13%|\u2588\u258e        | 13/100 [00:00&lt;00:03, 22.89 it/sec, obj=1]\n    INFO - 10:51:37:         R2Measure\n    INFO - 10:51:37:             y[0]: 1.0&gt;=0.9 (train) - 1.0&gt;=0.8 (test)\n    INFO - 10:51:37:     14%|\u2588\u258d        | 14/100 [00:00&lt;00:03, 22.94 it/sec, obj=1]\n    INFO - 10:51:37:         R2Measure\n    INFO - 10:51:37:             y[0]: 1.0&gt;=0.9 (train) - 1.0&gt;=0.8 (test)\n    INFO - 10:51:37:     15%|\u2588\u258c        | 15/100 [00:00&lt;00:03, 22.99 it/sec, obj=1]\n    INFO - 10:51:37:         R2Measure\n    INFO - 10:51:37:             y[0]: 1.0&gt;=0.9 (train) - 1.0&gt;=0.8 (test)\n    INFO - 10:51:37:     16%|\u2588\u258c        | 16/100 [00:00&lt;00:03, 23.01 it/sec, obj=1]\n    INFO - 10:51:37:         R2Measure\n    INFO - 10:51:37:             y[0]: 1.0&gt;=0.9 (train) - 1.0&gt;=0.8 (test)\n    INFO - 10:51:37:     17%|\u2588\u258b        | 17/100 [00:00&lt;00:03, 22.99 it/sec, obj=1]\n    INFO - 10:51:37: Optimization result:\n    INFO - 10:51:37:    Optimizer info:\n    INFO - 10:51:37:       Status: None\n    INFO - 10:51:37:       Message: Successive iterates of the objective function are closer than ftol_rel or ftol_abs. GEMSEO stopped the driver.\n    INFO - 10:51:37:       Number of calls to the objective function by the optimizer: 18\n    INFO - 10:51:37:    Solution:\n    INFO - 10:51:37:       Objective: 0.9999999999999998\n    INFO - 10:51:37:       Design space:\n    INFO - 10:51:37:          +------+-------------+-------+-------------+-------+\n    INFO - 10:51:37:          | Name | Lower bound | Value | Upper bound | Type  |\n    INFO - 10:51:37:          +------+-------------+-------+-------------+-------+\n    INFO - 10:51:37:          | x    |      -1     |   0   |      1      | float |\n    INFO - 10:51:37:          +------+-------------+-------+-------------+-------+\n    INFO - 10:51:37: *** End UMDOScenario execution (time: 0:00:00.742531) ***\n</code></pre> <p>and plot the optimization history:</p> <pre><code>scenario.post_process(post_name=\"OptHistoryView\", save=False, show=True)\n</code></pre> <p>Out:</p> <pre><code>&lt;gemseo.post.opt_history_view.OptHistoryView object at 0x78c11dc66d90&gt;\n</code></pre> <p>Notice that the numerical solution</p> <pre><code>(scenario.optimization_result.x_opt[0], scenario.optimization_result.f_opt)\n</code></pre> <p>Out:</p> <pre><code>(0.0, 0.9999999999999998)\n</code></pre> <p>is close to the theoretical solution \\((x^*,\\mathbb{E}[(x^*+U)^2])=(0,1)\\).</p> <p>Total running time of the script: ( 0 minutes  1.293 seconds)</p> <p> Download Python source code: plot_pce_quadratic.py</p> <p> Download Jupyter notebook: plot_pce_quadratic.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/sampling/mg_execution_times/","title":"Computation times","text":"<p>00:08.166 total execution time for generated_examples_umdo_sampling files:</p> <p>+------------------------------------------------------------------------------------------------+-----------+--------+ | plot_s_rosenbrock (docs/examples/umdo/sampling/plot_s_rosenbrock.py) | 00:07.288 | 0.0 MB | +------------------------------------------------------------------------------------------------+-----------+--------+ | plot_s_quadratic (docs/examples/umdo/sampling/plot_s_quadratic.py)    | 00:00.878 | 0.0 MB | +------------------------------------------------------------------------------------------------+-----------+--------+ | s_sellar (docs/examples/umdo/sampling/s_sellar.py)                            | 00:00.000 | 0.0 MB | +------------------------------------------------------------------------------------------------+-----------+--------+ | s_sobieski (docs/examples/umdo/sampling/s_sobieski.py)                      | 00:00.000 | 0.0 MB | +------------------------------------------------------------------------------------------------+-----------+--------+</p>"},{"location":"generated/examples/umdo/sampling/plot_s_quadratic/","title":"A quadratic mono-disciplinary problem","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/sampling/plot_s_quadratic/#a-quadratic-mono-disciplinary-problem","title":"A quadratic mono-disciplinary problem","text":"<p>In this example, we consider the quadratic mono-disciplinary optimization problem</p> \\[\\min_{x\\in[-1,1]} \\mathbb{E}[(x+U)^2]\\] <p>where \\(U\\sim\\mathcal{N}(0,1)\\) is a standard Gaussian variable and \\(\\mathbb{E}\\) is the expectation operator.</p> <p>The objective can be rewritten as \\(x^2+1\\) and then the solution is obvious, namely</p> \\[(x^*,\\mathbb{E}[(x^*+U)^2])=(0,1).\\] <p>In the following, we will call \\(f\\) the function computing \\((x+U)^2\\) given \\(x\\) and \\(U\\).</p> <pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nconfigure_logger()\n</code></pre> <p>Out:</p> <pre><code>&lt;RootLogger root (INFO)&gt;\n</code></pre> <p>Firstly, we define an AnalyticDiscipline implementing the function \\(f\\):</p> <pre><code>discipline = AnalyticDiscipline({\"y\": \"(x+u)**2\"}, name=\"f\")\n</code></pre> <p>as well as the design space:</p> <pre><code>design_space = DesignSpace()\ndesign_space.add_variable(\"x\", lower_bound=-1, upper_bound=1.0, value=0.5)\n</code></pre> <p>and the uncertain space:</p> <pre><code>uncertain_space = ParameterSpace()\nuncertain_space.add_random_variable(\"u\", \"OTNormalDistribution\")\n</code></pre> <p>Out:</p> <pre><code>/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/pydantic/main.py:209: DeprecationWarning: Conversion of an array with ndim &gt; 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n</code></pre> <p>Then, we define a UMDOScenario to minimize the statistic \\(\\mathbb{E}[(x+U)^2]\\) estimated using a crude Monte Carlo sampling strategy with 50 samples at each iteration of the optimization loop:</p> <pre><code>scenario = UMDOScenario(\n    [discipline],\n    \"y\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    formulation_name=\"DisciplinaryOpt\",\n    statistic_estimation_parameters={\"n_samples\": 50},\n)\n</code></pre> <p>We execute this scenario using the gradient-free optimizer COBYLA:</p> <pre><code>scenario.execute(algo_name=\"NLOPT_COBYLA\", max_iter=100)\n</code></pre> <p>Out:</p> <pre><code>    INFO - 10:51:38:  \n    INFO - 10:51:38: *** Start UMDOScenario execution ***\n    INFO - 10:51:38: UMDOScenario\n    INFO - 10:51:38:    Disciplines: f\n    INFO - 10:51:38:    Formulation:\n    INFO - 10:51:38:       MDO formulation: DisciplinaryOpt\n    INFO - 10:51:38:       Statistic estimation: Sampling\n    INFO - 10:51:38:    Uncertain space:\n    INFO - 10:51:38:       +------+---------------------------+\n    INFO - 10:51:38:       | Name |        Distribution       |\n    INFO - 10:51:38:       +------+---------------------------+\n    INFO - 10:51:38:       |  u   | Normal(mu=0.0, sigma=1.0) |\n    INFO - 10:51:38:       +------+---------------------------+\n    INFO - 10:51:38: Optimization problem:\n    INFO - 10:51:38:    minimize E[y]\n    INFO - 10:51:38:    with respect to x\n    INFO - 10:51:38:    over the design space:\n    INFO - 10:51:38:       +------+-------------+-------+-------------+-------+\n    INFO - 10:51:38:       | Name | Lower bound | Value | Upper bound | Type  |\n    INFO - 10:51:38:       +------+-------------+-------+-------------+-------+\n    INFO - 10:51:38:       | x    |      -1     |  0.5  |      1      | float |\n    INFO - 10:51:38:       +------+-------------+-------+-------------+-------+\n    INFO - 10:51:38: Solving optimization problem with algorithm NLOPT_COBYLA:\n    INFO - 10:51:38:      1%|          | 1/100 [00:00&lt;00:01, 78.73 it/sec, obj=1.32]\n    INFO - 10:51:38:      2%|\u258f         | 2/100 [00:00&lt;00:01, 79.99 it/sec, obj=2.09]\n    INFO - 10:51:38:      3%|\u258e         | 3/100 [00:00&lt;00:01, 78.39 it/sec, obj=1.05]\n    INFO - 10:51:38:      4%|\u258d         | 4/100 [00:00&lt;00:01, 76.43 it/sec, obj=1.28]\n    INFO - 10:51:38:      5%|\u258c         | 5/100 [00:00&lt;00:01, 74.16 it/sec, obj=1.1]\n    INFO - 10:51:38:      6%|\u258c         | 6/100 [00:00&lt;00:01, 72.16 it/sec, obj=1.07]\n    INFO - 10:51:38:      7%|\u258b         | 7/100 [00:00&lt;00:01, 70.12 it/sec, obj=1.05]\n    INFO - 10:51:38:      8%|\u258a         | 8/100 [00:00&lt;00:01, 68.07 it/sec, obj=1.05]\n    INFO - 10:51:38:      9%|\u2589         | 9/100 [00:00&lt;00:01, 66.05 it/sec, obj=1.05]\n    INFO - 10:51:38:     10%|\u2588         | 10/100 [00:00&lt;00:01, 64.27 it/sec, obj=1.05]\n    INFO - 10:51:38:     11%|\u2588         | 11/100 [00:00&lt;00:01, 62.32 it/sec, obj=1.05]\n    INFO - 10:51:38:     12%|\u2588\u258f        | 12/100 [00:00&lt;00:01, 60.89 it/sec, obj=1.05]\n    INFO - 10:51:38:     13%|\u2588\u258e        | 13/100 [00:00&lt;00:01, 59.70 it/sec, obj=1.05]\n    INFO - 10:51:38:     14%|\u2588\u258d        | 14/100 [00:00&lt;00:01, 58.49 it/sec, obj=1.05]\n    INFO - 10:51:38:     15%|\u2588\u258c        | 15/100 [00:00&lt;00:01, 57.30 it/sec, obj=1.05]\n    INFO - 10:51:38:     16%|\u2588\u258c        | 16/100 [00:00&lt;00:01, 56.25 it/sec, obj=1.05]\n    INFO - 10:51:39:     17%|\u2588\u258b        | 17/100 [00:00&lt;00:01, 55.24 it/sec, obj=1.05]\n    INFO - 10:51:39:     18%|\u2588\u258a        | 18/100 [00:00&lt;00:01, 54.11 it/sec, obj=1.05]\n    INFO - 10:51:39:     19%|\u2588\u2589        | 19/100 [00:00&lt;00:01, 53.10 it/sec, obj=1.05]\n    INFO - 10:51:39:     20%|\u2588\u2588        | 20/100 [00:00&lt;00:01, 52.15 it/sec, obj=1.05]\n    INFO - 10:51:39: Optimization result:\n    INFO - 10:51:39:    Optimizer info:\n    INFO - 10:51:39:       Status: None\n    INFO - 10:51:39:       Message: Successive iterates of the objective function are closer than ftol_rel or ftol_abs. GEMSEO stopped the driver.\n    INFO - 10:51:39:       Number of calls to the objective function by the optimizer: 21\n    INFO - 10:51:39:    Solution:\n    INFO - 10:51:39:       Objective: 1.0467065707047472\n    INFO - 10:51:39:       Design space:\n    INFO - 10:51:39:          +------+-------------+-------------+-------------+-------+\n    INFO - 10:51:39:          | Name | Lower bound |    Value    | Upper bound | Type  |\n    INFO - 10:51:39:          +------+-------------+-------------+-------------+-------+\n    INFO - 10:51:39:          | x    |      -1     | -0.01953125 |      1      | float |\n    INFO - 10:51:39:          +------+-------------+-------------+-------------+-------+\n    INFO - 10:51:39: *** End UMDOScenario execution (time: 0:00:00.386286) ***\n</code></pre> <p>and plot the optimization history:</p> <pre><code>scenario.post_process(post_name=\"OptHistoryView\", save=False, show=True)\n</code></pre> <p>Out:</p> <pre><code>&lt;gemseo.post.opt_history_view.OptHistoryView object at 0x78c11c095520&gt;\n</code></pre> <p>Notice that the numerical solution</p> <pre><code>(scenario.optimization_result.x_opt[0], scenario.optimization_result.f_opt)\n</code></pre> <p>Out:</p> <pre><code>(-0.01953125, 1.0467065707047472)\n</code></pre> <p>is close to the theoretical solution \\((x^*,\\mathbb{E}[(x^*+U)^2])=(0,1)\\).</p> <p>Total running time of the script: ( 0 minutes  0.878 seconds)</p> <p> Download Python source code: plot_s_quadratic.py</p> <p> Download Jupyter notebook: plot_s_quadratic.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/sampling/plot_s_rosenbrock/","title":"The Rosenbrock mono-disciplinary problem","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/sampling/plot_s_rosenbrock/#the-rosenbrock-mono-disciplinary-problem","title":"The Rosenbrock mono-disciplinary problem","text":"<p>In this example, we consider the Rosenbrock mono-disciplinary optimization problem</p> \\[\\min_{x,y\\in[-2,2]} \\mathbb{E}[(U-x)^2+100(y-x^2)^2]\\] <p>where \\(U\\sim\\mathcal{N}(0,0.0025)\\) is a Gaussian variable and \\(\\mathbb{E}\\) is the expectation operator.</p> <p>In the following, we will call \\(f\\) the function computing \\((U-x)^2+100(y-x^2)^2\\) given \\(x\\), \\(y\\) and \\(U\\).</p> <pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nconfigure_logger()\n</code></pre> <p>Out:</p> <pre><code>&lt;RootLogger root (INFO)&gt;\n</code></pre> <p>Firstly, we define the discipline implementing the Rosenbrock function \\(f\\):</p> <pre><code>discipline = AnalyticDiscipline({\"z\": \"(u-x)**2+100*(y-x**2)**2\"}, name=\"f\")\n</code></pre> <p>where \\(x,y\\) belongs to the interval \\([-2,2]\\):</p> <pre><code>design_space = DesignSpace()\ndesign_space.add_variable(\"x\", lower_bound=-2, upper_bound=2.0, value=-2.0)\ndesign_space.add_variable(\"y\", lower_bound=-2, upper_bound=2.0, value=-2.0)\n</code></pre> <p>and \\(U\\) is a Gaussian variable with unit mean and standard deviation equal to 0.05:</p> <pre><code>uncertain_space = ParameterSpace()\nuncertain_space.add_random_variable(\"u\", \"OTNormalDistribution\", mu=1.0, sigma=0.05)\n</code></pre> <p>Out:</p> <pre><code>/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/pydantic/main.py:209: DeprecationWarning: Conversion of an array with ndim &gt; 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n</code></pre> <p>Then, we define a UMDOScenario to minimize the statistic \\(\\mathbb{E}[(U-x)^2+100(y-x^2)^2]\\) estimated using a first-order Taylor polynomial of \\(f\\) at \\(\\mathbb{E}[U]=0.2\\) at each iteration of the optimization loop:</p> <pre><code>scenario = UMDOScenario(\n    [discipline],\n    \"z\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    formulation_name=\"DisciplinaryOpt\",\n    statistic_estimation_parameters={\"n_samples\": 30},\n)\n</code></pre> <p>We execute it with the gradient-based optimizer SLSQP:</p> <p>Warning</p> <p>The implementation of statistic estimators do not allow for the moment to use analytical derivatives. Please use finite differences or complex step to approximate the gradients.</p> <pre><code>scenario.set_differentiation_method(\"finite_differences\")\nscenario.execute(algo_name=\"NLOPT_SLSQP\", max_iter=100)\n</code></pre> <p>Out:</p> <pre><code>    INFO - 10:51:39:  \n    INFO - 10:51:39: *** Start UMDOScenario execution ***\n    INFO - 10:51:39: UMDOScenario\n    INFO - 10:51:39:    Disciplines: f\n    INFO - 10:51:39:    Formulation:\n    INFO - 10:51:39:       MDO formulation: DisciplinaryOpt\n    INFO - 10:51:39:       Statistic estimation: Sampling\n    INFO - 10:51:39:    Uncertain space:\n    INFO - 10:51:39:       +------+----------------------------+\n    INFO - 10:51:39:       | Name |        Distribution        |\n    INFO - 10:51:39:       +------+----------------------------+\n    INFO - 10:51:39:       |  u   | Normal(mu=1.0, sigma=0.05) |\n    INFO - 10:51:39:       +------+----------------------------+\n    INFO - 10:51:39: Optimization problem:\n    INFO - 10:51:39:    minimize E[z]\n    INFO - 10:51:39:    with respect to x, y\n    INFO - 10:51:39:    over the design space:\n    INFO - 10:51:39:       +------+-------------+-------+-------------+-------+\n    INFO - 10:51:39:       | Name | Lower bound | Value | Upper bound | Type  |\n    INFO - 10:51:39:       +------+-------------+-------+-------------+-------+\n    INFO - 10:51:39:       | x    |      -2     |   -2  |      2      | float |\n    INFO - 10:51:39:       | y    |      -2     |   -2  |      2      | float |\n    INFO - 10:51:39:       +------+-------------+-------+-------------+-------+\n    INFO - 10:51:39: Solving optimization problem with algorithm NLOPT_SLSQP:\n    INFO - 10:51:39:      1%|          | 1/100 [00:00&lt;00:00, 102.94 it/sec, obj=3.61e+3]\n    INFO - 10:51:39:      2%|\u258f         | 2/100 [00:00&lt;00:05, 18.53 it/sec, obj=401]\n    INFO - 10:51:39:      3%|\u258e         | 3/100 [00:00&lt;00:05, 18.79 it/sec, obj=152]\n    INFO - 10:51:39:      4%|\u258d         | 4/100 [00:00&lt;00:04, 21.22 it/sec, obj=411]\n    INFO - 10:51:39:      5%|\u258c         | 5/100 [00:00&lt;00:03, 26.50 it/sec, obj=14]\n    INFO - 10:51:40:      6%|\u258c         | 6/100 [00:00&lt;00:05, 18.50 it/sec, obj=618]\n    INFO - 10:51:40:      7%|\u258b         | 7/100 [00:00&lt;00:04, 21.57 it/sec, obj=5.18]\n    INFO - 10:51:40:      8%|\u258a         | 8/100 [00:00&lt;00:05, 16.13 it/sec, obj=87.2]\n    INFO - 10:51:40:      9%|\u2589         | 9/100 [00:00&lt;00:05, 18.13 it/sec, obj=2.15]\n    INFO - 10:51:40:     10%|\u2588         | 10/100 [00:00&lt;00:06, 14.37 it/sec, obj=4.06]\n    INFO - 10:51:40:     11%|\u2588         | 11/100 [00:00&lt;00:05, 15.81 it/sec, obj=0.696]\n    INFO - 10:51:40:     12%|\u2588\u258f        | 12/100 [00:00&lt;00:07, 12.20 it/sec, obj=0.656]\n    INFO - 10:51:40:     13%|\u2588\u258e        | 13/100 [00:01&lt;00:07, 11.70 it/sec, obj=0.644]\n    INFO - 10:51:41:     14%|\u2588\u258d        | 14/100 [00:01&lt;00:07, 11.19 it/sec, obj=0.64]\n    INFO - 10:51:41:     15%|\u2588\u258c        | 15/100 [00:01&lt;00:07, 10.77 it/sec, obj=0.612]\n    INFO - 10:51:41:     16%|\u2588\u258c        | 16/100 [00:01&lt;00:08, 10.38 it/sec, obj=0.453]\n    INFO - 10:51:41:     17%|\u2588\u258b        | 17/100 [00:01&lt;00:07, 10.50 it/sec, obj=22.5]\n    INFO - 10:51:41:     18%|\u2588\u258a        | 18/100 [00:01&lt;00:07, 11.12 it/sec, obj=0.382]\n    INFO - 10:51:41:     19%|\u2588\u2589        | 19/100 [00:01&lt;00:08,  9.78 it/sec, obj=0.38]\n    INFO - 10:51:41:     20%|\u2588\u2588        | 20/100 [00:01&lt;00:07, 10.29 it/sec, obj=0.355]\n    INFO - 10:51:42:     21%|\u2588\u2588        | 21/100 [00:02&lt;00:08,  8.80 it/sec, obj=0.324]\n    INFO - 10:51:42:     22%|\u2588\u2588\u258f       | 22/100 [00:02&lt;00:09,  8.52 it/sec, obj=0.203]\n    INFO - 10:51:42:     23%|\u2588\u2588\u258e       | 23/100 [00:02&lt;00:09,  8.28 it/sec, obj=0.147]\n    INFO - 10:51:42:     24%|\u2588\u2588\u258d       | 24/100 [00:02&lt;00:09,  8.04 it/sec, obj=0.0677]\n    INFO - 10:51:42:     25%|\u2588\u2588\u258c       | 25/100 [00:03&lt;00:09,  8.09 it/sec, obj=0.759]\n    INFO - 10:51:42:     26%|\u2588\u2588\u258c       | 26/100 [00:03&lt;00:08,  8.41 it/sec, obj=0.0558]\n    INFO - 10:51:43:     27%|\u2588\u2588\u258b       | 27/100 [00:03&lt;00:09,  7.65 it/sec, obj=0.0626]\n    INFO - 10:51:43:     28%|\u2588\u2588\u258a       | 28/100 [00:03&lt;00:09,  7.94 it/sec, obj=0.0417]\n    INFO - 10:51:43:     29%|\u2588\u2588\u2589       | 29/100 [00:04&lt;00:10,  7.04 it/sec, obj=0.0328]\n    INFO - 10:51:44:     30%|\u2588\u2588\u2588       | 30/100 [00:04&lt;00:10,  6.87 it/sec, obj=0.0183]\n    INFO - 10:51:44:     31%|\u2588\u2588\u2588       | 31/100 [00:04&lt;00:10,  6.71 it/sec, obj=0.00884]\n    INFO - 10:51:44:     32%|\u2588\u2588\u2588\u258f      | 32/100 [00:04&lt;00:10,  6.55 it/sec, obj=0.00607]\n    INFO - 10:51:44:     33%|\u2588\u2588\u2588\u258e      | 33/100 [00:05&lt;00:10,  6.39 it/sec, obj=0.00298]\n    INFO - 10:51:45:     34%|\u2588\u2588\u2588\u258d      | 34/100 [00:05&lt;00:10,  6.25 it/sec, obj=0.00245]\n    INFO - 10:51:45:     35%|\u2588\u2588\u2588\u258c      | 35/100 [00:05&lt;00:10,  6.11 it/sec, obj=0.0024]\n    INFO - 10:51:45:     36%|\u2588\u2588\u2588\u258c      | 36/100 [00:06&lt;00:10,  5.98 it/sec, obj=0.00239]\n    INFO - 10:51:46:     37%|\u2588\u2588\u2588\u258b      | 37/100 [00:06&lt;00:10,  5.85 it/sec, obj=0.00239]\n    INFO - 10:51:46:     38%|\u2588\u2588\u2588\u258a      | 38/100 [00:06&lt;00:10,  5.87 it/sec, obj=0.00239]\n    INFO - 10:51:46:     39%|\u2588\u2588\u2588\u2589      | 39/100 [00:06&lt;00:10,  6.03 it/sec, obj=0.00239]\n    INFO - 10:51:46:     40%|\u2588\u2588\u2588\u2588      | 40/100 [00:06&lt;00:09,  6.11 it/sec, obj=0.00239]\n    INFO - 10:51:46:     41%|\u2588\u2588\u2588\u2588      | 41/100 [00:06&lt;00:09,  6.19 it/sec, obj=0.00239]\n    INFO - 10:51:46:     42%|\u2588\u2588\u2588\u2588\u258f     | 42/100 [00:06&lt;00:09,  6.27 it/sec, obj=0.00239]\n    INFO - 10:51:46:     43%|\u2588\u2588\u2588\u2588\u258e     | 43/100 [00:06&lt;00:08,  6.34 it/sec, obj=0.00239]\n    INFO - 10:51:46: Optimization result:\n    INFO - 10:51:46:    Optimizer info:\n    INFO - 10:51:46:       Status: None\n    INFO - 10:51:46:       Message: Successive iterates of the objective function are closer than ftol_rel or ftol_abs. GEMSEO stopped the driver.\n    INFO - 10:51:46:       Number of calls to the objective function by the optimizer: 52\n    INFO - 10:51:46:    Solution:\n    INFO - 10:51:46:       Objective: 0.002387443993474335\n    INFO - 10:51:46:       Design space:\n    INFO - 10:51:46:          +------+-------------+--------------------+-------------+-------+\n    INFO - 10:51:46:          | Name | Lower bound |       Value        | Upper bound | Type  |\n    INFO - 10:51:46:          +------+-------------+--------------------+-------------+-------+\n    INFO - 10:51:46:          | x    |      -2     | 0.9995607309583234 |      2      | float |\n    INFO - 10:51:46:          | y    |      -2     | 0.9991189652769399 |      2      | float |\n    INFO - 10:51:46:          +------+-------------+--------------------+-------------+-------+\n    INFO - 10:51:46: *** End UMDOScenario execution (time: 0:00:06.784954) ***\n</code></pre> <p>and plot the optimization history:</p> <pre><code>scenario.post_process(post_name=\"OptHistoryView\", save=False, show=True)\n</code></pre> <p>Out:</p> <pre><code>&lt;gemseo.post.opt_history_view.OptHistoryView object at 0x78c11c0481f0&gt;\n</code></pre> <p>Lastly, we can compare the numerical solution of this Rosenbrock problem under uncertainty</p> <pre><code>(scenario.optimization_result.x_opt, scenario.optimization_result.f_opt)\n</code></pre> <p>Out:</p> <pre><code>(array([0.99956073, 0.99911897]), 0.002387443993474335)\n</code></pre> <p>to the solution of the Rosenbrock problem without uncertainty, namely \\((x^*,f^*)=([1, 1], 0)\\).</p> <p>Total running time of the script: ( 0 minutes  7.288 seconds)</p> <p> Download Python source code: plot_s_rosenbrock.py</p> <p> Download Jupyter notebook: plot_s_rosenbrock.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/sampling/s_sellar/","title":"The Sellar's MDO problem","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/sampling/s_sellar/#the-sellars-mdo-problem","title":"The Sellar's MDO problem","text":"<p>In this example, we consider the Sellar's MDO problem under uncertainty</p> \\[\\min_{x,z_1,x_2} \\mathbb{E}[f(x,z_2,y_1,y_2)]\\] <p>over the design space \\([0,10]\\times[-10,10]\\times[0,10]\\) and under the inequality constraints</p> \\[\\mathbb{E}[c_1(y_1)]+3\\mathbb{S}[c_1(y_1)] \\leq 0\\] <p>and</p> \\[\\mathbb{E}[c_2(y_2)]+3\\mathbb{S}[c_2(y_2)] \\leq 0,\\] <p>where</p> <ul> <li>\\(\\mathbb{E}\\) is the expectation operator,</li> <li>\\(\\mathbb{S}\\) is the standard deviation operators,</li> <li>\\(f(x,z_2) = x^2 + z_2 + y_1^2 + \\exp(-y_2)\\) is the objective function,</li> <li>\\(c_1(y_1) = 3.16 - y_1^2\\) is the first constraint function,</li> <li>\\(c_2(y_2) = y_2 - 24.0\\) is the second constraint function,</li> <li>\\(y_1 = \\sqrt{z_1^2 + z_2 + x - ay_2}\\) is the first coupling equation,</li> <li>\\(y_2 = \\frac{\\log(1+\\exp(10y_1))}{5} - y_1 - \\frac{\\log(2)}{5} + z_1 + z_2\\)   is the second coupling equation,</li> <li>\\(a\\) is a random variable distributed   according to the triangular distribution \\(\\mathcal{T}(0.1,0.2,0.3)\\).</li> </ul> <pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nconfigure_logger()\n</code></pre> <p>Firstly, we create one discipline per couping equation and a system discipline to compute the objective and constraints:</p> <pre><code>system = AnalyticDiscipline({\n    \"obj\": \"x**2 + z2 + y1**2 + exp(-y2)\",\n    \"c1\": \"3.16 - y1 ** 2\",\n    \"c2\": \"y2 - 24.0\",\n})\ndisc1 = AnalyticDiscipline({\"y1\": \"(z1**2 + z2 + x - a*y2)**0.5\"})\ndisc2 = AnalyticDiscipline({\"y2\": \"abs(y1) + z1 + z2\"})\n</code></pre> <p>as well as the design space:</p> <pre><code>design_space = DesignSpace()\ndesign_space.add_variable(\"x\", 1, lower_bound=0.0, upper_bound=10.0, value=1.0)\ndesign_space.add_variable(\"z1\", 1, lower_bound=-10.0, upper_bound=10.0, value=4.0)\ndesign_space.add_variable(\"z2\", 1, lower_bound=0.0, upper_bound=10.0, value=3.0)\n</code></pre> <p>Secondly, we define the uncertain space:</p> <pre><code>uncertain_space = ParameterSpace()\n</code></pre> <p>with an uncertainty over the constant <code>\"a\"</code>:</p> <pre><code>uncertain_space.add_random_variable(\n    \"a\", \"OTTriangularDistribution\", minimum=0.1, maximum=0.3, mode=0.2\n)\n</code></pre> <p>Then, we define a UMDOScenario to minimize the statistic \\(\\mathbb{E}[f(x,z_2,y_1,y_2)]\\) estimated using a crude Monte Carlo sampling strategy with 100 samples at each iteration of the optimization loop:</p> <pre><code>scenario = UMDOScenario(\n    [system, disc1, disc2],\n    \"obj\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    formulation_name=\"MDF\",\n    statistic_estimation_parameters={\"n_samples\": 100},\n)\n</code></pre> <p>while satisfying the constraints \\(\\mathbb{E}[c_1(y_1)]+3\\mathbb{S}[c_1(y_1)] \\leq 0\\) and \\(\\mathbb{E}[c_2(y_2)]+3\\mathbb{S}[c_2(y_2)] \\leq 0\\):</p> <pre><code>scenario.add_constraint(\"c1\", \"Margin\", factor=3.0)\nscenario.add_constraint(\"c2\", \"Margin\", factor=3.0)\n</code></pre> <p>We execute this scenario using the gradient-free optimizer COBYLA:</p> <pre><code>scenario.execute(algo_name=\"NLOPT_COBYLA\", max_iter=200)\n</code></pre> <p>and plot the optimization history:</p> <pre><code>scenario.post_process(post_name=\"OptHistoryView\", save=True, show=False)\n</code></pre> <p>Lastly, we can compare the numerical solution of this Sellar's MDO problem under uncertainty</p> <pre><code>result = scenario.optimization_result\n(result.x_opt, result.constraint_values, result.f_opt)\n</code></pre> <p>to the solution of the Sellar's MDO problem without uncertainty, namely \\((x^*,c^*,f^*)=([0, 1.77, 0], [0, -20.58], 3.19)\\).</p> <p>Total running time of the script: ( 0 minutes  0.000 seconds)</p> <p> Download Python source code: s_sellar.py</p> <p> Download Jupyter notebook: s_sellar.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/sampling/s_sobieski/","title":"The Sobieski's SSBJ MDO problem","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/sampling/s_sobieski/#the-sobieskis-ssbj-mdo-problem","title":"The Sobieski's SSBJ MDO problem","text":"<pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.problems.mdo.sobieski.core.problem import SobieskiProblem\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiAerodynamics\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiMission\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiPropulsion\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiStructure\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nconfigure_logger()\n</code></pre> <p>Firstly, we instantiate the discipline of Sobieski's SSBJ problem:</p> <pre><code>mission = SobieskiMission()\nstructure = SobieskiStructure()\npropulsion = SobieskiPropulsion()\naerodynamics = SobieskiAerodynamics()\n</code></pre> <p>as well as the design space:</p> <pre><code>design_space = SobieskiProblem().design_space\n</code></pre> <p>Secondly, we define the uncertain space:</p> <pre><code>uncertain_space = ParameterSpace()\n</code></pre> <p>with an uncertainty over the constant <code>\"c_4\"</code>:</p> <pre><code>uncertain_space.add_random_variable(\n    \"c_4\", \"OTNormalDistribution\", mu=0.01375, sigma=0.01375 * 0.05\n)\n</code></pre> <p>and an uncertainty over the design variable <code>\"x_2\"</code>, expressed as an additive term <code>\"u_x_2\"</code> defined just after in the UMDOScenario:</p> <pre><code>uncertain_space.add_random_variable(\n    \"u_x_2\", \"OTNormalDistribution\", mu=0.0, sigma=1 * 0.05\n)\n</code></pre> <p>Then, we build an UMDOScenario to maximize a sampling-based estimation of the expectation \\(\\mathbb{E}[y_4]\\):</p> <pre><code>scenario = UMDOScenario(\n    [mission, structure, propulsion, aerodynamics],\n    \"y_4\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    formulation_name=\"MDF\",\n    statistic_estimation_parameters={\"n_samples\": 10},\n    maximize_objective=True,\n    uncertain_design_variables={\"x_2\": \"{}+u_x_2\"},\n)\n</code></pre> <p>while satisfying margin constraints of the form \\(\\mathbb{E}[g_i]+3\\mathbb{S}[g_i]\\)</p> <pre><code>scenario.add_constraint(\"g_1\", \"Margin\", factor=3.0)\nscenario.add_constraint(\"g_2\", \"Margin\", factor=3.0)\nscenario.add_constraint(\"g_3\", \"Margin\", factor=3.0)\n</code></pre> <p>and execute it with a gradient-free optimizer:</p> <pre><code>scenario.execute(algo_name=\"NLOPT_COBYLA\", max_iter=100)\n</code></pre> <p>Lastly, we can plot the optimization history view:</p> <pre><code>scenario.post_process(post_name=\"OptHistoryView\", save=False, show=True)\n</code></pre> <p>Total running time of the script: ( 0 minutes  0.000 seconds)</p> <p> Download Python source code: s_sobieski.py</p> <p> Download Jupyter notebook: s_sobieski.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/sequential_sampling/mg_execution_times/","title":"Computation times","text":"<p>00:01.085 total execution time for generated_examples_umdo_sequential_sampling files:</p> <p>+-----------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_ss_quadratic (docs/examples/umdo/sequential_sampling/plot_ss_quadratic.py) | 00:01.085 | 0.0 MB | +-----------------------------------------------------------------------------------------------------------+-----------+--------+</p>"},{"location":"generated/examples/umdo/sequential_sampling/plot_ss_quadratic/","title":"A quadratic mono-disciplinary problem","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/sequential_sampling/plot_ss_quadratic/#a-quadratic-mono-disciplinary-problem","title":"A quadratic mono-disciplinary problem","text":"<p>In this example, we consider the quadratic mono-disciplinary optimization problem</p> \\[\\min_{x\\in[-1,1]} \\mathbb{E}[(x+U)^2]\\] <p>where \\(U\\sim\\mathcal{N}(0,1)\\) is a standard Gaussian variable and \\(\\mathbb{E}\\) is the expectation operator.</p> <p>The objective can be rewritten as \\(x^2+1\\) and then the solution is obvious, namely</p> \\[(x^*,\\mathbb{E}[(x^*+U)^2])=(0,1).\\] <p>In the following, we will call \\(f\\) the function computing \\((x+U)^2\\) given \\(x\\) and \\(U\\).</p> <pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nconfigure_logger()\n</code></pre> <p>Out:</p> <pre><code>&lt;RootLogger root (INFO)&gt;\n</code></pre> <p>Firstly, we define an AnalyticDiscipline implementing the function \\(f\\):</p> <pre><code>discipline = AnalyticDiscipline({\"y\": \"(x+u)**2\"}, name=\"f\")\n</code></pre> <p>as well as the design space:</p> <pre><code>design_space = DesignSpace()\ndesign_space.add_variable(\"x\", lower_bound=-1, upper_bound=1.0, value=0.5)\n</code></pre> <p>and the uncertain space:</p> <pre><code>uncertain_space = ParameterSpace()\nuncertain_space.add_random_variable(\"u\", \"OTNormalDistribution\")\n</code></pre> <p>Out:</p> <pre><code>/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/pydantic/main.py:209: DeprecationWarning: Conversion of an array with ndim &gt; 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n</code></pre> <p>Then, we define a UMDOScenario to minimize the statistic \\(\\mathbb{E}[(x+U)^2]\\) estimated using a crude Monte Carlo sampling strategy with 20 samples at the initial iteration of the optimization loop, 25 samples at the second iteration, and so on until the seventh iteration where the number of samples is equal to 50 until the end of the loop.</p> <pre><code>scenario = UMDOScenario(\n    [discipline],\n    \"y\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    formulation_name=\"DisciplinaryOpt\",\n    statistic_estimation=\"SequentialSampling\",\n    statistic_estimation_parameters={\n        \"n_samples\": 50,\n        \"initial_n_samples\": 20,\n        \"n_samples_increment\": 5,\n    },\n)\n</code></pre> <p>We execute this scenario using the gradient-free optimizer COBYLA:</p> <pre><code>scenario.execute(algo_name=\"NLOPT_COBYLA\", max_iter=100)\n</code></pre> <p>Out:</p> <pre><code>    INFO - 10:51:48:  \n    INFO - 10:51:48: *** Start UMDOScenario execution ***\n    INFO - 10:51:48: UMDOScenario\n    INFO - 10:51:48:    Disciplines: f\n    INFO - 10:51:48:    Formulation:\n    INFO - 10:51:48:       MDO formulation: DisciplinaryOpt\n    INFO - 10:51:48:       Statistic estimation: SequentialSampling\n    INFO - 10:51:48:    Uncertain space:\n    INFO - 10:51:48:       +------+---------------------------+\n    INFO - 10:51:48:       | Name |        Distribution       |\n    INFO - 10:51:48:       +------+---------------------------+\n    INFO - 10:51:48:       |  u   | Normal(mu=0.0, sigma=1.0) |\n    INFO - 10:51:48:       +------+---------------------------+\n    INFO - 10:51:48: Optimization problem:\n    INFO - 10:51:48:    minimize E[y]\n    INFO - 10:51:48:    with respect to x\n    INFO - 10:51:48:    over the design space:\n    INFO - 10:51:48:       +------+-------------+-------+-------------+-------+\n    INFO - 10:51:48:       | Name | Lower bound | Value | Upper bound | Type  |\n    INFO - 10:51:48:       +------+-------------+-------+-------------+-------+\n    INFO - 10:51:48:       | x    |      -1     |  0.5  |      1      | float |\n    INFO - 10:51:48:       +------+-------------+-------+-------------+-------+\n    INFO - 10:51:48: Solving optimization problem with algorithm NLOPT_COBYLA:\n    INFO - 10:51:48:      1%|          | 1/100 [00:00&lt;00:00, 137.59 it/sec, obj=1.25]\n    INFO - 10:51:48:      2%|\u258f         | 2/100 [00:00&lt;00:00, 142.99 it/sec, obj=1.9]\n    INFO - 10:51:48:      3%|\u258e         | 3/100 [00:00&lt;00:00, 132.64 it/sec, obj=0.955]\n    INFO - 10:51:48:      4%|\u258d         | 4/100 [00:00&lt;00:00, 123.57 it/sec, obj=1.31]\n    INFO - 10:51:48:      5%|\u258c         | 5/100 [00:00&lt;00:00, 113.92 it/sec, obj=1.16]\n    INFO - 10:51:48:      6%|\u258c         | 6/100 [00:00&lt;00:00, 105.03 it/sec, obj=0.957]\n    INFO - 10:51:48:      7%|\u258b         | 7/100 [00:00&lt;00:00, 96.78 it/sec, obj=1.05]\n    INFO - 10:51:48:      8%|\u258a         | 8/100 [00:00&lt;00:01, 90.61 it/sec, obj=1.05]\n    INFO - 10:51:48:      9%|\u2589         | 9/100 [00:00&lt;00:01, 85.64 it/sec, obj=1.05]\n    INFO - 10:51:48:     10%|\u2588         | 10/100 [00:00&lt;00:01, 81.38 it/sec, obj=1.05]\n    INFO - 10:51:48:     11%|\u2588         | 11/100 [00:00&lt;00:01, 77.82 it/sec, obj=1.05]\n    INFO - 10:51:48:     12%|\u2588\u258f        | 12/100 [00:00&lt;00:01, 74.67 it/sec, obj=1.05]\n    INFO - 10:51:48:     13%|\u2588\u258e        | 13/100 [00:00&lt;00:01, 71.25 it/sec, obj=1.05]\n    INFO - 10:51:48:     14%|\u2588\u258d        | 14/100 [00:00&lt;00:01, 68.58 it/sec, obj=1.05]\n    INFO - 10:51:48:     15%|\u2588\u258c        | 15/100 [00:00&lt;00:01, 66.32 it/sec, obj=1.05]\n    INFO - 10:51:48:     16%|\u2588\u258c        | 16/100 [00:00&lt;00:01, 64.22 it/sec, obj=1.05]\n    INFO - 10:51:48:     17%|\u2588\u258b        | 17/100 [00:00&lt;00:01, 62.31 it/sec, obj=1.05]\n    INFO - 10:51:48:     18%|\u2588\u258a        | 18/100 [00:00&lt;00:01, 60.58 it/sec, obj=1.05]\n    INFO - 10:51:48:     19%|\u2588\u2589        | 19/100 [00:00&lt;00:01, 59.03 it/sec, obj=1.05]\n    INFO - 10:51:48:     20%|\u2588\u2588        | 20/100 [00:00&lt;00:01, 57.60 it/sec, obj=1.05]\n    INFO - 10:51:48:     21%|\u2588\u2588        | 21/100 [00:00&lt;00:01, 56.22 it/sec, obj=1.05]\n    INFO - 10:51:48:     22%|\u2588\u2588\u258f       | 22/100 [00:00&lt;00:01, 54.80 it/sec, obj=1.05]\n    INFO - 10:51:48:     23%|\u2588\u2588\u258e       | 23/100 [00:00&lt;00:01, 53.56 it/sec, obj=1.05]\n    INFO - 10:51:48:     24%|\u2588\u2588\u258d       | 24/100 [00:00&lt;00:01, 52.44 it/sec, obj=1.05]\n    INFO - 10:51:48:     25%|\u2588\u2588\u258c       | 25/100 [00:00&lt;00:01, 51.38 it/sec, obj=1.05]\n    INFO - 10:51:48:     26%|\u2588\u2588\u258c       | 26/100 [00:00&lt;00:01, 50.28 it/sec, obj=1.05]\n    INFO - 10:51:48: Optimization result:\n    INFO - 10:51:48:    Optimizer info:\n    INFO - 10:51:48:       Status: None\n    INFO - 10:51:48:       Message: Successive iterates of the objective function are closer than ftol_rel or ftol_abs. GEMSEO stopped the driver.\n    INFO - 10:51:48:       Number of calls to the objective function by the optimizer: 27\n    INFO - 10:51:48:    Solution:\n    INFO - 10:51:48:       Objective: 0.9546340808849048\n    INFO - 10:51:48:       Design space:\n    INFO - 10:51:48:          +------+-------------+-------+-------------+-------+\n    INFO - 10:51:48:          | Name | Lower bound | Value | Upper bound | Type  |\n    INFO - 10:51:48:          +------+-------------+-------+-------------+-------+\n    INFO - 10:51:48:          | x    |      -1     |   0   |      1      | float |\n    INFO - 10:51:48:          +------+-------------+-------+-------------+-------+\n    INFO - 10:51:48: *** End UMDOScenario execution (time: 0:00:00.519845) ***\n</code></pre> <p>and plot the optimization history:</p> <pre><code>scenario.post_process(post_name=\"OptHistoryView\", save=False, show=True)\n</code></pre> <p>Out:</p> <pre><code>&lt;gemseo.post.opt_history_view.OptHistoryView object at 0x78c11c267eb0&gt;\n</code></pre> <p>Notice that the numerical solution</p> <pre><code>(scenario.optimization_result.x_opt[0], scenario.optimization_result.f_opt)\n</code></pre> <p>Out:</p> <pre><code>(0.0, 0.9546340808849048)\n</code></pre> <p>is close to the theoretical solution \\((x^*,\\mathbb{E}[(x^*+U)^2])=(0,1)\\).</p> <p>Total running time of the script: ( 0 minutes  1.085 seconds)</p> <p> Download Python source code: plot_ss_quadratic.py</p> <p> Download Jupyter notebook: plot_ss_quadratic.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/surrogate/mg_execution_times/","title":"Computation times","text":"<p>00:01.617 total execution time for generated_examples_umdo_surrogate files:</p> <p>+----------------------------------------------------------------------------------------+-----------+--------+ | plot_surrogate (docs/examples/umdo/surrogate/plot_surrogate.py) | 00:01.617 | 0.0 MB | +----------------------------------------------------------------------------------------+-----------+--------+</p>"},{"location":"generated/examples/umdo/surrogate/plot_surrogate/","title":"A quadratic mono-disciplinary problem","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/surrogate/plot_surrogate/#a-quadratic-mono-disciplinary-problem","title":"A quadratic mono-disciplinary problem","text":"<p>In this example, we consider the quadratic mono-disciplinary optimization problem</p> \\[\\min_{x\\in[-1,1]} \\mathbb{E}[(x+U)^2]\\] <p>where \\(U\\sim\\mathcal{N}(0,1)\\) is a standard Gaussian variable and \\(\\mathbb{E}\\) is the expectation operator.</p> <p>The objective can be rewritten as \\(x^2+1\\) and then the solution is obvious, namely</p> \\[(x^*,\\mathbb{E}[(x^*+U)^2])=(0,1).\\] <p>In the following, we will call \\(f\\) the function computing \\((x+U)^2\\) given \\(x\\) and \\(U\\).</p> <pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nconfigure_logger()\n</code></pre> <p>Out:</p> <pre><code>&lt;RootLogger root (INFO)&gt;\n</code></pre> <p>Firstly, we define an AnalyticDiscipline implementing the function \\(f\\):</p> <pre><code>discipline = AnalyticDiscipline({\"y\": \"(x+u)**2\"}, name=\"f\")\n</code></pre> <p>as well as the design space:</p> <pre><code>design_space = DesignSpace()\ndesign_space.add_variable(\"x\", lower_bound=-1, upper_bound=1.0, value=0.5)\n</code></pre> <p>and the uncertain space:</p> <pre><code>uncertain_space = ParameterSpace()\nuncertain_space.add_random_variable(\"u\", \"OTNormalDistribution\")\n</code></pre> <p>Out:</p> <pre><code>/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/pydantic/main.py:209: DeprecationWarning: Conversion of an array with ndim &gt; 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n</code></pre> <p>Then, we define a UMDOScenario to minimize the statistic \\(\\mathbb{E}[(x+U)^2]\\) estimated by sampling a surrogate model trained from 20 samples at each iteration of the optimization loop:</p> <pre><code>scenario = UMDOScenario(\n    [discipline],\n    \"y\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    formulation_name=\"DisciplinaryOpt\",\n    statistic_estimation=\"Surrogate\",\n    statistic_estimation_parameters={\"doe_n_samples\": 20},\n)\n</code></pre> <p>We execute this scenario using the gradient-free optimizer COBYLA:</p> <pre><code>scenario.execute(algo_name=\"NLOPT_COBYLA\", max_iter=100)\n</code></pre> <p>Out:</p> <pre><code>    INFO - 10:51:49:  \n    INFO - 10:51:49: *** Start UMDOScenario execution ***\n    INFO - 10:51:49: UMDOScenario\n    INFO - 10:51:49:    Disciplines: f\n    INFO - 10:51:49:    Formulation:\n    INFO - 10:51:49:       MDO formulation: DisciplinaryOpt\n    INFO - 10:51:49:       Statistic estimation: Surrogate\n    INFO - 10:51:49:    Uncertain space:\n    INFO - 10:51:49:       +------+---------------------------+\n    INFO - 10:51:49:       | Name |        Distribution       |\n    INFO - 10:51:49:       +------+---------------------------+\n    INFO - 10:51:49:       |  u   | Normal(mu=0.0, sigma=1.0) |\n    INFO - 10:51:49:       +------+---------------------------+\n    INFO - 10:51:49: Optimization problem:\n    INFO - 10:51:49:    minimize E[y]\n    INFO - 10:51:49:    with respect to x\n    INFO - 10:51:49:    over the design space:\n    INFO - 10:51:49:       +------+-------------+-------+-------------+-------+\n    INFO - 10:51:49:       | Name | Lower bound | Value | Upper bound | Type  |\n    INFO - 10:51:49:       +------+-------------+-------+-------------+-------+\n    INFO - 10:51:49:       | x    |      -1     |  0.5  |      1      | float |\n    INFO - 10:51:49:       +------+-------------+-------+-------------+-------+\n    INFO - 10:51:49: Solving optimization problem with algorithm NLOPT_COBYLA:\n    INFO - 10:51:49:         R2Measure\n    INFO - 10:51:49:             y[0]: 1.0&gt;=0.9 (train) - 0.9217777493097341&gt;=0.8 (test)\n    INFO - 10:51:49:      1%|          | 1/100 [00:00&lt;00:23,  4.15 it/sec, obj=1.22]\n    INFO - 10:51:49:         R2Measure\n    INFO - 10:51:49:             y[0]: 1.0&gt;=0.9 (train) - 0.9397200205696712&gt;=0.8 (test)\n    INFO - 10:51:49:      2%|\u258f         | 2/100 [00:00&lt;00:14,  6.93 it/sec, obj=1.97]\n    INFO - 10:51:49:         R2Measure\n    INFO - 10:51:49:             y[0]: 1.0&gt;=0.9 (train) - 0.9200667047682353&gt;=0.8 (test)\n    INFO - 10:51:49:      3%|\u258e         | 3/100 [00:00&lt;00:10,  9.01 it/sec, obj=0.971]\n    INFO - 10:51:49:         R2Measure\n    INFO - 10:51:49:             y[0]: 1.0&gt;=0.9 (train) - 0.9576853196908376&gt;=0.8 (test)\n    INFO - 10:51:49:      4%|\u258d         | 4/100 [00:00&lt;00:09, 10.60 it/sec, obj=1.22]\n    INFO - 10:51:49:         R2Measure\n    INFO - 10:51:50:             y[0]: 1.0&gt;=0.9 (train) - 0.9392935047078771&gt;=0.8 (test)\n    INFO - 10:51:50:      5%|\u258c         | 5/100 [00:00&lt;00:08, 11.85 it/sec, obj=1.03]\n    INFO - 10:51:50:         R2Measure\n    INFO - 10:51:50:             y[0]: 1.0&gt;=0.9 (train) - 0.9151534540405701&gt;=0.8 (test)\n    INFO - 10:51:50:      6%|\u258c         | 6/100 [00:00&lt;00:07, 12.84 it/sec, obj=0.986]\n    INFO - 10:51:50:         R2Measure\n    INFO - 10:51:50:             y[0]: 1.0&gt;=0.9 (train) - 0.9240577719857522&gt;=0.8 (test)\n    INFO - 10:51:50:      7%|\u258b         | 7/100 [00:00&lt;00:06, 13.58 it/sec, obj=0.975]\n    INFO - 10:51:50:         R2Measure\n    INFO - 10:51:50:             y[0]: 1.0&gt;=0.9 (train) - 0.9184279653726527&gt;=0.8 (test)\n    INFO - 10:51:50:      8%|\u258a         | 8/100 [00:00&lt;00:06, 14.29 it/sec, obj=0.972]\n    INFO - 10:51:50:         R2Measure\n    INFO - 10:51:50:             y[0]: 1.0&gt;=0.9 (train) - 0.9209801782618341&gt;=0.8 (test)\n    INFO - 10:51:50:      9%|\u2589         | 9/100 [00:00&lt;00:06, 14.88 it/sec, obj=0.971]\n    INFO - 10:51:50:         R2Measure\n    INFO - 10:51:50:             y[0]: 1.0&gt;=0.9 (train) - 0.9196329699289312&gt;=0.8 (test)\n    INFO - 10:51:50:     10%|\u2588         | 10/100 [00:00&lt;00:05, 15.39 it/sec, obj=0.971]\n    INFO - 10:51:50:         R2Measure\n    INFO - 10:51:50:             y[0]: 1.0&gt;=0.9 (train) - 0.9202893940998883&gt;=0.8 (test)\n    INFO - 10:51:50:     11%|\u2588         | 11/100 [00:00&lt;00:05, 15.77 it/sec, obj=0.971]\n    INFO - 10:51:50:         R2Measure\n    INFO - 10:51:50:             y[0]: 1.0&gt;=0.9 (train) - 0.919956807011983&gt;=0.8 (test)\n    INFO - 10:51:50:     12%|\u2588\u258f        | 12/100 [00:00&lt;00:05, 16.10 it/sec, obj=0.971]\n    INFO - 10:51:50:         R2Measure\n    INFO - 10:51:50:             y[0]: 1.0&gt;=0.9 (train) - 0.9201220164676971&gt;=0.8 (test)\n    INFO - 10:51:50:     13%|\u2588\u258e        | 13/100 [00:00&lt;00:05, 16.36 it/sec, obj=0.971]\n    INFO - 10:51:50:         R2Measure\n    INFO - 10:51:50:             y[0]: 1.0&gt;=0.9 (train) - 0.9200391394885165&gt;=0.8 (test)\n    INFO - 10:51:50:     14%|\u2588\u258d        | 14/100 [00:00&lt;00:05, 16.66 it/sec, obj=0.971]\n    INFO - 10:51:50:         R2Measure\n    INFO - 10:51:50:             y[0]: 1.0&gt;=0.9 (train) - 0.9200116347093735&gt;=0.8 (test)\n    INFO - 10:51:50:     15%|\u2588\u258c        | 15/100 [00:00&lt;00:05, 16.93 it/sec, obj=0.971]\n    INFO - 10:51:50:         R2Measure\n    INFO - 10:51:50:             y[0]: 1.0&gt;=0.9 (train) - 0.9199841905207045&gt;=0.8 (test)\n    INFO - 10:51:50:     16%|\u2588\u258c        | 16/100 [00:00&lt;00:04, 17.18 it/sec, obj=0.971]\n    INFO - 10:51:50:         R2Measure\n    INFO - 10:51:50:             y[0]: 1.0&gt;=0.9 (train) - 0.9199979050356278&gt;=0.8 (test)\n    INFO - 10:51:50:     17%|\u2588\u258b        | 17/100 [00:00&lt;00:04, 17.42 it/sec, obj=0.971]\n    INFO - 10:51:50:         R2Measure\n    INFO - 10:51:50:             y[0]: 1.0&gt;=0.9 (train) - 0.9200185052273065&gt;=0.8 (test)\n    INFO - 10:51:50:     18%|\u2588\u258a        | 18/100 [00:01&lt;00:04, 17.64 it/sec, obj=0.971]\n    INFO - 10:51:50:         R2Measure\n    INFO - 10:51:50:             y[0]: 1.0&gt;=0.9 (train) - 0.9200253795307446&gt;=0.8 (test)\n    INFO - 10:51:50:     19%|\u2588\u2589        | 19/100 [00:01&lt;00:04, 17.83 it/sec, obj=0.971]\n    INFO - 10:51:50: Optimization result:\n    INFO - 10:51:50:    Optimizer info:\n    INFO - 10:51:50:       Status: None\n    INFO - 10:51:50:       Message: Successive iterates of the objective function are closer than ftol_rel or ftol_abs. GEMSEO stopped the driver.\n    INFO - 10:51:50:       Number of calls to the objective function by the optimizer: 20\n    INFO - 10:51:50:    Solution:\n    INFO - 10:51:50:       Objective: 0.9706618824138679\n    INFO - 10:51:50:       Design space:\n    INFO - 10:51:50:          +------+-------------+-----------------+-------------+-------+\n    INFO - 10:51:50:          | Name | Lower bound |      Value      | Upper bound | Type  |\n    INFO - 10:51:50:          +------+-------------+-----------------+-------------+-------+\n    INFO - 10:51:50:          | x    |      -1     | 0.0008544921875 |      1      | float |\n    INFO - 10:51:50:          +------+-------------+-----------------+-------------+-------+\n    INFO - 10:51:50: *** End UMDOScenario execution (time: 0:00:01.069246) ***\n</code></pre> <p>and plot the optimization history:</p> <pre><code>scenario.post_process(post_name=\"OptHistoryView\", save=False, show=True)\n</code></pre> <p>Out:</p> <pre><code>&lt;gemseo.post.opt_history_view.OptHistoryView object at 0x78c11c95d940&gt;\n</code></pre> <p>Notice that the numerical solution</p> <pre><code>(scenario.optimization_result.x_opt[0], scenario.optimization_result.f_opt)\n</code></pre> <p>Out:</p> <pre><code>(0.0008544921875, 0.9706618824138679)\n</code></pre> <p>is close to the theoretical solution \\((x^*,\\mathbb{E}[(x^*+U)^2])=(0,1)\\).</p> <p>Total running time of the script: ( 0 minutes  1.617 seconds)</p> <p> Download Python source code: plot_surrogate.py</p> <p> Download Jupyter notebook: plot_surrogate.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/taylor_polynomial/mg_execution_times/","title":"Computation times","text":"<p>00:00.615 total execution time for generated_examples_umdo_taylor_polynomial files:</p> <p>+---------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_tp_quadratic (docs/examples/umdo/taylor_polynomial/plot_tp_quadratic.py) | 00:00.615 | 0.0 MB | +---------------------------------------------------------------------------------------------------------+-----------+--------+ | tp_sellar (docs/examples/umdo/taylor_polynomial/tp_sellar.py)                         | 00:00.000 | 0.0 MB | +---------------------------------------------------------------------------------------------------------+-----------+--------+ | tp_sobieski (docs/examples/umdo/taylor_polynomial/tp_sobieski.py)                   | 00:00.000 | 0.0 MB | +---------------------------------------------------------------------------------------------------------+-----------+--------+</p>"},{"location":"generated/examples/umdo/taylor_polynomial/plot_tp_quadratic/","title":"A quadratic mono-disciplinary problem","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/taylor_polynomial/plot_tp_quadratic/#a-quadratic-mono-disciplinary-problem","title":"A quadratic mono-disciplinary problem","text":"<p>In this example, we consider the quadratic mono-disciplinary optimization problem</p> \\[\\min_{x\\in[-1,1]} \\mathbb{E}[(x+U)^2]\\] <p>where \\(U\\sim\\mathcal{N}(0,1)\\) is a standard Gaussian variable and \\(\\mathbb{E}\\) is the expectation operator.</p> <p>The objective can be rewritten as \\(x^2+1\\) and then the solution is obvious, namely</p> \\[(x^*,\\mathbb{E}[(x^*+U)^2])=(0,1).\\] <p>In the following, we will call \\(f\\) the function computing \\((x+U)^2\\) given \\(x\\) and \\(U\\).</p> <pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nconfigure_logger()\n</code></pre> <p>Out:</p> <pre><code>&lt;RootLogger root (INFO)&gt;\n</code></pre> <p>Firstly, we define an AnalyticDiscipline implementing the function \\(f\\):</p> <pre><code>discipline = AnalyticDiscipline({\"y\": \"(x+u)**2\"}, name=\"f\")\n</code></pre> <p>as well as the design space:</p> <pre><code>design_space = DesignSpace()\ndesign_space.add_variable(\"x\", lower_bound=-1, upper_bound=1.0, value=0.5)\n</code></pre> <p>and the uncertain space:</p> <pre><code>uncertain_space = ParameterSpace()\nuncertain_space.add_random_variable(\"u\", \"OTNormalDistribution\")\n</code></pre> <p>Out:</p> <pre><code>/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/pydantic/main.py:209: DeprecationWarning: Conversion of an array with ndim &gt; 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n</code></pre> <p>Then, we define a UMDOScenario to minimize the statistic \\(\\mathbb{E}[(x+U)^2]\\) estimated using a first-order Taylor polynomial of \\(f\\) at \\(\\mathbb{E}[U]=0\\) at each iteration of the optimization loop:</p> <pre><code>scenario = UMDOScenario(\n    [discipline],\n    \"y\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    formulation_name=\"DisciplinaryOpt\",\n    statistic_estimation=\"TaylorPolynomial\",\n)\n</code></pre> <p>Out:</p> <pre><code>/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/pydantic/main.py:209: DeprecationWarning: Conversion of an array with ndim &gt; 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n</code></pre> <p>We execute this scenario using the gradient-free optimizer COBYLA:</p> <pre><code>scenario.execute(algo_name=\"NLOPT_COBYLA\", max_iter=100)\n</code></pre> <p>Out:</p> <pre><code>    INFO - 10:51:51:  \n    INFO - 10:51:51: *** Start UMDOScenario execution ***\n    INFO - 10:51:51: UMDOScenario\n    INFO - 10:51:51:    Disciplines: f\n    INFO - 10:51:51:    Formulation:\n    INFO - 10:51:51:       MDO formulation: DisciplinaryOpt\n    INFO - 10:51:51:       Statistic estimation: TaylorPolynomial\n    INFO - 10:51:51:    Uncertain space:\n    INFO - 10:51:51:       +------+---------------------------+\n    INFO - 10:51:51:       | Name |        Distribution       |\n    INFO - 10:51:51:       +------+---------------------------+\n    INFO - 10:51:51:       |  u   | Normal(mu=0.0, sigma=1.0) |\n    INFO - 10:51:51:       +------+---------------------------+\n    INFO - 10:51:51: Optimization problem:\n    INFO - 10:51:51:    minimize E[y]\n    INFO - 10:51:51:    with respect to x\n    INFO - 10:51:51:    over the design space:\n    INFO - 10:51:51:       +------+-------------+-------+-------------+-------+\n    INFO - 10:51:51:       | Name | Lower bound | Value | Upper bound | Type  |\n    INFO - 10:51:51:       +------+-------------+-------+-------------+-------+\n    INFO - 10:51:51:       | x    |      -1     |  0.5  |      1      | float |\n    INFO - 10:51:51:       +------+-------------+-------+-------------+-------+\n    INFO - 10:51:51: Solving optimization problem with algorithm NLOPT_COBYLA:\n    INFO - 10:51:51:      1%|          | 1/100 [00:00&lt;00:00, 385.83 it/sec, obj=0.25]\n    INFO - 10:51:51:      2%|\u258f         | 2/100 [00:00&lt;00:00, 541.31 it/sec, obj=1]\n    INFO - 10:51:51:      3%|\u258e         | 3/100 [00:00&lt;00:00, 441.91 it/sec, obj=0]\n    INFO - 10:51:51:      4%|\u258d         | 4/100 [00:00&lt;00:00, 490.28 it/sec, obj=0.25]\n    INFO - 10:51:51:      5%|\u258c         | 5/100 [00:00&lt;00:00, 535.48 it/sec, obj=0.0625]\n    INFO - 10:51:51:      6%|\u258c         | 6/100 [00:00&lt;00:00, 559.51 it/sec, obj=0.0156]\n    INFO - 10:51:51:      7%|\u258b         | 7/100 [00:00&lt;00:00, 592.58 it/sec, obj=0.00391]\n    INFO - 10:51:51:      8%|\u258a         | 8/100 [00:00&lt;00:00, 623.18 it/sec, obj=0.000977]\n    INFO - 10:51:51:      9%|\u2589         | 9/100 [00:00&lt;00:00, 649.45 it/sec, obj=0.000244]\n    INFO - 10:51:51:     10%|\u2588         | 10/100 [00:00&lt;00:00, 673.77 it/sec, obj=6.1e-5]\n    INFO - 10:51:51:     11%|\u2588         | 11/100 [00:00&lt;00:00, 694.58 it/sec, obj=1.53e-5]\n    INFO - 10:51:51:     12%|\u2588\u258f        | 12/100 [00:00&lt;00:00, 713.47 it/sec, obj=3.81e-6]\n    INFO - 10:51:51:     13%|\u2588\u258e        | 13/100 [00:00&lt;00:00, 730.00 it/sec, obj=9.54e-7]\n    INFO - 10:51:51:     14%|\u2588\u258d        | 14/100 [00:00&lt;00:00, 743.60 it/sec, obj=2.38e-7]\n    INFO - 10:51:51:     15%|\u2588\u258c        | 15/100 [00:00&lt;00:00, 756.62 it/sec, obj=5.96e-8]\n    INFO - 10:51:51:     16%|\u2588\u258c        | 16/100 [00:00&lt;00:00, 769.00 it/sec, obj=1.49e-8]\n    INFO - 10:51:51:     17%|\u2588\u258b        | 17/100 [00:00&lt;00:00, 780.51 it/sec, obj=3.73e-9]\n    INFO - 10:51:51:     18%|\u2588\u258a        | 18/100 [00:00&lt;00:00, 791.57 it/sec, obj=9.31e-10]\n    INFO - 10:51:51:     19%|\u2588\u2589        | 19/100 [00:00&lt;00:00, 800.63 it/sec, obj=2.33e-10]\n    INFO - 10:51:51:     20%|\u2588\u2588        | 20/100 [00:00&lt;00:00, 810.13 it/sec, obj=5.82e-11]\n    INFO - 10:51:51:     21%|\u2588\u2588        | 21/100 [00:00&lt;00:00, 819.02 it/sec, obj=1.46e-11]\n    INFO - 10:51:51:     22%|\u2588\u2588\u258f       | 22/100 [00:00&lt;00:00, 826.12 it/sec, obj=3.64e-12]\n    INFO - 10:51:51:     23%|\u2588\u2588\u258e       | 23/100 [00:00&lt;00:00, 831.21 it/sec, obj=9.09e-13]\n    INFO - 10:51:51:     24%|\u2588\u2588\u258d       | 24/100 [00:00&lt;00:00, 838.29 it/sec, obj=2.27e-13]\n    INFO - 10:51:51:     25%|\u2588\u2588\u258c       | 25/100 [00:00&lt;00:00, 845.21 it/sec, obj=5.68e-14]\n    INFO - 10:51:51:     26%|\u2588\u2588\u258c       | 26/100 [00:00&lt;00:00, 852.13 it/sec, obj=1.42e-14]\n    INFO - 10:51:51:     27%|\u2588\u2588\u258b       | 27/100 [00:00&lt;00:00, 857.89 it/sec, obj=3.55e-15]\n    INFO - 10:51:51: Optimization result:\n    INFO - 10:51:51:    Optimizer info:\n    INFO - 10:51:51:       Status: None\n    INFO - 10:51:51:       Message: Successive iterates of the objective function are closer than ftol_rel or ftol_abs. GEMSEO stopped the driver.\n    INFO - 10:51:51:       Number of calls to the objective function by the optimizer: 28\n    INFO - 10:51:51:    Solution:\n    INFO - 10:51:51:       Objective: 0.0\n    INFO - 10:51:51:       Design space:\n    INFO - 10:51:51:          +------+-------------+-------+-------------+-------+\n    INFO - 10:51:51:          | Name | Lower bound | Value | Upper bound | Type  |\n    INFO - 10:51:51:          +------+-------------+-------+-------------+-------+\n    INFO - 10:51:51:          | x    |      -1     |   0   |      1      | float |\n    INFO - 10:51:51:          +------+-------------+-------+-------------+-------+\n    INFO - 10:51:51: *** End UMDOScenario execution (time: 0:00:00.034590) ***\n</code></pre> <p>and plot the optimization history:</p> <pre><code>scenario.post_process(post_name=\"OptHistoryView\", save=False, show=True)\n</code></pre> <p>Out:</p> <pre><code>&lt;gemseo.post.opt_history_view.OptHistoryView object at 0x78c11c1422e0&gt;\n</code></pre> <p>Notice that the numerical solution</p> <pre><code>(scenario.optimization_result.x_opt[0], scenario.optimization_result.f_opt)\n</code></pre> <p>Out:</p> <pre><code>(0.0, 0.0)\n</code></pre> <p>is far from the theoretical solution \\((x^*,\\mathbb{E}[(x^*+U)^2])=(0,1)\\) in terms of objective value, as the objective function is far from being quadratic with respect to \\(U\\). However, we can see that the optimum design value is equal to the theoretical one.</p> <p>On the other hand, we can use a second-order Taylor polynomial</p> <pre><code>scenario = UMDOScenario(\n    [discipline],\n    \"y\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    formulation_name=\"DisciplinaryOpt\",\n    statistic_estimation=\"TaylorPolynomial\",\n    statistic_estimation_parameters={\"second_order\": True},\n)\nscenario.execute(algo_name=\"NLOPT_COBYLA\", max_iter=100)\n</code></pre> <p>Out:</p> <pre><code>/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/pydantic/main.py:209: DeprecationWarning: Conversion of an array with ndim &gt; 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n    INFO - 10:51:51:  \n    INFO - 10:51:51: *** Start UMDOScenario execution ***\n    INFO - 10:51:51: UMDOScenario\n    INFO - 10:51:51:    Disciplines: f\n    INFO - 10:51:51:    Formulation:\n    INFO - 10:51:51:       MDO formulation: DisciplinaryOpt\n    INFO - 10:51:51:       Statistic estimation: TaylorPolynomial\n    INFO - 10:51:51:    Uncertain space:\n    INFO - 10:51:51:       +------+---------------------------+\n    INFO - 10:51:51:       | Name |        Distribution       |\n    INFO - 10:51:51:       +------+---------------------------+\n    INFO - 10:51:51:       |  u   | Normal(mu=0.0, sigma=1.0) |\n    INFO - 10:51:51:       +------+---------------------------+\n    INFO - 10:51:51: Optimization problem:\n    INFO - 10:51:51:    minimize E[y]\n    INFO - 10:51:51:    with respect to x\n    INFO - 10:51:51:    over the design space:\n    INFO - 10:51:51:       +------+-------------+-------+-------------+-------+\n    INFO - 10:51:51:       | Name | Lower bound | Value | Upper bound | Type  |\n    INFO - 10:51:51:       +------+-------------+-------+-------------+-------+\n    INFO - 10:51:51:       | x    |      -1     |   0   |      1      | float |\n    INFO - 10:51:51:       +------+-------------+-------+-------------+-------+\n    INFO - 10:51:51: Solving optimization problem with algorithm NLOPT_COBYLA:\n    INFO - 10:51:51:      1%|          | 1/100 [00:00&lt;00:00, 537.11 it/sec, obj=1]\n    INFO - 10:51:51:      2%|\u258f         | 2/100 [00:00&lt;00:00, 616.18 it/sec, obj=1.25]\n    INFO - 10:51:51:      3%|\u258e         | 3/100 [00:00&lt;00:00, 626.33 it/sec, obj=1.25]\n    INFO - 10:51:51: Optimization result:\n    INFO - 10:51:51:    Optimizer info:\n    INFO - 10:51:51:       Status: None\n    INFO - 10:51:51:       Message: Successive iterates of the objective function are closer than ftol_rel or ftol_abs. GEMSEO stopped the driver.\n    INFO - 10:51:51:       Number of calls to the objective function by the optimizer: 4\n    INFO - 10:51:51:    Solution:\n    INFO - 10:51:51:       Objective: 1.0\n    INFO - 10:51:51:       Design space:\n    INFO - 10:51:51:          +------+-------------+-------+-------------+-------+\n    INFO - 10:51:51:          | Name | Lower bound | Value | Upper bound | Type  |\n    INFO - 10:51:51:          +------+-------------+-------+-------------+-------+\n    INFO - 10:51:51:          | x    |      -1     |   0   |      1      | float |\n    INFO - 10:51:51:          +------+-------------+-------+-------------+-------+\n    INFO - 10:51:51: *** End UMDOScenario execution (time: 0:00:00.007431) ***\n</code></pre> <p>and see that it gives the exact solution:</p> <pre><code>(scenario.optimization_result.x_opt[0], scenario.optimization_result.f_opt)\n</code></pre> <p>Out:</p> <pre><code>(0.0, 1.0)\n</code></pre> <p>which is quite logical in this simple example since the function \\(f\\) is quadratic with respect to \\(U\\).</p> <p>Total running time of the script: ( 0 minutes  0.615 seconds)</p> <p> Download Python source code: plot_tp_quadratic.py</p> <p> Download Jupyter notebook: plot_tp_quadratic.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/taylor_polynomial/tp_sellar/","title":"The Sellar's MDO problem","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/taylor_polynomial/tp_sellar/#the-sellars-mdo-problem","title":"The Sellar's MDO problem","text":"<p>In this example, we consider the Sellar's MDO problem under uncertainty</p> \\[\\min_{x,z_1,x_2} \\mathbb{E}[f(x,z_2,y_1,y_2)]\\] <p>over the design space \\([0,10]\\times[-10,10]\\times[0,10]\\) and under the inequality constraints</p> \\[\\mathbb{E}[c_1(y_1)]+3\\mathbb{S}[c_1(y_1)] \\leq 0\\] <p>and</p> \\[\\mathbb{E}[c_2(y_2)]+3\\mathbb{S}[c_2(y_2)] \\leq 0,\\] <p>where</p> <ul> <li>\\(\\mathbb{E}\\) is the expectation operator,</li> <li>\\(\\mathbb{S}\\) is the standard deviation operators,</li> <li>\\(f(x,z_2) = x^2 + z_2 + y_1^2 + \\exp(-y_2)\\) is the objective function,</li> <li>\\(c_1(y_1) = 3.16 - y_1^2\\) is the first constraint function,</li> <li>\\(c_2(y_2) = y_2 - 24.0\\) is the second constraint function,</li> <li>\\(y_1 = \\sqrt{z_1^2 + z_2 + x - ay_2}\\) is the first coupling equation,</li> <li>\\(y_2 = \\frac{\\log(1+\\exp(10y_1))}{5} - y_1 - \\frac{\\log(2)}{5} + z_1 + z_2\\)   is the second coupling equation,</li> <li>\\(a\\) is a random variable distributed   according to the triangular distribution \\(\\mathcal{T}(0.1,0.2,0.3)\\).</li> </ul> <pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nconfigure_logger()\n</code></pre> <p>Firstly, we create one discipline per couping equation and a system discipline to compute the objective and constraints:</p> <pre><code>system = AnalyticDiscipline({\n    \"obj\": \"x**2 + z2 + y1**2 + exp(-y2)\",\n    \"c1\": \"3.16 - y1 ** 2\",\n    \"c2\": \"y2 - 24.0\",\n})\ndisc1 = AnalyticDiscipline({\"y1\": \"(z1**2 + z2 + x - a*y2)**0.5\"})\ndisc2 = AnalyticDiscipline({\"y2\": \"2/10*log(1+exp(10*y1))-y1-2/10*log(2) + z1 + z2\"})\n</code></pre> <p>as well as the design space:</p> <pre><code>design_space = DesignSpace()\ndesign_space.add_variable(\"x\", 1, lower_bound=0.0, upper_bound=10.0, value=1.0)\ndesign_space.add_variable(\"z1\", 1, lower_bound=-10.0, upper_bound=10.0, value=4.0)\ndesign_space.add_variable(\"z2\", 1, lower_bound=0.0, upper_bound=10.0, value=3.0)\n</code></pre> <p>Secondly, we define the uncertain space:</p> <pre><code>uncertain_space = ParameterSpace()\n</code></pre> <p>with an uncertainty over the constant <code>\"a\"</code>:</p> <pre><code>uncertain_space.add_random_variable(\n    \"a\", \"OTTriangularDistribution\", minimum=0.1, maximum=0.3, mode=0.2\n)\n</code></pre> <p>Then, we define a UMDOScenario to minimize the statistic \\(\\mathbb{E}[f(x,z_2,y_1,y_2)]\\) estimated using a first-order Taylor polynomial of \\(f\\) at \\(\\mathbb{E}[a]=0.2\\) at each iteration of the optimization loop:</p> <pre><code>scenario = UMDOScenario(\n    [system, disc1, disc2],\n    \"obj\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    formulation_name=\"MDF\",\n    statistic_estimation=\"TaylorPolynomial\",\n)\n</code></pre> <p>while satisfying the constraints \\(\\mathbb{E}[c_1(y_1)]+3\\mathbb{S}[c_1(y_1)] \\leq 0\\) and \\(\\mathbb{E}[c_2(y_2)]+3\\mathbb{S}[c_2(y_2)] \\leq 0\\):</p> <pre><code>scenario.add_constraint(\"c1\", \"Margin\", factor=3.0)\nscenario.add_constraint(\"c2\", \"Margin\", factor=3.0)\n</code></pre> <p>We execute this scenario using the gradient-free optimizer COBYLA:</p> <pre><code>scenario.execute(algo_name=\"NLOPT_COBYLA\", max_iter=200)\n</code></pre> <p>and plot the optimization history:</p> <pre><code>scenario.post_process(post_name=\"OptHistoryView\", save=False, show=True)\n</code></pre> <p>Lastly, we can compare the numerical solution of this Sellar's MDO problem under uncertainty</p> <pre><code>result = scenario.optimization_result\n(result.x_opt, result.constraint_values, result.f_opt)\n</code></pre> <p>to the solution of the Sellar's MDO problem without uncertainty, namely \\((x^*,c^*,f^*)=([0, 1.77, 0], [0, -20.58], 3.19)\\).</p> <p>Total running time of the script: ( 0 minutes  0.000 seconds)</p> <p> Download Python source code: tp_sellar.py</p> <p> Download Jupyter notebook: tp_sellar.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/umdo/taylor_polynomial/tp_sobieski/","title":"The Sobieski's SSBJ MDO problem","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/umdo/taylor_polynomial/tp_sobieski/#the-sobieskis-ssbj-mdo-problem","title":"The Sobieski's SSBJ MDO problem","text":"<pre><code>from __future__ import annotations\n\nfrom gemseo import configure_logger\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.problems.mdo.sobieski.core.problem import SobieskiProblem\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiAerodynamics\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiMission\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiPropulsion\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiStructure\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nconfigure_logger()\n</code></pre> <p>Firstly, we instantiate the discipline of Sobieski's SSBJ problem:</p> <pre><code>mission = SobieskiMission()\nstructure = SobieskiStructure()\npropulsion = SobieskiPropulsion()\naerodynamics = SobieskiAerodynamics()\n</code></pre> <p>as well as the design space:</p> <pre><code>design_space = SobieskiProblem().design_space\n</code></pre> <p>Secondly, we define the uncertain space:</p> <pre><code>uncertain_space = ParameterSpace()\n</code></pre> <p>with an uncertainty over the constant <code>\"c_4\"</code>:</p> <pre><code>uncertain_space.add_random_variable(\n    \"c_4\", \"OTNormalDistribution\", mu=0.01375, sigma=0.01375 * 0.05\n)\n</code></pre> <p>and an uncertainty over the design variable <code>\"x_2\"</code>, expressed as an additive term <code>\"u_x_2\"</code> defined just after in the UMDOScenario:</p> <pre><code>uncertain_space.add_random_variable(\n    \"u_x_2\", \"OTNormalDistribution\", mu=0.0, sigma=1 * 0.05\n)\n</code></pre> <p>Then, we build an UMDOScenario to maximize a first-order linearization-based estimation (default estimation method) of the expectation \\(\\mathbb{E}[y_4]\\):</p> <pre><code>scenario = UMDOScenario(\n    [mission, structure, propulsion, aerodynamics],\n    \"y_4\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    formulation_name=\"MDF\",\n    statistic_estimation=\"TaylorPolynomial\",\n    # statistic_estimation_parameters={\"second_order\": True},\n    maximize_objective=True,\n    uncertain_design_variables={\"x_2\": \"{}+u_x_2\"},\n)\n</code></pre> <p>while satisfying margin constraints of the form \\(\\mathbb{E}[g_i]+3\\mathbb{S}[g_i]\\)</p> <pre><code>scenario.add_constraint(\"g_1\", \"Margin\", factor=3.0)\nscenario.add_constraint(\"g_2\", \"Margin\", factor=3.0)\nscenario.add_constraint(\"g_3\", \"Margin\", factor=3.0)\n</code></pre> <p>and execute it with a gradient-free optimizer:</p> <pre><code>scenario.execute(algo_name=\"NLOPT_COBYLA\", max_iter=100)\n</code></pre> <p>Lastly, we can plot the optimization history view:</p> <pre><code>scenario.post_process(post_name=\"OptHistoryView\", save=False, show=True)\n</code></pre> <p>Total running time of the script: ( 0 minutes  0.000 seconds)</p> <p> Download Python source code: tp_sobieski.py</p> <p> Download Jupyter notebook: tp_sobieski.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/visualizations/","title":"Visualization","text":""},{"location":"generated/examples/visualizations/#data-visualization","title":"Data visualization","text":""},{"location":"generated/examples/visualizations/#sobol-graph","title":"Sobol' graph","text":"<p> Sobol' graph for the Sellar use case. </p> <p> Sobol' graph for the Ishigami use case. </p> <p> Sobol' graph for the Sobieski's SSBJ use case. </p>"},{"location":"generated/examples/visualizations/#uncertain-coupling-graph","title":"Uncertain coupling graph","text":"<p> The uncertain coupling graph for the Sobieski's SSBJ use case. </p> <p> Download all examples in Python source code: visualizations_python.zip</p> <p> Download all examples in Jupyter notebooks: visualizations_jupyter.zip</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/visualizations/sobol_graph/mg_execution_times/","title":"Computation times","text":"<p>00:04.221 total execution time for generated_examples_visualizations_sobol_graph files:</p> <p>+-------------------------------------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_sobieski_sobol_graph (docs/examples/visualizations/sobol_graph/plot_sobieski_sobol_graph.py) | 00:03.597 | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_sellar_sobol_graph (docs/examples/visualizations/sobol_graph/plot_sellar_sobol_graph.py)       | 00:00.594 | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_ishigami_sobol_graph (docs/examples/visualizations/sobol_graph/plot_ishigami_sobol_graph.py) | 00:00.030 | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------------+-----------+--------+</p>"},{"location":"generated/examples/visualizations/sobol_graph/plot_ishigami_sobol_graph/","title":"Sobol' graph for the Ishigami use case.","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/visualizations/sobol_graph/plot_ishigami_sobol_graph/#sobol-graph-for-the-ishigami-use-case","title":"Sobol' graph for the Ishigami use case.","text":"<pre><code>from __future__ import annotations\n\nfrom gemseo.problems.uncertainty.ishigami.statistics import SOBOL_1\nfrom gemseo.problems.uncertainty.ishigami.statistics import SOBOL_2\nfrom gemseo.problems.uncertainty.ishigami.statistics import SOBOL_3\nfrom gemseo.problems.uncertainty.ishigami.statistics import SOBOL_12\nfrom gemseo.problems.uncertainty.ishigami.statistics import SOBOL_13\nfrom gemseo.problems.uncertainty.ishigami.statistics import SOBOL_23\nfrom gemseo.problems.uncertainty.ishigami.statistics import TOTAL_SOBOL_1\nfrom gemseo.problems.uncertainty.ishigami.statistics import TOTAL_SOBOL_2\nfrom gemseo.problems.uncertainty.ishigami.statistics import TOTAL_SOBOL_3\n\nfrom gemseo_umdo.visualizations.sobol_graph import SobolGraph\n</code></pre> <p>First, we define the first-, second- and total-order Sobol' indices of the different uncertain variables:</p> <pre><code>first_order_indices = {\"X1\": SOBOL_1, \"X2\": SOBOL_2, \"X3\": SOBOL_3}\ntotal_order_indices = {\"X1\": TOTAL_SOBOL_1, \"X2\": TOTAL_SOBOL_2, \"X3\": TOTAL_SOBOL_3}\nsecond_order_indices = {\n    (\"X1\", \"X2\"): SOBOL_12,\n    (\"X1\", \"X3\"): SOBOL_13,\n    (\"X2\", \"X3\"): SOBOL_23,\n}\n</code></pre> <p>Then, we draw the Sobol' graph:</p> <pre><code>sobol_graph = SobolGraph(\n    first_order_indices,\n    second_order_indices=second_order_indices,\n    total_order_indices=total_order_indices,\n)\nsobol_graph\n</code></pre> X1     (56, 31) X1 (56, 31) X3     (24, 0) X3 (24, 0) X1     (56, 31)-&gt;X3     (24, 0) X2     (44, 44) X2 (44, 44) <p>Sphinx Gallery and Jupyter Notebook can display <code>sobol_graph</code> in the web browser. You can also use <code>sobol_graph.visualize()</code> to save it on the disk or display it with a dedicated program.</p> <p>Total running time of the script: ( 0 minutes  0.030 seconds)</p> <p> Download Python source code: plot_ishigami_sobol_graph.py</p> <p> Download Jupyter notebook: plot_ishigami_sobol_graph.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/visualizations/sobol_graph/plot_sellar_sobol_graph/","title":"Sobol' graph for the Sellar use case.","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/visualizations/sobol_graph/plot_sellar_sobol_graph/#sobol-graph-for-the-sellar-use-case","title":"Sobol' graph for the Sellar use case.","text":"<pre><code>from __future__ import annotations\n\nfrom gemseo.problems.mdo.sellar.sellar_1 import Sellar1\nfrom gemseo.problems.mdo.sellar.sellar_2 import Sellar2\nfrom gemseo.problems.mdo.sellar.sellar_design_space import SellarDesignSpace\nfrom gemseo.problems.mdo.sellar.sellar_system import SellarSystem\nfrom gemseo.uncertainty.sensitivity.sobol_analysis import SobolAnalysis\n\nfrom gemseo_umdo.visualizations.sobol_graph import SobolGraph\n</code></pre> <p>First, we consider the SellarDesignSpace as the uncertain space, which means that the uncertain variables are the design variables uniformly distributed between their lower and upper bounds:</p> <pre><code>design_space = SellarDesignSpace(dtype=\"float64\")\n</code></pre> <p>Then, we define the disciplines:</p> <pre><code>disciplines = [Sellar1(), Sellar2(), SellarSystem()]\n</code></pre> <p>Thirdly, we compute the Sobol' indices for all the outputs of the MDO problem:</p> <pre><code>sobol_analysis = SobolAnalysis()\nsobol_analysis.compute_samples(disciplines, design_space, 100)\nsobol_analysis.compute_indices()\n</code></pre> <p>Out:</p> <pre><code>SobolAnalysis.SensitivityIndices(first={'c_1': [{'x_1': array([-0.34410788]), 'x_2': array([-0.29843742]), 'x_shared': array([ 1.4609366 , -0.30485751]), 'y_1': array([], dtype=float64), 'y_2': array([], dtype=float64)}], 'c_2': [{'x_1': array([-0.53113253]), 'x_2': array([-0.38770084]), 'x_shared': array([ 0.16102727, -0.23098258]), 'y_1': array([], dtype=float64), 'y_2': array([], dtype=float64)}], 'obj': [{'x_1': array([0.27800538]), 'x_2': array([0.38104748]), 'x_shared': array([ 0.13907665, -0.22035748]), 'y_1': array([], dtype=float64), 'y_2': array([], dtype=float64)}], 'y_1': [{'x_1': array([-0.37913248]), 'x_2': array([-0.31458256]), 'x_shared': array([ 1.55138982, -0.32269607]), 'y_1': array([], dtype=float64), 'y_2': array([], dtype=float64)}], 'y_2': [{'x_1': array([-0.53113253]), 'x_2': array([-0.38770084]), 'x_shared': array([ 0.16102727, -0.23098258]), 'y_1': array([], dtype=float64), 'y_2': array([], dtype=float64)}]}, second={'c_1': [{'x_1': {'x_1': array([[0.]]), 'x_2': array([[0.56701565]]), 'x_shared': array([[0.64222341, 0.56724841]]), 'y_1': array([], shape=(1, 0), dtype=float64), 'y_2': array([], shape=(1, 0), dtype=float64)}, 'x_2': {'x_1': array([[0.56701565]]), 'x_2': array([[0.]]), 'x_shared': array([[0.53308573, 0.55716927]]), 'y_1': array([], shape=(1, 0), dtype=float64), 'y_2': array([], shape=(1, 0), dtype=float64)}, 'x_shared': {'x_1': array([[0.64222341],\n       [0.56724841]]), 'x_2': array([[0.53308573],\n       [0.55716927]]), 'x_shared': array([[0.        , 0.67760025],\n       [0.67760025, 0.        ]]), 'y_1': array([], shape=(2, 0), dtype=float64), 'y_2': array([], shape=(2, 0), dtype=float64)}, 'y_1': {'x_1': array([], shape=(0, 1), dtype=float64), 'x_2': array([], shape=(0, 1), dtype=float64), 'x_shared': array([], shape=(0, 2), dtype=float64), 'y_1': array([], shape=(0, 0), dtype=float64), 'y_2': array([], shape=(0, 0), dtype=float64)}, 'y_2': {'x_1': array([], shape=(0, 1), dtype=float64), 'x_2': array([], shape=(0, 1), dtype=float64), 'x_shared': array([], shape=(0, 2), dtype=float64), 'y_1': array([], shape=(0, 0), dtype=float64), 'y_2': array([], shape=(0, 0), dtype=float64)}}], 'c_2': [{'x_1': {'x_1': array([[0.]]), 'x_2': array([[0.97693332]]), 'x_shared': array([[1.02843539, 0.98166627]]), 'y_1': array([], shape=(1, 0), dtype=float64), 'y_2': array([], shape=(1, 0), dtype=float64)}, 'x_2': {'x_1': array([[0.97693332]]), 'x_2': array([[0.]]), 'x_shared': array([[1.03793979, 0.99780661]]), 'y_1': array([], shape=(1, 0), dtype=float64), 'y_2': array([], shape=(1, 0), dtype=float64)}, 'x_shared': {'x_1': array([[1.02843539],\n       [0.98166627]]), 'x_2': array([[1.03793979],\n       [0.99780661]]), 'x_shared': array([[0.        , 1.17629671],\n       [1.17629671, 0.        ]]), 'y_1': array([], shape=(2, 0), dtype=float64), 'y_2': array([], shape=(2, 0), dtype=float64)}, 'y_1': {'x_1': array([], shape=(0, 1), dtype=float64), 'x_2': array([], shape=(0, 1), dtype=float64), 'x_shared': array([], shape=(0, 2), dtype=float64), 'y_1': array([], shape=(0, 0), dtype=float64), 'y_2': array([], shape=(0, 0), dtype=float64)}, 'y_2': {'x_1': array([], shape=(0, 1), dtype=float64), 'x_2': array([], shape=(0, 1), dtype=float64), 'x_shared': array([], shape=(0, 2), dtype=float64), 'y_1': array([], shape=(0, 0), dtype=float64), 'y_2': array([], shape=(0, 0), dtype=float64)}}], 'obj': [{'x_1': {'x_1': array([[0.]]), 'x_2': array([[0.1349524]]), 'x_shared': array([[-0.18981858,  0.0144984 ]]), 'y_1': array([], shape=(1, 0), dtype=float64), 'y_2': array([], shape=(1, 0), dtype=float64)}, 'x_2': {'x_1': array([[0.1349524]]), 'x_2': array([[0.]]), 'x_shared': array([[-0.21880146,  0.26163531]]), 'y_1': array([], shape=(1, 0), dtype=float64), 'y_2': array([], shape=(1, 0), dtype=float64)}, 'x_shared': {'x_1': array([[-0.18981858],\n       [ 0.0144984 ]]), 'x_2': array([[-0.21880146],\n       [ 0.26163531]]), 'x_shared': array([[0.        , 0.44771454],\n       [0.44771454, 0.        ]]), 'y_1': array([], shape=(2, 0), dtype=float64), 'y_2': array([], shape=(2, 0), dtype=float64)}, 'y_1': {'x_1': array([], shape=(0, 1), dtype=float64), 'x_2': array([], shape=(0, 1), dtype=float64), 'x_shared': array([], shape=(0, 2), dtype=float64), 'y_1': array([], shape=(0, 0), dtype=float64), 'y_2': array([], shape=(0, 0), dtype=float64)}, 'y_2': {'x_1': array([], shape=(0, 1), dtype=float64), 'x_2': array([], shape=(0, 1), dtype=float64), 'x_shared': array([], shape=(0, 2), dtype=float64), 'y_1': array([], shape=(0, 0), dtype=float64), 'y_2': array([], shape=(0, 0), dtype=float64)}}], 'y_1': [{'x_1': {'x_1': array([[0.]]), 'x_2': array([[0.61333702]]), 'x_shared': array([[0.80500281, 0.60420385]]), 'y_1': array([], shape=(1, 0), dtype=float64), 'y_2': array([], shape=(1, 0), dtype=float64)}, 'x_2': {'x_1': array([[0.61333702]]), 'x_2': array([[0.]]), 'x_shared': array([[0.5548233 , 0.59360034]]), 'y_1': array([], shape=(1, 0), dtype=float64), 'y_2': array([], shape=(1, 0), dtype=float64)}, 'x_shared': {'x_1': array([[0.80500281],\n       [0.60420385]]), 'x_2': array([[0.5548233 ],\n       [0.59360034]]), 'x_shared': array([[0.        , 0.59408379],\n       [0.59408379, 0.        ]]), 'y_1': array([], shape=(2, 0), dtype=float64), 'y_2': array([], shape=(2, 0), dtype=float64)}, 'y_1': {'x_1': array([], shape=(0, 1), dtype=float64), 'x_2': array([], shape=(0, 1), dtype=float64), 'x_shared': array([], shape=(0, 2), dtype=float64), 'y_1': array([], shape=(0, 0), dtype=float64), 'y_2': array([], shape=(0, 0), dtype=float64)}, 'y_2': {'x_1': array([], shape=(0, 1), dtype=float64), 'x_2': array([], shape=(0, 1), dtype=float64), 'x_shared': array([], shape=(0, 2), dtype=float64), 'y_1': array([], shape=(0, 0), dtype=float64), 'y_2': array([], shape=(0, 0), dtype=float64)}}], 'y_2': [{'x_1': {'x_1': array([[0.]]), 'x_2': array([[0.97693332]]), 'x_shared': array([[1.02843539, 0.98166627]]), 'y_1': array([], shape=(1, 0), dtype=float64), 'y_2': array([], shape=(1, 0), dtype=float64)}, 'x_2': {'x_1': array([[0.97693332]]), 'x_2': array([[0.]]), 'x_shared': array([[1.03793979, 0.99780661]]), 'y_1': array([], shape=(1, 0), dtype=float64), 'y_2': array([], shape=(1, 0), dtype=float64)}, 'x_shared': {'x_1': array([[1.02843539],\n       [0.98166627]]), 'x_2': array([[1.03793979],\n       [0.99780661]]), 'x_shared': array([[0.        , 1.17629671],\n       [1.17629671, 0.        ]]), 'y_1': array([], shape=(2, 0), dtype=float64), 'y_2': array([], shape=(2, 0), dtype=float64)}, 'y_1': {'x_1': array([], shape=(0, 1), dtype=float64), 'x_2': array([], shape=(0, 1), dtype=float64), 'x_shared': array([], shape=(0, 2), dtype=float64), 'y_1': array([], shape=(0, 0), dtype=float64), 'y_2': array([], shape=(0, 0), dtype=float64)}, 'y_2': {'x_1': array([], shape=(0, 1), dtype=float64), 'x_2': array([], shape=(0, 1), dtype=float64), 'x_shared': array([], shape=(0, 2), dtype=float64), 'y_1': array([], shape=(0, 0), dtype=float64), 'y_2': array([], shape=(0, 0), dtype=float64)}}]}, total={'c_1': [{'x_1': array([-0.06242711]), 'x_2': array([-0.02552407]), 'x_shared': array([1.91531727, 0.0261901 ]), 'y_1': array([], dtype=float64), 'y_2': array([], dtype=float64)}], 'c_2': [{'x_1': array([-0.00958813]), 'x_2': array([0.17352049]), 'x_shared': array([1.10455106, 0.28830073]), 'y_1': array([], dtype=float64), 'y_2': array([], dtype=float64)}], 'obj': [{'x_1': array([0.14342032]), 'x_2': array([0.38962347]), 'x_shared': array([ 0.5997534 , -0.17876174]), 'y_1': array([], dtype=float64), 'y_2': array([], dtype=float64)}], 'y_1': [{'x_1': array([-0.02665882]), 'x_2': array([-0.03806079]), 'x_shared': array([1.93039396, 0.04341187]), 'y_1': array([], dtype=float64), 'y_2': array([], dtype=float64)}], 'y_2': [{'x_1': array([-0.00958813]), 'x_2': array([0.17352049]), 'x_shared': array([1.10455106, 0.28830073]), 'y_1': array([], dtype=float64), 'y_2': array([], dtype=float64)}]})\n</code></pre> <p>Lastly, we draw the Sobol' graph :</p> <pre><code>sobol_graph = SobolGraph.from_analysis(sobol_analysis, output_name=\"obj\")\nsobol_graph\n</code></pre> x_1     (14, 28) x_1 (14, 28) x_2     (39, 38) x_2 (39, 38) x_1     (14, 28)-&gt;x_2     (39, 38) x_shared[1]     (0, 0) x_shared[1] (0, 0) x_2     (39, 38)-&gt;x_shared[1]     (0, 0) x_shared[0]     (60, 14) x_shared[0] (60, 14) x_shared[0]     (60, 14)-&gt;x_shared[1]     (0, 0) <p>Sphinx Gallery and Jupyter Notebook can display <code>sobol_graph</code> in the web browser. You can also use <code>sobol_graph.visualize()</code> to save it on the disk or display it with a dedicated program.</p> <p>Total running time of the script: ( 0 minutes  0.594 seconds)</p> <p> Download Python source code: plot_sellar_sobol_graph.py</p> <p> Download Jupyter notebook: plot_sellar_sobol_graph.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/visualizations/sobol_graph/plot_sobieski_sobol_graph/","title":"Sobol' graph for the Sobieski's SSBJ use case.","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/visualizations/sobol_graph/plot_sobieski_sobol_graph/#sobol-graph-for-the-sobieskis-ssbj-use-case","title":"Sobol' graph for the Sobieski's SSBJ use case.","text":"<pre><code>from __future__ import annotations\n\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.problems.mdo.sobieski.core.problem import SobieskiProblem\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiAerodynamics\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiMission\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiPropulsion\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiStructure\nfrom gemseo.uncertainty.sensitivity.sobol_analysis import SobolAnalysis\nfrom gemseo.utils.data_conversion import split_array_to_dict_of_arrays\n\nfrom gemseo_umdo.visualizations.sobol_graph import SobolGraph\n</code></pre> <p>First, we define an uncertain space around the optimum design:</p> <pre><code>design_space = SobieskiProblem().design_space\ndesign_variable_names = [\"x_1\", \"x_2\", \"x_3\", \"x_shared\"]\ndesign_space.filter(design_variable_names)\noptimum_design = split_array_to_dict_of_arrays(\n    SobieskiProblem().optimum_design,\n    design_space.variable_sizes,\n    design_variable_names,\n)\n\nuncertain_space = DesignSpace()\nfor name, value in optimum_design.items():\n    uncertain_space.add_variable(\n        name,\n        size=value.size,\n        lower_bound=value * 0.95,\n        upper_bound=value * 1.05,\n        value=value,\n    )\n</code></pre> <p>Out:</p> <pre><code>/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/pydantic/main.py:209: DeprecationWarning: Conversion of an array with ndim &gt; 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n</code></pre> <p>Then, we define the disciplines:</p> <pre><code>disciplines = [\n    SobieskiAerodynamics(),\n    SobieskiStructure(),\n    SobieskiPropulsion(),\n    SobieskiMission(),\n]\n</code></pre> <p>Thirdly, we compute the Sobol' indices for all the outputs of the MDO problem:</p> <pre><code>sobol_analysis = SobolAnalysis()\nsobol_analysis.compute_samples(disciplines, uncertain_space, 100)\nsobol_analysis.compute_indices()\n</code></pre> <p>Out:</p> <pre><code>/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/gemseo/problems/mdo/sobieski/core/utils.py:225: DeprecationWarning: Conversion of an array with ndim &gt; 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  ai_coeff[index] = -(f_bound[2] - f_bound[0]) / (2 * mtx_shifted[0, 1])\n\nSobolAnalysis.SensitivityIndices(first={'g_1': [{'x_1': array([ 1.25794269, -0.32644388]), 'x_2': array([-0.05557633]), 'x_3': array([-0.05557633]), 'x_shared': array([12.38277997, -0.05557633, -0.05557633, -1.05536659, -0.05557633,\n        0.69775338])}, {'x_1': array([1.59909832, 0.32261034]), 'x_2': array([0.38144802]), 'x_3': array([0.38144802]), 'x_shared': array([11.47445703,  0.38144802,  0.38144802, -0.97815587,  0.38144802,\n        1.41774286])}, {'x_1': array([1.72521777, 0.59361554]), 'x_2': array([0.55746056]), 'x_3': array([0.55746056]), 'x_shared': array([11.01723805,  0.55746056,  0.55746056, -0.9406981 ,  0.55746056,\n        1.7075232 ])}, {'x_1': array([1.78929737, 0.74015108]), 'x_2': array([0.65100393]), 'x_3': array([0.65100393]), 'x_shared': array([10.75036711,  0.65100393,  0.65100393, -0.91912888,  0.65100393,\n        1.86147795])}, {'x_1': array([1.82775987, 0.83156332]), 'x_2': array([0.70876004]), 'x_3': array([0.70876004]), 'x_shared': array([10.57666774,  0.70876004,  0.70876004, -0.90519019,  0.70876004,\n        1.95651438])}, {'x_1': array([2.14904245, 2.64149302]), 'x_2': array([1.03865101]), 'x_3': array([1.03865101]), 'x_shared': array([ 1.03865101,  1.03865101,  1.03865101, -0.85288882,  1.03865101,\n        2.97117135])}, {'x_1': array([2.14904245, 2.64149302]), 'x_2': array([1.03865101]), 'x_3': array([1.03865101]), 'x_shared': array([ 1.03865101,  1.03865101,  1.03865101, -0.85288882,  1.03865101,\n        2.97117135])}], 'g_2': [{'x_1': array([-1.78397901, -1.78397901]), 'x_2': array([-1.78397901]), 'x_3': array([-1.78397901]), 'x_shared': array([14.06439183, -1.78397901, -1.78397901, -1.78397901, -1.78397901,\n       -1.78397901])}], 'g_3': [{'x_1': array([0.37344871, 0.37341757]), 'x_2': array([0.37074072]), 'x_3': array([0.27642848]), 'x_shared': array([0.43630773, 0.27560325, 0.49427916, 0.37346968, 0.40593033,\n       0.38001693])}, {'x_1': array([0.37344871, 0.37341757]), 'x_2': array([0.37074072]), 'x_3': array([0.27642848]), 'x_shared': array([0.43630773, 0.27560325, 0.49427916, 0.37346968, 0.40593033,\n       0.38001693])}, {'x_1': array([0.15567479, 0.15567479]), 'x_2': array([0.15567479]), 'x_3': array([0.02790736]), 'x_shared': array([0.15567479, 0.22115212, 0.35393535, 0.15567479, 0.15567479,\n       0.15567479])}, {'x_1': array([-0.2723266, -0.2723266]), 'x_2': array([-0.2723266]), 'x_3': array([-0.2723266]), 'x_shared': array([-0.2723266 , -0.2723266 ,  0.36138885, -0.2723266 , -0.2723266 ,\n       -0.2723266 ])}], 'y_1': [{'x_1': array([1.39702333, 1.7601833 ]), 'x_2': array([1.38644236]), 'x_3': array([1.29818376]), 'x_shared': array([1.88540586, 0.99931345, 1.11362047, 1.33119305, 2.13959087,\n       1.25530508])}, {'x_1': array([-0.32221698, -0.32221698]), 'x_2': array([-0.32221698]), 'x_3': array([-0.32221698]), 'x_shared': array([ 1.02765459, -0.32221698, -0.32221698,  0.29295912, -0.32221698,\n        1.48147708])}, {'x_1': array([2.14904245, 2.64149302]), 'x_2': array([1.03865101]), 'x_3': array([1.03865101]), 'x_shared': array([ 1.03865101,  1.03865101,  1.03865101, -0.85288882,  1.03865101,\n        2.97117135])}], 'y_11': [{'x_1': array([-0.52854918,  0.2031868 ]), 'x_2': array([-0.54405614]), 'x_3': array([-0.44134369]), 'x_shared': array([-0.63777848, -0.32103443, -1.00368678, -0.30372194,  0.4909986 ,\n        0.34072182])}], 'y_12': [{'x_1': array([1.39702333, 1.7601833 ]), 'x_2': array([1.38644236]), 'x_3': array([1.29818376]), 'x_shared': array([1.88540586, 0.99931345, 1.11362047, 1.33119305, 2.13959087,\n       1.25530508])}, {'x_1': array([2.14904245, 2.64149302]), 'x_2': array([1.03865101]), 'x_3': array([1.03865101]), 'x_shared': array([ 1.03865101,  1.03865101,  1.03865101, -0.85288882,  1.03865101,\n        2.97117135])}], 'y_14': [{'x_1': array([1.39702333, 1.7601833 ]), 'x_2': array([1.38644236]), 'x_3': array([1.29818376]), 'x_shared': array([1.88540586, 0.99931345, 1.11362047, 1.33119305, 2.13959087,\n       1.25530508])}, {'x_1': array([-0.32221698, -0.32221698]), 'x_2': array([-0.32221698]), 'x_3': array([-0.32221698]), 'x_shared': array([ 1.02765459, -0.32221698, -0.32221698,  0.29295912, -0.32221698,\n        1.48147708])}], 'y_2': [{'x_1': array([1.39702628, 1.76018348]), 'x_2': array([1.3864453]), 'x_3': array([1.2981857]), 'x_shared': array([1.88541217, 0.99931574, 1.11362606, 1.3311949 , 2.13959583,\n       1.25530806])}, {'x_1': array([0.33948382, 0.33943319]), 'x_2': array([0.33649526]), 'x_3': array([0.33844346]), 'x_shared': array([0.41305532, 0.21372957, 0.46903264, 0.33950848, 0.38374435,\n       0.34981841])}, {'x_1': array([-0.00570744,  0.11370254]), 'x_2': array([-0.00932724]), 'x_3': array([0.03728088]), 'x_shared': array([-0.0051026 , -0.0272534 ,  0.55710865, -0.01538402, -0.06301126,\n        0.01880815])}], 'y_21': [{'x_1': array([1.39702628, 1.76018348]), 'x_2': array([1.3864453]), 'x_3': array([1.2981857]), 'x_shared': array([1.88541217, 0.99931574, 1.11362606, 1.3311949 , 2.13959583,\n       1.25530806])}], 'y_23': [{'x_1': array([0.33948382, 0.33943319]), 'x_2': array([0.33649526]), 'x_3': array([0.33844346]), 'x_shared': array([0.41305532, 0.21372957, 0.46903264, 0.33950848, 0.38374435,\n       0.34981841])}], 'y_24': [{'x_1': array([-0.00570744,  0.11370254]), 'x_2': array([-0.00932724]), 'x_3': array([0.03728088]), 'x_shared': array([-0.0051026 , -0.0272534 ,  0.55710865, -0.01538402, -0.06301126,\n        0.01880815])}], 'y_3': [{'x_1': array([0.00932773, 0.00932773]), 'x_2': array([0.00932773]), 'x_3': array([-0.00610765]), 'x_shared': array([0.00932773, 0.03243592, 0.42907723, 0.00932773, 0.00932773,\n       0.00932773])}, {'x_1': array([0.37078897, 0.37076038]), 'x_2': array([0.36813537]), 'x_3': array([0.27521916]), 'x_shared': array([0.43259873, 0.27308947, 0.4871585 , 0.37080979, 0.40323311,\n       0.37725532])}, {'x_1': array([0.37344871, 0.37341757]), 'x_2': array([0.37074072]), 'x_3': array([0.27642848]), 'x_shared': array([0.43630773, 0.27560325, 0.49427916, 0.37346968, 0.40593033,\n       0.38001693])}], 'y_31': [{'x_1': array([0.37078897, 0.37076038]), 'x_2': array([0.36813537]), 'x_3': array([0.27521916]), 'x_shared': array([0.43259873, 0.27308947, 0.4871585 , 0.37080979, 0.40323311,\n       0.37725532])}], 'y_32': [{'x_1': array([0.37344871, 0.37341757]), 'x_2': array([0.37074072]), 'x_3': array([0.27642848]), 'x_shared': array([0.43630773, 0.27560325, 0.49427916, 0.37346968, 0.40593033,\n       0.38001693])}], 'y_34': [{'x_1': array([0.00932773, 0.00932773]), 'x_2': array([0.00932773]), 'x_3': array([-0.00610765]), 'x_shared': array([0.00932773, 0.03243592, 0.42907723, 0.00932773, 0.00932773,\n       0.00932773])}], 'y_4': [{'x_1': array([0.13474834, 0.13195322]), 'x_2': array([0.12802588]), 'x_3': array([0.12367789]), 'x_shared': array([0.07868618, 0.27624245, 0.3744171 , 0.17136041, 0.19931191,\n       0.16968404])}]}, second={'g_1': [{'x_1': {'x_1': array([[ 0.        , -1.33012176],\n       [-1.33012176,  0.        ]]), 'x_2': array([[-1.22440811],\n       [-0.26814783]]), 'x_3': array([[-1.22440811],\n       [-0.26814783]]), 'x_shared': array([[-2.49473229, -1.22440811, -1.22440811, -1.12140412, -1.22440811,\n        -1.30955348],\n       [ 1.2598181 , -0.26814783, -0.26814783, -0.27935095, -0.26814783,\n        -0.34571335]])}, 'x_2': {'x_1': array([[-1.22440811, -0.26814783]]), 'x_2': array([[0.]]), 'x_3': array([[-0.05476005]]), 'x_shared': array([[-0.05476005, -0.05476005, -0.05476005, -0.05476005, -0.05476005,\n        -0.05476005]])}, 'x_3': {'x_1': array([[-1.22440811, -0.26814783]]), 'x_2': array([[-0.05476005]]), 'x_3': array([[0.]]), 'x_shared': array([[-0.05476005, -0.05476005, -0.05476005, -0.05476005, -0.05476005,\n        -0.05476005]])}, 'x_shared': {'x_1': array([[-2.49473229,  1.2598181 ],\n       [-1.22440811, -0.26814783],\n       [-1.22440811, -0.26814783],\n       [-1.12140412, -0.27935095],\n       [-1.22440811, -0.26814783],\n       [-1.30955348, -0.34571335]]), 'x_2': array([[-0.05476005],\n       [-0.05476005],\n       [-0.05476005],\n       [-0.05476005],\n       [-0.05476005],\n       [-0.05476005]]), 'x_3': array([[-0.05476005],\n       [-0.05476005],\n       [-0.05476005],\n       [-0.05476005],\n       [-0.05476005],\n       [-0.05476005]]), 'x_shared': array([[ 0.        , -9.43181956, -9.43181956, -8.71601145, -9.43181956,\n        -9.76851244],\n       [-9.43181956,  0.        , -0.05476005, -0.05476005, -0.05476005,\n        -0.05476005],\n       [-9.43181956, -0.05476005,  0.        , -0.05476005, -0.05476005,\n        -0.05476005],\n       [-8.71601145, -0.05476005, -0.05476005,  0.        ,  1.13335547,\n         1.32157824],\n       [-9.43181956, -0.05476005, -0.05476005,  1.13335547,  0.        ,\n        -0.05476005],\n       [-9.76851244, -0.05476005, -0.05476005,  1.32157824, -0.05476005,\n         0.        ]])}}, {'x_1': {'x_1': array([[ 0.      , -2.030818],\n       [-2.030818,  0.      ]]), 'x_2': array([[-1.92566953],\n       [-1.2777357 ]]), 'x_3': array([[-1.92566953],\n       [-1.2777357 ]]), 'x_shared': array([[-3.02868555, -1.92566953, -1.92566953, -1.79228949, -1.92566953,\n        -2.03486034],\n       [ 0.50399995, -1.2777357 , -1.2777357 , -1.25560654, -1.2777357 ,\n        -1.4343896 ]])}, 'x_2': {'x_1': array([[-1.92566953, -1.2777357 ]]), 'x_2': array([[0.]]), 'x_3': array([[-0.78291844]]), 'x_shared': array([[-0.78291844, -0.78291844, -0.78291844, -0.78291844, -0.78291844,\n        -0.78291844]])}, 'x_3': {'x_1': array([[-1.92566953, -1.2777357 ]]), 'x_2': array([[-0.78291844]]), 'x_3': array([[0.]]), 'x_shared': array([[-0.78291844, -0.78291844, -0.78291844, -0.78291844, -0.78291844,\n        -0.78291844]])}, 'x_shared': {'x_1': array([[-3.02868555,  0.50399995],\n       [-1.92566953, -1.2777357 ],\n       [-1.92566953, -1.2777357 ],\n       [-1.79228949, -1.25560654],\n       [-1.92566953, -1.2777357 ],\n       [-2.03486034, -1.4343896 ]]), 'x_2': array([[-0.78291844],\n       [-0.78291844],\n       [-0.78291844],\n       [-0.78291844],\n       [-0.78291844],\n       [-0.78291844]]), 'x_3': array([[-0.78291844],\n       [-0.78291844],\n       [-0.78291844],\n       [-0.78291844],\n       [-0.78291844],\n       [-0.78291844]]), 'x_shared': array([[ 0.        , -9.54632805, -9.54632805, -8.66167114, -9.54632805,\n        -9.92137233],\n       [-9.54632805,  0.        , -0.78291844, -0.78291844, -0.78291844,\n        -0.78291844],\n       [-9.54632805, -0.78291844,  0.        , -0.78291844, -0.78291844,\n        -0.78291844],\n       [-8.66167114, -0.78291844, -0.78291844,  0.        ,  0.94844799,\n         1.24591169],\n       [-9.54632805, -0.78291844, -0.78291844,  0.94844799,  0.        ,\n        -0.78291844],\n       [-9.92137233, -0.78291844, -0.78291844,  1.24591169, -0.78291844,\n         0.        ]])}}, {'x_1': {'x_1': array([[ 0.        , -2.29911085],\n       [-2.29911085,  0.        ]]), 'x_2': array([[-2.19538963],\n       [-1.68606696]]), 'x_3': array([[-2.19538963],\n       [-1.68606696]]), 'x_shared': array([[-3.22263164, -2.19538963, -2.19538963, -2.05253321, -2.19538963,\n        -2.31207735],\n       [ 0.17791995, -1.68606696, -1.68606696, -1.64637166, -1.68606696,\n        -1.88088338]])}, 'x_2': {'x_1': array([[-2.19538963, -1.68606696]]), 'x_2': array([[0.]]), 'x_3': array([[-1.07617]]), 'x_shared': array([[-1.07617, -1.07617, -1.07617, -1.07617, -1.07617, -1.07617]])}, 'x_3': {'x_1': array([[-2.19538963, -1.68606696]]), 'x_2': array([[-1.07617]]), 'x_3': array([[0.]]), 'x_shared': array([[-1.07617, -1.07617, -1.07617, -1.07617, -1.07617, -1.07617]])}, 'x_shared': {'x_1': array([[-3.22263164,  0.17791995],\n       [-2.19538963, -1.68606696],\n       [-2.19538963, -1.68606696],\n       [-2.05253321, -1.64637166],\n       [-2.19538963, -1.68606696],\n       [-2.31207735, -1.88088338]]), 'x_2': array([[-1.07617],\n       [-1.07617],\n       [-1.07617],\n       [-1.07617],\n       [-1.07617],\n       [-1.07617]]), 'x_3': array([[-1.07617],\n       [-1.07617],\n       [-1.07617],\n       [-1.07617],\n       [-1.07617],\n       [-1.07617]]), 'x_shared': array([[ 0.        , -9.51390592, -9.51390592, -8.57121163, -9.51390592,\n        -9.90197908],\n       [-9.51390592,  0.        , -1.07617   , -1.07617   , -1.07617   ,\n        -1.07617   ],\n       [-9.51390592, -1.07617   ,  0.        , -1.07617   , -1.07617   ,\n        -1.07617   ],\n       [-8.57121163, -1.07617   , -1.07617   ,  0.        ,  0.86589942,\n         1.2118906 ],\n       [-9.51390592, -1.07617   , -1.07617   ,  0.86589942,  0.        ,\n        -1.07617   ],\n       [-9.90197908, -1.07617   , -1.07617   ,  1.2118906 , -1.07617   ,\n         0.        ]])}}, {'x_1': {'x_1': array([[ 0.        , -2.43806194],\n       [-2.43806194,  0.        ]]), 'x_2': array([[-2.33541269],\n       [-1.90352685]]), 'x_3': array([[-2.33541269],\n       [-1.90352685]]), 'x_shared': array([[-3.32019176e+00, -2.33541269e+00, -2.33541269e+00,\n        -2.18824047e+00, -2.33541269e+00, -2.45551318e+00],\n       [-1.04056535e-03, -1.90352685e+00, -1.90352685e+00,\n        -1.85341379e+00, -1.90352685e+00, -2.12027357e+00]])}, 'x_2': {'x_1': array([[-2.33541269, -1.90352685]]), 'x_2': array([[0.]]), 'x_3': array([[-1.23201689]]), 'x_shared': array([[-1.23201689, -1.23201689, -1.23201689, -1.23201689, -1.23201689,\n        -1.23201689]])}, 'x_3': {'x_1': array([[-2.33541269, -1.90352685]]), 'x_2': array([[-1.23201689]]), 'x_3': array([[0.]]), 'x_shared': array([[-1.23201689, -1.23201689, -1.23201689, -1.23201689, -1.23201689,\n        -1.23201689]])}, 'x_shared': {'x_1': array([[-3.32019176e+00, -1.04056535e-03],\n       [-2.33541269e+00, -1.90352685e+00],\n       [-2.33541269e+00, -1.90352685e+00],\n       [-2.18824047e+00, -1.85341379e+00],\n       [-2.33541269e+00, -1.90352685e+00],\n       [-2.45551318e+00, -2.12027357e+00]]), 'x_2': array([[-1.23201689],\n       [-1.23201689],\n       [-1.23201689],\n       [-1.23201689],\n       [-1.23201689],\n       [-1.23201689]]), 'x_3': array([[-1.23201689],\n       [-1.23201689],\n       [-1.23201689],\n       [-1.23201689],\n       [-1.23201689],\n       [-1.23201689]]), 'x_shared': array([[ 0.        , -9.47615409, -9.47615409, -8.50521945, -9.47615409,\n        -9.87051999],\n       [-9.47615409,  0.        , -1.23201689, -1.23201689, -1.23201689,\n        -1.23201689],\n       [-9.47615409, -1.23201689,  0.        , -1.23201689, -1.23201689,\n        -1.23201689],\n       [-8.50521945, -1.23201689, -1.23201689,  0.        ,  0.81991803,\n         1.19288325],\n       [-9.47615409, -1.23201689, -1.23201689,  0.81991803,  0.        ,\n        -1.23201689],\n       [-9.87051999, -1.23201689, -1.23201689,  1.19288325, -1.23201689,\n         0.        ]])}}, {'x_1': {'x_1': array([[ 0.        , -2.52249492],\n       [-2.52249492,  0.        ]]), 'x_2': array([[-2.4206247 ],\n       [-2.03795999]]), 'x_3': array([[-2.4206247 ],\n       [-2.03795999]]), 'x_shared': array([[-3.37836655, -2.4206247 , -2.4206247 , -2.27105715, -2.4206247 ,\n        -2.54261867],\n       [-0.11365226, -2.03795999, -2.03795999, -1.98101023, -2.03795999,\n        -2.26886332]])}, 'x_2': {'x_1': array([[-2.4206247 , -2.03795999]]), 'x_2': array([[0.]]), 'x_3': array([[-1.32823927]]), 'x_shared': array([[-1.32823927, -1.32823927, -1.32823927, -1.32823927, -1.32823927,\n        -1.32823927]])}, 'x_3': {'x_1': array([[-2.4206247 , -2.03795999]]), 'x_2': array([[-1.32823927]]), 'x_3': array([[0.]]), 'x_shared': array([[-1.32823927, -1.32823927, -1.32823927, -1.32823927, -1.32823927,\n        -1.32823927]])}, 'x_shared': {'x_1': array([[-3.37836655, -0.11365226],\n       [-2.4206247 , -2.03795999],\n       [-2.4206247 , -2.03795999],\n       [-2.27105715, -1.98101023],\n       [-2.4206247 , -2.03795999],\n       [-2.54261867, -2.26886332]]), 'x_2': array([[-1.32823927],\n       [-1.32823927],\n       [-1.32823927],\n       [-1.32823927],\n       [-1.32823927],\n       [-1.32823927]]), 'x_3': array([[-1.32823927],\n       [-1.32823927],\n       [-1.32823927],\n       [-1.32823927],\n       [-1.32823927],\n       [-1.32823927]]), 'x_shared': array([[ 0.        , -9.44517383, -9.44517383, -8.45777635, -9.44517383,\n        -9.84318894],\n       [-9.44517383,  0.        , -1.32823927, -1.32823927, -1.32823927,\n        -1.32823927],\n       [-9.44517383, -1.32823927,  0.        , -1.32823927, -1.32823927,\n        -1.32823927],\n       [-8.45777635, -1.32823927, -1.32823927,  0.        ,  0.79073906,\n         1.18080126],\n       [-9.44517383, -1.32823927, -1.32823927,  0.79073906,  0.        ,\n        -1.32823927],\n       [-9.84318894, -1.32823927, -1.32823927,  1.18080126, -1.32823927,\n         0.        ]])}}, {'x_1': {'x_1': array([[ 0.        , -3.68593707],\n       [-3.68593707,  0.        ]]), 'x_2': array([[-3.46975419],\n       [-2.95554582]]), 'x_3': array([[-3.46975419],\n       [-2.95554582]]), 'x_shared': array([[-3.46975419, -3.46975419, -3.46975419, -2.81081562, -3.46975419,\n        -4.01503385],\n       [-2.95554582, -2.95554582, -2.95554582, -2.78524532, -2.95554582,\n        -3.52865329]])}, 'x_2': {'x_1': array([[-3.46975419, -2.95554582]]), 'x_2': array([[0.]]), 'x_3': array([[-1.88378948]]), 'x_shared': array([[-1.88378948, -1.88378948, -1.88378948, -1.88378948, -1.88378948,\n        -1.88378948]])}, 'x_3': {'x_1': array([[-3.46975419, -2.95554582]]), 'x_2': array([[-1.88378948]]), 'x_3': array([[0.]]), 'x_shared': array([[-1.88378948, -1.88378948, -1.88378948, -1.88378948, -1.88378948,\n        -1.88378948]])}, 'x_shared': {'x_1': array([[-3.46975419, -2.95554582],\n       [-3.46975419, -2.95554582],\n       [-3.46975419, -2.95554582],\n       [-2.81081562, -2.78524532],\n       [-3.46975419, -2.95554582],\n       [-4.01503385, -3.52865329]]), 'x_2': array([[-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948]]), 'x_3': array([[-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948]]), 'x_shared': array([[ 0.        , -1.88378948, -1.88378948, -1.88378948, -1.88378948,\n        -1.88378948],\n       [-1.88378948,  0.        , -1.88378948, -1.88378948, -1.88378948,\n        -1.88378948],\n       [-1.88378948, -1.88378948,  0.        , -1.88378948, -1.88378948,\n        -1.88378948],\n       [-1.88378948, -1.88378948, -1.88378948,  0.        ,  1.53465731,\n         3.27890399],\n       [-1.88378948, -1.88378948, -1.88378948,  1.53465731,  0.        ,\n        -1.88378948],\n       [-1.88378948, -1.88378948, -1.88378948,  3.27890399, -1.88378948,\n         0.        ]])}}, {'x_1': {'x_1': array([[ 0.        , -3.68593707],\n       [-3.68593707,  0.        ]]), 'x_2': array([[-3.46975419],\n       [-2.95554582]]), 'x_3': array([[-3.46975419],\n       [-2.95554582]]), 'x_shared': array([[-3.46975419, -3.46975419, -3.46975419, -2.81081562, -3.46975419,\n        -4.01503385],\n       [-2.95554582, -2.95554582, -2.95554582, -2.78524532, -2.95554582,\n        -3.52865329]])}, 'x_2': {'x_1': array([[-3.46975419, -2.95554582]]), 'x_2': array([[0.]]), 'x_3': array([[-1.88378948]]), 'x_shared': array([[-1.88378948, -1.88378948, -1.88378948, -1.88378948, -1.88378948,\n        -1.88378948]])}, 'x_3': {'x_1': array([[-3.46975419, -2.95554582]]), 'x_2': array([[-1.88378948]]), 'x_3': array([[0.]]), 'x_shared': array([[-1.88378948, -1.88378948, -1.88378948, -1.88378948, -1.88378948,\n        -1.88378948]])}, 'x_shared': {'x_1': array([[-3.46975419, -2.95554582],\n       [-3.46975419, -2.95554582],\n       [-3.46975419, -2.95554582],\n       [-2.81081562, -2.78524532],\n       [-3.46975419, -2.95554582],\n       [-4.01503385, -3.52865329]]), 'x_2': array([[-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948]]), 'x_3': array([[-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948]]), 'x_shared': array([[ 0.        , -1.88378948, -1.88378948, -1.88378948, -1.88378948,\n        -1.88378948],\n       [-1.88378948,  0.        , -1.88378948, -1.88378948, -1.88378948,\n        -1.88378948],\n       [-1.88378948, -1.88378948,  0.        , -1.88378948, -1.88378948,\n        -1.88378948],\n       [-1.88378948, -1.88378948, -1.88378948,  0.        ,  1.53465731,\n         3.27890399],\n       [-1.88378948, -1.88378948, -1.88378948,  1.53465731,  0.        ,\n        -1.88378948],\n       [-1.88378948, -1.88378948, -1.88378948,  3.27890399, -1.88378948,\n         0.        ]])}}], 'g_2': [{'x_1': {'x_1': array([[0.        , 2.67431043],\n       [2.67431043, 0.        ]]), 'x_2': array([[2.67431043],\n       [2.67431043]]), 'x_3': array([[2.67431043],\n       [2.67431043]]), 'x_shared': array([[2.67431043, 2.67431043, 2.67431043, 2.67431043, 2.67431043,\n        2.67431043],\n       [2.67431043, 2.67431043, 2.67431043, 2.67431043, 2.67431043,\n        2.67431043]])}, 'x_2': {'x_1': array([[2.67431043, 2.67431043]]), 'x_2': array([[0.]]), 'x_3': array([[2.67431043]]), 'x_shared': array([[2.67431043, 2.67431043, 2.67431043, 2.67431043, 2.67431043,\n        2.67431043]])}, 'x_3': {'x_1': array([[2.67431043, 2.67431043]]), 'x_2': array([[2.67431043]]), 'x_3': array([[0.]]), 'x_shared': array([[2.67431043, 2.67431043, 2.67431043, 2.67431043, 2.67431043,\n        2.67431043]])}, 'x_shared': {'x_1': array([[2.67431043, 2.67431043],\n       [2.67431043, 2.67431043],\n       [2.67431043, 2.67431043],\n       [2.67431043, 2.67431043],\n       [2.67431043, 2.67431043],\n       [2.67431043, 2.67431043]]), 'x_2': array([[2.67431043],\n       [2.67431043],\n       [2.67431043],\n       [2.67431043],\n       [2.67431043],\n       [2.67431043]]), 'x_3': array([[2.67431043],\n       [2.67431043],\n       [2.67431043],\n       [2.67431043],\n       [2.67431043],\n       [2.67431043]]), 'x_shared': array([[ 0.        , -6.21198826, -6.21198826, -6.21198826, -6.21198826,\n        -6.21198826],\n       [-6.21198826,  0.        ,  2.67431043,  2.67431043,  2.67431043,\n         2.67431043],\n       [-6.21198826,  2.67431043,  0.        ,  2.67431043,  2.67431043,\n         2.67431043],\n       [-6.21198826,  2.67431043,  2.67431043,  0.        ,  2.67431043,\n         2.67431043],\n       [-6.21198826,  2.67431043,  2.67431043,  2.67431043,  0.        ,\n         2.67431043],\n       [-6.21198826,  2.67431043,  2.67431043,  2.67431043,  2.67431043,\n         0.        ]])}}], 'g_3': [{'x_1': {'x_1': array([[ 0.        , -0.65446902],\n       [-0.65446902,  0.        ]]), 'x_2': array([[-0.65446943],\n       [-0.6547183 ]]), 'x_3': array([[-0.65447059],\n       [-0.65476368]]), 'x_shared': array([[-0.65446376, -0.65447717, -0.65448766, -0.65446903, -0.65445145,\n        -0.65447479],\n       [-0.65468846, -0.65463623, -0.65450767, -0.6547172 , -0.65475441,\n        -0.65469715]])}, 'x_2': {'x_1': array([[-0.65446943, -0.6547183 ]]), 'x_2': array([[0.]]), 'x_3': array([[-0.65513895]]), 'x_shared': array([[-0.65364071, -0.64957331, -0.65361609, -0.65478425, -0.65281374,\n        -0.65682092]])}, 'x_3': {'x_1': array([[-0.65447059, -0.65476368]]), 'x_2': array([[-0.65513895]]), 'x_3': array([[0.]]), 'x_shared': array([[-0.49581736, -0.52825994, -0.44619693, -0.50999028, -0.51956593,\n        -0.49936174]])}, 'x_shared': {'x_1': array([[-0.65446376, -0.65468846],\n       [-0.65447717, -0.65463623],\n       [-0.65448766, -0.65450767],\n       [-0.65446903, -0.6547172 ],\n       [-0.65445145, -0.65475441],\n       [-0.65447479, -0.65469715]]), 'x_2': array([[-0.65364071],\n       [-0.64957331],\n       [-0.65361609],\n       [-0.65478425],\n       [-0.65281374],\n       [-0.65682092]]), 'x_3': array([[-0.49581736],\n       [-0.52825994],\n       [-0.44619693],\n       [-0.50999028],\n       [-0.51956593],\n       [-0.49936174]]), 'x_shared': array([[ 0.        , -0.73961162, -0.76367658, -0.74081939, -0.75542285,\n        -0.73782958],\n       [-0.73961162,  0.        , -0.217186  , -0.0253624 ,  0.02780089,\n         0.0503513 ],\n       [-0.76367658, -0.217186  ,  0.        , -0.54523946, -0.4011258 ,\n        -0.57220677],\n       [-0.74081939, -0.0253624 , -0.54523946,  0.        , -0.65455737,\n        -0.65456072],\n       [-0.75542285,  0.02780089, -0.4011258 , -0.65455737,  0.        ,\n        -0.78337698],\n       [-0.73782958,  0.0503513 , -0.57220677, -0.65456072, -0.78337698,\n         0.        ]])}}, {'x_1': {'x_1': array([[ 0.        , -0.65446902],\n       [-0.65446902,  0.        ]]), 'x_2': array([[-0.65446943],\n       [-0.6547183 ]]), 'x_3': array([[-0.65447059],\n       [-0.65476368]]), 'x_shared': array([[-0.65446376, -0.65447717, -0.65448766, -0.65446903, -0.65445145,\n        -0.65447479],\n       [-0.65468846, -0.65463623, -0.65450767, -0.6547172 , -0.65475441,\n        -0.65469715]])}, 'x_2': {'x_1': array([[-0.65446943, -0.6547183 ]]), 'x_2': array([[0.]]), 'x_3': array([[-0.65513895]]), 'x_shared': array([[-0.65364071, -0.64957331, -0.65361609, -0.65478425, -0.65281374,\n        -0.65682092]])}, 'x_3': {'x_1': array([[-0.65447059, -0.65476368]]), 'x_2': array([[-0.65513895]]), 'x_3': array([[0.]]), 'x_shared': array([[-0.49581736, -0.52825994, -0.44619693, -0.50999028, -0.51956593,\n        -0.49936174]])}, 'x_shared': {'x_1': array([[-0.65446376, -0.65468846],\n       [-0.65447717, -0.65463623],\n       [-0.65448766, -0.65450767],\n       [-0.65446903, -0.6547172 ],\n       [-0.65445145, -0.65475441],\n       [-0.65447479, -0.65469715]]), 'x_2': array([[-0.65364071],\n       [-0.64957331],\n       [-0.65361609],\n       [-0.65478425],\n       [-0.65281374],\n       [-0.65682092]]), 'x_3': array([[-0.49581736],\n       [-0.52825994],\n       [-0.44619693],\n       [-0.50999028],\n       [-0.51956593],\n       [-0.49936174]]), 'x_shared': array([[ 0.        , -0.73961162, -0.76367658, -0.74081939, -0.75542285,\n        -0.73782958],\n       [-0.73961162,  0.        , -0.217186  , -0.0253624 ,  0.02780089,\n         0.0503513 ],\n       [-0.76367658, -0.217186  ,  0.        , -0.54523946, -0.4011258 ,\n        -0.57220677],\n       [-0.74081939, -0.0253624 , -0.54523946,  0.        , -0.65455737,\n        -0.65456072],\n       [-0.75542285,  0.02780089, -0.4011258 , -0.65455737,  0.        ,\n        -0.78337698],\n       [-0.73782958,  0.0503513 , -0.57220677, -0.65456072, -0.78337698,\n         0.        ]])}}, {'x_1': {'x_1': array([[ 0.        , -0.27575023],\n       [-0.27575023,  0.        ]]), 'x_2': array([[-0.27575023],\n       [-0.27575023]]), 'x_3': array([[-0.27575023],\n       [-0.27575023]]), 'x_shared': array([[-0.27575023, -0.27575023, -0.27575023, -0.27575023, -0.27575023,\n        -0.27575023],\n       [-0.27575023, -0.27575023, -0.27575023, -0.27575023, -0.27575023,\n        -0.27575023]])}, 'x_2': {'x_1': array([[-0.27575023, -0.27575023]]), 'x_2': array([[0.]]), 'x_3': array([[-0.27575023]]), 'x_shared': array([[-0.27575023, -0.27575023, -0.27575023, -0.27575023, -0.27575023,\n        -0.27575023]])}, 'x_3': {'x_1': array([[-0.27575023, -0.27575023]]), 'x_2': array([[-0.27575023]]), 'x_3': array([[0.]]), 'x_shared': array([[ 0.01305851, -0.06785798,  0.15128947,  0.01305851,  0.01305851,\n         0.01305851]])}, 'x_shared': {'x_1': array([[-0.27575023, -0.27575023],\n       [-0.27575023, -0.27575023],\n       [-0.27575023, -0.27575023],\n       [-0.27575023, -0.27575023],\n       [-0.27575023, -0.27575023],\n       [-0.27575023, -0.27575023]]), 'x_2': array([[-0.27575023],\n       [-0.27575023],\n       [-0.27575023],\n       [-0.27575023],\n       [-0.27575023],\n       [-0.27575023]]), 'x_3': array([[ 0.01305851],\n       [-0.06785798],\n       [ 0.15128947],\n       [ 0.01305851],\n       [ 0.01305851],\n       [ 0.01305851]]), 'x_shared': array([[ 0.        , -0.27575023, -0.27575023, -0.27575023, -0.27575023,\n        -0.27575023],\n       [-0.27575023,  0.        ,  0.09096629,  0.24281157,  0.24281157,\n         0.24281157],\n       [-0.27575023,  0.09096629,  0.        , -0.35422855, -0.35422855,\n        -0.35422855],\n       [-0.27575023,  0.24281157, -0.35422855,  0.        , -0.27575023,\n        -0.27575023],\n       [-0.27575023,  0.24281157, -0.35422855, -0.27575023,  0.        ,\n        -0.27575023],\n       [-0.27575023,  0.24281157, -0.35422855, -0.27575023, -0.27575023,\n         0.        ]])}}, {'x_1': {'x_1': array([[0.        , 0.47537351],\n       [0.47537351, 0.        ]]), 'x_2': array([[0.47537351],\n       [0.47537351]]), 'x_3': array([[0.47537351],\n       [0.47537351]]), 'x_shared': array([[0.47537351, 0.47537351, 0.47537351, 0.47537351, 0.47537351,\n        0.47537351],\n       [0.47537351, 0.47537351, 0.47537351, 0.47537351, 0.47537351,\n        0.47537351]])}, 'x_2': {'x_1': array([[0.47537351, 0.47537351]]), 'x_2': array([[0.]]), 'x_3': array([[0.47537351]]), 'x_shared': array([[0.47537351, 0.47537351, 0.47537351, 0.47537351, 0.47537351,\n        0.47537351]])}, 'x_3': {'x_1': array([[0.47537351, 0.47537351]]), 'x_2': array([[0.47537351]]), 'x_3': array([[0.]]), 'x_shared': array([[0.47537351, 0.47537351, 0.47537351, 0.47537351, 0.47537351,\n        0.47537351]])}, 'x_shared': {'x_1': array([[0.47537351, 0.47537351],\n       [0.47537351, 0.47537351],\n       [0.47537351, 0.47537351],\n       [0.47537351, 0.47537351],\n       [0.47537351, 0.47537351],\n       [0.47537351, 0.47537351]]), 'x_2': array([[0.47537351],\n       [0.47537351],\n       [0.47537351],\n       [0.47537351],\n       [0.47537351],\n       [0.47537351]]), 'x_3': array([[0.47537351],\n       [0.47537351],\n       [0.47537351],\n       [0.47537351],\n       [0.47537351],\n       [0.47537351]]), 'x_shared': array([[0.        , 0.47537351, 0.47537351, 0.47537351, 0.47537351,\n        0.47537351],\n       [0.47537351, 0.        , 0.47537351, 0.47537351, 0.47537351,\n        0.47537351],\n       [0.47537351, 0.47537351, 0.        , 1.12516626, 1.12516626,\n        1.12516626],\n       [0.47537351, 0.47537351, 1.12516626, 0.        , 0.47537351,\n        0.47537351],\n       [0.47537351, 0.47537351, 1.12516626, 0.47537351, 0.        ,\n        0.47537351],\n       [0.47537351, 0.47537351, 1.12516626, 0.47537351, 0.47537351,\n        0.        ]])}}], 'y_1': [{'x_1': {'x_1': array([[ 0.        , -2.44485171],\n       [-2.44485171,  0.        ]]), 'x_2': array([[-2.44403802],\n       [-3.08539811]]), 'x_3': array([[-2.44396411],\n       [-3.15829258]]), 'x_shared': array([[-2.44622902, -2.4436664 , -2.4426117 , -2.44315718, -2.44861333,\n        -2.44241367],\n       [-2.86119748, -3.00235475, -2.78685628, -3.06868825, -3.21566813,\n        -2.94808741]])}, 'x_2': {'x_1': array([[-2.44403802, -3.08539811]]), 'x_2': array([[0.]]), 'x_3': array([[-2.42929124]]), 'x_shared': array([[-2.42514395, -2.42487638, -2.42796091, -2.43158833, -2.4244911 ,\n        -2.43383928]])}, 'x_3': {'x_1': array([[-2.44396411, -3.15829258]]), 'x_2': array([[-2.42929124]]), 'x_3': array([[0.]]), 'x_shared': array([[-2.2232619 , -2.29489205, -2.23230766, -2.27285613, -2.30135851,\n        -2.25511429]])}, 'x_shared': {'x_1': array([[-2.44622902, -2.86119748],\n       [-2.4436664 , -3.00235475],\n       [-2.4426117 , -2.78685628],\n       [-2.44315718, -3.06868825],\n       [-2.44861333, -3.21566813],\n       [-2.44241367, -2.94808741]]), 'x_2': array([[-2.42514395],\n       [-2.42487638],\n       [-2.42796091],\n       [-2.43158833],\n       [-2.4244911 ],\n       [-2.43383928]]), 'x_3': array([[-2.2232619 ],\n       [-2.29489205],\n       [-2.23230766],\n       [-2.27285613],\n       [-2.30135851],\n       [-2.25511429]]), 'x_shared': array([[ 0.        , -3.1639928 , -3.24177393, -3.13457359, -3.41658759,\n        -3.13926163],\n       [-3.1639928 ,  0.        , -1.83109408, -1.58608777, -1.5754729 ,\n        -1.49682369],\n       [-3.24177393, -1.83109408,  0.        , -2.04574607, -1.72270442,\n        -2.09387172],\n       [-3.13457359, -1.58608777, -2.04574607,  0.        , -2.25573439,\n        -2.51093853],\n       [-3.41658759, -1.5754729 , -1.72270442, -2.25573439,  0.        ,\n        -3.33166046],\n       [-3.13926163, -1.49682369, -2.09387172, -2.51093853, -3.33166046,\n         0.        ]])}}, {'x_1': {'x_1': array([[0.        , 0.50460033],\n       [0.50460033, 0.        ]]), 'x_2': array([[0.50460033],\n       [0.50460033]]), 'x_3': array([[0.50460033],\n       [0.50460033]]), 'x_shared': array([[0.50460033, 0.50460033, 0.50460033, 0.50460033, 0.50460033,\n        0.50460033],\n       [0.50460033, 0.50460033, 0.50460033, 0.50460033, 0.50460033,\n        0.50460033]])}, 'x_2': {'x_1': array([[0.50460033, 0.50460033]]), 'x_2': array([[0.]]), 'x_3': array([[0.50460033]]), 'x_shared': array([[0.50460033, 0.50460033, 0.50460033, 0.50460033, 0.50460033,\n        0.50460033]])}, 'x_3': {'x_1': array([[0.50460033, 0.50460033]]), 'x_2': array([[0.50460033]]), 'x_3': array([[0.]]), 'x_shared': array([[0.50460033, 0.50460033, 0.50460033, 0.50460033, 0.50460033,\n        0.50460033]])}, 'x_shared': {'x_1': array([[0.50460033, 0.50460033],\n       [0.50460033, 0.50460033],\n       [0.50460033, 0.50460033],\n       [0.50460033, 0.50460033],\n       [0.50460033, 0.50460033],\n       [0.50460033, 0.50460033]]), 'x_2': array([[0.50460033],\n       [0.50460033],\n       [0.50460033],\n       [0.50460033],\n       [0.50460033],\n       [0.50460033]]), 'x_3': array([[0.50460033],\n       [0.50460033],\n       [0.50460033],\n       [0.50460033],\n       [0.50460033],\n       [0.50460033]]), 'x_shared': array([[ 0.        , -0.91308686, -0.91308686, -0.59789578, -0.91308686,\n        -0.59862833],\n       [-0.91308686,  0.        ,  0.50460033,  0.50460033,  0.50460033,\n         0.50460033],\n       [-0.91308686,  0.50460033,  0.        ,  0.50460033,  0.50460033,\n         0.50460033],\n       [-0.59789578,  0.50460033,  0.50460033,  0.        ,  0.31013608,\n        -0.62288116],\n       [-0.91308686,  0.50460033,  0.50460033,  0.31013608,  0.        ,\n         0.50460033],\n       [-0.59862833,  0.50460033,  0.50460033, -0.62288116,  0.50460033,\n         0.        ]])}}, {'x_1': {'x_1': array([[ 0.        , -3.68593707],\n       [-3.68593707,  0.        ]]), 'x_2': array([[-3.46975419],\n       [-2.95554582]]), 'x_3': array([[-3.46975419],\n       [-2.95554582]]), 'x_shared': array([[-3.46975419, -3.46975419, -3.46975419, -2.81081562, -3.46975419,\n        -4.01503385],\n       [-2.95554582, -2.95554582, -2.95554582, -2.78524532, -2.95554582,\n        -3.52865329]])}, 'x_2': {'x_1': array([[-3.46975419, -2.95554582]]), 'x_2': array([[0.]]), 'x_3': array([[-1.88378948]]), 'x_shared': array([[-1.88378948, -1.88378948, -1.88378948, -1.88378948, -1.88378948,\n        -1.88378948]])}, 'x_3': {'x_1': array([[-3.46975419, -2.95554582]]), 'x_2': array([[-1.88378948]]), 'x_3': array([[0.]]), 'x_shared': array([[-1.88378948, -1.88378948, -1.88378948, -1.88378948, -1.88378948,\n        -1.88378948]])}, 'x_shared': {'x_1': array([[-3.46975419, -2.95554582],\n       [-3.46975419, -2.95554582],\n       [-3.46975419, -2.95554582],\n       [-2.81081562, -2.78524532],\n       [-3.46975419, -2.95554582],\n       [-4.01503385, -3.52865329]]), 'x_2': array([[-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948]]), 'x_3': array([[-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948]]), 'x_shared': array([[ 0.        , -1.88378948, -1.88378948, -1.88378948, -1.88378948,\n        -1.88378948],\n       [-1.88378948,  0.        , -1.88378948, -1.88378948, -1.88378948,\n        -1.88378948],\n       [-1.88378948, -1.88378948,  0.        , -1.88378948, -1.88378948,\n        -1.88378948],\n       [-1.88378948, -1.88378948, -1.88378948,  0.        ,  1.53465731,\n         3.27890399],\n       [-1.88378948, -1.88378948, -1.88378948,  1.53465731,  0.        ,\n        -1.88378948],\n       [-1.88378948, -1.88378948, -1.88378948,  3.27890399, -1.88378948,\n         0.        ]])}}], 'y_11': [{'x_1': {'x_1': array([[0.        , 0.90414914],\n       [0.90414914, 0.        ]]), 'x_2': array([[0.90484403],\n       [0.46377225]]), 'x_3': array([[0.90493334],\n       [0.36327016]]), 'x_shared': array([[0.90707841, 0.90521938, 0.90678728, 0.90370255, 0.89734485,\n        0.90167882],\n       [0.26460947, 0.50769629, 0.82943443, 0.44620262, 0.30817302,\n        0.20775504]])}, 'x_2': {'x_1': array([[0.90484403, 0.46377225]]), 'x_2': array([[0.]]), 'x_3': array([[0.91605223]]), 'x_shared': array([[0.91257588, 0.92046001, 0.9166723 , 0.91894708, 0.92488293,\n        0.92378051]])}, 'x_3': {'x_1': array([[0.90493334, 0.36327016]]), 'x_2': array([[0.91605223]]), 'x_3': array([[0.]]), 'x_shared': array([[0.88064536, 0.91322007, 0.99586985, 0.92619958, 0.91124852,\n        0.88953544]])}, 'x_shared': {'x_1': array([[0.90707841, 0.26460947],\n       [0.90521938, 0.50769629],\n       [0.90678728, 0.82943443],\n       [0.90370255, 0.44620262],\n       [0.89734485, 0.30817302],\n       [0.90167882, 0.20775504]]), 'x_2': array([[0.91257588],\n       [0.92046001],\n       [0.9166723 ],\n       [0.91894708],\n       [0.92488293],\n       [0.92378051]]), 'x_3': array([[0.88064536],\n       [0.91322007],\n       [0.99586985],\n       [0.92619958],\n       [0.91124852],\n       [0.88953544]]), 'x_shared': array([[ 0.        ,  1.20235752,  1.30361696,  1.27606465,  1.51345475,\n         1.27517406],\n       [ 1.20235752,  0.        ,  0.99732496,  1.06298972,  1.24940043,\n         0.9031584 ],\n       [ 1.30361696,  0.99732496,  0.        ,  1.26940127,  1.67490638,\n         1.39284984],\n       [ 1.27606465,  1.06298972,  1.26940127,  0.        ,  0.6926428 ,\n         0.69100519],\n       [ 1.51345475,  1.24940043,  1.67490638,  0.6926428 ,  0.        ,\n        -0.48609777],\n       [ 1.27517406,  0.9031584 ,  1.39284984,  0.69100519, -0.48609777,\n         0.        ]])}}], 'y_12': [{'x_1': {'x_1': array([[ 0.        , -2.44485171],\n       [-2.44485171,  0.        ]]), 'x_2': array([[-2.44403802],\n       [-3.08539811]]), 'x_3': array([[-2.44396411],\n       [-3.15829258]]), 'x_shared': array([[-2.44622902, -2.4436664 , -2.4426117 , -2.44315718, -2.44861333,\n        -2.44241367],\n       [-2.86119748, -3.00235475, -2.78685628, -3.06868825, -3.21566813,\n        -2.94808741]])}, 'x_2': {'x_1': array([[-2.44403802, -3.08539811]]), 'x_2': array([[0.]]), 'x_3': array([[-2.42929124]]), 'x_shared': array([[-2.42514395, -2.42487638, -2.42796091, -2.43158833, -2.4244911 ,\n        -2.43383928]])}, 'x_3': {'x_1': array([[-2.44396411, -3.15829258]]), 'x_2': array([[-2.42929124]]), 'x_3': array([[0.]]), 'x_shared': array([[-2.2232619 , -2.29489205, -2.23230766, -2.27285613, -2.30135851,\n        -2.25511429]])}, 'x_shared': {'x_1': array([[-2.44622902, -2.86119748],\n       [-2.4436664 , -3.00235475],\n       [-2.4426117 , -2.78685628],\n       [-2.44315718, -3.06868825],\n       [-2.44861333, -3.21566813],\n       [-2.44241367, -2.94808741]]), 'x_2': array([[-2.42514395],\n       [-2.42487638],\n       [-2.42796091],\n       [-2.43158833],\n       [-2.4244911 ],\n       [-2.43383928]]), 'x_3': array([[-2.2232619 ],\n       [-2.29489205],\n       [-2.23230766],\n       [-2.27285613],\n       [-2.30135851],\n       [-2.25511429]]), 'x_shared': array([[ 0.        , -3.1639928 , -3.24177393, -3.13457359, -3.41658759,\n        -3.13926163],\n       [-3.1639928 ,  0.        , -1.83109408, -1.58608777, -1.5754729 ,\n        -1.49682369],\n       [-3.24177393, -1.83109408,  0.        , -2.04574607, -1.72270442,\n        -2.09387172],\n       [-3.13457359, -1.58608777, -2.04574607,  0.        , -2.25573439,\n        -2.51093853],\n       [-3.41658759, -1.5754729 , -1.72270442, -2.25573439,  0.        ,\n        -3.33166046],\n       [-3.13926163, -1.49682369, -2.09387172, -2.51093853, -3.33166046,\n         0.        ]])}}, {'x_1': {'x_1': array([[ 0.        , -3.68593707],\n       [-3.68593707,  0.        ]]), 'x_2': array([[-3.46975419],\n       [-2.95554582]]), 'x_3': array([[-3.46975419],\n       [-2.95554582]]), 'x_shared': array([[-3.46975419, -3.46975419, -3.46975419, -2.81081562, -3.46975419,\n        -4.01503385],\n       [-2.95554582, -2.95554582, -2.95554582, -2.78524532, -2.95554582,\n        -3.52865329]])}, 'x_2': {'x_1': array([[-3.46975419, -2.95554582]]), 'x_2': array([[0.]]), 'x_3': array([[-1.88378948]]), 'x_shared': array([[-1.88378948, -1.88378948, -1.88378948, -1.88378948, -1.88378948,\n        -1.88378948]])}, 'x_3': {'x_1': array([[-3.46975419, -2.95554582]]), 'x_2': array([[-1.88378948]]), 'x_3': array([[0.]]), 'x_shared': array([[-1.88378948, -1.88378948, -1.88378948, -1.88378948, -1.88378948,\n        -1.88378948]])}, 'x_shared': {'x_1': array([[-3.46975419, -2.95554582],\n       [-3.46975419, -2.95554582],\n       [-3.46975419, -2.95554582],\n       [-2.81081562, -2.78524532],\n       [-3.46975419, -2.95554582],\n       [-4.01503385, -3.52865329]]), 'x_2': array([[-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948]]), 'x_3': array([[-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948],\n       [-1.88378948]]), 'x_shared': array([[ 0.        , -1.88378948, -1.88378948, -1.88378948, -1.88378948,\n        -1.88378948],\n       [-1.88378948,  0.        , -1.88378948, -1.88378948, -1.88378948,\n        -1.88378948],\n       [-1.88378948, -1.88378948,  0.        , -1.88378948, -1.88378948,\n        -1.88378948],\n       [-1.88378948, -1.88378948, -1.88378948,  0.        ,  1.53465731,\n         3.27890399],\n       [-1.88378948, -1.88378948, -1.88378948,  1.53465731,  0.        ,\n        -1.88378948],\n       [-1.88378948, -1.88378948, -1.88378948,  3.27890399, -1.88378948,\n         0.        ]])}}], 'y_14': [{'x_1': {'x_1': array([[ 0.        , -2.44485171],\n       [-2.44485171,  0.        ]]), 'x_2': array([[-2.44403802],\n       [-3.08539811]]), 'x_3': array([[-2.44396411],\n       [-3.15829258]]), 'x_shared': array([[-2.44622902, -2.4436664 , -2.4426117 , -2.44315718, -2.44861333,\n        -2.44241367],\n       [-2.86119748, -3.00235475, -2.78685628, -3.06868825, -3.21566813,\n        -2.94808741]])}, 'x_2': {'x_1': array([[-2.44403802, -3.08539811]]), 'x_2': array([[0.]]), 'x_3': array([[-2.42929124]]), 'x_shared': array([[-2.42514395, -2.42487638, -2.42796091, -2.43158833, -2.4244911 ,\n        -2.43383928]])}, 'x_3': {'x_1': array([[-2.44396411, -3.15829258]]), 'x_2': array([[-2.42929124]]), 'x_3': array([[0.]]), 'x_shared': array([[-2.2232619 , -2.29489205, -2.23230766, -2.27285613, -2.30135851,\n        -2.25511429]])}, 'x_shared': {'x_1': array([[-2.44622902, -2.86119748],\n       [-2.4436664 , -3.00235475],\n       [-2.4426117 , -2.78685628],\n       [-2.44315718, -3.06868825],\n       [-2.44861333, -3.21566813],\n       [-2.44241367, -2.94808741]]), 'x_2': array([[-2.42514395],\n       [-2.42487638],\n       [-2.42796091],\n       [-2.43158833],\n       [-2.4244911 ],\n       [-2.43383928]]), 'x_3': array([[-2.2232619 ],\n       [-2.29489205],\n       [-2.23230766],\n       [-2.27285613],\n       [-2.30135851],\n       [-2.25511429]]), 'x_shared': array([[ 0.        , -3.1639928 , -3.24177393, -3.13457359, -3.41658759,\n        -3.13926163],\n       [-3.1639928 ,  0.        , -1.83109408, -1.58608777, -1.5754729 ,\n        -1.49682369],\n       [-3.24177393, -1.83109408,  0.        , -2.04574607, -1.72270442,\n        -2.09387172],\n       [-3.13457359, -1.58608777, -2.04574607,  0.        , -2.25573439,\n        -2.51093853],\n       [-3.41658759, -1.5754729 , -1.72270442, -2.25573439,  0.        ,\n        -3.33166046],\n       [-3.13926163, -1.49682369, -2.09387172, -2.51093853, -3.33166046,\n         0.        ]])}}, {'x_1': {'x_1': array([[0.        , 0.50460033],\n       [0.50460033, 0.        ]]), 'x_2': array([[0.50460033],\n       [0.50460033]]), 'x_3': array([[0.50460033],\n       [0.50460033]]), 'x_shared': array([[0.50460033, 0.50460033, 0.50460033, 0.50460033, 0.50460033,\n        0.50460033],\n       [0.50460033, 0.50460033, 0.50460033, 0.50460033, 0.50460033,\n        0.50460033]])}, 'x_2': {'x_1': array([[0.50460033, 0.50460033]]), 'x_2': array([[0.]]), 'x_3': array([[0.50460033]]), 'x_shared': array([[0.50460033, 0.50460033, 0.50460033, 0.50460033, 0.50460033,\n        0.50460033]])}, 'x_3': {'x_1': array([[0.50460033, 0.50460033]]), 'x_2': array([[0.50460033]]), 'x_3': array([[0.]]), 'x_shared': array([[0.50460033, 0.50460033, 0.50460033, 0.50460033, 0.50460033,\n        0.50460033]])}, 'x_shared': {'x_1': array([[0.50460033, 0.50460033],\n       [0.50460033, 0.50460033],\n       [0.50460033, 0.50460033],\n       [0.50460033, 0.50460033],\n       [0.50460033, 0.50460033],\n       [0.50460033, 0.50460033]]), 'x_2': array([[0.50460033],\n       [0.50460033],\n       [0.50460033],\n       [0.50460033],\n       [0.50460033],\n       [0.50460033]]), 'x_3': array([[0.50460033],\n       [0.50460033],\n       [0.50460033],\n       [0.50460033],\n       [0.50460033],\n       [0.50460033]]), 'x_shared': array([[ 0.        , -0.91308686, -0.91308686, -0.59789578, -0.91308686,\n        -0.59862833],\n       [-0.91308686,  0.        ,  0.50460033,  0.50460033,  0.50460033,\n         0.50460033],\n       [-0.91308686,  0.50460033,  0.        ,  0.50460033,  0.50460033,\n         0.50460033],\n       [-0.59789578,  0.50460033,  0.50460033,  0.        ,  0.31013608,\n        -0.62288116],\n       [-0.91308686,  0.50460033,  0.50460033,  0.31013608,  0.        ,\n         0.50460033],\n       [-0.59862833,  0.50460033,  0.50460033, -0.62288116,  0.50460033,\n         0.        ]])}}], 'y_2': [{'x_1': {'x_1': array([[ 0.        , -2.44485696],\n       [-2.44485696,  0.        ]]), 'x_2': array([[-2.44404327],\n       [-3.08540115]]), 'x_3': array([[-2.44396937],\n       [-3.15829639]]), 'x_shared': array([[-2.44623436, -2.44367166, -2.44261691, -2.44316239, -2.44861876,\n        -2.44241886],\n       [-2.86120088, -3.00235869, -2.78686209, -3.06869215, -3.21567059,\n        -2.94809138]])}, 'x_2': {'x_1': array([[-2.44404327, -3.08540115]]), 'x_2': array([[0.]]), 'x_3': array([[-2.42929697]]), 'x_shared': array([[-2.42515024, -2.42488221, -2.42796636, -2.43159383, -2.42449795,\n        -2.43384457]])}, 'x_3': {'x_1': array([[-2.44396937, -3.15829639]]), 'x_2': array([[-2.42929697]]), 'x_3': array([[0.]]), 'x_shared': array([[-2.22326733, -2.29489588, -2.23231151, -2.27286145, -2.30136545,\n        -2.25511979]])}, 'x_shared': {'x_1': array([[-2.44623436, -2.86120088],\n       [-2.44367166, -3.00235869],\n       [-2.44261691, -2.78686209],\n       [-2.44316239, -3.06869215],\n       [-2.44861876, -3.21567059],\n       [-2.44241886, -2.94809138]]), 'x_2': array([[-2.42515024],\n       [-2.42488221],\n       [-2.42796636],\n       [-2.43159383],\n       [-2.42449795],\n       [-2.43384457]]), 'x_3': array([[-2.22326733],\n       [-2.29489588],\n       [-2.23231151],\n       [-2.27286145],\n       [-2.30136545],\n       [-2.25511979]]), 'x_shared': array([[ 0.        , -3.16400123, -3.24178415, -3.13458404, -3.41660166,\n        -3.13927321],\n       [-3.16400123,  0.        , -1.83110364, -1.58609702, -1.57548624,\n        -1.49683451],\n       [-3.24178415, -1.83110364,  0.        , -2.04575841, -1.72272189,\n        -2.09388651],\n       [-3.13458404, -1.58609702, -2.04575841,  0.        , -2.25574536,\n        -2.51094519],\n       [-3.41660166, -1.57548624, -1.72272189, -2.25574536,  0.        ,\n        -3.33166901],\n       [-3.13927321, -1.49683451, -2.09388651, -2.51094519, -3.33166901,\n         0.        ]])}}, {'x_1': {'x_1': array([[ 0.        , -0.59639476],\n       [-0.59639476,  0.        ]]), 'x_2': array([[-0.59639518],\n       [-0.59668333]]), 'x_3': array([[-0.59639482],\n       [-0.5966817 ]]), 'x_shared': array([[-0.59638939, -0.59640338, -0.59641395, -0.59639477, -0.59637678,\n        -0.59640062],\n       [-0.59665062, -0.59659979, -0.59645524, -0.59668216, -0.59672259,\n        -0.59665956]])}, 'x_2': {'x_1': array([[-0.59639518, -0.59668333]]), 'x_2': array([[0.]]), 'x_3': array([[-0.5967372]]), 'x_shared': array([[-0.59557345, -0.59135745, -0.59550887, -0.5967442 , -0.59474013,\n        -0.59883396]])}, 'x_3': {'x_1': array([[-0.59639482, -0.5966817 ]]), 'x_2': array([[-0.5967372]]), 'x_3': array([[0.]]), 'x_shared': array([[-0.59555047, -0.59397057, -0.59444432, -0.59565703, -0.59600821,\n        -0.59609727]])}, 'x_shared': {'x_1': array([[-0.59638939, -0.59665062],\n       [-0.59640338, -0.59659979],\n       [-0.59641395, -0.59645524],\n       [-0.59639477, -0.59668216],\n       [-0.59637678, -0.59672259],\n       [-0.59640062, -0.59665956]]), 'x_2': array([[-0.59557345],\n       [-0.59135745],\n       [-0.59550887],\n       [-0.5967442 ],\n       [-0.59474013],\n       [-0.59883396]]), 'x_3': array([[-0.59555047],\n       [-0.59397057],\n       [-0.59444432],\n       [-0.59565703],\n       [-0.59600821],\n       [-0.59609727]]), 'x_shared': array([[ 0.        , -0.67987884, -0.70839309, -0.68226504, -0.69665084,\n        -0.67987417],\n       [-0.67987884,  0.        , -0.11655273,  0.07798152,  0.13203774,\n         0.1575433 ],\n       [-0.70839309, -0.11655273,  0.        , -0.39587655, -0.24545434,\n        -0.42665416],\n       [-0.68226504,  0.07798152, -0.39587655,  0.        , -0.59648772,\n        -0.59649148],\n       [-0.69665084,  0.13203774, -0.24545434, -0.59648772,  0.        ,\n        -0.76536914],\n       [-0.67987417,  0.1575433 , -0.42665416, -0.59649148, -0.76536914,\n         0.        ]])}}, {'x_1': {'x_1': array([[0.        , 0.00830552],\n       [0.00830552, 0.        ]]), 'x_2': array([[0.0083529 ],\n       [0.03064471]]), 'x_3': array([[0.00839807],\n       [0.01713854]]), 'x_shared': array([[ 0.00843538,  0.00823691,  0.00754317,  0.00854628,  0.00902024,\n         0.00819458],\n       [ 0.03092797,  0.05231111, -0.16007365,  0.03689895,  0.04683525,\n         0.01248904]])}, 'x_2': {'x_1': array([[0.0083529 , 0.03064471]]), 'x_2': array([[0.]]), 'x_3': array([[0.00688666]]), 'x_shared': array([[0.00706045, 0.01284031, 0.00667439, 0.00817778, 0.00945568,\n        0.0049891 ]])}, 'x_3': {'x_1': array([[0.00839807, 0.01713854]]), 'x_2': array([[0.00688666]]), 'x_3': array([[0.]]), 'x_shared': array([[-0.03740817, -0.02333909, -0.07776429, -0.03563398, -0.03464748,\n        -0.04125889]])}, 'x_shared': {'x_1': array([[ 0.00843538,  0.03092797],\n       [ 0.00823691,  0.05231111],\n       [ 0.00754317, -0.16007365],\n       [ 0.00854628,  0.03689895],\n       [ 0.00902024,  0.04683525],\n       [ 0.00819458,  0.01248904]]), 'x_2': array([[0.00706045],\n       [0.01284031],\n       [0.00667439],\n       [0.00817778],\n       [0.00945568],\n       [0.0049891 ]]), 'x_3': array([[-0.03740817],\n       [-0.02333909],\n       [-0.07776429],\n       [-0.03563398],\n       [-0.03464748],\n       [-0.04125889]]), 'x_shared': array([[ 0.        ,  0.01765723, -0.01112965,  0.01897911,  0.02578004,\n         0.01309436],\n       [ 0.01765723,  0.        ,  0.53426597,  0.58521304,  0.6727104 ,\n         0.69904114],\n       [-0.01112965,  0.53426597,  0.        , -0.08595813,  0.06208561,\n        -0.15926839],\n       [ 0.01897911,  0.58521304, -0.08595813,  0.        ,  0.02356198,\n         0.05499389],\n       [ 0.02578004,  0.6727104 ,  0.06208561,  0.02356198,  0.        ,\n        -0.0268144 ],\n       [ 0.01309436,  0.69904114, -0.15926839,  0.05499389, -0.0268144 ,\n         0.        ]])}}], 'y_21': [{'x_1': {'x_1': array([[ 0.        , -2.44485696],\n       [-2.44485696,  0.        ]]), 'x_2': array([[-2.44404327],\n       [-3.08540115]]), 'x_3': array([[-2.44396937],\n       [-3.15829639]]), 'x_shared': array([[-2.44623436, -2.44367166, -2.44261691, -2.44316239, -2.44861876,\n        -2.44241886],\n       [-2.86120088, -3.00235869, -2.78686209, -3.06869215, -3.21567059,\n        -2.94809138]])}, 'x_2': {'x_1': array([[-2.44404327, -3.08540115]]), 'x_2': array([[0.]]), 'x_3': array([[-2.42929697]]), 'x_shared': array([[-2.42515024, -2.42488221, -2.42796636, -2.43159383, -2.42449795,\n        -2.43384457]])}, 'x_3': {'x_1': array([[-2.44396937, -3.15829639]]), 'x_2': array([[-2.42929697]]), 'x_3': array([[0.]]), 'x_shared': array([[-2.22326733, -2.29489588, -2.23231151, -2.27286145, -2.30136545,\n        -2.25511979]])}, 'x_shared': {'x_1': array([[-2.44623436, -2.86120088],\n       [-2.44367166, -3.00235869],\n       [-2.44261691, -2.78686209],\n       [-2.44316239, -3.06869215],\n       [-2.44861876, -3.21567059],\n       [-2.44241886, -2.94809138]]), 'x_2': array([[-2.42515024],\n       [-2.42488221],\n       [-2.42796636],\n       [-2.43159383],\n       [-2.42449795],\n       [-2.43384457]]), 'x_3': array([[-2.22326733],\n       [-2.29489588],\n       [-2.23231151],\n       [-2.27286145],\n       [-2.30136545],\n       [-2.25511979]]), 'x_shared': array([[ 0.        , -3.16400123, -3.24178415, -3.13458404, -3.41660166,\n        -3.13927321],\n       [-3.16400123,  0.        , -1.83110364, -1.58609702, -1.57548624,\n        -1.49683451],\n       [-3.24178415, -1.83110364,  0.        , -2.04575841, -1.72272189,\n        -2.09388651],\n       [-3.13458404, -1.58609702, -2.04575841,  0.        , -2.25574536,\n        -2.51094519],\n       [-3.41660166, -1.57548624, -1.72272189, -2.25574536,  0.        ,\n        -3.33166901],\n       [-3.13927321, -1.49683451, -2.09388651, -2.51094519, -3.33166901,\n         0.        ]])}}], 'y_23': [{'x_1': {'x_1': array([[ 0.        , -0.59639476],\n       [-0.59639476,  0.        ]]), 'x_2': array([[-0.59639518],\n       [-0.59668333]]), 'x_3': array([[-0.59639482],\n       [-0.5966817 ]]), 'x_shared': array([[-0.59638939, -0.59640338, -0.59641395, -0.59639477, -0.59637678,\n        -0.59640062],\n       [-0.59665062, -0.59659979, -0.59645524, -0.59668216, -0.59672259,\n        -0.59665956]])}, 'x_2': {'x_1': array([[-0.59639518, -0.59668333]]), 'x_2': array([[0.]]), 'x_3': array([[-0.5967372]]), 'x_shared': array([[-0.59557345, -0.59135745, -0.59550887, -0.5967442 , -0.59474013,\n        -0.59883396]])}, 'x_3': {'x_1': array([[-0.59639482, -0.5966817 ]]), 'x_2': array([[-0.5967372]]), 'x_3': array([[0.]]), 'x_shared': array([[-0.59555047, -0.59397057, -0.59444432, -0.59565703, -0.59600821,\n        -0.59609727]])}, 'x_shared': {'x_1': array([[-0.59638939, -0.59665062],\n       [-0.59640338, -0.59659979],\n       [-0.59641395, -0.59645524],\n       [-0.59639477, -0.59668216],\n       [-0.59637678, -0.59672259],\n       [-0.59640062, -0.59665956]]), 'x_2': array([[-0.59557345],\n       [-0.59135745],\n       [-0.59550887],\n       [-0.5967442 ],\n       [-0.59474013],\n       [-0.59883396]]), 'x_3': array([[-0.59555047],\n       [-0.59397057],\n       [-0.59444432],\n       [-0.59565703],\n       [-0.59600821],\n       [-0.59609727]]), 'x_shared': array([[ 0.        , -0.67987884, -0.70839309, -0.68226504, -0.69665084,\n        -0.67987417],\n       [-0.67987884,  0.        , -0.11655273,  0.07798152,  0.13203774,\n         0.1575433 ],\n       [-0.70839309, -0.11655273,  0.        , -0.39587655, -0.24545434,\n        -0.42665416],\n       [-0.68226504,  0.07798152, -0.39587655,  0.        , -0.59648772,\n        -0.59649148],\n       [-0.69665084,  0.13203774, -0.24545434, -0.59648772,  0.        ,\n        -0.76536914],\n       [-0.67987417,  0.1575433 , -0.42665416, -0.59649148, -0.76536914,\n         0.        ]])}}], 'y_24': [{'x_1': {'x_1': array([[0.        , 0.00830552],\n       [0.00830552, 0.        ]]), 'x_2': array([[0.0083529 ],\n       [0.03064471]]), 'x_3': array([[0.00839807],\n       [0.01713854]]), 'x_shared': array([[ 0.00843538,  0.00823691,  0.00754317,  0.00854628,  0.00902024,\n         0.00819458],\n       [ 0.03092797,  0.05231111, -0.16007365,  0.03689895,  0.04683525,\n         0.01248904]])}, 'x_2': {'x_1': array([[0.0083529 , 0.03064471]]), 'x_2': array([[0.]]), 'x_3': array([[0.00688666]]), 'x_shared': array([[0.00706045, 0.01284031, 0.00667439, 0.00817778, 0.00945568,\n        0.0049891 ]])}, 'x_3': {'x_1': array([[0.00839807, 0.01713854]]), 'x_2': array([[0.00688666]]), 'x_3': array([[0.]]), 'x_shared': array([[-0.03740817, -0.02333909, -0.07776429, -0.03563398, -0.03464748,\n        -0.04125889]])}, 'x_shared': {'x_1': array([[ 0.00843538,  0.03092797],\n       [ 0.00823691,  0.05231111],\n       [ 0.00754317, -0.16007365],\n       [ 0.00854628,  0.03689895],\n       [ 0.00902024,  0.04683525],\n       [ 0.00819458,  0.01248904]]), 'x_2': array([[0.00706045],\n       [0.01284031],\n       [0.00667439],\n       [0.00817778],\n       [0.00945568],\n       [0.0049891 ]]), 'x_3': array([[-0.03740817],\n       [-0.02333909],\n       [-0.07776429],\n       [-0.03563398],\n       [-0.03464748],\n       [-0.04125889]]), 'x_shared': array([[ 0.        ,  0.01765723, -0.01112965,  0.01897911,  0.02578004,\n         0.01309436],\n       [ 0.01765723,  0.        ,  0.53426597,  0.58521304,  0.6727104 ,\n         0.69904114],\n       [-0.01112965,  0.53426597,  0.        , -0.08595813,  0.06208561,\n        -0.15926839],\n       [ 0.01897911,  0.58521304, -0.08595813,  0.        ,  0.02356198,\n         0.05499389],\n       [ 0.02578004,  0.6727104 ,  0.06208561,  0.02356198,  0.        ,\n        -0.0268144 ],\n       [ 0.01309436,  0.69904114, -0.15926839,  0.05499389, -0.0268144 ,\n         0.        ]])}}], 'y_3': [{'x_1': {'x_1': array([[ 0.        , -0.01704647],\n       [-0.01704647,  0.        ]]), 'x_2': array([[-0.01704647],\n       [-0.01704647]]), 'x_3': array([[-0.01704647],\n       [-0.01704647]]), 'x_shared': array([[-0.01704647, -0.01704647, -0.01704647, -0.01704647, -0.01704647,\n        -0.01704647],\n       [-0.01704647, -0.01704647, -0.01704647, -0.01704647, -0.01704647,\n        -0.01704647]])}, 'x_2': {'x_1': array([[-0.01704647, -0.01704647]]), 'x_2': array([[0.]]), 'x_3': array([[-0.01704647]]), 'x_shared': array([[-0.01704647, -0.01704647, -0.01704647, -0.01704647, -0.01704647,\n        -0.01704647]])}, 'x_3': {'x_1': array([[-0.01704647, -0.01704647]]), 'x_2': array([[-0.01704647]]), 'x_3': array([[0.]]), 'x_shared': array([[-0.0015891 , -0.00386702,  0.01505761, -0.0015891 , -0.0015891 ,\n        -0.0015891 ]])}, 'x_shared': {'x_1': array([[-0.01704647, -0.01704647],\n       [-0.01704647, -0.01704647],\n       [-0.01704647, -0.01704647],\n       [-0.01704647, -0.01704647],\n       [-0.01704647, -0.01704647],\n       [-0.01704647, -0.01704647]]), 'x_2': array([[-0.01704647],\n       [-0.01704647],\n       [-0.01704647],\n       [-0.01704647],\n       [-0.01704647],\n       [-0.01704647]]), 'x_3': array([[-0.0015891 ],\n       [-0.00386702],\n       [ 0.01505761],\n       [-0.0015891 ],\n       [-0.0015891 ],\n       [-0.0015891 ]]), 'x_shared': array([[ 0.        , -0.01704647, -0.01704647, -0.01704647, -0.01704647,\n        -0.01704647],\n       [-0.01704647,  0.        ,  0.30256195,  0.41417593,  0.41417593,\n         0.41417593],\n       [-0.01704647,  0.30256195,  0.        ,  0.10449216,  0.10449216,\n         0.10449216],\n       [-0.01704647,  0.41417593,  0.10449216,  0.        , -0.01704647,\n        -0.01704647],\n       [-0.01704647,  0.41417593,  0.10449216, -0.01704647,  0.        ,\n        -0.01704647],\n       [-0.01704647,  0.41417593,  0.10449216, -0.01704647, -0.01704647,\n         0.        ]])}}, {'x_1': {'x_1': array([[ 0.        , -0.64983475],\n       [-0.64983475,  0.        ]]), 'x_2': array([[-0.64983515],\n       [-0.65008795]]), 'x_3': array([[-0.6498363 ],\n       [-0.65013203]]), 'x_shared': array([[-0.64982961, -0.64984294, -0.64985322, -0.64983476, -0.64981755,\n        -0.6498404 ],\n       [-0.65005867, -0.65000333, -0.6498799 , -0.65008683, -0.65012373,\n        -0.65006783]])}, 'x_2': {'x_1': array([[-0.64983515, -0.65008795]]), 'x_2': array([[0.]]), 'x_3': array([[-0.6505736]]), 'x_shared': array([[-0.64910071, -0.64502447, -0.64902736, -0.65022444, -0.64831295,\n        -0.6522342 ]])}, 'x_3': {'x_1': array([[-0.6498363 , -0.65013203]]), 'x_2': array([[-0.6505736]]), 'x_3': array([[0.]]), 'x_shared': array([[-0.49387276, -0.52528335, -0.44574003, -0.50767112, -0.51701136,\n        -0.49740547]])}, 'x_shared': {'x_1': array([[-0.64982961, -0.65005867],\n       [-0.64984294, -0.65000333],\n       [-0.64985322, -0.6498799 ],\n       [-0.64983476, -0.65008683],\n       [-0.64981755, -0.65012373],\n       [-0.6498404 , -0.65006783]]), 'x_2': array([[-0.64910071],\n       [-0.64502447],\n       [-0.64902736],\n       [-0.65022444],\n       [-0.64831295],\n       [-0.6522342 ]]), 'x_3': array([[-0.49387276],\n       [-0.52528335],\n       [-0.44574003],\n       [-0.50767112],\n       [-0.51701136],\n       [-0.49740547]]), 'x_shared': array([[ 0.        , -0.73375112, -0.75683497, -0.73458662, -0.74883583,\n        -0.73155155],\n       [-0.73375112,  0.        , -0.21466883, -0.02126292,  0.031749  ,\n         0.05359174],\n       [-0.75683497, -0.21466883,  0.        , -0.53507177, -0.39365149,\n        -0.56084951],\n       [-0.73458662, -0.02126292, -0.53507177,  0.        , -0.64992269,\n        -0.64992595],\n       [-0.74883583,  0.031749  , -0.39365149, -0.64992269,  0.        ,\n        -0.7790996 ],\n       [-0.73155155,  0.05359174, -0.56084951, -0.64992595, -0.7790996 ,\n         0.        ]])}}, {'x_1': {'x_1': array([[ 0.        , -0.65446902],\n       [-0.65446902,  0.        ]]), 'x_2': array([[-0.65446943],\n       [-0.6547183 ]]), 'x_3': array([[-0.65447059],\n       [-0.65476368]]), 'x_shared': array([[-0.65446376, -0.65447717, -0.65448766, -0.65446903, -0.65445145,\n        -0.65447479],\n       [-0.65468846, -0.65463623, -0.65450767, -0.6547172 , -0.65475441,\n        -0.65469715]])}, 'x_2': {'x_1': array([[-0.65446943, -0.6547183 ]]), 'x_2': array([[0.]]), 'x_3': array([[-0.65513895]]), 'x_shared': array([[-0.65364071, -0.64957331, -0.65361609, -0.65478425, -0.65281374,\n        -0.65682092]])}, 'x_3': {'x_1': array([[-0.65447059, -0.65476368]]), 'x_2': array([[-0.65513895]]), 'x_3': array([[0.]]), 'x_shared': array([[-0.49581736, -0.52825994, -0.44619693, -0.50999028, -0.51956593,\n        -0.49936174]])}, 'x_shared': {'x_1': array([[-0.65446376, -0.65468846],\n       [-0.65447717, -0.65463623],\n       [-0.65448766, -0.65450767],\n       [-0.65446903, -0.6547172 ],\n       [-0.65445145, -0.65475441],\n       [-0.65447479, -0.65469715]]), 'x_2': array([[-0.65364071],\n       [-0.64957331],\n       [-0.65361609],\n       [-0.65478425],\n       [-0.65281374],\n       [-0.65682092]]), 'x_3': array([[-0.49581736],\n       [-0.52825994],\n       [-0.44619693],\n       [-0.50999028],\n       [-0.51956593],\n       [-0.49936174]]), 'x_shared': array([[ 0.        , -0.73961162, -0.76367658, -0.74081939, -0.75542285,\n        -0.73782958],\n       [-0.73961162,  0.        , -0.217186  , -0.0253624 ,  0.02780089,\n         0.0503513 ],\n       [-0.76367658, -0.217186  ,  0.        , -0.54523946, -0.4011258 ,\n        -0.57220677],\n       [-0.74081939, -0.0253624 , -0.54523946,  0.        , -0.65455737,\n        -0.65456072],\n       [-0.75542285,  0.02780089, -0.4011258 , -0.65455737,  0.        ,\n        -0.78337698],\n       [-0.73782958,  0.0503513 , -0.57220677, -0.65456072, -0.78337698,\n         0.        ]])}}], 'y_31': [{'x_1': {'x_1': array([[ 0.        , -0.64983475],\n       [-0.64983475,  0.        ]]), 'x_2': array([[-0.64983515],\n       [-0.65008795]]), 'x_3': array([[-0.6498363 ],\n       [-0.65013203]]), 'x_shared': array([[-0.64982961, -0.64984294, -0.64985322, -0.64983476, -0.64981755,\n        -0.6498404 ],\n       [-0.65005867, -0.65000333, -0.6498799 , -0.65008683, -0.65012373,\n        -0.65006783]])}, 'x_2': {'x_1': array([[-0.64983515, -0.65008795]]), 'x_2': array([[0.]]), 'x_3': array([[-0.6505736]]), 'x_shared': array([[-0.64910071, -0.64502447, -0.64902736, -0.65022444, -0.64831295,\n        -0.6522342 ]])}, 'x_3': {'x_1': array([[-0.6498363 , -0.65013203]]), 'x_2': array([[-0.6505736]]), 'x_3': array([[0.]]), 'x_shared': array([[-0.49387276, -0.52528335, -0.44574003, -0.50767112, -0.51701136,\n        -0.49740547]])}, 'x_shared': {'x_1': array([[-0.64982961, -0.65005867],\n       [-0.64984294, -0.65000333],\n       [-0.64985322, -0.6498799 ],\n       [-0.64983476, -0.65008683],\n       [-0.64981755, -0.65012373],\n       [-0.6498404 , -0.65006783]]), 'x_2': array([[-0.64910071],\n       [-0.64502447],\n       [-0.64902736],\n       [-0.65022444],\n       [-0.64831295],\n       [-0.6522342 ]]), 'x_3': array([[-0.49387276],\n       [-0.52528335],\n       [-0.44574003],\n       [-0.50767112],\n       [-0.51701136],\n       [-0.49740547]]), 'x_shared': array([[ 0.        , -0.73375112, -0.75683497, -0.73458662, -0.74883583,\n        -0.73155155],\n       [-0.73375112,  0.        , -0.21466883, -0.02126292,  0.031749  ,\n         0.05359174],\n       [-0.75683497, -0.21466883,  0.        , -0.53507177, -0.39365149,\n        -0.56084951],\n       [-0.73458662, -0.02126292, -0.53507177,  0.        , -0.64992269,\n        -0.64992595],\n       [-0.74883583,  0.031749  , -0.39365149, -0.64992269,  0.        ,\n        -0.7790996 ],\n       [-0.73155155,  0.05359174, -0.56084951, -0.64992595, -0.7790996 ,\n         0.        ]])}}], 'y_32': [{'x_1': {'x_1': array([[ 0.        , -0.65446902],\n       [-0.65446902,  0.        ]]), 'x_2': array([[-0.65446943],\n       [-0.6547183 ]]), 'x_3': array([[-0.65447059],\n       [-0.65476368]]), 'x_shared': array([[-0.65446376, -0.65447717, -0.65448766, -0.65446903, -0.65445145,\n        -0.65447479],\n       [-0.65468846, -0.65463623, -0.65450767, -0.6547172 , -0.65475441,\n        -0.65469715]])}, 'x_2': {'x_1': array([[-0.65446943, -0.6547183 ]]), 'x_2': array([[0.]]), 'x_3': array([[-0.65513895]]), 'x_shared': array([[-0.65364071, -0.64957331, -0.65361609, -0.65478425, -0.65281374,\n        -0.65682092]])}, 'x_3': {'x_1': array([[-0.65447059, -0.65476368]]), 'x_2': array([[-0.65513895]]), 'x_3': array([[0.]]), 'x_shared': array([[-0.49581736, -0.52825994, -0.44619693, -0.50999028, -0.51956593,\n        -0.49936174]])}, 'x_shared': {'x_1': array([[-0.65446376, -0.65468846],\n       [-0.65447717, -0.65463623],\n       [-0.65448766, -0.65450767],\n       [-0.65446903, -0.6547172 ],\n       [-0.65445145, -0.65475441],\n       [-0.65447479, -0.65469715]]), 'x_2': array([[-0.65364071],\n       [-0.64957331],\n       [-0.65361609],\n       [-0.65478425],\n       [-0.65281374],\n       [-0.65682092]]), 'x_3': array([[-0.49581736],\n       [-0.52825994],\n       [-0.44619693],\n       [-0.50999028],\n       [-0.51956593],\n       [-0.49936174]]), 'x_shared': array([[ 0.        , -0.73961162, -0.76367658, -0.74081939, -0.75542285,\n        -0.73782958],\n       [-0.73961162,  0.        , -0.217186  , -0.0253624 ,  0.02780089,\n         0.0503513 ],\n       [-0.76367658, -0.217186  ,  0.        , -0.54523946, -0.4011258 ,\n        -0.57220677],\n       [-0.74081939, -0.0253624 , -0.54523946,  0.        , -0.65455737,\n        -0.65456072],\n       [-0.75542285,  0.02780089, -0.4011258 , -0.65455737,  0.        ,\n        -0.78337698],\n       [-0.73782958,  0.0503513 , -0.57220677, -0.65456072, -0.78337698,\n         0.        ]])}}], 'y_34': [{'x_1': {'x_1': array([[ 0.        , -0.01704647],\n       [-0.01704647,  0.        ]]), 'x_2': array([[-0.01704647],\n       [-0.01704647]]), 'x_3': array([[-0.01704647],\n       [-0.01704647]]), 'x_shared': array([[-0.01704647, -0.01704647, -0.01704647, -0.01704647, -0.01704647,\n        -0.01704647],\n       [-0.01704647, -0.01704647, -0.01704647, -0.01704647, -0.01704647,\n        -0.01704647]])}, 'x_2': {'x_1': array([[-0.01704647, -0.01704647]]), 'x_2': array([[0.]]), 'x_3': array([[-0.01704647]]), 'x_shared': array([[-0.01704647, -0.01704647, -0.01704647, -0.01704647, -0.01704647,\n        -0.01704647]])}, 'x_3': {'x_1': array([[-0.01704647, -0.01704647]]), 'x_2': array([[-0.01704647]]), 'x_3': array([[0.]]), 'x_shared': array([[-0.0015891 , -0.00386702,  0.01505761, -0.0015891 , -0.0015891 ,\n        -0.0015891 ]])}, 'x_shared': {'x_1': array([[-0.01704647, -0.01704647],\n       [-0.01704647, -0.01704647],\n       [-0.01704647, -0.01704647],\n       [-0.01704647, -0.01704647],\n       [-0.01704647, -0.01704647],\n       [-0.01704647, -0.01704647]]), 'x_2': array([[-0.01704647],\n       [-0.01704647],\n       [-0.01704647],\n       [-0.01704647],\n       [-0.01704647],\n       [-0.01704647]]), 'x_3': array([[-0.0015891 ],\n       [-0.00386702],\n       [ 0.01505761],\n       [-0.0015891 ],\n       [-0.0015891 ],\n       [-0.0015891 ]]), 'x_shared': array([[ 0.        , -0.01704647, -0.01704647, -0.01704647, -0.01704647,\n        -0.01704647],\n       [-0.01704647,  0.        ,  0.30256195,  0.41417593,  0.41417593,\n         0.41417593],\n       [-0.01704647,  0.30256195,  0.        ,  0.10449216,  0.10449216,\n         0.10449216],\n       [-0.01704647,  0.41417593,  0.10449216,  0.        , -0.01704647,\n        -0.01704647],\n       [-0.01704647,  0.41417593,  0.10449216, -0.01704647,  0.        ,\n        -0.01704647],\n       [-0.01704647,  0.41417593,  0.10449216, -0.01704647, -0.01704647,\n         0.        ]])}}], 'y_4': [{'x_1': {'x_1': array([[ 0.        , -0.23791398],\n       [-0.23791398,  0.        ]]), 'x_2': array([[-0.23790782],\n       [-0.24412857]]), 'x_3': array([[-0.23791123],\n       [-0.24540145]]), 'x_shared': array([[-0.23787308, -0.2378815 , -0.23774514, -0.23795715, -0.23815544,\n        -0.23795018],\n       [-0.24854548, -0.25077639, -0.20615977, -0.24576713, -0.24923839,\n        -0.24790077]])}, 'x_2': {'x_1': array([[-0.23790782, -0.24412857]]), 'x_2': array([[0.]]), 'x_3': array([[-0.23406768]]), 'x_shared': array([[-0.23506859, -0.22899433, -0.23473725, -0.23250219, -0.2293002 ,\n        -0.23267563]])}, 'x_3': {'x_1': array([[-0.23791123, -0.24540145]]), 'x_2': array([[-0.23406768]]), 'x_3': array([[0.]]), 'x_shared': array([[-0.22229809, -0.22311763, -0.20149952, -0.22030859, -0.2218345 ,\n        -0.22086071]])}, 'x_shared': {'x_1': array([[-0.23787308, -0.24854548],\n       [-0.2378815 , -0.25077639],\n       [-0.23774514, -0.20615977],\n       [-0.23795715, -0.24576713],\n       [-0.23815544, -0.24923839],\n       [-0.23795018, -0.24790077]]), 'x_2': array([[-0.23506859],\n       [-0.22899433],\n       [-0.23473725],\n       [-0.23250219],\n       [-0.2293002 ],\n       [-0.23267563]]), 'x_3': array([[-0.22229809],\n       [-0.22311763],\n       [-0.20149952],\n       [-0.22030859],\n       [-0.2218345 ],\n       [-0.22086071]]), 'x_shared': array([[ 0.        , -0.16278642, -0.10909606, -0.13076867, -0.09116842,\n        -0.13516625],\n       [-0.16278642,  0.        ,  0.32110569,  0.29273649,  0.41905119,\n         0.2829479 ],\n       [-0.10909606,  0.32110569,  0.        , -0.26131068, -0.01032547,\n        -0.25027565],\n       [-0.13076867,  0.29273649, -0.26131068,  0.        , -0.26902898,\n        -0.24009156],\n       [-0.09116842,  0.41905119, -0.01032547, -0.26902898,  0.        ,\n        -0.45492535],\n       [-0.13516625,  0.2829479 , -0.25027565, -0.24009156, -0.45492535,\n         0.        ]])}}]}, total={'g_1': [{'x_1': array([-0.06409028, -0.89924381]), 'x_2': array([-0.20023777]), 'x_3': array([-0.20023777]), 'x_shared': array([ 2.70743344, -0.20023777, -0.20023777,  0.01367927, -0.20023777,\n       -0.44385   ])}, {'x_1': array([-0.08062251, -0.82652285]), 'x_2': array([-0.15276836]), 'x_3': array([-0.15276836]), 'x_shared': array([ 2.08528533, -0.15276836, -0.15276836,  0.21524092, -0.15276836,\n       -0.55035268])}, {'x_1': array([-0.0864275, -0.7898062]), 'x_2': array([-0.13356686]), 'x_3': array([-0.13356686]), 'x_shared': array([ 1.82381834, -0.13356686, -0.13356686,  0.30365424, -0.13356686,\n       -0.59635336])}, {'x_1': array([-0.08928965, -0.76835203]), 'x_2': array([-0.12334036]), 'x_3': array([-0.12334036]), 'x_shared': array([ 1.68201275, -0.12334036, -0.12334036,  0.35253231, -0.12334036,\n       -0.62161246])}, {'x_1': array([-0.09097346, -0.75438013]), 'x_2': array([-0.11701813]), 'x_3': array([-0.11701813]), 'x_shared': array([ 1.59339411, -0.11701813, -0.11701813,  0.38341746, -0.11701813,\n       -0.63751151])}, {'x_1': array([-0.56145556,  0.44974742]), 'x_2': array([-0.08702435]), 'x_3': array([-0.08702435]), 'x_shared': array([-0.08702435, -0.08702435, -0.08702435,  1.40229147, -0.08702435,\n       -1.09440129])}, {'x_1': array([-0.56145556,  0.44974742]), 'x_2': array([-0.08702435]), 'x_3': array([-0.08702435]), 'x_shared': array([-0.08702435, -0.08702435, -0.08702435,  1.40229147, -0.08702435,\n       -1.09440129])}], 'g_2': [{'x_1': array([-0.59687045, -0.59687045]), 'x_2': array([-0.59687045]), 'x_3': array([-0.59687045]), 'x_shared': array([ 6.3652017 , -0.59687045, -0.59687045, -0.59687045, -0.59687045,\n       -0.59687045])}], 'g_3': [{'x_1': array([-0.0010972 , -0.00135805]), 'x_2': array([-0.00445962]), 'x_3': array([0.05848542]), 'x_shared': array([-0.02863292,  0.56154848,  0.27492934, -0.00114928, -0.11721704,\n       -0.06833947])}, {'x_1': array([-0.0010972 , -0.00135805]), 'x_2': array([-0.00445962]), 'x_3': array([0.05848542]), 'x_shared': array([-0.02863292,  0.56154848,  0.27492934, -0.00114928, -0.11721704,\n       -0.06833947])}, {'x_1': array([-0.00443377, -0.00443377]), 'x_2': array([-0.00443377]), 'x_3': array([0.14725238]), 'x_shared': array([-0.00443377,  0.60573952,  0.12196367, -0.00443377, -0.00443377,\n       -0.00443377])}, {'x_1': array([-0.00159737, -0.00159737]), 'x_2': array([-0.00159737]), 'x_3': array([-0.00159737]), 'x_shared': array([-0.00159737, -0.00159737,  1.28191082, -0.00159737, -0.00159737,\n       -0.00159737])}], 'y_1': [{'x_1': array([-0.00382801, -0.28779994]), 'x_2': array([-0.00034189]), 'x_3': array([0.06814377]), 'x_shared': array([-0.2566161 ,  0.38996348,  0.19141919, -0.0362913 , -0.35961796,\n       -0.04686076])}, {'x_1': array([-0.07937656, -0.07937656]), 'x_2': array([-0.07937656]), 'x_3': array([-0.07937656]), 'x_shared': array([-0.05676045, -0.07937656, -0.07937656,  0.36940585, -0.07937656,\n        1.42047138])}, {'x_1': array([-0.56145556,  0.44974742]), 'x_2': array([-0.08702435]), 'x_3': array([-0.08702435]), 'x_shared': array([-0.08702435, -0.08702435, -0.08702435,  1.40229147, -0.08702435,\n       -1.09440129])}], 'y_11': [{'x_1': array([-0.0338149 ,  0.36652652]), 'x_2': array([-0.03715257]), 'x_3': array([0.1270494]), 'x_shared': array([ 0.21045362,  0.47914641, -0.20694599,  0.11033823,  0.06262316,\n        0.52863878])}], 'y_12': [{'x_1': array([-0.00382801, -0.28779994]), 'x_2': array([-0.00034189]), 'x_3': array([0.06814377]), 'x_shared': array([-0.2566161 ,  0.38996348,  0.19141919, -0.0362913 , -0.35961796,\n       -0.04686076])}, {'x_1': array([-0.56145556,  0.44974742]), 'x_2': array([-0.08702435]), 'x_3': array([-0.08702435]), 'x_shared': array([-0.08702435, -0.08702435, -0.08702435,  1.40229147, -0.08702435,\n       -1.09440129])}], 'y_14': [{'x_1': array([-0.00382801, -0.28779994]), 'x_2': array([-0.00034189]), 'x_3': array([0.06814377]), 'x_shared': array([-0.2566161 ,  0.38996348,  0.19141919, -0.0362913 , -0.35961796,\n       -0.04686076])}, {'x_1': array([-0.07937656, -0.07937656]), 'x_2': array([-0.07937656]), 'x_3': array([-0.07937656]), 'x_shared': array([-0.05676045, -0.07937656, -0.07937656,  0.36940585, -0.07937656,\n        1.42047138])}], 'y_2': [{'x_1': array([-0.00382801, -0.28779904]), 'x_2': array([-0.00034187]), 'x_3': array([0.06814447]), 'x_shared': array([-0.25661667,  0.38996229,  0.19141728, -0.03629053, -0.35961755,\n       -0.04686027])}, {'x_1': array([-0.00290415, -0.00323088]), 'x_2': array([-0.00646936]), 'x_3': array([-0.00100787]), 'x_shared': array([-0.02162375,  0.57194863,  0.36071446, -0.00295507, -0.14641397,\n       -0.05889873])}, {'x_1': array([-0.00217609,  0.11584589]), 'x_2': array([-0.00738895]), 'x_3': array([-0.00272057]), 'x_shared': array([-0.0052864 ,  0.56707226,  0.41557318,  0.02545564, -0.11162603,\n       -0.03523156])}], 'y_21': [{'x_1': array([-0.00382801, -0.28779904]), 'x_2': array([-0.00034187]), 'x_3': array([0.06814447]), 'x_shared': array([-0.25661667,  0.38996229,  0.19141728, -0.03629053, -0.35961755,\n       -0.04686027])}], 'y_23': [{'x_1': array([-0.00290415, -0.00323088]), 'x_2': array([-0.00646936]), 'x_3': array([-0.00100787]), 'x_shared': array([-0.02162375,  0.57194863,  0.36071446, -0.00295507, -0.14641397,\n       -0.05889873])}], 'y_24': [{'x_1': array([-0.00217609,  0.11584589]), 'x_2': array([-0.00738895]), 'x_3': array([-0.00272057]), 'x_shared': array([-0.0052864 ,  0.56707226,  0.41557318,  0.02545564, -0.11162603,\n       -0.03523156])}], 'y_3': [{'x_1': array([-0.0009888, -0.0009888]), 'x_2': array([-0.0009888]), 'x_3': array([0.00088859]), 'x_shared': array([-0.0009888 ,  0.45431126,  0.54123151, -0.0009888 , -0.0009888 ,\n       -0.0009888 ])}, {'x_1': array([-0.00111916, -0.00138512]), 'x_2': array([-0.0045175]), 'x_3': array([0.05800667]), 'x_shared': array([-0.02799224,  0.56261159,  0.27780377, -0.00117139, -0.11677492,\n       -0.06829691])}, {'x_1': array([-0.0010972 , -0.00135805]), 'x_2': array([-0.00445962]), 'x_3': array([0.05848542]), 'x_shared': array([-0.02863292,  0.56154848,  0.27492934, -0.00114928, -0.11721704,\n       -0.06833947])}], 'y_31': [{'x_1': array([-0.00111916, -0.00138512]), 'x_2': array([-0.0045175]), 'x_3': array([0.05800667]), 'x_shared': array([-0.02799224,  0.56261159,  0.27780377, -0.00117139, -0.11677492,\n       -0.06829691])}], 'y_32': [{'x_1': array([-0.0010972 , -0.00135805]), 'x_2': array([-0.00445962]), 'x_3': array([0.05848542]), 'x_shared': array([-0.02863292,  0.56154848,  0.27492934, -0.00114928, -0.11721704,\n       -0.06833947])}], 'y_34': [{'x_1': array([-0.0009888, -0.0009888]), 'x_2': array([-0.0009888]), 'x_3': array([0.00088859]), 'x_shared': array([-0.0009888 ,  0.45431126,  0.54123151, -0.0009888 , -0.0009888 ,\n       -0.0009888 ])}], 'y_4': [{'x_1': array([-0.00277676,  0.00126616]), 'x_2': array([-0.00639952]), 'x_3': array([0.00847911]), 'x_shared': array([ 0.03408707,  0.72505752,  0.11247439,  0.04675498, -0.13660393,\n        0.0485379 ])}]})\n</code></pre> <p>Lastly, we draw the Sobol' graph:</p> <pre><code>sobol_graph = SobolGraph.from_analysis(sobol_analysis, output_name=\"y_4\")\nsobol_graph\n</code></pre> x_1[0]     (0, 13) x_1[0] (0, 13) x_1[1]     (0, 13) x_1[1] (0, 13) x_2     (0, 13) x_2 (0, 13) x_3     (1, 12) x_3 (1, 12) x_shared[0]     (3, 8) x_shared[0] (3, 8) x_shared[1]     (73, 28) x_shared[1] (73, 28) x_shared[2]     (11, 37) x_shared[2] (11, 37) x_shared[1]     (73, 28)-&gt;x_shared[2]     (11, 37) x_shared[3]     (5, 17) x_shared[3] (5, 17) x_shared[1]     (73, 28)-&gt;x_shared[3]     (5, 17) x_shared[4]     (0, 20) x_shared[4] (0, 20) x_shared[1]     (73, 28)-&gt;x_shared[4]     (0, 20) x_shared[5]     (5, 17) x_shared[5] (5, 17) x_shared[1]     (73, 28)-&gt;x_shared[5]     (5, 17) <p>Sphinx Gallery and Jupyter Notebook can display <code>sobol_graph</code> in the web browser. You can also use <code>sobol_graph.visualize()</code> to save it on the disk or display it with a dedicated program.</p> <p>Total running time of the script: ( 0 minutes  3.597 seconds)</p> <p> Download Python source code: plot_sobieski_sobol_graph.py</p> <p> Download Jupyter notebook: plot_sobieski_sobol_graph.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/visualizations/uncertain_coupling_graph/mg_execution_times/","title":"Computation times","text":"<p>00:04.014 total execution time for generated_examples_visualizations_uncertain_coupling_graph files:</p> <p>+-----------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_sobieski_coupling_graph (docs/examples/visualizations/uncertain_coupling_graph/plot_sobieski_coupling_graph.py) | 00:04.014 | 0.0 MB | +-----------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+--------+</p>"},{"location":"generated/examples/visualizations/uncertain_coupling_graph/plot_sobieski_coupling_graph/","title":"The uncertain coupling graph for the Sobieski's SSBJ use case.","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/visualizations/uncertain_coupling_graph/plot_sobieski_coupling_graph/#the-uncertain-coupling-graph-for-the-sobieskis-ssbj-use-case","title":"The uncertain coupling graph for the Sobieski's SSBJ use case.","text":"<pre><code>from __future__ import annotations\n\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.problems.mdo.sobieski.core.problem import SobieskiProblem\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiAerodynamics\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiMission\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiPropulsion\nfrom gemseo.problems.mdo.sobieski.disciplines import SobieskiStructure\nfrom gemseo.utils.data_conversion import split_array_to_dict_of_arrays\n\nfrom gemseo_umdo.visualizations.uncertain_coupling_graph import UncertainCouplingGraph\n</code></pre> <p>First, we define an uncertain space around the optimum design:</p> <pre><code>design_space = SobieskiProblem().design_space\ndesign_variable_names = [\"x_1\", \"x_2\", \"x_3\", \"x_shared\"]\ndesign_space.filter(design_variable_names)\noptimum_design = split_array_to_dict_of_arrays(\n    SobieskiProblem().optimum_design,\n    design_space.variable_sizes,\n    design_variable_names,\n)\n\nuncertain_space = DesignSpace()\nfor name, value in optimum_design.items():\n    uncertain_space.add_variable(\n        name,\n        size=value.size,\n        lower_bound=value * 0.95,\n        upper_bound=value * 1.05,\n        value=value,\n    )\n</code></pre> <p>Out:</p> <pre><code>/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/pydantic/main.py:209: DeprecationWarning: Conversion of an array with ndim &gt; 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n</code></pre> <p>Then, we define the disciplines:</p> <pre><code>disciplines = [\n    SobieskiAerodynamics(),\n    SobieskiStructure(),\n    SobieskiPropulsion(),\n    SobieskiMission(),\n]\n</code></pre> <p>Thirdly, we instantiate an uncertain coupling graph:</p> <pre><code>uncertain_coupling_graph = UncertainCouplingGraph(disciplines, uncertain_space)\n</code></pre> <p>and sample the multidisciplinary system with 100 evaluations:</p> <pre><code>uncertain_coupling_graph.sample(100)\n</code></pre> <p>Out:</p> <pre><code>/builds/gemseo/dev/gemseo-umdo/.tox/doc/lib64/python3.9/site-packages/gemseo/problems/mdo/sobieski/core/utils.py:225: DeprecationWarning: Conversion of an array with ndim &gt; 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  ai_coeff[index] = -(f_bound[2] - f_bound[0]) / (2 * mtx_shifted[0, 1])\n</code></pre> <p>Lastly, we visualize it:</p> <pre><code>uncertain_coupling_graph.visualize(save=False, show=True)\n</code></pre> SobieskiAerodynamics SobieskiAerodynamics SobieskiStructure SobieskiStructure SobieskiAerodynamics-&gt;SobieskiStructure y_21 SobieskiPropulsion SobieskiPropulsion SobieskiAerodynamics-&gt;SobieskiPropulsion y_23 SobieskiMission SobieskiMission SobieskiAerodynamics-&gt;SobieskiMission y_24 SobieskiStructure-&gt;SobieskiAerodynamics y_12[0] SobieskiStructure-&gt;SobieskiAerodynamics y_12[1] SobieskiStructure-&gt;SobieskiMission y_14[0] SobieskiStructure-&gt;SobieskiMission y_14[1] SobieskiPropulsion-&gt;SobieskiAerodynamics y_32 SobieskiPropulsion-&gt;SobieskiStructure y_31 SobieskiPropulsion-&gt;SobieskiMission y_34 <p>In this example designed for Sphinx Gallery and Jupyter Notebook, we do not save the graph on the disk (<code>save=False</code>) or display it with a dedicated program (<code>save=True</code>) but display it in the web browser.</p> <p>Total running time of the script: ( 0 minutes  4.014 seconds)</p> <p> Download Python source code: plot_sobieski_coupling_graph.py</p> <p> Download Jupyter notebook: plot_sobieski_coupling_graph.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>gemseo_umdo<ul> <li>_utils<ul> <li>compatibility<ul> <li>openturns</li> </ul> </li> </ul> </li> <li>disciplines<ul> <li>additive_noiser</li> <li>base_noiser</li> <li>multiplicative_noiser</li> <li>noiser_factory</li> </ul> </li> <li>formulations<ul> <li>_functions<ul> <li>base_statistic_function</li> <li>base_statistic_function_for_sampling</li> <li>hessian_function</li> <li>iterative_estimation</li> <li>statistic_function_for_control_variate</li> <li>statistic_function_for_iterative_sampling</li> <li>statistic_function_for_pce</li> <li>statistic_function_for_standard_sampling</li> <li>statistic_function_for_surrogate</li> <li>statistic_function_for_taylor_polynomial</li> </ul> </li> <li>_statistics<ul> <li>base_statistic_estimator</li> <li>control_variate<ul> <li>base_control_variate_estimator</li> <li>factory</li> <li>margin</li> <li>mean</li> <li>probability</li> <li>standard_deviation</li> <li>variance</li> </ul> </li> <li>iterative_sampling<ul> <li>base_central_moment</li> <li>base_sampling_estimator</li> <li>factory</li> <li>margin</li> <li>mean</li> <li>probability</li> <li>standard_deviation</li> <li>variance</li> </ul> </li> <li>pce<ul> <li>base_pce_estimator</li> <li>factory</li> <li>margin</li> <li>mean</li> <li>standard_deviation</li> <li>variance</li> </ul> </li> <li>sampling<ul> <li>base_sampling_estimator</li> <li>factory</li> <li>margin</li> <li>mean</li> <li>probability</li> <li>standard_deviation</li> <li>variance</li> </ul> </li> <li>taylor_polynomial<ul> <li>base_taylor_polynomial_estimator</li> <li>factory</li> <li>margin</li> <li>mean</li> <li>standard_deviation</li> <li>variance</li> </ul> </li> </ul> </li> <li>base_umdo_formulation</li> <li>base_umdo_formulation_settings</li> <li>control_variate</li> <li>control_variate_settings</li> <li>factory</li> <li>pce</li> <li>pce_settings</li> <li>sampling</li> <li>sampling_settings</li> <li>sequential_sampling</li> <li>sequential_sampling_settings</li> <li>surrogate</li> <li>surrogate_settings</li> <li>taylor_polynomial</li> <li>taylor_polynomial_settings</li> </ul> </li> <li>monte_carlo_sampler</li> <li>scenarios<ul> <li>base_u_scenario</li> <li>udoe_scenario</li> <li>umdo_scenario</li> </ul> </li> <li>statistics<ul> <li>multilevel<ul> <li>base_pilot</li> <li>mlmc<ul> <li>level</li> <li>mlmc</li> <li>pilots<ul> <li>base_mlmc_pilot</li> <li>factory</li> <li>mean</li> <li>variance</li> </ul> </li> </ul> </li> <li>mlmc_mlcv<ul> <li>level</li> <li>mlmc_mlcv</li> <li>pilots<ul> <li>base_mlmc_mlcv_pilot</li> <li>factory</li> <li>mean</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> <li>use_cases<ul> <li>beam_model<ul> <li>advanced_uncertain_space</li> <li>constraints</li> <li>core<ul> <li>design_space</li> <li>model</li> <li>output_data</li> <li>variables</li> </ul> </li> <li>design_space</li> <li>discipline</li> <li>uncertain_space</li> </ul> </li> <li>heat_equation<ul> <li>configuration</li> <li>discipline</li> <li>model</li> <li>uncertain_space</li> </ul> </li> <li>spring_mass_model<ul> <li>discipline</li> <li>model</li> <li>uncertain_space</li> </ul> </li> </ul> </li> <li>visualizations<ul> <li>sobol_graph</li> <li>uncertain_coupling_graph</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/gemseo_umdo/","title":"API documentation","text":""},{"location":"reference/gemseo_umdo/#gemseo_umdo","title":"gemseo_umdo","text":"<p>A plug-in for multidisciplinary design under uncertainty.</p>"},{"location":"reference/gemseo_umdo/monte_carlo_sampler/","title":"Monte carlo sampler","text":""},{"location":"reference/gemseo_umdo/monte_carlo_sampler/#gemseo_umdo.monte_carlo_sampler","title":"monte_carlo_sampler","text":"<p>A Monte Carlo sampler.</p>"},{"location":"reference/gemseo_umdo/monte_carlo_sampler/#gemseo_umdo.monte_carlo_sampler-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/monte_carlo_sampler/#gemseo_umdo.monte_carlo_sampler.MonteCarloSampler","title":"MonteCarloSampler","text":"<pre><code>MonteCarloSampler(input_space: DesignSpace)\n</code></pre> <p>A Monte Carlo sampler taking advantage of the vectorized functions.</p> <p>Parameters:</p> <ul> <li> <code>input_space</code>               (<code>DesignSpace</code>)           \u2013            <p>The input space on which to sample the functions.</p> </li> </ul> Source code in <code>src/gemseo_umdo/monte_carlo_sampler.py</code> <pre><code>def __init__(self, input_space: DesignSpace) -&gt; None:\n    \"\"\"\n    Args:\n        input_space: The input space on which to sample the functions.\n    \"\"\"  # noqa:D205 D212 D415\n    self.__algo = OpenTURNS(\"OT_MONTE_CARLO\")\n    self.__functions = []\n    self.__input_space = input_space\n    self.__input_histories = []\n    self.__output_histories = []\n    self.__all_functions_are_vectorized = True\n</code></pre>"},{"location":"reference/gemseo_umdo/monte_carlo_sampler/#gemseo_umdo.monte_carlo_sampler.MonteCarloSampler-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/monte_carlo_sampler/#gemseo_umdo.monte_carlo_sampler.MonteCarloSampler.input_history","title":"input_history  <code>property</code>","text":"<pre><code>input_history: NDArray[float]\n</code></pre> <p>The history of the function inputs.</p>"},{"location":"reference/gemseo_umdo/monte_carlo_sampler/#gemseo_umdo.monte_carlo_sampler.MonteCarloSampler.output_history","title":"output_history  <code>property</code>","text":"<pre><code>output_history: NDArray[float]\n</code></pre> <p>The history of the function outputs.</p>"},{"location":"reference/gemseo_umdo/monte_carlo_sampler/#gemseo_umdo.monte_carlo_sampler.MonteCarloSampler-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/monte_carlo_sampler/#gemseo_umdo.monte_carlo_sampler.MonteCarloSampler.add_function","title":"add_function","text":"<pre><code>add_function(\n    function: FunctionType, is_vectorized: bool = True\n) -&gt; None\n</code></pre> <p>Add a function to sample.</p> <p>Parameters:</p> <ul> <li> <code>function</code>               (<code>FunctionType</code>)           \u2013            <p>A function to sample.</p> </li> <li> <code>is_vectorized</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether the function is vectorized.</p> </li> </ul> Source code in <code>src/gemseo_umdo/monte_carlo_sampler.py</code> <pre><code>def add_function(self, function: FunctionType, is_vectorized: bool = True) -&gt; None:\n    \"\"\"Add a function to sample.\n\n    Args:\n        function: A function to sample.\n        is_vectorized: Whether the function is vectorized.\n    \"\"\"\n    self.__all_functions_are_vectorized &amp;= is_vectorized\n    self.__functions.append(function)\n</code></pre>"},{"location":"reference/gemseo_umdo/_utils/","title":"utils","text":""},{"location":"reference/gemseo_umdo/_utils/#gemseo_umdo._utils","title":"_utils","text":"<p>Utilities.</p>"},{"location":"reference/gemseo_umdo/_utils/compatibility/","title":"Compatibility","text":""},{"location":"reference/gemseo_umdo/_utils/compatibility/#gemseo_umdo._utils.compatibility","title":"compatibility","text":"<p>Compatibility between different versions of packages.</p>"},{"location":"reference/gemseo_umdo/_utils/compatibility/openturns/","title":"Openturns","text":""},{"location":"reference/gemseo_umdo/_utils/compatibility/openturns/#gemseo_umdo._utils.compatibility.openturns","title":"openturns","text":"<p>Compatibility between different versions of openturns.</p>"},{"location":"reference/gemseo_umdo/disciplines/","title":"Disciplines","text":""},{"location":"reference/gemseo_umdo/disciplines/#gemseo_umdo.disciplines","title":"disciplines","text":"<p>Some disciplines.</p>"},{"location":"reference/gemseo_umdo/disciplines/additive_noiser/","title":"Additive noiser","text":""},{"location":"reference/gemseo_umdo/disciplines/additive_noiser/#gemseo_umdo.disciplines.additive_noiser","title":"additive_noiser","text":"<p>A discipline adding a random variable to a variable.</p>"},{"location":"reference/gemseo_umdo/disciplines/additive_noiser/#gemseo_umdo.disciplines.additive_noiser-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/disciplines/additive_noiser/#gemseo_umdo.disciplines.additive_noiser.AdditiveNoiser","title":"AdditiveNoiser","text":"<pre><code>AdditiveNoiser(\n    variable_name: str,\n    noised_variable_name: str,\n    uncertain_variable_name: str,\n)\n</code></pre> <p>               Bases: <code>BaseNoiser</code></p> <p>A discipline adding a random variable to a variable.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>variable_name</code>               (<code>str</code>)           \u2013            <p>The name of the variable to be noised.</p> </li> <li> <code>noised_variable_name</code>               (<code>str</code>)           \u2013            <p>The name of the variable once noised.</p> </li> <li> <code>uncertain_variable_name</code>               (<code>str</code>)           \u2013            <p>The name of the uncertain variable.</p> </li> </ul> Source code in <code>src/gemseo_umdo/disciplines/base_noiser.py</code> <pre><code>def __init__(\n    self,\n    variable_name: str,\n    noised_variable_name: str,\n    uncertain_variable_name: str,\n) -&gt; None:\n    \"\"\"\n    Args:\n        variable_name: The name of the variable to be noised.\n        noised_variable_name: The name of the variable once noised.\n        uncertain_variable_name: The name of the uncertain variable.\n    \"\"\"  # noqa: D205 D212 D415\n    self._noised_variable_name = noised_variable_name\n    self._variable_name = variable_name\n    self._uncertain_variable_name = uncertain_variable_name\n    super().__init__()\n    self.input_grammar.update_from_names([variable_name, uncertain_variable_name])\n    self.output_grammar.update_from_names([noised_variable_name])\n</code></pre>"},{"location":"reference/gemseo_umdo/disciplines/additive_noiser/#gemseo_umdo.disciplines.additive_noiser.AdditiveNoiser-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/disciplines/additive_noiser/#gemseo_umdo.disciplines.additive_noiser.AdditiveNoiser.SHORT_NAME","title":"SHORT_NAME  <code>class-attribute</code>","text":"<pre><code>SHORT_NAME: str = '+'\n</code></pre> <p>A short name of the noising discipline to instantiate it more easily.</p> <p>For example, <code>\"*\"</code> would be a good short name for a <code>\"MultiplicativeNoiser\"</code>, i.e. clear and concise.</p> <p>In particular, this short name can be used to set the <code>uncertain_design_variables</code> argument of UDOEScenario and UMDOScenario.</p>"},{"location":"reference/gemseo_umdo/disciplines/base_noiser/","title":"Base noiser","text":""},{"location":"reference/gemseo_umdo/disciplines/base_noiser/#gemseo_umdo.disciplines.base_noiser","title":"base_noiser","text":"<p>A noising discipline.</p>"},{"location":"reference/gemseo_umdo/disciplines/base_noiser/#gemseo_umdo.disciplines.base_noiser-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/disciplines/base_noiser/#gemseo_umdo.disciplines.base_noiser.BaseNoiser","title":"BaseNoiser","text":"<pre><code>BaseNoiser(\n    variable_name: str,\n    noised_variable_name: str,\n    uncertain_variable_name: str,\n)\n</code></pre> <p>               Bases: <code>Discipline</code></p> <p>A discipline noising a variable.</p> <p>UDOEScenario and UMDOScenario create this kind of discipline when using their argument <code>uncertain_design_variables</code> in order to define the link between design and uncertain variables in an intuitive way.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>variable_name</code>               (<code>str</code>)           \u2013            <p>The name of the variable to be noised.</p> </li> <li> <code>noised_variable_name</code>               (<code>str</code>)           \u2013            <p>The name of the variable once noised.</p> </li> <li> <code>uncertain_variable_name</code>               (<code>str</code>)           \u2013            <p>The name of the uncertain variable.</p> </li> </ul> Source code in <code>src/gemseo_umdo/disciplines/base_noiser.py</code> <pre><code>def __init__(\n    self,\n    variable_name: str,\n    noised_variable_name: str,\n    uncertain_variable_name: str,\n) -&gt; None:\n    \"\"\"\n    Args:\n        variable_name: The name of the variable to be noised.\n        noised_variable_name: The name of the variable once noised.\n        uncertain_variable_name: The name of the uncertain variable.\n    \"\"\"  # noqa: D205 D212 D415\n    self._noised_variable_name = noised_variable_name\n    self._variable_name = variable_name\n    self._uncertain_variable_name = uncertain_variable_name\n    super().__init__()\n    self.input_grammar.update_from_names([variable_name, uncertain_variable_name])\n    self.output_grammar.update_from_names([noised_variable_name])\n</code></pre>"},{"location":"reference/gemseo_umdo/disciplines/base_noiser/#gemseo_umdo.disciplines.base_noiser.BaseNoiser-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/disciplines/base_noiser/#gemseo_umdo.disciplines.base_noiser.BaseNoiser.SHORT_NAME","title":"SHORT_NAME  <code>class-attribute</code>","text":"<pre><code>SHORT_NAME: str = ''\n</code></pre> <p>A short name of the noising discipline to instantiate it more easily.</p> <p>For example, <code>\"*\"</code> would be a good short name for a <code>\"MultiplicativeNoiser\"</code>, i.e. clear and concise.</p> <p>In particular, this short name can be used to set the <code>uncertain_design_variables</code> argument of UDOEScenario and UMDOScenario.</p>"},{"location":"reference/gemseo_umdo/disciplines/multiplicative_noiser/","title":"Multiplicative noiser","text":""},{"location":"reference/gemseo_umdo/disciplines/multiplicative_noiser/#gemseo_umdo.disciplines.multiplicative_noiser","title":"multiplicative_noiser","text":"<p>A discipline multiplying a variable by a random variable plus one.</p>"},{"location":"reference/gemseo_umdo/disciplines/multiplicative_noiser/#gemseo_umdo.disciplines.multiplicative_noiser-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/disciplines/multiplicative_noiser/#gemseo_umdo.disciplines.multiplicative_noiser.MultiplicativeNoiser","title":"MultiplicativeNoiser","text":"<pre><code>MultiplicativeNoiser(\n    variable_name: str,\n    noised_variable_name: str,\n    uncertain_variable_name: str,\n)\n</code></pre> <p>               Bases: <code>BaseNoiser</code></p> <p>A discipline multiplying a variable by a random variable plus one.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>variable_name</code>               (<code>str</code>)           \u2013            <p>The name of the variable to be noised.</p> </li> <li> <code>noised_variable_name</code>               (<code>str</code>)           \u2013            <p>The name of the variable once noised.</p> </li> <li> <code>uncertain_variable_name</code>               (<code>str</code>)           \u2013            <p>The name of the uncertain variable.</p> </li> </ul> Source code in <code>src/gemseo_umdo/disciplines/base_noiser.py</code> <pre><code>def __init__(\n    self,\n    variable_name: str,\n    noised_variable_name: str,\n    uncertain_variable_name: str,\n) -&gt; None:\n    \"\"\"\n    Args:\n        variable_name: The name of the variable to be noised.\n        noised_variable_name: The name of the variable once noised.\n        uncertain_variable_name: The name of the uncertain variable.\n    \"\"\"  # noqa: D205 D212 D415\n    self._noised_variable_name = noised_variable_name\n    self._variable_name = variable_name\n    self._uncertain_variable_name = uncertain_variable_name\n    super().__init__()\n    self.input_grammar.update_from_names([variable_name, uncertain_variable_name])\n    self.output_grammar.update_from_names([noised_variable_name])\n</code></pre>"},{"location":"reference/gemseo_umdo/disciplines/multiplicative_noiser/#gemseo_umdo.disciplines.multiplicative_noiser.MultiplicativeNoiser-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/disciplines/multiplicative_noiser/#gemseo_umdo.disciplines.multiplicative_noiser.MultiplicativeNoiser.SHORT_NAME","title":"SHORT_NAME  <code>class-attribute</code>","text":"<pre><code>SHORT_NAME: str = '*'\n</code></pre> <p>A short name of the noising discipline to instantiate it more easily.</p> <p>For example, <code>\"*\"</code> would be a good short name for a <code>\"MultiplicativeNoiser\"</code>, i.e. clear and concise.</p> <p>In particular, this short name can be used to set the <code>uncertain_design_variables</code> argument of UDOEScenario and UMDOScenario.</p>"},{"location":"reference/gemseo_umdo/disciplines/noiser_factory/","title":"Noiser factory","text":""},{"location":"reference/gemseo_umdo/disciplines/noiser_factory/#gemseo_umdo.disciplines.noiser_factory","title":"noiser_factory","text":"<p>A factory of noising disciplines.</p>"},{"location":"reference/gemseo_umdo/disciplines/noiser_factory/#gemseo_umdo.disciplines.noiser_factory-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/disciplines/noiser_factory/#gemseo_umdo.disciplines.noiser_factory.NoiserFactory","title":"NoiserFactory","text":"<pre><code>NoiserFactory()\n</code></pre> <p>               Bases: <code>DisciplineFactory</code></p> <p>A factory of noising disciplines.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> Source code in <code>src/gemseo_umdo/disciplines/noiser_factory.py</code> <pre><code>def __init__(self):  # noqa: D107\n    super().__init__()\n    self.__short_names_to_class_names = {\n        self.get_class(class_name).SHORT_NAME: class_name\n        for class_name in self.class_names\n    }\n</code></pre>"},{"location":"reference/gemseo_umdo/disciplines/noiser_factory/#gemseo_umdo.disciplines.noiser_factory.NoiserFactory-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/disciplines/noiser_factory/#gemseo_umdo.disciplines.noiser_factory.NoiserFactory.create","title":"create","text":"<pre><code>create(\n    noiser_name: str,\n    variable_name: str,\n    noised_variable_name: str,\n    uncertain_variable_name: str,\n) -&gt; BaseNoiser\n</code></pre> <p>Create an :class:<code>.Discipline</code> from its name.</p> <p>Parameters:</p> <ul> <li> <code>noiser_name</code>               (<code>str</code>)           \u2013            <p>Either the class name or the short name of the noising discipline.</p> </li> <li> <code>variable_name</code>               (<code>str</code>)           \u2013            <p>The name of the variable to be noised.</p> </li> <li> <code>noised_variable_name</code>               (<code>str</code>)           \u2013            <p>The name of the variable once noised.</p> </li> <li> <code>uncertain_variable_name</code>               (<code>str</code>)           \u2013            <p>The name of the uncertain variable.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>BaseNoiser</code>           \u2013            <p>The discipline.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>TypeError</code>             \u2013            <p>If the class cannot be instantiated.</p> </li> </ul> Source code in <code>src/gemseo_umdo/disciplines/noiser_factory.py</code> <pre><code>def create(\n    self,\n    noiser_name: str,\n    variable_name: str,\n    noised_variable_name: str,\n    uncertain_variable_name: str,\n) -&gt; BaseNoiser:\n    \"\"\"\n    Args:\n        noiser_name: Either the class name or the short name\n            of the noising discipline.\n        variable_name: The name of the variable to be noised.\n        noised_variable_name: The name of the variable once noised.\n        uncertain_variable_name: The name of the uncertain variable.\n    \"\"\"  # noqa: D205 D212 D415\n    class_names = self.class_names\n    if noiser_name in class_names:\n        class_name = noiser_name\n    else:\n        class_name = self.__short_names_to_class_names[noiser_name]\n\n    return super().create(\n        class_name,\n        variable_name=variable_name,\n        noised_variable_name=noised_variable_name,\n        uncertain_variable_name=uncertain_variable_name,\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/","title":"Formulations","text":""},{"location":"reference/gemseo_umdo/formulations/#gemseo_umdo.formulations","title":"formulations","text":"<p>Formulations for multidisciplinary design problems under uncertainty.</p> <p>An MDOFormulation defines an OptimizationProblem from one or several MDODisciplines, a DesignSpace, an objective and constraints. The objective can be either minimized (default) or maximized.</p> <p>In the context of deterministic MDO, the OptimizationProblem is handled by a driver (see DriverLibrary), typically an optimizer (see OptimizationLibrary), or a design of experiments (DOE, see DOELibrary).</p> <p>In the frame of U-MDO, the BaseUMDOFormulation uses an MDOFormulation with a ParameterSpace defining the uncertain variables and executes the corresponding OptimizationProblem with a particular DOE. Then, it post-processed the associated Database to estimate the statistics applied to the objective and constraints.</p> <p>The most common BaseUMDOFormulation is Sampling, consisting in estimating the statistics with (quasi) Monte Carlo techniques.</p>"},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation/","title":"Base umdo formulation","text":""},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation/#gemseo_umdo.formulations.base_umdo_formulation","title":"base_umdo_formulation","text":"<p>Base class for U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation/#gemseo_umdo.formulations.base_umdo_formulation-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation/#gemseo_umdo.formulations.base_umdo_formulation.BaseUMDOFormulation","title":"BaseUMDOFormulation","text":"<pre><code>BaseUMDOFormulation(\n    disciplines: Sequence[Discipline],\n    objective_name: str,\n    design_space: DesignSpace,\n    mdo_formulation: BaseMDOFormulation,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    objective_statistic_parameters: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    mdo_formulation_settings: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    **settings: Any\n)\n</code></pre> <p>               Bases: <code>BaseFormulation</code></p> <p>Base class for U-MDO formulations.</p> <p>A U-MDO formulation rewrites a multidisciplinary optimization problem under uncertainty, a.k.a. U-MDO problem, as a standard optimization problem without uncertainty.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>disciplines</code>               (<code>Sequence[Discipline]</code>)           \u2013            <p>The disciplines.</p> </li> <li> <code>objective_name</code>               (<code>str</code>)           \u2013            <p>The name(s) of the discipline output(s) used as objective. If multiple names are passed, the objective will be a vector.</p> </li> <li> <code>design_space</code>               (<code>DesignSpace</code>)           \u2013            <p>The design space.</p> </li> <li> <code>mdo_formulation</code>               (<code>BaseMDOFormulation</code>)           \u2013            <p>The MDO formulation generating functions evaluable over the uncertain space and differentiable with respect to the design variables.</p> </li> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain variables with their probability distributions.</p> </li> <li> <code>objective_statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the objective.</p> </li> <li> <code>objective_statistic_parameters</code>               (<code>StrKeyMapping</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The values of the parameters of the statistic to be applied to the objective, if any.</p> </li> <li> <code>mdo_formulation_settings</code>               (<code>StrKeyMapping</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The settings of the MDO formulation.</p> </li> <li> <code>**settings</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The settings of the formulation. This argument is ignored when <code>settings_model</code> is not <code>None</code>.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def __init__(\n    self,\n    disciplines: Sequence[Discipline],\n    objective_name: str,\n    design_space: DesignSpace,\n    mdo_formulation: BaseMDOFormulation,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    objective_statistic_parameters: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    mdo_formulation_settings: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    **settings: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        mdo_formulation: The MDO formulation\n            generating functions evaluable over the uncertain space\n            and differentiable with respect to the design variables.\n        uncertain_space: The uncertain variables\n            with their probability distributions.\n        objective_statistic_name: The name of the statistic\n            to be applied to the objective.\n        objective_statistic_parameters: The values of the parameters\n            of the statistic to be applied to the objective, if any.\n        mdo_formulation_settings: The settings of the MDO formulation.\n    \"\"\"  # noqa: D205 D212 D415\n    if self._STATISTIC_FUNCTION_CLASS is not None:\n        self._statistic_function_class = self._STATISTIC_FUNCTION_CLASS\n        self._statistic_factory = self._STATISTIC_FACTORY\n\n    self.__available_statistics = self._statistic_factory.class_names\n    self._mdo_formulation = mdo_formulation\n    self._uncertain_space = uncertain_space\n\n    # Create the auxiliary MDO formulation if required.\n    self._auxiliary_mdo_formulation = None\n    if self._USE_AUXILIARY_MDO_FORMULATION:\n        self._auxiliary_mdo_formulation = mdo_formulation.__class__(\n            disciplines,\n            objective_name,\n            uncertain_space,\n            **mdo_formulation_settings,\n        )\n\n    # Create the objective name.\n    objective_name = self.__compute_name(\n        objective_name,\n        objective_statistic_name,\n        **objective_statistic_parameters,\n    )\n    super().__init__(disciplines, objective_name, design_space, **settings)\n    self.name = f\"{self.__class__.__name__}[{mdo_formulation.__class__.__name__}]\"\n\n    # Replace the objective function by a statistic function.\n    sub_opt_problem = mdo_formulation.optimization_problem\n    objective = self._statistic_function_class(\n        self,\n        sub_opt_problem.objective,\n        MDOFunction.FunctionType.OBJ,\n        objective_statistic_name,\n        **objective_statistic_parameters,\n    )\n    objective.name = objective_name\n    self.optimization_problem.objective = objective\n    self.optimization_problem.minimize_objective = (\n        mdo_formulation.optimization_problem.minimize_objective\n    )\n\n    # Initialize the cache mechanism.\n    self.input_data_to_output_data = {}\n    self.optimization_problem.add_listener(self._clear_input_data_to_output_data)\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation/#gemseo_umdo.formulations.base_umdo_formulation.BaseUMDOFormulation-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation/#gemseo_umdo.formulations.base_umdo_formulation.BaseUMDOFormulation.auxiliary_mdo_formulation","title":"auxiliary_mdo_formulation  <code>property</code>","text":"<pre><code>auxiliary_mdo_formulation: BaseMDOFormulation\n</code></pre> <p>The auxiliary MDO formulation.</p> <p>The functions are evaluable over the uncertain space and differentiable with respect to the uncertain variables.</p>"},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation/#gemseo_umdo.formulations.base_umdo_formulation.BaseUMDOFormulation.available_statistics","title":"available_statistics  <code>property</code>","text":"<pre><code>available_statistics: list[str]\n</code></pre> <p>The names of the statistics to quantify the output uncertainties.</p>"},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation/#gemseo_umdo.formulations.base_umdo_formulation.BaseUMDOFormulation.input_data_to_output_data","title":"input_data_to_output_data  <code>instance-attribute</code>","text":"<pre><code>input_data_to_output_data: dict[\n    HashableNdarray, dict[str, Any]\n] = {}\n</code></pre> <p>The output samples or output statistics associated with the input data.</p>"},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation/#gemseo_umdo.formulations.base_umdo_formulation.BaseUMDOFormulation.mdo_formulation","title":"mdo_formulation  <code>property</code>","text":"<pre><code>mdo_formulation: BaseMDOFormulation\n</code></pre> <p>The MDO formulation.</p> <p>The functions are evaluable over the uncertain space and differentiable with respect to the design variables.</p>"},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation/#gemseo_umdo.formulations.base_umdo_formulation.BaseUMDOFormulation.uncertain_space","title":"uncertain_space  <code>property</code>","text":"<pre><code>uncertain_space: ParameterSpace\n</code></pre> <p>The uncertain variable space.</p>"},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation/#gemseo_umdo.formulations.base_umdo_formulation.BaseUMDOFormulation-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation/#gemseo_umdo.formulations.base_umdo_formulation.BaseUMDOFormulation.add_constraint","title":"add_constraint","text":"<pre><code>add_constraint(\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: ConstraintType = INEQ,\n    constraint_name: str = \"\",\n    value: float = 0.0,\n    positive: bool = False,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Add an equality or inequality constraint to the optimization problem.</p> <p>An equality constraint is written as :math:<code>c(x)=a</code>, a positive inequality constraint is written as :math:<code>c(x)\\geq a</code> and a negative inequality constraint is written as :math:<code>c(x)\\leq a</code>.</p> <p>This constraint is in addition to those created by the formulation, e.g. consistency constraints in IDF.</p> <p>The strategy of repartition of the constraints is defined by the formulation.</p> <p>Parameters:</p> <ul> <li> <code>output_name</code>               (<code>str | Sequence[str]</code>)           \u2013            <p>The name(s) of the outputs computed by :math:<code>c(x)</code>. If several names are given, a single discipline must provide all outputs.</p> </li> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the constraint.</p> </li> <li> <code>constraint_type</code>               (<code>ConstraintType</code>, default:                   <code>INEQ</code> )           \u2013            <p>The type of constraint.</p> </li> <li> <code>constraint_name</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>The name of the constraint to be stored. If empty, the name of the constraint is generated from <code>output_name</code>, <code>constraint_type</code>, <code>value</code> and <code>positive</code>.</p> </li> <li> <code>value</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>The value :math:<code>a</code>.</p> </li> <li> <code>positive</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether the inequality constraint is positive.</p> </li> <li> <code>**statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def add_constraint(\n    self,\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: MDOFunction.ConstraintType = MDOFunction.ConstraintType.INEQ,\n    constraint_name: str = \"\",\n    value: float = 0.0,\n    positive: bool = False,\n    **statistic_parameters: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        statistic_name: The name of the statistic to be applied to the constraint.\n        statistic_parameters: The values of the parameters of the statistic\n            to be applied to the constraint, if any.\n    \"\"\"  # noqa: D205 D212 D415\n    if self._auxiliary_mdo_formulation is not None:\n        self._auxiliary_mdo_formulation.add_observable(output_name)\n\n    self._mdo_formulation.add_observable(output_name)\n    constraint = self._statistic_function_class(\n        self,\n        self._mdo_formulation.optimization_problem.observables[-1],\n        MDOFunction.FunctionType.NONE,\n        statistic_name,\n        **statistic_parameters,\n    )\n    name = self.__compute_name(output_name, statistic_name, **statistic_parameters)\n    constraint.output_names = [name]\n    if constraint_name:\n        constraint.name = constraint_name\n        constraint.has_default_name = False\n    else:\n        constraint.name = name\n        constraint.has_default_name = True\n    self.optimization_problem.add_constraint(\n        constraint,\n        value=value,\n        positive=positive,\n        constraint_type=constraint_type,\n    )\n    self._post_add_constraint()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation/#gemseo_umdo.formulations.base_umdo_formulation.BaseUMDOFormulation.add_observable","title":"add_observable","text":"<pre><code>add_observable(\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: str = \"\",\n    discipline: Discipline | None = None,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Add an observable to the optimization problem.</p> <p>The repartition strategy of the observable is defined in the formulation class.</p> <p>Parameters:</p> <ul> <li> <code>output_names</code>               (<code>Sequence[str]</code>)           \u2013            <p>The name(s) of the output(s) to observe.</p> </li> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the observable.</p> </li> <li> <code>observable_name</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>The name of the observable. If empty, the output name is used by default.</p> </li> <li> <code>discipline</code>               (<code>Discipline | None</code>, default:                   <code>None</code> )           \u2013            <p>The discipline computing the observed outputs. If <code>None</code>, the discipline is detected from inner disciplines.</p> </li> <li> <code>**statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def add_observable(\n    self,\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: str = \"\",\n    discipline: Discipline | None = None,\n    **statistic_parameters: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        statistic_name: The name of the statistic to be applied to the observable.\n        statistic_parameters: The values of the parameters\n            of the statistic to be applied to the observable, if any.\n    \"\"\"  # noqa: D205 D212 D415\n    if self._auxiliary_mdo_formulation is not None:\n        self._auxiliary_mdo_formulation.add_observable(\n            output_names,\n            observable_name=observable_name,\n            discipline=discipline,\n        )\n\n    self._mdo_formulation.add_observable(\n        output_names,\n        observable_name=observable_name,\n        discipline=discipline,\n    )\n    sub_opt_problem = self._mdo_formulation.optimization_problem\n    observable = self._statistic_function_class(\n        self,\n        sub_opt_problem.observables[-1],\n        MDOFunction.FunctionType.NONE,\n        statistic_name,\n        **statistic_parameters,\n    )\n    observable.name = self.__compute_name(\n        observable_name or output_names, statistic_name, **statistic_parameters\n    )\n    self.optimization_problem.add_observable(observable)\n    self._post_add_observable()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation/#gemseo_umdo.formulations.base_umdo_formulation.BaseUMDOFormulation.get_top_level_disciplines","title":"get_top_level_disciplines","text":"<pre><code>get_top_level_disciplines() -&gt; list[Discipline]\n</code></pre> <p>Return the disciplines which inputs are required to run the scenario.</p> <p>A formulation seeks to compute the objective and constraints from the input variables. It structures the optimization problem into multiple levels of disciplines. The disciplines directly depending on these inputs are called top level disciplines.</p> <p>By default, this method returns all disciplines. This method can be overloaded by subclasses.</p> <p>Returns:</p> <ul> <li> <code>list[Discipline]</code>           \u2013            <p>The top level disciplines.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def get_top_level_disciplines(self) -&gt; list[Discipline]:  # noqa: D102\n    return self._mdo_formulation.get_top_level_disciplines()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation/#gemseo_umdo.formulations.base_umdo_formulation.BaseUMDOFormulation.update_top_level_disciplines","title":"update_top_level_disciplines","text":"<pre><code>update_top_level_disciplines(\n    design_values: RealArray,\n) -&gt; None\n</code></pre> <p>Update the default input values of the top-level disciplines.</p> <p>Parameters:</p> <ul> <li> <code>design_values</code>               (<code>RealArray</code>)           \u2013            <p>The values of the design variables to update the default input values of the top-level disciplines.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def update_top_level_disciplines(self, design_values: RealArray) -&gt; None:\n    \"\"\"Update the default input values of the top-level disciplines.\n\n    Args:\n        design_values: The values of the design variables\n            to update the default input values of the top-level disciplines.\n    \"\"\"\n    design_values = split_array_to_dict_of_arrays(\n        design_values,\n        self.design_space.variable_sizes,\n        self.design_space.variable_names,\n    )\n    for formulation in [self._mdo_formulation, self._auxiliary_mdo_formulation]:\n        if formulation is None:\n            continue\n\n        for discipline in formulation.get_top_level_disciplines():\n            discipline.default_input_data.update({\n                k: v\n                for k, v in design_values.items()\n                if k in discipline.input_grammar\n            })\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation_settings/","title":"Base umdo formulation settings","text":""},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation_settings/#gemseo_umdo.formulations.base_umdo_formulation_settings","title":"base_umdo_formulation_settings","text":"<p>The base class for the settings of U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation_settings/#gemseo_umdo.formulations.base_umdo_formulation_settings-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/base_umdo_formulation_settings/#gemseo_umdo.formulations.base_umdo_formulation_settings.BaseUMDOFormulationSettings","title":"BaseUMDOFormulationSettings","text":"<p>               Bases: <code>BaseModel</code></p> <p>The base class for the settings of U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/control_variate/","title":"Control variate","text":""},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate","title":"control_variate","text":"<p>Control variate-based U-MDO formulation.</p> <p>ControlVariate is an BaseUMDOFormulation estimating the statistics with first-order Taylor polynomials as control variates:</p> \\[\\tilde{f}(x,u)=f(x,\\mu) + (u-\\mu)\\frac{\\partial f(x,\\mu)}{\\partial u}\\] <p>where \\(u\\) is a realization of the random variable \\(U\\) and \\(\\mu=\\mathbb{E}[U]\\).</p> <p>The expectation \\(\\mathbb{E}[f(x,U)]\\) can be approximated by the control variate estimator</p> \\[\\frac{1}{N}\\sum_{i=1}^N f\\left(x,U^{(i)}\\right) +\\alpha_N\\left(\\frac{1}{N}\\sum_{j=1}^N \\tilde{f}\\left(x,U^{(j)}\\right)-f(x,\\mu)\\right)\\] <p>where \\(\\alpha_N\\) is the empirical estimator of \\(\\frac{\\text{cov}\\left[f(x,U),\\tilde{f}(x,u)\\right]} {\\mathbb{V}\\left[f(x,U)\\right]}\\) and \\(U^{(1)},\\ldots,U^{(N)}\\) are \\(N\\) independent realizations of \\(U\\).</p>"},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate.ControlVariate","title":"ControlVariate","text":"<pre><code>ControlVariate(\n    disciplines: Sequence[Discipline],\n    objective_name: str,\n    design_space: DesignSpace,\n    mdo_formulation: BaseMDOFormulation,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    n_samples: int | None,\n    objective_statistic_parameters: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    algo: str = \"OT_OPT_LHS\",\n    algo_options: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    seed: int = SEED,\n    mdo_formulation_settings: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    **settings: Any\n)\n</code></pre> <p>               Bases: <code>BaseUMDOFormulation</code></p> <p>Control variate-based U-MDO formulation.</p> <p>DOE algorithms</p> <p>This formulation uses a DOE algorithm; read the GEMSEO documentation. for more information about the available DOE algorithm names and options.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>disciplines</code>               (<code>Sequence[Discipline]</code>)           \u2013            <p>The disciplines.</p> </li> <li> <code>objective_name</code>               (<code>str</code>)           \u2013            <p>The name(s) of the discipline output(s) used as objective. If multiple names are passed, the objective will be a vector.</p> </li> <li> <code>design_space</code>               (<code>DesignSpace</code>)           \u2013            <p>The design space.</p> </li> <li> <code>mdo_formulation</code>               (<code>BaseMDOFormulation</code>)           \u2013            <p>The MDO formulation generating functions evaluable over the uncertain space and differentiable with respect to the design variables.</p> </li> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain variables with their probability distributions.</p> </li> <li> <code>objective_statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the objective.</p> </li> <li> <code>n_samples</code>               (<code>int | None</code>)           \u2013            <p>The number of samples to be generated by the DOE algorithm. If <code>None</code>, the DOE algorithm uses no <code>n_samples</code> argument but potentially a mandatory argument to be defined in <code>algo_options</code> (e.g. <code>samples</code> for the <code>CustomDOE</code> algorithm).</p> </li> <li> <code>objective_statistic_parameters</code>               (<code>StrKeyMapping</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The values of the parameters of the statistic to be applied to the objective, if any.</p> </li> <li> <code>algo</code>               (<code>str</code>, default:                   <code>'OT_OPT_LHS'</code> )           \u2013            <p>The name of the DOE algorithm.</p> </li> <li> <code>algo_options</code>               (<code>StrKeyMapping</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The options of the DOE algorithm.</p> </li> <li> <code>seed</code>               (<code>int</code>, default:                   <code>SEED</code> )           \u2013            <p>The seed for reproducibility.</p> </li> <li> <code>mdo_formulation_settings</code>               (<code>StrKeyMapping</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The settings of the MDO formulation.</p> </li> <li> <code>**settings</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The settings of the formulation. This argument is ignored when <code>settings_model</code> is not <code>None</code>.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/control_variate.py</code> <pre><code>def __init__(\n    self,\n    disciplines: Sequence[Discipline],\n    objective_name: str,\n    design_space: DesignSpace,\n    mdo_formulation: BaseMDOFormulation,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    n_samples: int | None,\n    objective_statistic_parameters: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    algo: str = \"OT_OPT_LHS\",\n    algo_options: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    seed: int = SEED,\n    mdo_formulation_settings: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    **settings: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        n_samples: The number of samples to be generated by the DOE algorithm.\n            If `None`,\n            the DOE algorithm uses no `n_samples` argument\n            but potentially a mandatory argument to be defined in `algo_options`\n            (e.g. `samples` for the `CustomDOE` algorithm).\n        algo: The name of the DOE algorithm.\n        algo_options: The options of the DOE algorithm.\n        seed: The seed for reproducibility.\n    \"\"\"  # noqa: D205 D212 D415\n    self.__doe_algo = DOELibraryFactory().create(algo)\n    self.__doe_algo_options = dict(algo_options)\n    if \"n_samples\" in self.__doe_algo.ALGORITHM_INFOS[algo].Settings.model_fields:\n        self.__doe_algo_options[\"n_samples\"] = n_samples\n    self.__n_samples = n_samples\n    self.__seed = seed\n    super().__init__(\n        disciplines,\n        objective_name,\n        design_space,\n        mdo_formulation,\n        uncertain_space,\n        objective_statistic_name,\n        objective_statistic_parameters=objective_statistic_parameters,\n        mdo_formulation_settings=mdo_formulation_settings,\n        **settings,\n    )\n    self.name = (\n        f\"{self.__class__.__name__}\"\n        f\"[{mdo_formulation.__class__.__name__}; {algo}({n_samples})]\"\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate.ControlVariate-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate.ControlVariate.auxiliary_mdo_formulation","title":"auxiliary_mdo_formulation  <code>property</code>","text":"<pre><code>auxiliary_mdo_formulation: BaseMDOFormulation\n</code></pre> <p>The auxiliary MDO formulation.</p> <p>The functions are evaluable over the uncertain space and differentiable with respect to the uncertain variables.</p>"},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate.ControlVariate.available_statistics","title":"available_statistics  <code>property</code>","text":"<pre><code>available_statistics: list[str]\n</code></pre> <p>The names of the statistics to quantify the output uncertainties.</p>"},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate.ControlVariate.doe_algo","title":"doe_algo  <code>property</code>","text":"<pre><code>doe_algo: BaseDOELibrary\n</code></pre> <p>The DOE library configured with an algorithm.</p>"},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate.ControlVariate.input_data_to_output_data","title":"input_data_to_output_data  <code>instance-attribute</code>","text":"<pre><code>input_data_to_output_data: dict[\n    HashableNdarray, dict[str, Any]\n] = {}\n</code></pre> <p>The output samples or output statistics associated with the input data.</p>"},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate.ControlVariate.mdo_formulation","title":"mdo_formulation  <code>property</code>","text":"<pre><code>mdo_formulation: BaseMDOFormulation\n</code></pre> <p>The MDO formulation.</p> <p>The functions are evaluable over the uncertain space and differentiable with respect to the design variables.</p>"},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate.ControlVariate.uncertain_space","title":"uncertain_space  <code>property</code>","text":"<pre><code>uncertain_space: ParameterSpace\n</code></pre> <p>The uncertain variable space.</p>"},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate.ControlVariate-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate.ControlVariate.add_constraint","title":"add_constraint","text":"<pre><code>add_constraint(\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: ConstraintType = INEQ,\n    constraint_name: str = \"\",\n    value: float = 0.0,\n    positive: bool = False,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Add an equality or inequality constraint to the optimization problem.</p> <p>An equality constraint is written as :math:<code>c(x)=a</code>, a positive inequality constraint is written as :math:<code>c(x)\\geq a</code> and a negative inequality constraint is written as :math:<code>c(x)\\leq a</code>.</p> <p>This constraint is in addition to those created by the formulation, e.g. consistency constraints in IDF.</p> <p>The strategy of repartition of the constraints is defined by the formulation.</p> <p>Parameters:</p> <ul> <li> <code>output_name</code>               (<code>str | Sequence[str]</code>)           \u2013            <p>The name(s) of the outputs computed by :math:<code>c(x)</code>. If several names are given, a single discipline must provide all outputs.</p> </li> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the constraint.</p> </li> <li> <code>constraint_type</code>               (<code>ConstraintType</code>, default:                   <code>INEQ</code> )           \u2013            <p>The type of constraint.</p> </li> <li> <code>constraint_name</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>The name of the constraint to be stored. If empty, the name of the constraint is generated from <code>output_name</code>, <code>constraint_type</code>, <code>value</code> and <code>positive</code>.</p> </li> <li> <code>value</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>The value :math:<code>a</code>.</p> </li> <li> <code>positive</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether the inequality constraint is positive.</p> </li> <li> <code>**statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def add_constraint(\n    self,\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: MDOFunction.ConstraintType = MDOFunction.ConstraintType.INEQ,\n    constraint_name: str = \"\",\n    value: float = 0.0,\n    positive: bool = False,\n    **statistic_parameters: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        statistic_name: The name of the statistic to be applied to the constraint.\n        statistic_parameters: The values of the parameters of the statistic\n            to be applied to the constraint, if any.\n    \"\"\"  # noqa: D205 D212 D415\n    if self._auxiliary_mdo_formulation is not None:\n        self._auxiliary_mdo_formulation.add_observable(output_name)\n\n    self._mdo_formulation.add_observable(output_name)\n    constraint = self._statistic_function_class(\n        self,\n        self._mdo_formulation.optimization_problem.observables[-1],\n        MDOFunction.FunctionType.NONE,\n        statistic_name,\n        **statistic_parameters,\n    )\n    name = self.__compute_name(output_name, statistic_name, **statistic_parameters)\n    constraint.output_names = [name]\n    if constraint_name:\n        constraint.name = constraint_name\n        constraint.has_default_name = False\n    else:\n        constraint.name = name\n        constraint.has_default_name = True\n    self.optimization_problem.add_constraint(\n        constraint,\n        value=value,\n        positive=positive,\n        constraint_type=constraint_type,\n    )\n    self._post_add_constraint()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate.ControlVariate.add_observable","title":"add_observable","text":"<pre><code>add_observable(\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: str = \"\",\n    discipline: Discipline | None = None,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Add an observable to the optimization problem.</p> <p>The repartition strategy of the observable is defined in the formulation class.</p> <p>Parameters:</p> <ul> <li> <code>output_names</code>               (<code>Sequence[str]</code>)           \u2013            <p>The name(s) of the output(s) to observe.</p> </li> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the observable.</p> </li> <li> <code>observable_name</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>The name of the observable. If empty, the output name is used by default.</p> </li> <li> <code>discipline</code>               (<code>Discipline | None</code>, default:                   <code>None</code> )           \u2013            <p>The discipline computing the observed outputs. If <code>None</code>, the discipline is detected from inner disciplines.</p> </li> <li> <code>**statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def add_observable(\n    self,\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: str = \"\",\n    discipline: Discipline | None = None,\n    **statistic_parameters: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        statistic_name: The name of the statistic to be applied to the observable.\n        statistic_parameters: The values of the parameters\n            of the statistic to be applied to the observable, if any.\n    \"\"\"  # noqa: D205 D212 D415\n    if self._auxiliary_mdo_formulation is not None:\n        self._auxiliary_mdo_formulation.add_observable(\n            output_names,\n            observable_name=observable_name,\n            discipline=discipline,\n        )\n\n    self._mdo_formulation.add_observable(\n        output_names,\n        observable_name=observable_name,\n        discipline=discipline,\n    )\n    sub_opt_problem = self._mdo_formulation.optimization_problem\n    observable = self._statistic_function_class(\n        self,\n        sub_opt_problem.observables[-1],\n        MDOFunction.FunctionType.NONE,\n        statistic_name,\n        **statistic_parameters,\n    )\n    observable.name = self.__compute_name(\n        observable_name or output_names, statistic_name, **statistic_parameters\n    )\n    self.optimization_problem.add_observable(observable)\n    self._post_add_observable()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate.ControlVariate.compute_samples","title":"compute_samples","text":"<pre><code>compute_samples(problem: OptimizationProblem) -&gt; None\n</code></pre> <p>Evaluate the functions of a problem with a DOE algorithm.</p> <p>Parameters:</p> <ul> <li> <code>problem</code>               (<code>OptimizationProblem</code>)           \u2013            <p>The problem.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/control_variate.py</code> <pre><code>def compute_samples(self, problem: OptimizationProblem) -&gt; None:\n    \"\"\"Evaluate the functions of a problem with a DOE algorithm.\n\n    Args:\n        problem: The problem.\n    \"\"\"\n    with LoggingContext(logging.getLogger(\"gemseo\")):\n        self.__doe_algo.seed = self.__seed\n        self.__doe_algo.execute(problem, **self.__doe_algo_options)\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate.ControlVariate.evaluate_with_mean","title":"evaluate_with_mean","text":"<pre><code>evaluate_with_mean() -&gt; None\n</code></pre> <p>Evaluate the Taylor polynomials at the mean value of the uncertain vector.</p> Source code in <code>src/gemseo_umdo/formulations/control_variate.py</code> <pre><code>def evaluate_with_mean(self) -&gt; None:\n    \"\"\"Evaluate the Taylor polynomials at the mean value of the uncertain vector.\"\"\"\n    problem = self.auxiliary_mdo_formulation.optimization_problem\n    objective = problem.objective\n    if objective is objective.original:\n        problem.preprocess_functions(\n            is_function_input_normalized=False, eval_obs_jac=True\n        )\n    output_functions, jacobian_functions = problem.get_functions(\n        observable_names=(), jacobian_names=()\n    )\n    problem.evaluate_functions(\n        self._uncertain_space.distribution.mean,\n        output_functions=output_functions or None,\n        jacobian_functions=jacobian_functions or None,\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate.ControlVariate.get_top_level_disciplines","title":"get_top_level_disciplines","text":"<pre><code>get_top_level_disciplines() -&gt; list[Discipline]\n</code></pre> <p>Return the disciplines which inputs are required to run the scenario.</p> <p>A formulation seeks to compute the objective and constraints from the input variables. It structures the optimization problem into multiple levels of disciplines. The disciplines directly depending on these inputs are called top level disciplines.</p> <p>By default, this method returns all disciplines. This method can be overloaded by subclasses.</p> <p>Returns:</p> <ul> <li> <code>list[Discipline]</code>           \u2013            <p>The top level disciplines.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def get_top_level_disciplines(self) -&gt; list[Discipline]:  # noqa: D102\n    return self._mdo_formulation.get_top_level_disciplines()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/control_variate/#gemseo_umdo.formulations.control_variate.ControlVariate.update_top_level_disciplines","title":"update_top_level_disciplines","text":"<pre><code>update_top_level_disciplines(\n    design_values: RealArray,\n) -&gt; None\n</code></pre> <p>Update the default input values of the top-level disciplines.</p> <p>Parameters:</p> <ul> <li> <code>design_values</code>               (<code>RealArray</code>)           \u2013            <p>The values of the design variables to update the default input values of the top-level disciplines.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def update_top_level_disciplines(self, design_values: RealArray) -&gt; None:\n    \"\"\"Update the default input values of the top-level disciplines.\n\n    Args:\n        design_values: The values of the design variables\n            to update the default input values of the top-level disciplines.\n    \"\"\"\n    design_values = split_array_to_dict_of_arrays(\n        design_values,\n        self.design_space.variable_sizes,\n        self.design_space.variable_names,\n    )\n    for formulation in [self._mdo_formulation, self._auxiliary_mdo_formulation]:\n        if formulation is None:\n            continue\n\n        for discipline in formulation.get_top_level_disciplines():\n            discipline.default_input_data.update({\n                k: v\n                for k, v in design_values.items()\n                if k in discipline.input_grammar\n            })\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/control_variate_settings/","title":"Control variate settings","text":""},{"location":"reference/gemseo_umdo/formulations/control_variate_settings/#gemseo_umdo.formulations.control_variate_settings","title":"control_variate_settings","text":"<p>Settings for the control variate-based U-MDO formulation.</p>"},{"location":"reference/gemseo_umdo/formulations/control_variate_settings/#gemseo_umdo.formulations.control_variate_settings-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/control_variate_settings/#gemseo_umdo.formulations.control_variate_settings.ControlVariateSettings","title":"ControlVariateSettings","text":"<p>               Bases: <code>BaseUMDOFormulationSettings</code></p> <p>The settings for the control variate-based U-MDO formulation.</p>"},{"location":"reference/gemseo_umdo/formulations/factory/","title":"Factory","text":""},{"location":"reference/gemseo_umdo/formulations/factory/#gemseo_umdo.formulations.factory","title":"factory","text":"<p>Factory of U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/factory/#gemseo_umdo.formulations.factory-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/factory/#gemseo_umdo.formulations.factory.UMDOFormulationsFactory","title":"UMDOFormulationsFactory","text":"<p>               Bases: <code>MDOFormulationFactory</code></p> <p>The factory of U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/","title":"Pce","text":""},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce","title":"pce","text":"<p>PCE-based U-MDO formulation.</p> <p>PCE is an BaseUMDOFormulation estimating the statistics from the coefficients of a polynomial chaos expansion (PCE).</p> <p>E.g.</p> \\[\\mathbb{E}[f(x,U)] \\approx \\alpha_0\\] <p>or</p> \\[\\mathbb{V}[f(x,U)] \\approx \\sum_{1&lt;i\\leq P}\\alpha_i^2\\] <p>where \\((\\alpha_i)_{1\\leq i \\leq N}\\) are the coefficients of the PCE</p> \\[\\hat{f}_x(U)=\\alpha_0 + \\sum_{1&lt;i\\leq P}\\alpha_i\\Phi_i(U)\\] <p>built at \\(x\\) over the uncertain space.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE","title":"PCE","text":"<pre><code>PCE(\n    disciplines: Sequence[Discipline],\n    objective_name: str,\n    design_space: DesignSpace,\n    mdo_formulation: BaseMDOFormulation,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    objective_statistic_parameters: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    doe_algo: str = \"OT_OPT_LHS\",\n    doe_algo_options: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    doe_n_samples: int | None = None,\n    pce_options: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    quality_name: str = \"R2Measure\",\n    quality_threshold: (\n        float | Mapping[str, float | Iterable[float]]\n    ) = 0.9,\n    quality_cv_compute: bool = True,\n    quality_cv_n_folds: int = 5,\n    quality_cv_randomize: bool = True,\n    quality_cv_seed: int | None = None,\n    quality_cv_threshold: (\n        float | Mapping[str, float | Iterable[float]]\n    ) = 0.8,\n    mdo_formulation_settings: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    **settings: Any\n)\n</code></pre> <p>               Bases: <code>Surrogate</code></p> <p>PCE-based U-MDO formulation.</p> <p>DOE algorithms</p> <p>This formulation uses a DOE algorithm; read the GEMSEO documentation. for more information about the available DOE algorithm names and options.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>disciplines</code>               (<code>Sequence[Discipline]</code>)           \u2013            <p>The disciplines.</p> </li> <li> <code>objective_name</code>               (<code>str</code>)           \u2013            <p>The name(s) of the discipline output(s) used as objective. If multiple names are passed, the objective will be a vector.</p> </li> <li> <code>design_space</code>               (<code>DesignSpace</code>)           \u2013            <p>The design space.</p> </li> <li> <code>mdo_formulation</code>               (<code>BaseMDOFormulation</code>)           \u2013            <p>The MDO formulation generating functions evaluable over the uncertain space and differentiable with respect to the design variables.</p> </li> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain variables with their probability distributions.</p> </li> <li> <code>objective_statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the objective.</p> </li> <li> <code>objective_statistic_parameters</code>               (<code>StrKeyMapping</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The values of the parameters of the statistic to be applied to the objective, if any.</p> </li> <li> <code>doe_algo</code>               (<code>str</code>, default:                   <code>'OT_OPT_LHS'</code> )           \u2013            <p>The name of the DOE algorithm.</p> </li> <li> <code>doe_algo_options</code>               (<code>StrKeyMapping</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The options of the DOE algorithm.</p> </li> <li> <code>doe_n_samples</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>The number of samples to be generated by the DOE algorithm. If <code>None</code>, the DOE algorithm does not use <code>doe_n_samples</code> argument but potentially a mandatory argument to be defined in <code>doe_algo_options</code> (e.g. <code>samples</code> for the <code>CustomDOE</code> algorithm).</p> </li> <li> <code>pce_options</code>               (<code>StrKeyMapping</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The options of the PCERegressor.</p> </li> <li> <code>quality_name</code>               (<code>str</code>, default:                   <code>'R2Measure'</code> )           \u2013            <p>The name of the measure to assess the quality of the regressor.</p> </li> <li> <code>quality_threshold</code>               (<code>float | Mapping[str, float | Iterable[float]]</code>, default:                   <code>0.9</code> )           \u2013            <p>The learning quality threshold below which a warning is logged.</p> </li> <li> <code>quality_cv_compute</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to estimate the quality by cross-validation (CV).</p> </li> <li> <code>quality_cv_n_folds</code>               (<code>int</code>, default:                   <code>5</code> )           \u2013            <p>The description is missing.</p> </li> <li> <code>quality_cv_randomize</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to shuffle the samples before dividing them in folds in the case of the CV technique.</p> </li> <li> <code>quality_cv_seed</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>The seed of the pseudo-random number generator. If <code>None</code>, an unpredictable generator is used.</p> </li> <li> <code>quality_cv_threshold</code>               (<code>float | Mapping[str, float | Iterable[float]]</code>, default:                   <code>0.8</code> )           \u2013            <p>The CV quality threshold below which a warning is logged.</p> </li> <li> <code>mdo_formulation_settings</code>               (<code>StrKeyMapping</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The settings of the MDO formulation.</p> </li> <li> <code>**settings</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The settings of the formulation. This argument is ignored when <code>settings_model</code> is not <code>None</code>.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>When <code>n_samples</code> is <code>None</code>, whereas it is required by the DOE algorithm.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/pce.py</code> <pre><code>def __init__(\n    self,\n    disciplines: Sequence[Discipline],\n    objective_name: str,\n    design_space: DesignSpace,\n    mdo_formulation: BaseMDOFormulation,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    objective_statistic_parameters: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    doe_algo: str = \"OT_OPT_LHS\",\n    doe_algo_options: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    doe_n_samples: int | None = None,\n    pce_options: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    quality_name: str = \"R2Measure\",\n    quality_threshold: float | Mapping[str, float | Iterable[float]] = 0.9,\n    quality_cv_compute: bool = True,\n    quality_cv_n_folds: int = 5,\n    quality_cv_randomize: bool = True,\n    quality_cv_seed: int | None = None,\n    quality_cv_threshold: float | Mapping[str, float | Iterable[float]] = 0.8,\n    mdo_formulation_settings: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    **settings: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        pce_options: The options of the\n            [PCERegressor][gemseo.mlearning.regression.algos.pce.PCERegressor].\n    \"\"\"  # noqa: D205 D212 D415\n    super().__init__(\n        disciplines,\n        objective_name,\n        design_space,\n        mdo_formulation,\n        uncertain_space,\n        objective_statistic_name,\n        objective_statistic_parameters=objective_statistic_parameters,\n        mdo_formulation_settings=mdo_formulation_settings,\n        doe_algo=doe_algo,\n        doe_algo_options=doe_algo_options,\n        doe_n_samples=doe_n_samples,\n        regressor_name=\"PCERegressor\",\n        regressor_options=pce_options,\n        quality_name=quality_name,\n        quality_threshold=quality_threshold,\n        quality_cv_compute=quality_cv_compute,\n        quality_cv_n_folds=quality_cv_n_folds,\n        quality_cv_randomize=quality_cv_randomize,\n        quality_cv_seed=quality_cv_seed,\n        quality_cv_threshold=quality_cv_threshold,\n        **settings,\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.auxiliary_mdo_formulation","title":"auxiliary_mdo_formulation  <code>property</code>","text":"<pre><code>auxiliary_mdo_formulation: BaseMDOFormulation\n</code></pre> <p>The auxiliary MDO formulation.</p> <p>The functions are evaluable over the uncertain space and differentiable with respect to the uncertain variables.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.available_statistics","title":"available_statistics  <code>property</code>","text":"<pre><code>available_statistics: list[str]\n</code></pre> <p>The names of the statistics to quantify the output uncertainties.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.cv_threshold","title":"cv_threshold  <code>instance-attribute</code>","text":"<pre><code>cv_threshold: dict[str, RealArray] = {}\n</code></pre> <p>The cross-validation threshold component-wise.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.input_data_to_output_data","title":"input_data_to_output_data  <code>instance-attribute</code>","text":"<pre><code>input_data_to_output_data: dict[\n    HashableNdarray, dict[str, Any]\n] = {}\n</code></pre> <p>The output samples or output statistics associated with the input data.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.input_samples","title":"input_samples  <code>instance-attribute</code>","text":"<pre><code>input_samples: dict[str, RealArray] = convert_array_to_dict(\n    compute_doe(\n        uncertain_space,\n        n_samples=regressor_n_samples,\n        seed=regressor_sampling_seed,\n    )\n)\n</code></pre> <p>The input_samples.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.is_surrogate_quality_bad","title":"is_surrogate_quality_bad  <code>instance-attribute</code>","text":"<pre><code>is_surrogate_quality_bad: Callable[[float, float], bool] = (\n    gt if smaller_is_better else lt\n)\n</code></pre> <p>A function to indicate if the regressor is good for an output component.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.mdo_formulation","title":"mdo_formulation  <code>property</code>","text":"<pre><code>mdo_formulation: BaseMDOFormulation\n</code></pre> <p>The MDO formulation.</p> <p>The functions are evaluable over the uncertain space and differentiable with respect to the design variables.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.quality","title":"quality  <code>instance-attribute</code>","text":"<pre><code>quality: type[BaseRegressorQuality] = get_class(\n    quality_name\n)\n</code></pre> <p>The class to assess the quality of the regressor.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.quality_cv_options","title":"quality_cv_options  <code>instance-attribute</code>","text":"<pre><code>quality_cv_options: dict[str, bool | int | None]\n</code></pre> <p>The options of the CV technique; if empty, do not use it.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.quality_cv_threshold","title":"quality_cv_threshold  <code>instance-attribute</code>","text":"<pre><code>quality_cv_threshold: (\n    float | Mapping[str, float | Iterable[float]]\n) = quality_cv_threshold\n</code></pre> <p>The CV quality threshold below which a warning is logged.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.quality_operators","title":"quality_operators  <code>instance-attribute</code>","text":"<pre><code>quality_operators: tuple[str, str] = (\n    (\"&lt;=\", \"&gt;\") if smaller_is_better else (\"&gt;=\", \"&lt;\")\n)\n</code></pre> <p>The operators <code>(o1, o2)</code> to compare the quality of the regressor and a threshold.</p> <p>\"A o1 B\" means that A is better or equal to B. \"A o2 B\" means that A is less good than B.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.quality_threshold","title":"quality_threshold  <code>instance-attribute</code>","text":"<pre><code>quality_threshold: (\n    float | Mapping[str, float | Iterable[float]]\n) = quality_threshold\n</code></pre> <p>The learning quality threshold below which a warning is logged.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.regressor_name","title":"regressor_name  <code>instance-attribute</code>","text":"<pre><code>regressor_name: str = regressor_name\n</code></pre> <p>The regressor class name.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.regressor_options","title":"regressor_options  <code>instance-attribute</code>","text":"<pre><code>regressor_options: StrKeyMapping = regressor_options\n</code></pre> <p>The BaseRegressor.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.threshold","title":"threshold  <code>instance-attribute</code>","text":"<pre><code>threshold: dict[str, RealArray] = {}\n</code></pre> <p>The learning quality threshold component-wise.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.uncertain_space","title":"uncertain_space  <code>property</code>","text":"<pre><code>uncertain_space: ParameterSpace\n</code></pre> <p>The uncertain variable space.</p>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.add_constraint","title":"add_constraint","text":"<pre><code>add_constraint(\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: ConstraintType = INEQ,\n    constraint_name: str = \"\",\n    value: float = 0.0,\n    positive: bool = False,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Add an equality or inequality constraint to the optimization problem.</p> <p>An equality constraint is written as :math:<code>c(x)=a</code>, a positive inequality constraint is written as :math:<code>c(x)\\geq a</code> and a negative inequality constraint is written as :math:<code>c(x)\\leq a</code>.</p> <p>This constraint is in addition to those created by the formulation, e.g. consistency constraints in IDF.</p> <p>The strategy of repartition of the constraints is defined by the formulation.</p> <p>Parameters:</p> <ul> <li> <code>output_name</code>               (<code>str | Sequence[str]</code>)           \u2013            <p>The name(s) of the outputs computed by :math:<code>c(x)</code>. If several names are given, a single discipline must provide all outputs.</p> </li> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the constraint.</p> </li> <li> <code>constraint_type</code>               (<code>ConstraintType</code>, default:                   <code>INEQ</code> )           \u2013            <p>The type of constraint.</p> </li> <li> <code>constraint_name</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>The name of the constraint to be stored. If empty, the name of the constraint is generated from <code>output_name</code>, <code>constraint_type</code>, <code>value</code> and <code>positive</code>.</p> </li> <li> <code>value</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>The value :math:<code>a</code>.</p> </li> <li> <code>positive</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether the inequality constraint is positive.</p> </li> <li> <code>**statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def add_constraint(\n    self,\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: MDOFunction.ConstraintType = MDOFunction.ConstraintType.INEQ,\n    constraint_name: str = \"\",\n    value: float = 0.0,\n    positive: bool = False,\n    **statistic_parameters: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        statistic_name: The name of the statistic to be applied to the constraint.\n        statistic_parameters: The values of the parameters of the statistic\n            to be applied to the constraint, if any.\n    \"\"\"  # noqa: D205 D212 D415\n    if self._auxiliary_mdo_formulation is not None:\n        self._auxiliary_mdo_formulation.add_observable(output_name)\n\n    self._mdo_formulation.add_observable(output_name)\n    constraint = self._statistic_function_class(\n        self,\n        self._mdo_formulation.optimization_problem.observables[-1],\n        MDOFunction.FunctionType.NONE,\n        statistic_name,\n        **statistic_parameters,\n    )\n    name = self.__compute_name(output_name, statistic_name, **statistic_parameters)\n    constraint.output_names = [name]\n    if constraint_name:\n        constraint.name = constraint_name\n        constraint.has_default_name = False\n    else:\n        constraint.name = name\n        constraint.has_default_name = True\n    self.optimization_problem.add_constraint(\n        constraint,\n        value=value,\n        positive=positive,\n        constraint_type=constraint_type,\n    )\n    self._post_add_constraint()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.add_observable","title":"add_observable","text":"<pre><code>add_observable(\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: str = \"\",\n    discipline: Discipline | None = None,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Add an observable to the optimization problem.</p> <p>The repartition strategy of the observable is defined in the formulation class.</p> <p>Parameters:</p> <ul> <li> <code>output_names</code>               (<code>Sequence[str]</code>)           \u2013            <p>The name(s) of the output(s) to observe.</p> </li> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the observable.</p> </li> <li> <code>observable_name</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>The name of the observable. If empty, the output name is used by default.</p> </li> <li> <code>discipline</code>               (<code>Discipline | None</code>, default:                   <code>None</code> )           \u2013            <p>The discipline computing the observed outputs. If <code>None</code>, the discipline is detected from inner disciplines.</p> </li> <li> <code>**statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def add_observable(\n    self,\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: str = \"\",\n    discipline: Discipline | None = None,\n    **statistic_parameters: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        statistic_name: The name of the statistic to be applied to the observable.\n        statistic_parameters: The values of the parameters\n            of the statistic to be applied to the observable, if any.\n    \"\"\"  # noqa: D205 D212 D415\n    if self._auxiliary_mdo_formulation is not None:\n        self._auxiliary_mdo_formulation.add_observable(\n            output_names,\n            observable_name=observable_name,\n            discipline=discipline,\n        )\n\n    self._mdo_formulation.add_observable(\n        output_names,\n        observable_name=observable_name,\n        discipline=discipline,\n    )\n    sub_opt_problem = self._mdo_formulation.optimization_problem\n    observable = self._statistic_function_class(\n        self,\n        sub_opt_problem.observables[-1],\n        MDOFunction.FunctionType.NONE,\n        statistic_name,\n        **statistic_parameters,\n    )\n    observable.name = self.__compute_name(\n        observable_name or output_names, statistic_name, **statistic_parameters\n    )\n    self.optimization_problem.add_observable(observable)\n    self._post_add_observable()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.compute_samples","title":"compute_samples","text":"<pre><code>compute_samples(problem: OptimizationProblem) -&gt; IODataset\n</code></pre> <p>Evaluate the functions of a problem with a DOE algorithm.</p> <p>Parameters:</p> <ul> <li> <code>problem</code>               (<code>OptimizationProblem</code>)           \u2013            <p>The problem.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/surrogate.py</code> <pre><code>def compute_samples(self, problem: OptimizationProblem) -&gt; IODataset:\n    \"\"\"Evaluate the functions of a problem with a DOE algorithm.\n\n    Args:\n        problem: The problem.\n    \"\"\"\n    with LoggingContext(logging.getLogger(\"gemseo\")):\n        self.__doe_algo.execute(problem, **self.__doe_algo_options)\n\n    io_dataset = problem.to_dataset(opt_naming=False)\n    if not self.threshold:\n        names_to_sizes = {\n            name: len(\n                io_dataset.get_variable_components(io_dataset.OUTPUT_GROUP, name)\n            )\n            for name in io_dataset.output_names\n        }\n        self.threshold = self.__compute_threshold(\n            names_to_sizes, self.quality_threshold\n        )\n        self.cv_threshold = self.__compute_threshold(\n            names_to_sizes, self.quality_cv_threshold\n        )\n\n    return io_dataset\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.get_top_level_disciplines","title":"get_top_level_disciplines","text":"<pre><code>get_top_level_disciplines() -&gt; list[Discipline]\n</code></pre> <p>Return the disciplines which inputs are required to run the scenario.</p> <p>A formulation seeks to compute the objective and constraints from the input variables. It structures the optimization problem into multiple levels of disciplines. The disciplines directly depending on these inputs are called top level disciplines.</p> <p>By default, this method returns all disciplines. This method can be overloaded by subclasses.</p> <p>Returns:</p> <ul> <li> <code>list[Discipline]</code>           \u2013            <p>The top level disciplines.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def get_top_level_disciplines(self) -&gt; list[Discipline]:  # noqa: D102\n    return self._mdo_formulation.get_top_level_disciplines()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/pce/#gemseo_umdo.formulations.pce.PCE.update_top_level_disciplines","title":"update_top_level_disciplines","text":"<pre><code>update_top_level_disciplines(\n    design_values: RealArray,\n) -&gt; None\n</code></pre> <p>Update the default input values of the top-level disciplines.</p> <p>Parameters:</p> <ul> <li> <code>design_values</code>               (<code>RealArray</code>)           \u2013            <p>The values of the design variables to update the default input values of the top-level disciplines.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def update_top_level_disciplines(self, design_values: RealArray) -&gt; None:\n    \"\"\"Update the default input values of the top-level disciplines.\n\n    Args:\n        design_values: The values of the design variables\n            to update the default input values of the top-level disciplines.\n    \"\"\"\n    design_values = split_array_to_dict_of_arrays(\n        design_values,\n        self.design_space.variable_sizes,\n        self.design_space.variable_names,\n    )\n    for formulation in [self._mdo_formulation, self._auxiliary_mdo_formulation]:\n        if formulation is None:\n            continue\n\n        for discipline in formulation.get_top_level_disciplines():\n            discipline.default_input_data.update({\n                k: v\n                for k, v in design_values.items()\n                if k in discipline.input_grammar\n            })\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/pce_settings/","title":"Pce settings","text":""},{"location":"reference/gemseo_umdo/formulations/pce_settings/#gemseo_umdo.formulations.pce_settings","title":"pce_settings","text":"<p>Settings for the PCE-based U-MDO formulation.</p>"},{"location":"reference/gemseo_umdo/formulations/pce_settings/#gemseo_umdo.formulations.pce_settings-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/pce_settings/#gemseo_umdo.formulations.pce_settings.PCESettings","title":"PCESettings","text":"<p>               Bases: <code>BaseUMDOFormulationSettings</code></p> <p>The ettings for the PCE-based U-MDO formulation.</p>"},{"location":"reference/gemseo_umdo/formulations/sampling/","title":"Sampling","text":""},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling","title":"sampling","text":"<p>Sampling-based U-MDO formulation.</p> <p>Sampling is an BaseUMDOFormulation estimating the statistics with (quasi) Monte Carlo techniques.</p> <p>E.g.</p> \\[\\mathbb{E}[f(x,U)] \\approx \\frac{1}{N}\\sum_{i=1}^N f\\left(x,U^{(i)}\\right)\\] <p>or</p> \\[\\mathbb{V}[f(x,U)] \\approx \\frac{1}{N}\\sum_{i=1}^N \\left(f\\left(x,U^{(i)}\\right)- \\frac{1}{N}\\sum_{j=1}^N f\\left(x,U^{(j)}\\right)\\right)^2\\] <p>where \\(U\\) is normally distributed with mean \\(\\mu\\) and variance \\(\\sigma^2\\) and \\(U^{(1)},\\ldots,U^{(N)}\\) are \\(N\\) realizations of \\(U\\) obtained with an optimized Latin hypercube sampling technique.</p>"},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling.Sampling","title":"Sampling","text":"<pre><code>Sampling(\n    disciplines: Sequence[Discipline],\n    objective_name: str,\n    design_space: DesignSpace,\n    mdo_formulation: BaseMDOFormulation,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    n_samples: int | None = None,\n    objective_statistic_parameters: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    algo: str = \"OT_OPT_LHS\",\n    algo_options: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    seed: int = SEED,\n    estimate_statistics_iteratively: bool = True,\n    samples_directory_path: str | Path = \"\",\n    mdo_formulation_settings: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    **settings: Any\n)\n</code></pre> <p>               Bases: <code>BaseUMDOFormulation</code></p> <p>Sampling-based U-MDO formulation.</p> <p>DOE algorithms</p> <p>This formulation uses a DOE algorithm; read the GEMSEO documentation. for more information about the available DOE algorithm names and options.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>disciplines</code>               (<code>Sequence[Discipline]</code>)           \u2013            <p>The disciplines.</p> </li> <li> <code>objective_name</code>               (<code>str</code>)           \u2013            <p>The name(s) of the discipline output(s) used as objective. If multiple names are passed, the objective will be a vector.</p> </li> <li> <code>design_space</code>               (<code>DesignSpace</code>)           \u2013            <p>The design space.</p> </li> <li> <code>mdo_formulation</code>               (<code>BaseMDOFormulation</code>)           \u2013            <p>The MDO formulation generating functions evaluable over the uncertain space and differentiable with respect to the design variables.</p> </li> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain variables with their probability distributions.</p> </li> <li> <code>objective_statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the objective.</p> </li> <li> <code>n_samples</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>The number of samples to be generated by the DOE algorithm. If <code>None</code>, the DOE algorithm uses no <code>n_samples</code> argument but potentially a mandatory argument to be defined in <code>algo_options</code> (e.g. <code>samples</code> for the <code>CustomDOE</code> algorithm).</p> </li> <li> <code>objective_statistic_parameters</code>               (<code>StrKeyMapping</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The values of the parameters of the statistic to be applied to the objective, if any.</p> </li> <li> <code>algo</code>               (<code>str</code>, default:                   <code>'OT_OPT_LHS'</code> )           \u2013            <p>The name of the DOE algorithm.</p> </li> <li> <code>algo_options</code>               (<code>StrKeyMapping</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The options of the DOE algorithm.</p> </li> <li> <code>seed</code>               (<code>int</code>, default:                   <code>SEED</code> )           \u2013            <p>The seed for reproducibility.</p> </li> <li> <code>estimate_statistics_iteratively</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to estimate the statistics iteratively for memory reasons. This argument is ignored when <code>samples_directory_path</code> is defined; in this case, the statistics are not estimated iteratively.</p> </li> <li> <code>samples_directory_path</code>               (<code>str | Path</code>, default:                   <code>''</code> )           \u2013            <p>The path to a new directory where the samples stored as :class:<code>.IODataset</code> objects will be saved (one object per file, one file per iteration). This directory must not exist; it will be created by the formulation. If empty, do not save the samples.</p> </li> <li> <code>mdo_formulation_settings</code>               (<code>StrKeyMapping</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The settings of the MDO formulation.</p> </li> <li> <code>**settings</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The settings of the formulation. This argument is ignored when <code>settings_model</code> is not <code>None</code>.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>When <code>n_samples</code> is <code>None</code>, whereas it is required by the DOE algorithm.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/sampling.py</code> <pre><code>def __init__(\n    self,\n    disciplines: Sequence[Discipline],\n    objective_name: str,\n    design_space: DesignSpace,\n    mdo_formulation: BaseMDOFormulation,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    n_samples: int | None = None,\n    objective_statistic_parameters: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    algo: str = \"OT_OPT_LHS\",\n    algo_options: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    seed: int = SEED,\n    estimate_statistics_iteratively: bool = True,\n    samples_directory_path: str | Path = \"\",\n    mdo_formulation_settings: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    **settings: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        n_samples: The number of samples to be generated by the DOE algorithm.\n            If `None`,\n            the DOE algorithm uses no `n_samples` argument\n            but potentially a mandatory argument to be defined in `algo_options`\n            (e.g. `samples` for the `CustomDOE` algorithm).\n        algo: The name of the DOE algorithm.\n        algo_options: The options of the DOE algorithm.\n        seed: The seed for reproducibility.\n        estimate_statistics_iteratively: Whether to estimate\n            the statistics iteratively for memory reasons.\n            This argument is ignored when `samples_directory_path` is defined;\n            in this case, the statistics are not estimated iteratively.\n        samples_directory_path: The path to a new directory\n            where the samples stored as :class:`.IODataset` objects will be saved\n            (one object per file, one file per iteration).\n            This directory must not exist; it will be created by the formulation.\n            If empty, do not save the samples.\n\n    Raises:\n        ValueError: When `n_samples` is `None`,\n            whereas it is required by the DOE algorithm.\n    \"\"\"  # noqa: D205 D212 D415\n    self.callbacks = []\n    self.jacobian_callbacks = []\n    self.input_data_to_output_samples = {}\n    if samples_directory_path:\n        self.__samples_directory_path = Path(samples_directory_path)\n        self.__samples_directory_path.mkdir()\n        estimate_statistics_iteratively = False\n    else:\n        self.__samples_directory_path = \"\"\n\n    self._estimate_statistics_iteratively = estimate_statistics_iteratively\n    if estimate_statistics_iteratively:\n        self._statistic_factory = IterativeSamplingEstimatorFactory()\n        self._statistic_function_class = StatisticFunctionForIterativeSampling\n    else:\n        self._statistic_factory = SamplingEstimatorFactory()\n        self._statistic_function_class = StatisticFunctionForStandardSampling\n\n    self.__doe_algo = DOELibraryFactory().create(algo)\n    self.__doe_algo_options = dict(algo_options)\n    self.__doe_algo_options[\"use_database\"] = not estimate_statistics_iteratively\n    model_fields = self.__doe_algo.ALGORITHM_INFOS[algo].Settings.model_fields\n    if \"n_samples\" in model_fields:\n        if n_samples is None:\n            msg = \"Sampling: n_samples is required.\"\n            raise ValueError(msg)\n        self.__doe_algo_options[\"n_samples\"] = n_samples\n\n    if \"seed\" in model_fields:\n        self.__doe_algo_options[\"seed\"] = seed\n\n    self.__n_samples = n_samples\n    super().__init__(\n        disciplines,\n        objective_name,\n        design_space,\n        mdo_formulation,\n        uncertain_space,\n        objective_statistic_name,\n        objective_statistic_parameters=objective_statistic_parameters,\n        mdo_formulation_settings=mdo_formulation_settings,\n        **settings,\n    )\n    mdo_formulation = self._mdo_formulation.__class__.__name__\n    formulation = self.__class__.__name__\n    self.name = f\"{formulation}[{mdo_formulation}; {algo}({n_samples})]\"\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling.Sampling-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling.Sampling.auxiliary_mdo_formulation","title":"auxiliary_mdo_formulation  <code>property</code>","text":"<pre><code>auxiliary_mdo_formulation: BaseMDOFormulation\n</code></pre> <p>The auxiliary MDO formulation.</p> <p>The functions are evaluable over the uncertain space and differentiable with respect to the uncertain variables.</p>"},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling.Sampling.available_statistics","title":"available_statistics  <code>property</code>","text":"<pre><code>available_statistics: list[str]\n</code></pre> <p>The names of the statistics to quantify the output uncertainties.</p>"},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling.Sampling.callbacks","title":"callbacks  <code>instance-attribute</code>","text":"<pre><code>callbacks: list[CallbackType] = []\n</code></pre> <p>The callback functions for the DOE algorithm when computing the output data.</p>"},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling.Sampling.input_data_to_output_data","title":"input_data_to_output_data  <code>instance-attribute</code>","text":"<pre><code>input_data_to_output_data: dict[\n    HashableNdarray, dict[str, Any]\n] = {}\n</code></pre> <p>The output samples or output statistics associated with the input data.</p>"},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling.Sampling.jacobian_callbacks","title":"jacobian_callbacks  <code>instance-attribute</code>","text":"<pre><code>jacobian_callbacks: list[CallbackType] = []\n</code></pre> <p>The callback functions for the DOE algorithm when computing the Jacobian.</p>"},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling.Sampling.mdo_formulation","title":"mdo_formulation  <code>property</code>","text":"<pre><code>mdo_formulation: BaseMDOFormulation\n</code></pre> <p>The MDO formulation.</p> <p>The functions are evaluable over the uncertain space and differentiable with respect to the design variables.</p>"},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling.Sampling.uncertain_space","title":"uncertain_space  <code>property</code>","text":"<pre><code>uncertain_space: ParameterSpace\n</code></pre> <p>The uncertain variable space.</p>"},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling.Sampling-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling.Sampling.add_constraint","title":"add_constraint","text":"<pre><code>add_constraint(\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: ConstraintType = INEQ,\n    constraint_name: str = \"\",\n    value: float = 0.0,\n    positive: bool = False,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Add an equality or inequality constraint to the optimization problem.</p> <p>An equality constraint is written as :math:<code>c(x)=a</code>, a positive inequality constraint is written as :math:<code>c(x)\\geq a</code> and a negative inequality constraint is written as :math:<code>c(x)\\leq a</code>.</p> <p>This constraint is in addition to those created by the formulation, e.g. consistency constraints in IDF.</p> <p>The strategy of repartition of the constraints is defined by the formulation.</p> <p>Parameters:</p> <ul> <li> <code>output_name</code>               (<code>str | Sequence[str]</code>)           \u2013            <p>The name(s) of the outputs computed by :math:<code>c(x)</code>. If several names are given, a single discipline must provide all outputs.</p> </li> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the constraint.</p> </li> <li> <code>constraint_type</code>               (<code>ConstraintType</code>, default:                   <code>INEQ</code> )           \u2013            <p>The type of constraint.</p> </li> <li> <code>constraint_name</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>The name of the constraint to be stored. If empty, the name of the constraint is generated from <code>output_name</code>, <code>constraint_type</code>, <code>value</code> and <code>positive</code>.</p> </li> <li> <code>value</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>The value :math:<code>a</code>.</p> </li> <li> <code>positive</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether the inequality constraint is positive.</p> </li> <li> <code>**statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def add_constraint(\n    self,\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: MDOFunction.ConstraintType = MDOFunction.ConstraintType.INEQ,\n    constraint_name: str = \"\",\n    value: float = 0.0,\n    positive: bool = False,\n    **statistic_parameters: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        statistic_name: The name of the statistic to be applied to the constraint.\n        statistic_parameters: The values of the parameters of the statistic\n            to be applied to the constraint, if any.\n    \"\"\"  # noqa: D205 D212 D415\n    if self._auxiliary_mdo_formulation is not None:\n        self._auxiliary_mdo_formulation.add_observable(output_name)\n\n    self._mdo_formulation.add_observable(output_name)\n    constraint = self._statistic_function_class(\n        self,\n        self._mdo_formulation.optimization_problem.observables[-1],\n        MDOFunction.FunctionType.NONE,\n        statistic_name,\n        **statistic_parameters,\n    )\n    name = self.__compute_name(output_name, statistic_name, **statistic_parameters)\n    constraint.output_names = [name]\n    if constraint_name:\n        constraint.name = constraint_name\n        constraint.has_default_name = False\n    else:\n        constraint.name = name\n        constraint.has_default_name = True\n    self.optimization_problem.add_constraint(\n        constraint,\n        value=value,\n        positive=positive,\n        constraint_type=constraint_type,\n    )\n    self._post_add_constraint()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling.Sampling.add_observable","title":"add_observable","text":"<pre><code>add_observable(\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: str = \"\",\n    discipline: Discipline | None = None,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Add an observable to the optimization problem.</p> <p>The repartition strategy of the observable is defined in the formulation class.</p> <p>Parameters:</p> <ul> <li> <code>output_names</code>               (<code>Sequence[str]</code>)           \u2013            <p>The name(s) of the output(s) to observe.</p> </li> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the observable.</p> </li> <li> <code>observable_name</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>The name of the observable. If empty, the output name is used by default.</p> </li> <li> <code>discipline</code>               (<code>Discipline | None</code>, default:                   <code>None</code> )           \u2013            <p>The discipline computing the observed outputs. If <code>None</code>, the discipline is detected from inner disciplines.</p> </li> <li> <code>**statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def add_observable(\n    self,\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: str = \"\",\n    discipline: Discipline | None = None,\n    **statistic_parameters: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        statistic_name: The name of the statistic to be applied to the observable.\n        statistic_parameters: The values of the parameters\n            of the statistic to be applied to the observable, if any.\n    \"\"\"  # noqa: D205 D212 D415\n    if self._auxiliary_mdo_formulation is not None:\n        self._auxiliary_mdo_formulation.add_observable(\n            output_names,\n            observable_name=observable_name,\n            discipline=discipline,\n        )\n\n    self._mdo_formulation.add_observable(\n        output_names,\n        observable_name=observable_name,\n        discipline=discipline,\n    )\n    sub_opt_problem = self._mdo_formulation.optimization_problem\n    observable = self._statistic_function_class(\n        self,\n        sub_opt_problem.observables[-1],\n        MDOFunction.FunctionType.NONE,\n        statistic_name,\n        **statistic_parameters,\n    )\n    observable.name = self.__compute_name(\n        observable_name or output_names, statistic_name, **statistic_parameters\n    )\n    self.optimization_problem.add_observable(observable)\n    self._post_add_observable()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling.Sampling.compute_samples","title":"compute_samples","text":"<pre><code>compute_samples(\n    problem: OptimizationProblem,\n    input_data: RealArray,\n    compute_jacobian: bool = False,\n) -&gt; None\n</code></pre> <p>Evaluate the functions of a problem with a DOE algorithm.</p> <p>Parameters:</p> <ul> <li> <code>problem</code>               (<code>OptimizationProblem</code>)           \u2013            <p>The sampling problem.</p> </li> <li> <code>input_data</code>               (<code>RealArray</code>)           \u2013            <p>The input point at which to estimate the statistic.</p> </li> <li> <code>compute_jacobian</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to compute the Jacobian of the objective.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/sampling.py</code> <pre><code>def compute_samples(\n    self,\n    problem: OptimizationProblem,\n    input_data: RealArray,\n    compute_jacobian: bool = False,\n) -&gt; None:\n    \"\"\"Evaluate the functions of a problem with a DOE algorithm.\n\n    Args:\n        problem: The sampling problem.\n        input_data: The input point at which to estimate the statistic.\n        compute_jacobian: Whether to compute the Jacobian of the objective.\n    \"\"\"\n    callbacks_1 = list(self.__doe_algo_options.get(\"callbacks\", []))\n    callbacks_2 = self.jacobian_callbacks if compute_jacobian else self.callbacks\n    self.__doe_algo_options[\"callbacks\"] = callbacks_1 + callbacks_2\n    with LoggingContext(logging.getLogger(\"gemseo\")):\n        self.__doe_algo.execute(\n            problem,\n            eval_jac=compute_jacobian,\n            eval_obs_jac=compute_jacobian,\n            **self.__doe_algo_options,\n        )\n\n    if self.__samples_directory_path:\n        main_problem = self.optimization_problem\n        iteration = main_problem.evaluation_counter.current + 1\n        dataset = problem.to_dataset(f\"Iteration {iteration}\", opt_naming=False)\n        dataset.misc.update(\n            main_problem.design_space.convert_array_to_dict(input_data)\n        )\n        to_pickle(dataset, self.__samples_directory_path / f\"{iteration}.pkl\")\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling.Sampling.get_top_level_disciplines","title":"get_top_level_disciplines","text":"<pre><code>get_top_level_disciplines() -&gt; list[Discipline]\n</code></pre> <p>Return the disciplines which inputs are required to run the scenario.</p> <p>A formulation seeks to compute the objective and constraints from the input variables. It structures the optimization problem into multiple levels of disciplines. The disciplines directly depending on these inputs are called top level disciplines.</p> <p>By default, this method returns all disciplines. This method can be overloaded by subclasses.</p> <p>Returns:</p> <ul> <li> <code>list[Discipline]</code>           \u2013            <p>The top level disciplines.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def get_top_level_disciplines(self) -&gt; list[Discipline]:  # noqa: D102\n    return self._mdo_formulation.get_top_level_disciplines()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/sampling/#gemseo_umdo.formulations.sampling.Sampling.update_top_level_disciplines","title":"update_top_level_disciplines","text":"<pre><code>update_top_level_disciplines(\n    design_values: RealArray,\n) -&gt; None\n</code></pre> <p>Update the default input values of the top-level disciplines.</p> <p>Parameters:</p> <ul> <li> <code>design_values</code>               (<code>RealArray</code>)           \u2013            <p>The values of the design variables to update the default input values of the top-level disciplines.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def update_top_level_disciplines(self, design_values: RealArray) -&gt; None:\n    \"\"\"Update the default input values of the top-level disciplines.\n\n    Args:\n        design_values: The values of the design variables\n            to update the default input values of the top-level disciplines.\n    \"\"\"\n    design_values = split_array_to_dict_of_arrays(\n        design_values,\n        self.design_space.variable_sizes,\n        self.design_space.variable_names,\n    )\n    for formulation in [self._mdo_formulation, self._auxiliary_mdo_formulation]:\n        if formulation is None:\n            continue\n\n        for discipline in formulation.get_top_level_disciplines():\n            discipline.default_input_data.update({\n                k: v\n                for k, v in design_values.items()\n                if k in discipline.input_grammar\n            })\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/sampling_settings/","title":"Sampling settings","text":""},{"location":"reference/gemseo_umdo/formulations/sampling_settings/#gemseo_umdo.formulations.sampling_settings","title":"sampling_settings","text":"<p>Settings for the sampling-based U-MDO formulation.</p>"},{"location":"reference/gemseo_umdo/formulations/sampling_settings/#gemseo_umdo.formulations.sampling_settings-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/sampling_settings/#gemseo_umdo.formulations.sampling_settings.SamplingSettings","title":"SamplingSettings","text":"<p>               Bases: <code>BaseUMDOFormulationSettings</code></p> <p>The settings for the sampling-based U-MDO formulation.</p>"},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/","title":"Sequential sampling","text":""},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling","title":"sequential_sampling","text":"<p>Sequential sampling-based U-MDO formulation.</p> <p>SequentialSampling is a BaseUMDOFormulation estimating the statistics with sequential (quasi) Monte Carlo techniques.</p> <p>E.g.</p> \\[\\mathbb{E}[f(x,U)] \\approx \\frac{1}{N_k}\\sum_{i=1}^{N_k} f\\left(x,U^{(k,i)}\\right)\\] <p>or</p> \\[\\mathbb{V}[f(x,U)] \\approx \\frac{1}{N_k-1}\\sum_{i=1}^{N_k} \\left(f\\left(x,U^{(k,i)}\\right)- \\frac{1}{N_k}\\sum_{j=1}^{N_k} f\\left(x,U^{(k,j)}\\right)\\right)^2\\] <p>where \\(U\\) is normally distributed with mean \\(\\mu\\) and variance \\(\\sigma^2\\) and \\(U^{(k,1)},\\ldots,U^{(k,N_k)}\\) are \\(N_k\\) realizations of \\(U\\) obtained at the \\(k\\)-th iteration of the optimization loop with an optimized Latin hypercube sampling technique.</p>"},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling.SequentialSampling","title":"SequentialSampling","text":"<pre><code>SequentialSampling(\n    disciplines: Sequence[Discipline],\n    objective_name: str,\n    design_space: DesignSpace,\n    mdo_formulation: BaseMDOFormulation,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    n_samples: int,\n    initial_n_samples: int = 2,\n    n_samples_increment: int = 1,\n    objective_statistic_parameters: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    algo: str = \"OT_OPT_LHS\",\n    algo_options: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    seed: int = SEED,\n    estimate_statistics_iteratively: bool = True,\n    samples_directory_path: str | Path = \"\",\n    mdo_formulation_settings: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    **settings: Any\n)\n</code></pre> <p>               Bases: <code>Sampling</code></p> <p>Sequential sampling-based U-MDO formulation.</p> <p>DOE algorithms</p> <p>This formulation uses a DOE algorithm; read the GEMSEO documentation. for more information about the available DOE algorithm names and options.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>disciplines</code>               (<code>Sequence[Discipline]</code>)           \u2013            <p>The disciplines.</p> </li> <li> <code>objective_name</code>               (<code>str</code>)           \u2013            <p>The name(s) of the discipline output(s) used as objective. If multiple names are passed, the objective will be a vector.</p> </li> <li> <code>design_space</code>               (<code>DesignSpace</code>)           \u2013            <p>The design space.</p> </li> <li> <code>mdo_formulation</code>               (<code>BaseMDOFormulation</code>)           \u2013            <p>The MDO formulation generating functions evaluable over the uncertain space and differentiable with respect to the design variables.</p> </li> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain variables with their probability distributions.</p> </li> <li> <code>objective_statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the objective.</p> </li> <li> <code>n_samples</code>               (<code>int</code>)           \u2013            <p>The number of samples to be generated by the DOE algorithm. If <code>None</code>, the DOE algorithm uses no <code>n_samples</code> argument but potentially a mandatory argument to be defined in <code>algo_options</code> (e.g. <code>samples</code> for the <code>CustomDOE</code> algorithm).</p> </li> <li> <code>initial_n_samples</code>               (<code>int</code>, default:                   <code>2</code> )           \u2013            <p>The initial sampling size.</p> </li> <li> <code>n_samples_increment</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>The increment of the sampling size.</p> </li> <li> <code>objective_statistic_parameters</code>               (<code>StrKeyMapping</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The values of the parameters of the statistic to be applied to the objective, if any.</p> </li> <li> <code>algo</code>               (<code>str</code>, default:                   <code>'OT_OPT_LHS'</code> )           \u2013            <p>The name of the DOE algorithm.</p> </li> <li> <code>algo_options</code>               (<code>StrKeyMapping</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The options of the DOE algorithm.</p> </li> <li> <code>seed</code>               (<code>int</code>, default:                   <code>SEED</code> )           \u2013            <p>The seed for reproducibility.</p> </li> <li> <code>estimate_statistics_iteratively</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to estimate the statistics iteratively for memory reasons. This argument is ignored when <code>samples_directory_path</code> is defined; in this case, the statistics are not estimated iteratively.</p> </li> <li> <code>samples_directory_path</code>               (<code>str | Path</code>, default:                   <code>''</code> )           \u2013            <p>The path to a new directory where the samples stored as :class:<code>.IODataset</code> objects will be saved (one object per file, one file per iteration). This directory must not exist; it will be created by the formulation. If empty, do not save the samples.</p> </li> <li> <code>mdo_formulation_settings</code>               (<code>StrKeyMapping</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The settings of the MDO formulation.</p> </li> <li> <code>**settings</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The settings of the formulation. This argument is ignored when <code>settings_model</code> is not <code>None</code>.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>When <code>n_samples</code> is <code>None</code>, whereas it is required by the DOE algorithm.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/sequential_sampling.py</code> <pre><code>def __init__(\n    self,\n    disciplines: Sequence[Discipline],\n    objective_name: str,\n    design_space: DesignSpace,\n    mdo_formulation: BaseMDOFormulation,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    n_samples: int,\n    initial_n_samples: int = 2,\n    n_samples_increment: int = 1,\n    objective_statistic_parameters: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    algo: str = \"OT_OPT_LHS\",\n    algo_options: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    seed: int = SEED,\n    estimate_statistics_iteratively: bool = True,\n    samples_directory_path: str | Path = \"\",\n    mdo_formulation_settings: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    **settings: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        initial_n_samples: The initial sampling size.\n        n_samples_increment: The increment of the sampling size.\n    \"\"\"  # noqa: D205 D212 D415\n    super().__init__(\n        disciplines,\n        objective_name,\n        design_space,\n        mdo_formulation,\n        uncertain_space,\n        objective_statistic_name,\n        initial_n_samples,\n        objective_statistic_parameters=objective_statistic_parameters,\n        algo=algo,\n        algo_options=algo_options,\n        seed=seed,\n        estimate_statistics_iteratively=estimate_statistics_iteratively,\n        samples_directory_path=samples_directory_path,\n        mdo_formulation_settings=mdo_formulation_settings,\n        **settings,\n    )\n    self.__final_n_samples = n_samples\n    self.__n_samples_increment = n_samples_increment\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling.SequentialSampling-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling.SequentialSampling.auxiliary_mdo_formulation","title":"auxiliary_mdo_formulation  <code>property</code>","text":"<pre><code>auxiliary_mdo_formulation: BaseMDOFormulation\n</code></pre> <p>The auxiliary MDO formulation.</p> <p>The functions are evaluable over the uncertain space and differentiable with respect to the uncertain variables.</p>"},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling.SequentialSampling.available_statistics","title":"available_statistics  <code>property</code>","text":"<pre><code>available_statistics: list[str]\n</code></pre> <p>The names of the statistics to quantify the output uncertainties.</p>"},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling.SequentialSampling.callbacks","title":"callbacks  <code>instance-attribute</code>","text":"<pre><code>callbacks: list[CallbackType] = []\n</code></pre> <p>The callback functions for the DOE algorithm when computing the output data.</p>"},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling.SequentialSampling.input_data_to_output_data","title":"input_data_to_output_data  <code>instance-attribute</code>","text":"<pre><code>input_data_to_output_data: dict[\n    HashableNdarray, dict[str, Any]\n] = {}\n</code></pre> <p>The output samples or output statistics associated with the input data.</p>"},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling.SequentialSampling.jacobian_callbacks","title":"jacobian_callbacks  <code>instance-attribute</code>","text":"<pre><code>jacobian_callbacks: list[CallbackType] = []\n</code></pre> <p>The callback functions for the DOE algorithm when computing the Jacobian.</p>"},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling.SequentialSampling.mdo_formulation","title":"mdo_formulation  <code>property</code>","text":"<pre><code>mdo_formulation: BaseMDOFormulation\n</code></pre> <p>The MDO formulation.</p> <p>The functions are evaluable over the uncertain space and differentiable with respect to the design variables.</p>"},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling.SequentialSampling.uncertain_space","title":"uncertain_space  <code>property</code>","text":"<pre><code>uncertain_space: ParameterSpace\n</code></pre> <p>The uncertain variable space.</p>"},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling.SequentialSampling-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling.SequentialSampling.add_constraint","title":"add_constraint","text":"<pre><code>add_constraint(\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: ConstraintType = INEQ,\n    constraint_name: str = \"\",\n    value: float = 0.0,\n    positive: bool = False,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Add an equality or inequality constraint to the optimization problem.</p> <p>An equality constraint is written as :math:<code>c(x)=a</code>, a positive inequality constraint is written as :math:<code>c(x)\\geq a</code> and a negative inequality constraint is written as :math:<code>c(x)\\leq a</code>.</p> <p>This constraint is in addition to those created by the formulation, e.g. consistency constraints in IDF.</p> <p>The strategy of repartition of the constraints is defined by the formulation.</p> <p>Parameters:</p> <ul> <li> <code>output_name</code>               (<code>str | Sequence[str]</code>)           \u2013            <p>The name(s) of the outputs computed by :math:<code>c(x)</code>. If several names are given, a single discipline must provide all outputs.</p> </li> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the constraint.</p> </li> <li> <code>constraint_type</code>               (<code>ConstraintType</code>, default:                   <code>INEQ</code> )           \u2013            <p>The type of constraint.</p> </li> <li> <code>constraint_name</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>The name of the constraint to be stored. If empty, the name of the constraint is generated from <code>output_name</code>, <code>constraint_type</code>, <code>value</code> and <code>positive</code>.</p> </li> <li> <code>value</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>The value :math:<code>a</code>.</p> </li> <li> <code>positive</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether the inequality constraint is positive.</p> </li> <li> <code>**statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def add_constraint(\n    self,\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: MDOFunction.ConstraintType = MDOFunction.ConstraintType.INEQ,\n    constraint_name: str = \"\",\n    value: float = 0.0,\n    positive: bool = False,\n    **statistic_parameters: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        statistic_name: The name of the statistic to be applied to the constraint.\n        statistic_parameters: The values of the parameters of the statistic\n            to be applied to the constraint, if any.\n    \"\"\"  # noqa: D205 D212 D415\n    if self._auxiliary_mdo_formulation is not None:\n        self._auxiliary_mdo_formulation.add_observable(output_name)\n\n    self._mdo_formulation.add_observable(output_name)\n    constraint = self._statistic_function_class(\n        self,\n        self._mdo_formulation.optimization_problem.observables[-1],\n        MDOFunction.FunctionType.NONE,\n        statistic_name,\n        **statistic_parameters,\n    )\n    name = self.__compute_name(output_name, statistic_name, **statistic_parameters)\n    constraint.output_names = [name]\n    if constraint_name:\n        constraint.name = constraint_name\n        constraint.has_default_name = False\n    else:\n        constraint.name = name\n        constraint.has_default_name = True\n    self.optimization_problem.add_constraint(\n        constraint,\n        value=value,\n        positive=positive,\n        constraint_type=constraint_type,\n    )\n    self._post_add_constraint()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling.SequentialSampling.add_observable","title":"add_observable","text":"<pre><code>add_observable(\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: str = \"\",\n    discipline: Discipline | None = None,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Add an observable to the optimization problem.</p> <p>The repartition strategy of the observable is defined in the formulation class.</p> <p>Parameters:</p> <ul> <li> <code>output_names</code>               (<code>Sequence[str]</code>)           \u2013            <p>The name(s) of the output(s) to observe.</p> </li> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the observable.</p> </li> <li> <code>observable_name</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>The name of the observable. If empty, the output name is used by default.</p> </li> <li> <code>discipline</code>               (<code>Discipline | None</code>, default:                   <code>None</code> )           \u2013            <p>The discipline computing the observed outputs. If <code>None</code>, the discipline is detected from inner disciplines.</p> </li> <li> <code>**statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def add_observable(\n    self,\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: str = \"\",\n    discipline: Discipline | None = None,\n    **statistic_parameters: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        statistic_name: The name of the statistic to be applied to the observable.\n        statistic_parameters: The values of the parameters\n            of the statistic to be applied to the observable, if any.\n    \"\"\"  # noqa: D205 D212 D415\n    if self._auxiliary_mdo_formulation is not None:\n        self._auxiliary_mdo_formulation.add_observable(\n            output_names,\n            observable_name=observable_name,\n            discipline=discipline,\n        )\n\n    self._mdo_formulation.add_observable(\n        output_names,\n        observable_name=observable_name,\n        discipline=discipline,\n    )\n    sub_opt_problem = self._mdo_formulation.optimization_problem\n    observable = self._statistic_function_class(\n        self,\n        sub_opt_problem.observables[-1],\n        MDOFunction.FunctionType.NONE,\n        statistic_name,\n        **statistic_parameters,\n    )\n    observable.name = self.__compute_name(\n        observable_name or output_names, statistic_name, **statistic_parameters\n    )\n    self.optimization_problem.add_observable(observable)\n    self._post_add_observable()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling.SequentialSampling.compute_samples","title":"compute_samples","text":"<pre><code>compute_samples(\n    problem: OptimizationProblem,\n    input_data: RealArray,\n    compute_jacobian: bool = False,\n) -&gt; None\n</code></pre> <p>Evaluate the functions of a problem with a DOE algorithm.</p> <p>Parameters:</p> <ul> <li> <code>problem</code>               (<code>OptimizationProblem</code>)           \u2013            <p>The sampling problem.</p> </li> <li> <code>input_data</code>               (<code>RealArray</code>)           \u2013            <p>The input point at which to estimate the statistic.</p> </li> <li> <code>compute_jacobian</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to compute the Jacobian of the objective.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/sequential_sampling.py</code> <pre><code>def compute_samples(  # noqa: D102\n    self,\n    problem: OptimizationProblem,\n    input_data: RealArray,\n    compute_jacobian: bool = False,\n) -&gt; None:\n    super().compute_samples(problem, input_data, compute_jacobian=compute_jacobian)\n    if self._n_samples &lt; self.__final_n_samples:\n        self._n_samples = min(\n            self.__final_n_samples, self._n_samples + self.__n_samples_increment\n        )\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling.SequentialSampling.get_top_level_disciplines","title":"get_top_level_disciplines","text":"<pre><code>get_top_level_disciplines() -&gt; list[Discipline]\n</code></pre> <p>Return the disciplines which inputs are required to run the scenario.</p> <p>A formulation seeks to compute the objective and constraints from the input variables. It structures the optimization problem into multiple levels of disciplines. The disciplines directly depending on these inputs are called top level disciplines.</p> <p>By default, this method returns all disciplines. This method can be overloaded by subclasses.</p> <p>Returns:</p> <ul> <li> <code>list[Discipline]</code>           \u2013            <p>The top level disciplines.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def get_top_level_disciplines(self) -&gt; list[Discipline]:  # noqa: D102\n    return self._mdo_formulation.get_top_level_disciplines()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/sequential_sampling/#gemseo_umdo.formulations.sequential_sampling.SequentialSampling.update_top_level_disciplines","title":"update_top_level_disciplines","text":"<pre><code>update_top_level_disciplines(\n    design_values: RealArray,\n) -&gt; None\n</code></pre> <p>Update the default input values of the top-level disciplines.</p> <p>Parameters:</p> <ul> <li> <code>design_values</code>               (<code>RealArray</code>)           \u2013            <p>The values of the design variables to update the default input values of the top-level disciplines.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def update_top_level_disciplines(self, design_values: RealArray) -&gt; None:\n    \"\"\"Update the default input values of the top-level disciplines.\n\n    Args:\n        design_values: The values of the design variables\n            to update the default input values of the top-level disciplines.\n    \"\"\"\n    design_values = split_array_to_dict_of_arrays(\n        design_values,\n        self.design_space.variable_sizes,\n        self.design_space.variable_names,\n    )\n    for formulation in [self._mdo_formulation, self._auxiliary_mdo_formulation]:\n        if formulation is None:\n            continue\n\n        for discipline in formulation.get_top_level_disciplines():\n            discipline.default_input_data.update({\n                k: v\n                for k, v in design_values.items()\n                if k in discipline.input_grammar\n            })\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/sequential_sampling_settings/","title":"Sequential sampling settings","text":""},{"location":"reference/gemseo_umdo/formulations/sequential_sampling_settings/#gemseo_umdo.formulations.sequential_sampling_settings","title":"sequential_sampling_settings","text":"<p>Settings for the sequential sampling-based U-MDO formulation.</p>"},{"location":"reference/gemseo_umdo/formulations/sequential_sampling_settings/#gemseo_umdo.formulations.sequential_sampling_settings-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/sequential_sampling_settings/#gemseo_umdo.formulations.sequential_sampling_settings.SequentialSamplingSettings","title":"SequentialSamplingSettings","text":"<p>               Bases: <code>BaseUMDOFormulationSettings</code></p> <p>The settings for the sequential sampling-based U-MDO formulation.</p>"},{"location":"reference/gemseo_umdo/formulations/surrogate/","title":"Surrogate","text":""},{"location":"reference/gemseo_umdo/formulations/surrogate/#gemseo_umdo.formulations.surrogate","title":"surrogate","text":"<p>Surrogate-based U-MDO formulation.</p> <p>Surrogate is an BaseUMDOFormulation estimating the statistics with (quasi) Monte Carlo techniques applied to a surrogate model.</p> <p>E.g.</p> \\[\\mathbb{E}[f(x,U)] \\approx \\frac{1}{N}\\sum_{i=1}^N \\hat{f}_x\\left(U^{(i)}\\right)\\] <p>or</p> \\[\\mathbb{V}[f(x,U)] \\approx \\frac{1}{N}\\sum_{i=1}^N \\left(\\hat{f}_x\\left(U^{(i)}\\right)- \\frac{1}{N}\\sum_{j=1}^N \\hat{f}_x\\left(U^{(j)}\\right)\\right)^2\\] <p>where \\(\\hat{f}_x\\) is a surrogate model of \\(f\\) at \\(x\\), \\(U\\) is normally distributed with mean \\(\\mu\\) and variance \\(\\sigma^2\\) and \\(U^{(1)},\\ldots,U^{(N)}\\) are \\(N\\) realizations of \\(U\\) obtained with an optimized Latin hypercube sampling technique.</p>"},{"location":"reference/gemseo_umdo/formulations/surrogate/#gemseo_umdo.formulations.surrogate-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/surrogate/#gemseo_umdo.formulations.surrogate.Surrogate","title":"Surrogate","text":"<pre><code>Surrogate(\n    disciplines: Sequence[Discipline],\n    objective_name: str,\n    design_space: DesignSpace,\n    mdo_formulation: BaseMDOFormulation,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    objective_statistic_parameters: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    doe_algo: str = \"OT_OPT_LHS\",\n    doe_algo_options: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    doe_n_samples: int | None = None,\n    regressor_name: str = \"RBFRegressor\",\n    regressor_options: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    regressor_n_samples: int = 10000,\n    regressor_sampling_seed: int = SEED,\n    quality_name: str = \"R2Measure\",\n    quality_threshold: (\n        float | Mapping[str, float | Iterable[float]]\n    ) = 0.9,\n    quality_cv_compute: bool = True,\n    quality_cv_n_folds: int = 5,\n    quality_cv_randomize: bool = True,\n    quality_cv_seed: int | None = None,\n    quality_cv_threshold: (\n        float | Mapping[str, float | Iterable[float]]\n    ) = 0.8,\n    mdo_formulation_settings: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    **settings: Any\n)\n</code></pre> <p>               Bases: <code>BaseUMDOFormulation</code></p> <p>Surrogate-based U-MDO formulation.</p> <p>DOE algorithms</p> <p>This formulation uses a DOE algorithm; read the GEMSEO documentation. for more information about the available DOE algorithm names and options.</p> <p>Regression algorithms</p> <p>This formulation uses a regression algorithm; read the GEMSEO documentation. for more information about the available regression algorithm names and options.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>disciplines</code>               (<code>Sequence[Discipline]</code>)           \u2013            <p>The disciplines.</p> </li> <li> <code>objective_name</code>               (<code>str</code>)           \u2013            <p>The name(s) of the discipline output(s) used as objective. If multiple names are passed, the objective will be a vector.</p> </li> <li> <code>design_space</code>               (<code>DesignSpace</code>)           \u2013            <p>The design space.</p> </li> <li> <code>mdo_formulation</code>               (<code>BaseMDOFormulation</code>)           \u2013            <p>The MDO formulation generating functions evaluable over the uncertain space and differentiable with respect to the design variables.</p> </li> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain variables with their probability distributions.</p> </li> <li> <code>objective_statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the objective.</p> </li> <li> <code>objective_statistic_parameters</code>               (<code>StrKeyMapping</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The values of the parameters of the statistic to be applied to the objective, if any.</p> </li> <li> <code>doe_algo</code>               (<code>str</code>, default:                   <code>'OT_OPT_LHS'</code> )           \u2013            <p>The name of the DOE algorithm.</p> </li> <li> <code>doe_algo_options</code>               (<code>StrKeyMapping</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The options of the DOE algorithm.</p> </li> <li> <code>doe_n_samples</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>The number of samples to be generated by the DOE algorithm. If <code>None</code>, the DOE algorithm does not use <code>doe_n_samples</code> argument but potentially a mandatory argument to be defined in <code>doe_algo_options</code> (e.g. <code>samples</code> for the <code>CustomDOE</code> algorithm).</p> </li> <li> <code>regressor_name</code>               (<code>str</code>, default:                   <code>'RBFRegressor'</code> )           \u2013            <p>The regressor class name.</p> </li> <li> <code>regressor_options</code>               (<code>StrKeyMapping</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The options of the BaseRegressor.</p> </li> <li> <code>regressor_n_samples</code>               (<code>int</code>, default:                   <code>10000</code> )           \u2013            <p>The number of Monte Carlo samples to estimate the statistics from the regressor.</p> </li> <li> <code>regressor_sampling_seed</code>               (<code>int</code>, default:                   <code>SEED</code> )           \u2013            <p>the seed of the Monte Carlo sampler.</p> </li> <li> <code>quality_name</code>               (<code>str</code>, default:                   <code>'R2Measure'</code> )           \u2013            <p>The name of the measure to assess the quality of the regressor.</p> </li> <li> <code>quality_threshold</code>               (<code>float | Mapping[str, float | Iterable[float]]</code>, default:                   <code>0.9</code> )           \u2013            <p>The learning quality threshold below which a warning is logged.</p> </li> <li> <code>quality_cv_compute</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to estimate the quality by cross-validation (CV).</p> </li> <li> <code>quality_cv_n_folds</code>               (<code>int</code>, default:                   <code>5</code> )           \u2013            <p>The description is missing.</p> </li> <li> <code>quality_cv_randomize</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to shuffle the samples before dividing them in folds in the case of the CV technique.</p> </li> <li> <code>quality_cv_seed</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>The seed of the pseudo-random number generator. If <code>None</code>, an unpredictable generator is used.</p> </li> <li> <code>quality_cv_threshold</code>               (<code>float | Mapping[str, float | Iterable[float]]</code>, default:                   <code>0.8</code> )           \u2013            <p>The CV quality threshold below which a warning is logged.</p> </li> <li> <code>mdo_formulation_settings</code>               (<code>StrKeyMapping</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The settings of the MDO formulation.</p> </li> <li> <code>**settings</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The settings of the formulation. This argument is ignored when <code>settings_model</code> is not <code>None</code>.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>When <code>n_samples</code> is <code>None</code>, whereas it is required by the DOE algorithm.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/surrogate.py</code> <pre><code>def __init__(\n    self,\n    disciplines: Sequence[Discipline],\n    objective_name: str,\n    design_space: DesignSpace,\n    mdo_formulation: BaseMDOFormulation,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    objective_statistic_parameters: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    doe_algo: str = \"OT_OPT_LHS\",\n    doe_algo_options: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    doe_n_samples: int | None = None,\n    regressor_name: str = \"RBFRegressor\",\n    regressor_options: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    regressor_n_samples: int = 10000,\n    regressor_sampling_seed: int = SEED,\n    quality_name: str = \"R2Measure\",\n    quality_threshold: float | Mapping[str, float | Iterable[float]] = 0.9,\n    quality_cv_compute: bool = True,\n    quality_cv_n_folds: int = 5,\n    quality_cv_randomize: bool = True,\n    quality_cv_seed: int | None = None,\n    quality_cv_threshold: float | Mapping[str, float | Iterable[float]] = 0.8,\n    mdo_formulation_settings: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    **settings: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        doe_n_samples: The number of samples to be generated by the DOE algorithm.\n            If `None`,\n            the DOE algorithm does not use `doe_n_samples` argument\n            but potentially a mandatory argument to be defined in `doe_algo_options`\n            (e.g. `samples` for the `CustomDOE` algorithm).\n        doe_algo: The name of the DOE algorithm.\n        doe_algo_options: The options of the DOE algorithm.\n        regressor_name: The regressor class name.\n        regressor_options: The options of the\n            [BaseRegressor][gemseo.mlearning.regression.algos.base_regressor.BaseRegressor].\n        regressor_n_samples: The number of Monte Carlo samples\n            to estimate the statistics from the regressor.\n        regressor_sampling_seed: the seed of the Monte Carlo sampler.\n        quality_threshold: The learning quality threshold\n            below which a warning is logged.\n        quality_name: The name of the measure\n            to assess the quality of the regressor.\n        quality_cv_compute: Whether to estimate the quality\n            by cross-validation (CV).\n        quality_n_folds: The number of folds in the case of the CV technique.\n        quality_cv_randomize: Whether to shuffle the samples\n            before dividing them in folds in the case of the CV technique.\n        quality_cv_seed: The seed of the pseudo-random number generator.\n            If ``None``,\n            an unpredictable generator is used.\n        quality_cv_threshold: The CV quality threshold\n            below which a warning is logged.\n\n    Raises:\n        ValueError: When `n_samples` is `None`,\n            whereas it is required by the DOE algorithm.\n    \"\"\"  # noqa: D205 D212 D415\n    self.input_data_to_output_samples = {}\n    self.__doe_algo = DOELibraryFactory().create(doe_algo)\n    self.__doe_algo_options = dict(doe_algo_options)\n    model_fields = self.__doe_algo.ALGORITHM_INFOS[doe_algo].Settings.model_fields\n    if \"n_samples\" in model_fields:\n        if doe_n_samples is None:\n            msg = (\n                \"The doe_n_samples argument of \"\n                f\"the U-MDO formulation '{self.__class__.__name__}' \"\n                \"is required.\"\n            )\n            raise ValueError(msg)\n        self.__doe_algo_options[\"n_samples\"] = doe_n_samples\n\n    if \"seed\" in model_fields and self.__doe_algo_options.get(\"seed\") is None:\n        # Use a constant seed to use the same input samples at each design value.\n        self.__doe_algo_options[\"seed\"] = SEED\n\n    self.__n_samples = doe_n_samples\n    self._estimators = []\n    self.regressor_name = regressor_name\n    self.regressor_options = regressor_options\n    self.input_samples = uncertain_space.convert_array_to_dict(\n        SciPyDOE(\"MC\").compute_doe(\n            uncertain_space,\n            n_samples=regressor_n_samples,\n            seed=regressor_sampling_seed,\n        )\n    )\n    self.quality = RegressorQualityFactory().get_class(quality_name)\n    if quality_cv_compute:\n        self.quality_cv_options = {\n            \"n_folds\": quality_cv_n_folds,\n            \"seed\": quality_cv_seed,\n            \"randomize\": quality_cv_randomize,\n        }\n    else:\n        self.quality_cv_options = {}\n\n    self.quality_threshold = quality_threshold\n    self.quality_cv_threshold = quality_cv_threshold\n    super().__init__(\n        disciplines,\n        objective_name,\n        design_space,\n        mdo_formulation,\n        uncertain_space,\n        objective_statistic_name,\n        objective_statistic_parameters=objective_statistic_parameters,\n        mdo_formulation_settings=mdo_formulation_settings,\n        **settings,\n    )\n    mdo_formulation = self._mdo_formulation.__class__.__name__\n    formulation = self.__class__.__name__\n    self.name = f\"{formulation}[{mdo_formulation}; {doe_algo}({doe_n_samples})]\"\n    smaller_is_better = self.quality.SMALLER_IS_BETTER\n    self.is_surrogate_quality_bad = gt if smaller_is_better else lt\n    self.quality_operators = (\"&lt;=\", \"&gt;\") if smaller_is_better else (\"&gt;=\", \"&lt;\")\n    self.threshold = {}\n    self.cv_threshold = {}\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/surrogate/#gemseo_umdo.formulations.surrogate.Surrogate-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/formulations/surrogate/#gemseo_umdo.formulations.surrogate.Surrogate.auxiliary_mdo_formulation","title":"auxiliary_mdo_formulation  <code>property</code>","text":"<pre><code>auxiliary_mdo_formulation: BaseMDOFormulation\n</code></pre> <p>The auxiliary MDO formulation.</p> <p>The functions are evaluable over the uncertain space and differentiable with respect to the uncertain variables.</p>"},{"location":"reference/gemseo_umdo/formulations/surrogate/#gemseo_umdo.formulations.surrogate.Surrogate.available_statistics","title":"available_statistics  <code>property</code>","text":"<pre><code>available_statistics: list[str]\n</code></pre> <p>The names of the statistics to quantify the output uncertainties.</p>"},{"location":"reference/gemseo_umdo/formulations/surrogate/#gemseo_umdo.formulations.surrogate.Surrogate.cv_threshold","title":"cv_threshold  <code>instance-attribute</code>","text":"<pre><code>cv_threshold: dict[str, RealArray] = {}\n</code></pre> <p>The cross-validation threshold component-wise.</p>"},{"location":"reference/gemseo_umdo/formulations/surrogate/#gemseo_umdo.formulations.surrogate.Surrogate.input_data_to_output_data","title":"input_data_to_output_data  <code>instance-attribute</code>","text":"<pre><code>input_data_to_output_data: dict[\n    HashableNdarray, dict[str, Any]\n] = {}\n</code></pre> <p>The output samples or output statistics associated with the input data.</p>"},{"location":"reference/gemseo_umdo/formulations/surrogate/#gemseo_umdo.formulations.surrogate.Surrogate.input_samples","title":"input_samples  <code>instance-attribute</code>","text":"<pre><code>input_samples: dict[str, RealArray] = convert_array_to_dict(\n    compute_doe(\n        uncertain_space,\n        n_samples=regressor_n_samples,\n        seed=regressor_sampling_seed,\n    )\n)\n</code></pre> <p>The input_samples.</p>"},{"location":"reference/gemseo_umdo/formulations/surrogate/#gemseo_umdo.formulations.surrogate.Surrogate.is_surrogate_quality_bad","title":"is_surrogate_quality_bad  <code>instance-attribute</code>","text":"<pre><code>is_surrogate_quality_bad: Callable[[float, float], bool] = (\n    gt if smaller_is_better else lt\n)\n</code></pre> <p>A function to indicate if the regressor is good for an output component.</p>"},{"location":"reference/gemseo_umdo/formulations/surrogate/#gemseo_umdo.formulations.surrogate.Surrogate.mdo_formulation","title":"mdo_formulation  <code>property</code>","text":"<pre><code>mdo_formulation: BaseMDOFormulation\n</code></pre> <p>The MDO formulation.</p> <p>The functions are evaluable over the uncertain space and differentiable with respect to the design variables.</p>"},{"location":"reference/gemseo_umdo/formulations/surrogate/#gemseo_umdo.formulations.surrogate.Surrogate.quality","title":"quality  <code>instance-attribute</code>","text":"<pre><code>quality: type[BaseRegressorQuality] = get_class(\n    quality_name\n)\n</code></pre> <p>The class to assess the quality of the regressor.</p>"},{"location":"reference/gemseo_umdo/formulations/surrogate/#gemseo_umdo.formulations.surrogate.Surrogate.quality_cv_options","title":"quality_cv_options  <code>instance-attribute</code>","text":"<pre><code>quality_cv_options: dict[str, bool | int | None]\n</code></pre> <p>The options of the CV technique; if empty, do not use it.</p>"},{"location":"reference/gemseo_umdo/formulations/surrogate/#gemseo_umdo.formulations.surrogate.Surrogate.quality_cv_threshold","title":"quality_cv_threshold  <code>instance-attribute</code>","text":"<pre><code>quality_cv_threshold: (\n    float | Mapping[str, float | Iterable[float]]\n) = quality_cv_threshold\n</code></pre> <p>The CV quality threshold below which a warning is logged.</p>"},{"location":"reference/gemseo_umdo/formulations/surrogate/#gemseo_umdo.formulations.surrogate.Surrogate.quality_operators","title":"quality_operators  <code>instance-attribute</code>","text":"<pre><code>quality_operators: tuple[str, str] = (\n    (\"&lt;=\", \"&gt;\") if smaller_is_better else (\"&gt;=\", \"&lt;\")\n)\n</code></pre> <p>The operators <code>(o1, o2)</code> to compare the quality of the regressor and a threshold.</p> <p>\"A o1 B\" means that A is better or equal to B. \"A o2 B\" means that A is less good than B.</p>"},{"location":"reference/gemseo_umdo/formulations/surrogate/#gemseo_umdo.formulations.surrogate.Surrogate.quality_threshold","title":"quality_threshold  <code>instance-attribute</code>","text":"<pre><code>quality_threshold: (\n    float | Mapping[str, float | Iterable[float]]\n) = quality_threshold\n</code></pre> <p>The learning quality threshold below which a warning is logged.</p>"},{"location":"reference/gemseo_umdo/formulations/surrogate/#gemseo_umdo.formulations.surrogate.Surrogate.regressor_name","title":"regressor_name  <code>instance-attribute</code>","text":"<pre><code>regressor_name: str = regressor_name\n</code></pre> <p>The regressor class name.</p>"},{"location":"reference/gemseo_umdo/formulations/surrogate/#gemseo_umdo.formulations.surrogate.Surrogate.regressor_options","title":"regressor_options  <code>instance-attribute</code>","text":"<pre><code>regressor_options: StrKeyMapping = regressor_options\n</code></pre> <p>The BaseRegressor.</p>"},{"location":"reference/gemseo_umdo/formulations/surrogate/#gemseo_umdo.formulations.surrogate.Surrogate.threshold","title":"threshold  <code>instance-attribute</code>","text":"<pre><code>threshold: dict[str, RealArray] = {}\n</code></pre> <p>The learning quality threshold component-wise.</p>"},{"location":"reference/gemseo_umdo/formulations/surrogate/#gemseo_umdo.formulations.surrogate.Surrogate.uncertain_space","title":"uncertain_space  <code>property</code>","text":"<pre><code>uncertain_space: ParameterSpace\n</code></pre> <p>The uncertain variable space.</p>"},{"location":"reference/gemseo_umdo/formulations/surrogate/#gemseo_umdo.formulations.surrogate.Surrogate-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/surrogate/#gemseo_umdo.formulations.surrogate.Surrogate.add_constraint","title":"add_constraint","text":"<pre><code>add_constraint(\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: ConstraintType = INEQ,\n    constraint_name: str = \"\",\n    value: float = 0.0,\n    positive: bool = False,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Add an equality or inequality constraint to the optimization problem.</p> <p>An equality constraint is written as :math:<code>c(x)=a</code>, a positive inequality constraint is written as :math:<code>c(x)\\geq a</code> and a negative inequality constraint is written as :math:<code>c(x)\\leq a</code>.</p> <p>This constraint is in addition to those created by the formulation, e.g. consistency constraints in IDF.</p> <p>The strategy of repartition of the constraints is defined by the formulation.</p> <p>Parameters:</p> <ul> <li> <code>output_name</code>               (<code>str | Sequence[str]</code>)           \u2013            <p>The name(s) of the outputs computed by :math:<code>c(x)</code>. If several names are given, a single discipline must provide all outputs.</p> </li> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the constraint.</p> </li> <li> <code>constraint_type</code>               (<code>ConstraintType</code>, default:                   <code>INEQ</code> )           \u2013            <p>The type of constraint.</p> </li> <li> <code>constraint_name</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>The name of the constraint to be stored. If empty, the name of the constraint is generated from <code>output_name</code>, <code>constraint_type</code>, <code>value</code> and <code>positive</code>.</p> </li> <li> <code>value</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>The value :math:<code>a</code>.</p> </li> <li> <code>positive</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether the inequality constraint is positive.</p> </li> <li> <code>**statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def add_constraint(\n    self,\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: MDOFunction.ConstraintType = MDOFunction.ConstraintType.INEQ,\n    constraint_name: str = \"\",\n    value: float = 0.0,\n    positive: bool = False,\n    **statistic_parameters: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        statistic_name: The name of the statistic to be applied to the constraint.\n        statistic_parameters: The values of the parameters of the statistic\n            to be applied to the constraint, if any.\n    \"\"\"  # noqa: D205 D212 D415\n    if self._auxiliary_mdo_formulation is not None:\n        self._auxiliary_mdo_formulation.add_observable(output_name)\n\n    self._mdo_formulation.add_observable(output_name)\n    constraint = self._statistic_function_class(\n        self,\n        self._mdo_formulation.optimization_problem.observables[-1],\n        MDOFunction.FunctionType.NONE,\n        statistic_name,\n        **statistic_parameters,\n    )\n    name = self.__compute_name(output_name, statistic_name, **statistic_parameters)\n    constraint.output_names = [name]\n    if constraint_name:\n        constraint.name = constraint_name\n        constraint.has_default_name = False\n    else:\n        constraint.name = name\n        constraint.has_default_name = True\n    self.optimization_problem.add_constraint(\n        constraint,\n        value=value,\n        positive=positive,\n        constraint_type=constraint_type,\n    )\n    self._post_add_constraint()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/surrogate/#gemseo_umdo.formulations.surrogate.Surrogate.add_observable","title":"add_observable","text":"<pre><code>add_observable(\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: str = \"\",\n    discipline: Discipline | None = None,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Add an observable to the optimization problem.</p> <p>The repartition strategy of the observable is defined in the formulation class.</p> <p>Parameters:</p> <ul> <li> <code>output_names</code>               (<code>Sequence[str]</code>)           \u2013            <p>The name(s) of the output(s) to observe.</p> </li> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the observable.</p> </li> <li> <code>observable_name</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>The name of the observable. If empty, the output name is used by default.</p> </li> <li> <code>discipline</code>               (<code>Discipline | None</code>, default:                   <code>None</code> )           \u2013            <p>The discipline computing the observed outputs. If <code>None</code>, the discipline is detected from inner disciplines.</p> </li> <li> <code>**statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def add_observable(\n    self,\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: str = \"\",\n    discipline: Discipline | None = None,\n    **statistic_parameters: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        statistic_name: The name of the statistic to be applied to the observable.\n        statistic_parameters: The values of the parameters\n            of the statistic to be applied to the observable, if any.\n    \"\"\"  # noqa: D205 D212 D415\n    if self._auxiliary_mdo_formulation is not None:\n        self._auxiliary_mdo_formulation.add_observable(\n            output_names,\n            observable_name=observable_name,\n            discipline=discipline,\n        )\n\n    self._mdo_formulation.add_observable(\n        output_names,\n        observable_name=observable_name,\n        discipline=discipline,\n    )\n    sub_opt_problem = self._mdo_formulation.optimization_problem\n    observable = self._statistic_function_class(\n        self,\n        sub_opt_problem.observables[-1],\n        MDOFunction.FunctionType.NONE,\n        statistic_name,\n        **statistic_parameters,\n    )\n    observable.name = self.__compute_name(\n        observable_name or output_names, statistic_name, **statistic_parameters\n    )\n    self.optimization_problem.add_observable(observable)\n    self._post_add_observable()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/surrogate/#gemseo_umdo.formulations.surrogate.Surrogate.compute_samples","title":"compute_samples","text":"<pre><code>compute_samples(problem: OptimizationProblem) -&gt; IODataset\n</code></pre> <p>Evaluate the functions of a problem with a DOE algorithm.</p> <p>Parameters:</p> <ul> <li> <code>problem</code>               (<code>OptimizationProblem</code>)           \u2013            <p>The problem.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/surrogate.py</code> <pre><code>def compute_samples(self, problem: OptimizationProblem) -&gt; IODataset:\n    \"\"\"Evaluate the functions of a problem with a DOE algorithm.\n\n    Args:\n        problem: The problem.\n    \"\"\"\n    with LoggingContext(logging.getLogger(\"gemseo\")):\n        self.__doe_algo.execute(problem, **self.__doe_algo_options)\n\n    io_dataset = problem.to_dataset(opt_naming=False)\n    if not self.threshold:\n        names_to_sizes = {\n            name: len(\n                io_dataset.get_variable_components(io_dataset.OUTPUT_GROUP, name)\n            )\n            for name in io_dataset.output_names\n        }\n        self.threshold = self.__compute_threshold(\n            names_to_sizes, self.quality_threshold\n        )\n        self.cv_threshold = self.__compute_threshold(\n            names_to_sizes, self.quality_cv_threshold\n        )\n\n    return io_dataset\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/surrogate/#gemseo_umdo.formulations.surrogate.Surrogate.get_top_level_disciplines","title":"get_top_level_disciplines","text":"<pre><code>get_top_level_disciplines() -&gt; list[Discipline]\n</code></pre> <p>Return the disciplines which inputs are required to run the scenario.</p> <p>A formulation seeks to compute the objective and constraints from the input variables. It structures the optimization problem into multiple levels of disciplines. The disciplines directly depending on these inputs are called top level disciplines.</p> <p>By default, this method returns all disciplines. This method can be overloaded by subclasses.</p> <p>Returns:</p> <ul> <li> <code>list[Discipline]</code>           \u2013            <p>The top level disciplines.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def get_top_level_disciplines(self) -&gt; list[Discipline]:  # noqa: D102\n    return self._mdo_formulation.get_top_level_disciplines()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/surrogate/#gemseo_umdo.formulations.surrogate.Surrogate.update_top_level_disciplines","title":"update_top_level_disciplines","text":"<pre><code>update_top_level_disciplines(\n    design_values: RealArray,\n) -&gt; None\n</code></pre> <p>Update the default input values of the top-level disciplines.</p> <p>Parameters:</p> <ul> <li> <code>design_values</code>               (<code>RealArray</code>)           \u2013            <p>The values of the design variables to update the default input values of the top-level disciplines.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def update_top_level_disciplines(self, design_values: RealArray) -&gt; None:\n    \"\"\"Update the default input values of the top-level disciplines.\n\n    Args:\n        design_values: The values of the design variables\n            to update the default input values of the top-level disciplines.\n    \"\"\"\n    design_values = split_array_to_dict_of_arrays(\n        design_values,\n        self.design_space.variable_sizes,\n        self.design_space.variable_names,\n    )\n    for formulation in [self._mdo_formulation, self._auxiliary_mdo_formulation]:\n        if formulation is None:\n            continue\n\n        for discipline in formulation.get_top_level_disciplines():\n            discipline.default_input_data.update({\n                k: v\n                for k, v in design_values.items()\n                if k in discipline.input_grammar\n            })\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/surrogate_settings/","title":"Surrogate settings","text":""},{"location":"reference/gemseo_umdo/formulations/surrogate_settings/#gemseo_umdo.formulations.surrogate_settings","title":"surrogate_settings","text":"<p>Settings for the surrogate-based U-MDO formulation.</p>"},{"location":"reference/gemseo_umdo/formulations/surrogate_settings/#gemseo_umdo.formulations.surrogate_settings-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/surrogate_settings/#gemseo_umdo.formulations.surrogate_settings.SurrogateSettings","title":"SurrogateSettings","text":"<p>               Bases: <code>BaseUMDOFormulationSettings</code></p> <p>The settings for the surrogate-based U-MDO formulation.</p>"},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/","title":"Taylor polynomial","text":""},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial","title":"taylor_polynomial","text":"<p>U-MDO formulation based on Taylor polynomials.</p> <p>TaylorPolynomial is an BaseUMDOFormulation estimating the statistics with first- or second-order Taylor polynomials around the expectation of the uncertain variables:</p> \\[f(x,U)\\approx f(x,\\mu) + (U-\\mu)f'(x,\\mu).\\] <p>E.g.</p> \\[\\mathbb{E}[f(x,U)]\\approx \\frac{1}{N}\\sum_{i=1}^N f\\left(x,U^{(i)}\\right)\\] <p>or</p> \\[\\mathbb{V}[f(x,U)]\\approx \\sigma^2f'(x,\\mu)\\] <p>where \\(U\\) is normally distributed with mean \\(\\mu\\) and variance \\(\\sigma^2\\).</p>"},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial.TaylorPolynomial","title":"TaylorPolynomial","text":"<pre><code>TaylorPolynomial(\n    disciplines: Sequence[Discipline],\n    objective_name: str,\n    design_space: DesignSpace,\n    mdo_formulation: BaseMDOFormulation,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    objective_statistic_parameters: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    differentiation_method: DifferentiationMethod = USER_GRAD,\n    second_order: bool = False,\n    mdo_formulation_settings: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    **settings: Any\n)\n</code></pre> <p>               Bases: <code>BaseUMDOFormulation</code></p> <p>U-MDO formulation based on Taylor polynomials.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>disciplines</code>               (<code>Sequence[Discipline]</code>)           \u2013            <p>The disciplines.</p> </li> <li> <code>objective_name</code>               (<code>str</code>)           \u2013            <p>The name(s) of the discipline output(s) used as objective. If multiple names are passed, the objective will be a vector.</p> </li> <li> <code>design_space</code>               (<code>DesignSpace</code>)           \u2013            <p>The design space.</p> </li> <li> <code>mdo_formulation</code>               (<code>BaseMDOFormulation</code>)           \u2013            <p>The MDO formulation generating functions evaluable over the uncertain space and differentiable with respect to the design variables.</p> </li> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain variables with their probability distributions.</p> </li> <li> <code>objective_statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the objective.</p> </li> <li> <code>objective_statistic_parameters</code>               (<code>StrKeyMapping</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The values of the parameters of the statistic to be applied to the objective, if any.</p> </li> <li> <code>differentiation_method</code>               (<code>DifferentiationMethod</code>, default:                   <code>USER_GRAD</code> )           \u2013            <p>The type of method to compute the gradients.</p> </li> <li> <code>second_order</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to use second-order Taylor polynomials instead of first-order Taylor polynomials.</p> </li> <li> <code>mdo_formulation_settings</code>               (<code>StrKeyMapping</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The settings of the MDO formulation.</p> </li> <li> <code>**settings</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The settings of the formulation. This argument is ignored when <code>settings_model</code> is not <code>None</code>.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/taylor_polynomial.py</code> <pre><code>def __init__(  # noqa: D107\n    self,\n    disciplines: Sequence[Discipline],\n    objective_name: str,\n    design_space: DesignSpace,\n    mdo_formulation: BaseMDOFormulation,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    objective_statistic_parameters: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    differentiation_method: OptimizationProblem.DifferentiationMethod = OptimizationProblem.DifferentiationMethod.USER_GRAD,  # noqa: E501\n    second_order: bool = False,\n    mdo_formulation_settings: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    **settings: Any,\n) -&gt; None:  # noqa: D205 D212 D415\n    \"\"\"\n    Args:\n        differentiation_method: The type of method to compute the gradients.\n        second_order: Whether to use second-order Taylor polynomials\n            instead of first-order Taylor polynomials.\n    \"\"\"  # noqa: D205 D212 D415\n    self.__second_order = second_order\n    super().__init__(\n        disciplines,\n        objective_name,\n        design_space,\n        mdo_formulation,\n        uncertain_space,\n        objective_statistic_name,\n        objective_statistic_parameters=objective_statistic_parameters,\n        mdo_formulation_settings=mdo_formulation_settings,\n        **settings,\n    )\n\n    self.__hessian_fd_problem = None\n    problem = self._auxiliary_mdo_formulation.optimization_problem\n    if self.__second_order:\n        self.__hessian_fd_problem = OptimizationProblem(self.uncertain_space)\n        self.__hessian_fd_problem.objective = HessianFunction(problem.objective)\n\n    problem.differentiation_method = differentiation_method\n    problem.design_space = problem.design_space.to_design_space()\n    self.optimization_problem.differentiation_method = (\n        self.optimization_problem.ApproximationMode.FINITE_DIFFERENCES\n    )\n    self.optimization_problem.fd_step = 1e-6\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial.TaylorPolynomial-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial.TaylorPolynomial.auxiliary_mdo_formulation","title":"auxiliary_mdo_formulation  <code>property</code>","text":"<pre><code>auxiliary_mdo_formulation: BaseMDOFormulation\n</code></pre> <p>The auxiliary MDO formulation.</p> <p>The functions are evaluable over the uncertain space and differentiable with respect to the uncertain variables.</p>"},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial.TaylorPolynomial.available_statistics","title":"available_statistics  <code>property</code>","text":"<pre><code>available_statistics: list[str]\n</code></pre> <p>The names of the statistics to quantify the output uncertainties.</p>"},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial.TaylorPolynomial.hessian_fd_problem","title":"hessian_fd_problem  <code>property</code>","text":"<pre><code>hessian_fd_problem: OptimizationProblem | None\n</code></pre> <p>The problem related to the approximation of the Hessian.</p>"},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial.TaylorPolynomial.input_data_to_output_data","title":"input_data_to_output_data  <code>instance-attribute</code>","text":"<pre><code>input_data_to_output_data: dict[\n    HashableNdarray, dict[str, Any]\n] = {}\n</code></pre> <p>The output samples or output statistics associated with the input data.</p>"},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial.TaylorPolynomial.mdo_formulation","title":"mdo_formulation  <code>property</code>","text":"<pre><code>mdo_formulation: BaseMDOFormulation\n</code></pre> <p>The MDO formulation.</p> <p>The functions are evaluable over the uncertain space and differentiable with respect to the design variables.</p>"},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial.TaylorPolynomial.second_order","title":"second_order  <code>property</code>","text":"<pre><code>second_order: bool\n</code></pre> <p>Whether to use a second order approximation.</p>"},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial.TaylorPolynomial.uncertain_space","title":"uncertain_space  <code>property</code>","text":"<pre><code>uncertain_space: ParameterSpace\n</code></pre> <p>The uncertain variable space.</p>"},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial.TaylorPolynomial-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial.TaylorPolynomial.add_constraint","title":"add_constraint","text":"<pre><code>add_constraint(\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: ConstraintType = INEQ,\n    constraint_name: str = \"\",\n    value: float = 0.0,\n    positive: bool = False,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Add an equality or inequality constraint to the optimization problem.</p> <p>An equality constraint is written as :math:<code>c(x)=a</code>, a positive inequality constraint is written as :math:<code>c(x)\\geq a</code> and a negative inequality constraint is written as :math:<code>c(x)\\leq a</code>.</p> <p>This constraint is in addition to those created by the formulation, e.g. consistency constraints in IDF.</p> <p>The strategy of repartition of the constraints is defined by the formulation.</p> <p>Parameters:</p> <ul> <li> <code>output_name</code>               (<code>str | Sequence[str]</code>)           \u2013            <p>The name(s) of the outputs computed by :math:<code>c(x)</code>. If several names are given, a single discipline must provide all outputs.</p> </li> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the constraint.</p> </li> <li> <code>constraint_type</code>               (<code>ConstraintType</code>, default:                   <code>INEQ</code> )           \u2013            <p>The type of constraint.</p> </li> <li> <code>constraint_name</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>The name of the constraint to be stored. If empty, the name of the constraint is generated from <code>output_name</code>, <code>constraint_type</code>, <code>value</code> and <code>positive</code>.</p> </li> <li> <code>value</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>The value :math:<code>a</code>.</p> </li> <li> <code>positive</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether the inequality constraint is positive.</p> </li> <li> <code>**statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/taylor_polynomial.py</code> <pre><code>def add_constraint(  # noqa: D102\n    self,\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: MDOFunction.ConstraintType = MDOFunction.ConstraintType.INEQ,\n    constraint_name: str = \"\",\n    value: float = 0.0,\n    positive: bool = False,\n    **statistic_parameters: Any,\n) -&gt; None:\n    super().add_constraint(\n        output_name,\n        statistic_name,\n        constraint_type=constraint_type,\n        constraint_name=constraint_name,\n        value=value,\n        positive=positive,\n        **statistic_parameters,\n    )\n    if self.hessian_fd_problem is not None:\n        self.hessian_fd_problem.add_observable(\n            HessianFunction(\n                self._auxiliary_mdo_formulation.optimization_problem.observables[-1]\n            )\n        )\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial.TaylorPolynomial.add_observable","title":"add_observable","text":"<pre><code>add_observable(\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: Sequence[str] = \"\",\n    discipline: Discipline | None = None,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Add an observable to the optimization problem.</p> <p>The repartition strategy of the observable is defined in the formulation class.</p> <p>Parameters:</p> <ul> <li> <code>output_names</code>               (<code>Sequence[str]</code>)           \u2013            <p>The name(s) of the output(s) to observe.</p> </li> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the observable.</p> </li> <li> <code>observable_name</code>               (<code>Sequence[str]</code>, default:                   <code>''</code> )           \u2013            <p>The name of the observable. If empty, the output name is used by default.</p> </li> <li> <code>discipline</code>               (<code>Discipline | None</code>, default:                   <code>None</code> )           \u2013            <p>The discipline computing the observed outputs. If <code>None</code>, the discipline is detected from inner disciplines.</p> </li> <li> <code>**statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/taylor_polynomial.py</code> <pre><code>def add_observable(  # noqa: D102\n    self,\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: Sequence[str] = \"\",\n    discipline: Discipline | None = None,\n    **statistic_parameters: Any,\n) -&gt; None:\n    super().add_observable(\n        output_names,\n        statistic_name,\n        observable_name=observable_name,\n        discipline=discipline,\n        **statistic_parameters,\n    )\n    if self.hessian_fd_problem is not None:\n        self.hessian_fd_problem.add_observable(\n            HessianFunction(\n                self._auxiliary_mdo_formulation.optimization_problem.observables[-1]\n            ),\n        )\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial.TaylorPolynomial.evaluate_with_mean","title":"evaluate_with_mean","text":"<pre><code>evaluate_with_mean(\n    problem: OptimizationProblem, eval_jac: bool\n) -&gt; None\n</code></pre> <p>Evaluate the functions at the mean value of the uncertain vector.</p> <p>Parameters:</p> <ul> <li> <code>problem</code>               (<code>OptimizationProblem</code>)           \u2013            <p>The problem including the functions.</p> </li> <li> <code>eval_jac</code>               (<code>bool</code>)           \u2013            <p>Whether to evaluate the Jacobian functions.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/taylor_polynomial.py</code> <pre><code>def evaluate_with_mean(self, problem: OptimizationProblem, eval_jac: bool) -&gt; None:\n    \"\"\"Evaluate the functions at the mean value of the uncertain vector.\n\n    Args:\n        problem: The problem including the functions.\n        eval_jac: Whether to evaluate the Jacobian functions.\n    \"\"\"\n    objective = problem.objective\n    if objective is objective.original:\n        problem.preprocess_functions(\n            is_function_input_normalized=False, eval_obs_jac=eval_jac\n        )\n    output_functions, jacobian_functions = problem.get_functions(\n        observable_names=(), jacobian_names=() if eval_jac else None\n    )\n    problem.evaluate_functions(\n        self._uncertain_space.distribution.mean,\n        output_functions=output_functions or None,\n        jacobian_functions=jacobian_functions or None,\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial.TaylorPolynomial.get_top_level_disciplines","title":"get_top_level_disciplines","text":"<pre><code>get_top_level_disciplines() -&gt; list[Discipline]\n</code></pre> <p>Return the disciplines which inputs are required to run the scenario.</p> <p>A formulation seeks to compute the objective and constraints from the input variables. It structures the optimization problem into multiple levels of disciplines. The disciplines directly depending on these inputs are called top level disciplines.</p> <p>By default, this method returns all disciplines. This method can be overloaded by subclasses.</p> <p>Returns:</p> <ul> <li> <code>list[Discipline]</code>           \u2013            <p>The top level disciplines.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def get_top_level_disciplines(self) -&gt; list[Discipline]:  # noqa: D102\n    return self._mdo_formulation.get_top_level_disciplines()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial/#gemseo_umdo.formulations.taylor_polynomial.TaylorPolynomial.update_top_level_disciplines","title":"update_top_level_disciplines","text":"<pre><code>update_top_level_disciplines(\n    design_values: RealArray,\n) -&gt; None\n</code></pre> <p>Update the default input values of the top-level disciplines.</p> <p>Parameters:</p> <ul> <li> <code>design_values</code>               (<code>RealArray</code>)           \u2013            <p>The values of the design variables to update the default input values of the top-level disciplines.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/base_umdo_formulation.py</code> <pre><code>def update_top_level_disciplines(self, design_values: RealArray) -&gt; None:\n    \"\"\"Update the default input values of the top-level disciplines.\n\n    Args:\n        design_values: The values of the design variables\n            to update the default input values of the top-level disciplines.\n    \"\"\"\n    design_values = split_array_to_dict_of_arrays(\n        design_values,\n        self.design_space.variable_sizes,\n        self.design_space.variable_names,\n    )\n    for formulation in [self._mdo_formulation, self._auxiliary_mdo_formulation]:\n        if formulation is None:\n            continue\n\n        for discipline in formulation.get_top_level_disciplines():\n            discipline.default_input_data.update({\n                k: v\n                for k, v in design_values.items()\n                if k in discipline.input_grammar\n            })\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial_settings/","title":"Taylor polynomial settings","text":""},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial_settings/#gemseo_umdo.formulations.taylor_polynomial_settings","title":"taylor_polynomial_settings","text":"<p>Settings for the U-MDO formulation based on Taylor polynomials.</p>"},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial_settings/#gemseo_umdo.formulations.taylor_polynomial_settings-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/taylor_polynomial_settings/#gemseo_umdo.formulations.taylor_polynomial_settings.TaylorPolynomialSettings","title":"TaylorPolynomialSettings","text":"<p>               Bases: <code>BaseUMDOFormulationSettings</code></p> <p>The settings for the U-MDO formulation based on Taylor polynomials.</p>"},{"location":"reference/gemseo_umdo/formulations/_functions/","title":"functions","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/#gemseo_umdo.formulations._functions","title":"_functions","text":"<p>Functions to estimate statistics from a [BaseUMDOFormulation][gemseo_umdo.formulatio ns.base_umdo_formulation.BaseUMDOFormulation].</p> <p>The base function is a BaseStatisticFunction and derives from an MDOFunction. Most of the other _functions derive from BaseStatisticFunction and are associated with an BaseUMDOFormulation, e.g. Sampling. and TaylorPolynomial. The other modules are helpers.</p>"},{"location":"reference/gemseo_umdo/formulations/_functions/base_statistic_function/","title":"Base statistic function","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/base_statistic_function/#gemseo_umdo.formulations._functions.base_statistic_function","title":"base_statistic_function","text":"<p>A function to compute a statistic from a <code>BaseUMDOFormulation</code>.</p> <p>See Also: BaseUMDOFormulation.</p>"},{"location":"reference/gemseo_umdo/formulations/_functions/base_statistic_function/#gemseo_umdo.formulations._functions.base_statistic_function-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/base_statistic_function/#gemseo_umdo.formulations._functions.base_statistic_function.BaseStatisticFunction","title":"BaseStatisticFunction","text":"<pre><code>BaseStatisticFunction(\n    umdo_formulation: UMDOFormulationT,\n    function: MDOFunction,\n    function_type: FunctionType,\n    name: str,\n    **statistic_options: Any\n)\n</code></pre> <p>               Bases: <code>MDOFunction</code>, <code>Generic[UMDOFormulationT]</code></p> <p>A function to compute a statistic from a <code>BaseUMDOFormulation</code>.</p> <p>Parameters:</p> <ul> <li> <code>umdo_formulation</code>               (<code>UMDOFormulationT</code>)           \u2013            <p>The U-MDO formulation to which the BaseStatisticFunction is attached.</p> </li> <li> <code>function</code>               (<code>MDOFunction</code>)           \u2013            <p>The function for which we want to estimate an output statistic.</p> </li> <li> <code>function_type</code>               (<code>FunctionType</code>)           \u2013            <p>The type of function.</p> </li> <li> <code>name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic.</p> </li> <li> <code>**statistic_options</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The options of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_functions/base_statistic_function.py</code> <pre><code>def __init__(\n    self,\n    umdo_formulation: UMDOFormulationT,\n    function: MDOFunction,\n    function_type: MDOFunction.FunctionType,\n    name: str,\n    **statistic_options: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        umdo_formulation: The U-MDO formulation\n            to which the\n            [BaseStatisticFunction][gemseo_umdo.formulations._functions.base_statistic_function.BaseStatisticFunction]\n            is attached.\n        function: The function for which we want to estimate an output statistic.\n        function_type: The type of function.\n        name: The name of the statistic.\n        **statistic_options: The options of the statistic.\n    \"\"\"  # noqa: D205 D212 D415\n    function_name = function.name\n    self._function_name = function_name\n    self._function_jac_name = Database.get_gradient_name(function_name)\n    self._umdo_formulation = umdo_formulation\n    self._last_input_data = None\n    self._statistic_estimator = umdo_formulation._statistic_factory.create(\n        name, *self._statistic_estimator_parameters, **statistic_options\n    )\n    self._observable_name = (\n        f\"{self._statistic_estimator.__class__.__name__}[{function_name}]\"\n    )\n    self._observable_jac_name = Database.get_gradient_name(self._observable_name)\n    super().__init__(\n        self._func, name=function_name, f_type=function_type, jac=self._jac\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_functions/base_statistic_function_for_sampling/","title":"Base statistic function for sampling","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/base_statistic_function_for_sampling/#gemseo_umdo.formulations._functions.base_statistic_function_for_sampling","title":"base_statistic_function_for_sampling","text":"<p>A function to compute a statistic from <code>Sampling</code>.</p> <p>See also Sampling.</p>"},{"location":"reference/gemseo_umdo/formulations/_functions/base_statistic_function_for_sampling/#gemseo_umdo.formulations._functions.base_statistic_function_for_sampling-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/base_statistic_function_for_sampling/#gemseo_umdo.formulations._functions.base_statistic_function_for_sampling.BaseStatisticFunctionForSampling","title":"BaseStatisticFunctionForSampling","text":"<pre><code>BaseStatisticFunctionForSampling(\n    umdo_formulation: UMDOFormulationT,\n    function: MDOFunction,\n    function_type: FunctionType,\n    name: str,\n    **statistic_options: Any\n)\n</code></pre> <p>               Bases: <code>BaseStatisticFunction[UMDOFormulationT]</code></p> <p>A function to compute a statistic from <code>Sampling</code>.</p> <p>Parameters:</p> <ul> <li> <code>umdo_formulation</code>               (<code>UMDOFormulationT</code>)           \u2013            <p>The U-MDO formulation to which the BaseStatisticFunction is attached.</p> </li> <li> <code>function</code>               (<code>MDOFunction</code>)           \u2013            <p>The function for which we want to estimate an output statistic.</p> </li> <li> <code>function_type</code>               (<code>FunctionType</code>)           \u2013            <p>The type of function.</p> </li> <li> <code>name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic.</p> </li> <li> <code>**statistic_options</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The options of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_functions/base_statistic_function.py</code> <pre><code>def __init__(\n    self,\n    umdo_formulation: UMDOFormulationT,\n    function: MDOFunction,\n    function_type: MDOFunction.FunctionType,\n    name: str,\n    **statistic_options: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        umdo_formulation: The U-MDO formulation\n            to which the\n            [BaseStatisticFunction][gemseo_umdo.formulations._functions.base_statistic_function.BaseStatisticFunction]\n            is attached.\n        function: The function for which we want to estimate an output statistic.\n        function_type: The type of function.\n        name: The name of the statistic.\n        **statistic_options: The options of the statistic.\n    \"\"\"  # noqa: D205 D212 D415\n    function_name = function.name\n    self._function_name = function_name\n    self._function_jac_name = Database.get_gradient_name(function_name)\n    self._umdo_formulation = umdo_formulation\n    self._last_input_data = None\n    self._statistic_estimator = umdo_formulation._statistic_factory.create(\n        name, *self._statistic_estimator_parameters, **statistic_options\n    )\n    self._observable_name = (\n        f\"{self._statistic_estimator.__class__.__name__}[{function_name}]\"\n    )\n    self._observable_jac_name = Database.get_gradient_name(self._observable_name)\n    super().__init__(\n        self._func, name=function_name, f_type=function_type, jac=self._jac\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_functions/hessian_function/","title":"Hessian function","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/hessian_function/#gemseo_umdo.formulations._functions.hessian_function","title":"hessian_function","text":"<p>A function approximating the Hessian matrix by finite differences.</p>"},{"location":"reference/gemseo_umdo/formulations/_functions/hessian_function/#gemseo_umdo.formulations._functions.hessian_function-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/hessian_function/#gemseo_umdo.formulations._functions.hessian_function.HessianFunction","title":"HessianFunction","text":"<pre><code>HessianFunction(func: MDOFunction)\n</code></pre> <p>               Bases: <code>MDOFunction</code></p> <p>A function approximating the Hessian matrix by finite differences.</p> <p>Take an original function and approximate its Hessian with finite differences applied to its analytical or approximated Jacobian.</p> <p>Parameters:</p> <ul> <li> <code>func</code>               (<code>MDOFunction</code>)           \u2013            <p>The original function.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_functions/hessian_function.py</code> <pre><code>def __init__(self, func: MDOFunction) -&gt; None:\n    \"\"\"\n    Args:\n        func: The original function.\n    \"\"\"  # noqa: D205 D212 D415\n    self.__jac = func.jac if func.has_jac else FirstOrderFD(func.func).f_gradient\n    grad_tag = Database.GRAD_TAG\n    super().__init__(\n        FirstOrderFD(self._compute_jac).f_gradient,\n        f\"{grad_tag}{grad_tag}{func.name}\",\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_functions/iterative_estimation/","title":"Iterative estimation","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/iterative_estimation/#gemseo_umdo.formulations._functions.iterative_estimation","title":"iterative_estimation","text":"<p>A function updating the estimation of a statistic.</p>"},{"location":"reference/gemseo_umdo/formulations/_functions/iterative_estimation/#gemseo_umdo.formulations._functions.iterative_estimation-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/iterative_estimation/#gemseo_umdo.formulations._functions.iterative_estimation.IterativeEstimation","title":"IterativeEstimation","text":"<pre><code>IterativeEstimation(\n    output_name: str,\n    output_statistic_name: str,\n    statistic_estimator: BaseSamplingEstimator,\n    return_statistic_jacobian: bool = False,\n)\n</code></pre> <p>A functor to estimate a statistic iteratively.</p> <p>Call this functor to update the estimation of the statistic and access the last evaluation with :attr:<code>.last_evaluation</code>.</p> <p>The Sampling U-MDO formulation passes such functors to a DOELibrary as callback functions to update the statistics of the objective, constraints and observables.</p> <p>Parameters:</p> <ul> <li> <code>output_name</code>               (<code>str</code>)           \u2013            <p>The name of the output for which to estimate the statistic.</p> </li> <li> <code>output_statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic of the output.</p> </li> <li> <code>statistic_estimator</code>               (<code>BaseSamplingEstimator</code>)           \u2013            <p>The function to update the estimation of the statistic.</p> </li> <li> <code>return_statistic_jacobian</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to return the Jacobian of the statistic estimation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_functions/iterative_estimation.py</code> <pre><code>def __init__(\n    self,\n    output_name: str,\n    output_statistic_name: str,\n    statistic_estimator: BaseSamplingEstimator,\n    return_statistic_jacobian: bool = False,\n) -&gt; None:\n    \"\"\"\n    Args:\n        output_name: The name of the output for which to estimate the statistic.\n        output_statistic_name: The name of the statistic of the output.\n        statistic_estimator: The function to update the estimation of the statistic.\n        return_statistic_jacobian: Whether to return\n            the Jacobian of the statistic estimation.\n    \"\"\"  # noqa: D202 D205 D212 D415\n    self.output_name = output_name\n    self.output_statistic_name = output_statistic_name\n    self.last_estimation = array([])\n    self.statistic_estimator = statistic_estimator\n    self.return_statistic_jacobian = return_statistic_jacobian\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_functions/iterative_estimation/#gemseo_umdo.formulations._functions.iterative_estimation.IterativeEstimation-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/iterative_estimation/#gemseo_umdo.formulations._functions.iterative_estimation.IterativeEstimation.last_estimation","title":"last_estimation  <code>instance-attribute</code>","text":"<pre><code>last_estimation: RealArray = array([])\n</code></pre> <p>The last estimation of the statistic.</p>"},{"location":"reference/gemseo_umdo/formulations/_functions/iterative_estimation/#gemseo_umdo.formulations._functions.iterative_estimation.IterativeEstimation.output_name","title":"output_name  <code>instance-attribute</code>","text":"<pre><code>output_name: str = output_name\n</code></pre> <p>The name of the output.</p>"},{"location":"reference/gemseo_umdo/formulations/_functions/iterative_estimation/#gemseo_umdo.formulations._functions.iterative_estimation.IterativeEstimation.output_statistic_name","title":"output_statistic_name  <code>instance-attribute</code>","text":"<pre><code>output_statistic_name: str = output_statistic_name\n</code></pre> <p>The name of the statistic of the output.</p>"},{"location":"reference/gemseo_umdo/formulations/_functions/iterative_estimation/#gemseo_umdo.formulations._functions.iterative_estimation.IterativeEstimation.return_statistic_jacobian","title":"return_statistic_jacobian  <code>instance-attribute</code>","text":"<pre><code>return_statistic_jacobian: bool = return_statistic_jacobian\n</code></pre> <p>Whether the functor returns the Jacobian of the statistic estimation.</p>"},{"location":"reference/gemseo_umdo/formulations/_functions/iterative_estimation/#gemseo_umdo.formulations._functions.iterative_estimation.IterativeEstimation.statistic_estimator","title":"statistic_estimator  <code>instance-attribute</code>","text":"<pre><code>statistic_estimator: BaseSamplingEstimator = (\n    statistic_estimator\n)\n</code></pre> <p>The function to update the estimation of the statistic.</p>"},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_control_variate/","title":"Statistic function for control variate","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_control_variate/#gemseo_umdo.formulations._functions.statistic_function_for_control_variate","title":"statistic_function_for_control_variate","text":"<p>A function to compute a statistic from <code>ControlVariate</code>.</p> <p>See also ControlVariate.</p>"},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_control_variate/#gemseo_umdo.formulations._functions.statistic_function_for_control_variate-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_control_variate/#gemseo_umdo.formulations._functions.statistic_function_for_control_variate.StatisticFunctionForControlVariate","title":"StatisticFunctionForControlVariate","text":"<pre><code>StatisticFunctionForControlVariate(\n    umdo_formulation: UMDOFormulationT,\n    function: MDOFunction,\n    function_type: FunctionType,\n    name: str,\n    **statistic_options: Any\n)\n</code></pre> <p>               Bases: <code>BaseStatisticFunction[ControlVariateT]</code></p> <p>A function to compute a statistic from <code>ControlVariate</code>.</p> <p>Parameters:</p> <ul> <li> <code>umdo_formulation</code>               (<code>UMDOFormulationT</code>)           \u2013            <p>The U-MDO formulation to which the BaseStatisticFunction is attached.</p> </li> <li> <code>function</code>               (<code>MDOFunction</code>)           \u2013            <p>The function for which we want to estimate an output statistic.</p> </li> <li> <code>function_type</code>               (<code>FunctionType</code>)           \u2013            <p>The type of function.</p> </li> <li> <code>name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic.</p> </li> <li> <code>**statistic_options</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The options of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_functions/base_statistic_function.py</code> <pre><code>def __init__(\n    self,\n    umdo_formulation: UMDOFormulationT,\n    function: MDOFunction,\n    function_type: MDOFunction.FunctionType,\n    name: str,\n    **statistic_options: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        umdo_formulation: The U-MDO formulation\n            to which the\n            [BaseStatisticFunction][gemseo_umdo.formulations._functions.base_statistic_function.BaseStatisticFunction]\n            is attached.\n        function: The function for which we want to estimate an output statistic.\n        function_type: The type of function.\n        name: The name of the statistic.\n        **statistic_options: The options of the statistic.\n    \"\"\"  # noqa: D205 D212 D415\n    function_name = function.name\n    self._function_name = function_name\n    self._function_jac_name = Database.get_gradient_name(function_name)\n    self._umdo_formulation = umdo_formulation\n    self._last_input_data = None\n    self._statistic_estimator = umdo_formulation._statistic_factory.create(\n        name, *self._statistic_estimator_parameters, **statistic_options\n    )\n    self._observable_name = (\n        f\"{self._statistic_estimator.__class__.__name__}[{function_name}]\"\n    )\n    self._observable_jac_name = Database.get_gradient_name(self._observable_name)\n    super().__init__(\n        self._func, name=function_name, f_type=function_type, jac=self._jac\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_iterative_sampling/","title":"Statistic function for iterative sampling","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_iterative_sampling/#gemseo_umdo.formulations._functions.statistic_function_for_iterative_sampling","title":"statistic_function_for_iterative_sampling","text":"<p>A function to compute a statistic from <code>Sampling</code>.</p> <p>See also Sampling.</p>"},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_iterative_sampling/#gemseo_umdo.formulations._functions.statistic_function_for_iterative_sampling-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_iterative_sampling/#gemseo_umdo.formulations._functions.statistic_function_for_iterative_sampling.StatisticFunctionForIterativeSampling","title":"StatisticFunctionForIterativeSampling","text":"<pre><code>StatisticFunctionForIterativeSampling(\n    umdo_formulation: SamplingT,\n    function: MDOFunction,\n    function_type: FunctionType,\n    name: str,\n    **statistic_options: Any\n)\n</code></pre> <p>               Bases: <code>BaseStatisticFunctionForSampling[SamplingT]</code></p> <p>A function to compute a statistic from <code>Sampling</code>.</p> <p>Parameters:</p> <ul> <li> <code>umdo_formulation</code>               (<code>UMDOFormulationT</code>)           \u2013            <p>The U-MDO formulation to which the BaseStatisticFunction is attached.</p> </li> <li> <code>function</code>               (<code>MDOFunction</code>)           \u2013            <p>The function for which we want to estimate an output statistic.</p> </li> <li> <code>function_type</code>               (<code>FunctionType</code>)           \u2013            <p>The type of function.</p> </li> <li> <code>name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic.</p> </li> <li> <code>**statistic_options</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The options of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_functions/statistic_function_for_iterative_sampling.py</code> <pre><code>def __init__(\n    self,\n    umdo_formulation: SamplingT,\n    function: MDOFunction,\n    function_type: MDOFunction.FunctionType,\n    name: str,\n    **statistic_options: Any,\n) -&gt; None:\n    super().__init__(\n        umdo_formulation, function, function_type, name, **statistic_options\n    )\n    self._umdo_formulation.callbacks.append(\n        IterativeEstimation(\n            function.name, self._observable_name, self._statistic_estimator\n        )\n    )\n    self._umdo_formulation.jacobian_callbacks.append(\n        IterativeEstimation(\n            function.name,\n            self._observable_jac_name,\n            self._statistic_estimator,\n            return_statistic_jacobian=True,\n        )\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_pce/","title":"Statistic function for pce","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_pce/#gemseo_umdo.formulations._functions.statistic_function_for_pce","title":"statistic_function_for_pce","text":"<p>A function to compute a statistic from <code>PCE</code>.</p> <p>See also PCE.</p>"},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_pce/#gemseo_umdo.formulations._functions.statistic_function_for_pce-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_pce/#gemseo_umdo.formulations._functions.statistic_function_for_pce.StatisticFunctionForPCE","title":"StatisticFunctionForPCE","text":"<pre><code>StatisticFunctionForPCE(\n    umdo_formulation: UMDOFormulationT,\n    function: MDOFunction,\n    function_type: FunctionType,\n    name: str,\n    **statistic_options: Any\n)\n</code></pre> <p>               Bases: <code>StatisticFunctionForSurrogate[PCET]</code></p> <p>A function to compute a statistic from <code>PCE</code>.</p> <p>Parameters:</p> <ul> <li> <code>umdo_formulation</code>               (<code>UMDOFormulationT</code>)           \u2013            <p>The U-MDO formulation to which the BaseStatisticFunction is attached.</p> </li> <li> <code>function</code>               (<code>MDOFunction</code>)           \u2013            <p>The function for which we want to estimate an output statistic.</p> </li> <li> <code>function_type</code>               (<code>FunctionType</code>)           \u2013            <p>The type of function.</p> </li> <li> <code>name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic.</p> </li> <li> <code>**statistic_options</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The options of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_functions/base_statistic_function.py</code> <pre><code>def __init__(\n    self,\n    umdo_formulation: UMDOFormulationT,\n    function: MDOFunction,\n    function_type: MDOFunction.FunctionType,\n    name: str,\n    **statistic_options: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        umdo_formulation: The U-MDO formulation\n            to which the\n            [BaseStatisticFunction][gemseo_umdo.formulations._functions.base_statistic_function.BaseStatisticFunction]\n            is attached.\n        function: The function for which we want to estimate an output statistic.\n        function_type: The type of function.\n        name: The name of the statistic.\n        **statistic_options: The options of the statistic.\n    \"\"\"  # noqa: D205 D212 D415\n    function_name = function.name\n    self._function_name = function_name\n    self._function_jac_name = Database.get_gradient_name(function_name)\n    self._umdo_formulation = umdo_formulation\n    self._last_input_data = None\n    self._statistic_estimator = umdo_formulation._statistic_factory.create(\n        name, *self._statistic_estimator_parameters, **statistic_options\n    )\n    self._observable_name = (\n        f\"{self._statistic_estimator.__class__.__name__}[{function_name}]\"\n    )\n    self._observable_jac_name = Database.get_gradient_name(self._observable_name)\n    super().__init__(\n        self._func, name=function_name, f_type=function_type, jac=self._jac\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_standard_sampling/","title":"Statistic function for standard sampling","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_standard_sampling/#gemseo_umdo.formulations._functions.statistic_function_for_standard_sampling","title":"statistic_function_for_standard_sampling","text":"<p>A function to compute a statistic from <code>Sampling</code>.</p> <p>See also Sampling.</p>"},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_standard_sampling/#gemseo_umdo.formulations._functions.statistic_function_for_standard_sampling-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_standard_sampling/#gemseo_umdo.formulations._functions.statistic_function_for_standard_sampling.StatisticFunctionForStandardSampling","title":"StatisticFunctionForStandardSampling","text":"<pre><code>StatisticFunctionForStandardSampling(\n    umdo_formulation: UMDOFormulationT,\n    function: MDOFunction,\n    function_type: FunctionType,\n    name: str,\n    **statistic_options: Any\n)\n</code></pre> <p>               Bases: <code>BaseStatisticFunctionForSampling[SamplingT]</code></p> <p>A function to compute a statistic from <code>Sampling</code>.</p> <p>Parameters:</p> <ul> <li> <code>umdo_formulation</code>               (<code>UMDOFormulationT</code>)           \u2013            <p>The U-MDO formulation to which the BaseStatisticFunction is attached.</p> </li> <li> <code>function</code>               (<code>MDOFunction</code>)           \u2013            <p>The function for which we want to estimate an output statistic.</p> </li> <li> <code>function_type</code>               (<code>FunctionType</code>)           \u2013            <p>The type of function.</p> </li> <li> <code>name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic.</p> </li> <li> <code>**statistic_options</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The options of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_functions/base_statistic_function.py</code> <pre><code>def __init__(\n    self,\n    umdo_formulation: UMDOFormulationT,\n    function: MDOFunction,\n    function_type: MDOFunction.FunctionType,\n    name: str,\n    **statistic_options: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        umdo_formulation: The U-MDO formulation\n            to which the\n            [BaseStatisticFunction][gemseo_umdo.formulations._functions.base_statistic_function.BaseStatisticFunction]\n            is attached.\n        function: The function for which we want to estimate an output statistic.\n        function_type: The type of function.\n        name: The name of the statistic.\n        **statistic_options: The options of the statistic.\n    \"\"\"  # noqa: D205 D212 D415\n    function_name = function.name\n    self._function_name = function_name\n    self._function_jac_name = Database.get_gradient_name(function_name)\n    self._umdo_formulation = umdo_formulation\n    self._last_input_data = None\n    self._statistic_estimator = umdo_formulation._statistic_factory.create(\n        name, *self._statistic_estimator_parameters, **statistic_options\n    )\n    self._observable_name = (\n        f\"{self._statistic_estimator.__class__.__name__}[{function_name}]\"\n    )\n    self._observable_jac_name = Database.get_gradient_name(self._observable_name)\n    super().__init__(\n        self._func, name=function_name, f_type=function_type, jac=self._jac\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_surrogate/","title":"Statistic function for surrogate","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_surrogate/#gemseo_umdo.formulations._functions.statistic_function_for_surrogate","title":"statistic_function_for_surrogate","text":"<p>A function to compute a statistic from <code>Surrogate</code>.</p> <p>See also Surrogate.</p>"},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_surrogate/#gemseo_umdo.formulations._functions.statistic_function_for_surrogate-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_surrogate/#gemseo_umdo.formulations._functions.statistic_function_for_surrogate.StatisticFunctionForSurrogate","title":"StatisticFunctionForSurrogate","text":"<pre><code>StatisticFunctionForSurrogate(\n    umdo_formulation: UMDOFormulationT,\n    function: MDOFunction,\n    function_type: FunctionType,\n    name: str,\n    **statistic_options: Any\n)\n</code></pre> <p>               Bases: <code>BaseStatisticFunction[SurrogateT]</code></p> <p>A function to compute a statistic from <code>Surrogate</code>.</p> <p>Parameters:</p> <ul> <li> <code>umdo_formulation</code>               (<code>UMDOFormulationT</code>)           \u2013            <p>The U-MDO formulation to which the BaseStatisticFunction is attached.</p> </li> <li> <code>function</code>               (<code>MDOFunction</code>)           \u2013            <p>The function for which we want to estimate an output statistic.</p> </li> <li> <code>function_type</code>               (<code>FunctionType</code>)           \u2013            <p>The type of function.</p> </li> <li> <code>name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic.</p> </li> <li> <code>**statistic_options</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The options of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_functions/base_statistic_function.py</code> <pre><code>def __init__(\n    self,\n    umdo_formulation: UMDOFormulationT,\n    function: MDOFunction,\n    function_type: MDOFunction.FunctionType,\n    name: str,\n    **statistic_options: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        umdo_formulation: The U-MDO formulation\n            to which the\n            [BaseStatisticFunction][gemseo_umdo.formulations._functions.base_statistic_function.BaseStatisticFunction]\n            is attached.\n        function: The function for which we want to estimate an output statistic.\n        function_type: The type of function.\n        name: The name of the statistic.\n        **statistic_options: The options of the statistic.\n    \"\"\"  # noqa: D205 D212 D415\n    function_name = function.name\n    self._function_name = function_name\n    self._function_jac_name = Database.get_gradient_name(function_name)\n    self._umdo_formulation = umdo_formulation\n    self._last_input_data = None\n    self._statistic_estimator = umdo_formulation._statistic_factory.create(\n        name, *self._statistic_estimator_parameters, **statistic_options\n    )\n    self._observable_name = (\n        f\"{self._statistic_estimator.__class__.__name__}[{function_name}]\"\n    )\n    self._observable_jac_name = Database.get_gradient_name(self._observable_name)\n    super().__init__(\n        self._func, name=function_name, f_type=function_type, jac=self._jac\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_taylor_polynomial/","title":"Statistic function for taylor polynomial","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_taylor_polynomial/#gemseo_umdo.formulations._functions.statistic_function_for_taylor_polynomial","title":"statistic_function_for_taylor_polynomial","text":"<p>A function to compute a statistic from <code>TaylorPolynomial</code>.</p> <p>See also TaylorPolynomial.</p>"},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_taylor_polynomial/#gemseo_umdo.formulations._functions.statistic_function_for_taylor_polynomial-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_functions/statistic_function_for_taylor_polynomial/#gemseo_umdo.formulations._functions.statistic_function_for_taylor_polynomial.StatisticFunctionForTaylorPolynomial","title":"StatisticFunctionForTaylorPolynomial","text":"<pre><code>StatisticFunctionForTaylorPolynomial(\n    umdo_formulation: UMDOFormulationT,\n    function: MDOFunction,\n    function_type: FunctionType,\n    name: str,\n    **statistic_options: Any\n)\n</code></pre> <p>               Bases: <code>BaseStatisticFunction[TaylorPolynomialT]</code></p> <p>A function to compute a statistic from <code>TaylorPolynomial</code>.</p> <p>Parameters:</p> <ul> <li> <code>umdo_formulation</code>               (<code>UMDOFormulationT</code>)           \u2013            <p>The U-MDO formulation to which the BaseStatisticFunction is attached.</p> </li> <li> <code>function</code>               (<code>MDOFunction</code>)           \u2013            <p>The function for which we want to estimate an output statistic.</p> </li> <li> <code>function_type</code>               (<code>FunctionType</code>)           \u2013            <p>The type of function.</p> </li> <li> <code>name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic.</p> </li> <li> <code>**statistic_options</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The options of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_functions/base_statistic_function.py</code> <pre><code>def __init__(\n    self,\n    umdo_formulation: UMDOFormulationT,\n    function: MDOFunction,\n    function_type: MDOFunction.FunctionType,\n    name: str,\n    **statistic_options: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        umdo_formulation: The U-MDO formulation\n            to which the\n            [BaseStatisticFunction][gemseo_umdo.formulations._functions.base_statistic_function.BaseStatisticFunction]\n            is attached.\n        function: The function for which we want to estimate an output statistic.\n        function_type: The type of function.\n        name: The name of the statistic.\n        **statistic_options: The options of the statistic.\n    \"\"\"  # noqa: D205 D212 D415\n    function_name = function.name\n    self._function_name = function_name\n    self._function_jac_name = Database.get_gradient_name(function_name)\n    self._umdo_formulation = umdo_formulation\n    self._last_input_data = None\n    self._statistic_estimator = umdo_formulation._statistic_factory.create(\n        name, *self._statistic_estimator_parameters, **statistic_options\n    )\n    self._observable_name = (\n        f\"{self._statistic_estimator.__class__.__name__}[{function_name}]\"\n    )\n    self._observable_jac_name = Database.get_gradient_name(self._observable_name)\n    super().__init__(\n        self._func, name=function_name, f_type=function_type, jac=self._jac\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/","title":"statistics","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/#gemseo_umdo.formulations._statistics","title":"_statistics","text":"<p>Estimators of statistics associated with a U-MDO formulation.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/base_statistic_estimator/","title":"Base statistic estimator","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/base_statistic_estimator/#gemseo_umdo.formulations._statistics.base_statistic_estimator","title":"base_statistic_estimator","text":"<p>Base estimator of statistic associated with a U-MDO formulation.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/base_statistic_estimator/#gemseo_umdo.formulations._statistics.base_statistic_estimator-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/base_statistic_estimator/#gemseo_umdo.formulations._statistics.base_statistic_estimator.BaseStatisticEstimator","title":"BaseStatisticEstimator","text":"<p>The base statistic estimator for U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/base_statistic_estimator/#gemseo_umdo.formulations._statistics.base_statistic_estimator.BaseStatisticEstimator-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/base_statistic_estimator/#gemseo_umdo.formulations._statistics.base_statistic_estimator.BaseStatisticEstimator.compute_jacobian","title":"compute_jacobian","text":"<pre><code>compute_jacobian(*args: Any, **kwargs: Any) -&gt; RealArray\n</code></pre> <p>Compute the Jacobian of the statistic estimation.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>               (<code>Any</code>, default:                   <code>()</code> )           \u2013            <p>The mandatory arguments.</p> </li> <li> <code>**kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The optional arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The Jacobian of the statistic estimation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/base_statistic_estimator.py</code> <pre><code>def compute_jacobian(self, *args: Any, **kwargs: Any) -&gt; RealArray:  # noqa: D102\n    \"\"\"Compute the Jacobian of the statistic estimation.\n\n    Args:\n        *args: The mandatory arguments.\n        **kwargs: The optional arguments.\n\n    Returns:\n        The Jacobian of the statistic estimation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/base_statistic_estimator/#gemseo_umdo.formulations._statistics.base_statistic_estimator.BaseStatisticEstimator.estimate_statistic","title":"estimate_statistic  <code>abstractmethod</code>","text":"<pre><code>estimate_statistic(*args: Any, **kwargs: Any) -&gt; RealArray\n</code></pre> <p>Estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>               (<code>Any</code>, default:                   <code>()</code> )           \u2013            <p>The mandatory arguments.</p> </li> <li> <code>**kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The optional arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/base_statistic_estimator.py</code> <pre><code>@abstractmethod\ndef estimate_statistic(self, *args: Any, **kwargs: Any) -&gt; RealArray:  # noqa: D102\n    \"\"\"Estimate the statistic.\n\n    Args:\n        *args: The mandatory arguments.\n        **kwargs: The optional arguments.\n\n    Returns:\n        The estimation of the statistic.\n    \"\"\"\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/","title":"Control variate","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/#gemseo_umdo.formulations._statistics.control_variate","title":"control_variate","text":"<p>Estimators of statistics for U-MDO formulations based on control variates.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/base_control_variate_estimator/","title":"Base control variate estimator","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/base_control_variate_estimator/#gemseo_umdo.formulations._statistics.control_variate.base_control_variate_estimator","title":"base_control_variate_estimator","text":"<p>Base statistic estimator for U-MDO formulation based on control variates.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/base_control_variate_estimator/#gemseo_umdo.formulations._statistics.control_variate.base_control_variate_estimator-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/base_control_variate_estimator/#gemseo_umdo.formulations._statistics.control_variate.base_control_variate_estimator.BaseControlVariateEstimator","title":"BaseControlVariateEstimator","text":"<pre><code>BaseControlVariateEstimator(\n    uncertain_space: ParameterSpace,\n)\n</code></pre> <p>               Bases: <code>BaseStatisticEstimator</code></p> <p>Base statistic estimator for a U-MDO formulation using control variates.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain space.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/control_variate/base_control_variate_estimator.py</code> <pre><code>def __init__(self, uncertain_space: ParameterSpace) -&gt; None:\n    \"\"\"\n    Args:\n        uncertain_space: The uncertain space.\n    \"\"\"  # noqa: D205 D212 D415\n    self._u_mean = uncertain_space.distribution.mean\n    self._u_standard_deviation = uncertain_space.distribution.standard_deviation\n    self._uncertain_space = uncertain_space\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/base_control_variate_estimator/#gemseo_umdo.formulations._statistics.control_variate.base_control_variate_estimator.BaseControlVariateEstimator-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/base_control_variate_estimator/#gemseo_umdo.formulations._statistics.control_variate.base_control_variate_estimator.BaseControlVariateEstimator.compute_jacobian","title":"compute_jacobian","text":"<pre><code>compute_jacobian(*args: Any, **kwargs: Any) -&gt; RealArray\n</code></pre> <p>Compute the Jacobian of the statistic estimation.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>               (<code>Any</code>, default:                   <code>()</code> )           \u2013            <p>The mandatory arguments.</p> </li> <li> <code>**kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The optional arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The Jacobian of the statistic estimation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/base_statistic_estimator.py</code> <pre><code>def compute_jacobian(self, *args: Any, **kwargs: Any) -&gt; RealArray:  # noqa: D102\n    \"\"\"Compute the Jacobian of the statistic estimation.\n\n    Args:\n        *args: The mandatory arguments.\n        **kwargs: The optional arguments.\n\n    Returns:\n        The Jacobian of the statistic estimation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/base_control_variate_estimator/#gemseo_umdo.formulations._statistics.control_variate.base_control_variate_estimator.BaseControlVariateEstimator.estimate_statistic","title":"estimate_statistic  <code>abstractmethod</code>","text":"<pre><code>estimate_statistic(\n    samples: RealArray,\n    u_samples: RealArray,\n    mean: RealArray,\n    jac: RealArray,\n) -&gt; RealArray\n</code></pre> <p>Estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>samples</code>               (<code>RealArray</code>)           \u2013            <p>The output evaluations arranged in rows.</p> </li> <li> <code>u_samples</code>               (<code>RealArray</code>)           \u2013            <p>The input evaluations arranged in rows.</p> </li> <li> <code>mean</code>               (<code>RealArray</code>)           \u2013            <p>The output value at the mean input one.</p> </li> <li> <code>jac</code>               (<code>RealArray</code>)           \u2013            <p>The Jacobian value at the mean input one.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/control_variate/base_control_variate_estimator.py</code> <pre><code>@abstractmethod\ndef estimate_statistic(\n    self,\n    samples: RealArray,\n    u_samples: RealArray,\n    mean: RealArray,\n    jac: RealArray,\n) -&gt; RealArray:\n    \"\"\"\n    Args:\n        samples: The output evaluations arranged in rows.\n        u_samples: The input evaluations arranged in rows.\n        mean: The output value at the mean input one.\n        jac: The Jacobian value at the mean input one.\n    \"\"\"  # noqa: D205 D212 D415\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/factory/","title":"Factory","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/factory/#gemseo_umdo.formulations._statistics.control_variate.factory","title":"factory","text":"<p>A factory of statistic estimators for U-MDO formulations based on control variate.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/factory/#gemseo_umdo.formulations._statistics.control_variate.factory-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/factory/#gemseo_umdo.formulations._statistics.control_variate.factory.ControlVariateEstimatorFactory","title":"ControlVariateEstimatorFactory","text":"<p>               Bases: <code>BaseFactory</code></p> <p>The factory of statistic estimators based on control variates.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/margin/","title":"Margin","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/margin/#gemseo_umdo.formulations._statistics.control_variate.margin","title":"margin","text":"<p>Estimator of a margin for U-MDO formulations based on control variates.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/margin/#gemseo_umdo.formulations._statistics.control_variate.margin-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/margin/#gemseo_umdo.formulations._statistics.control_variate.margin.Margin","title":"Margin","text":"<pre><code>Margin(\n    uncertain_space: ParameterSpace, factor: float = 2.0\n)\n</code></pre> <p>               Bases: <code>BaseControlVariateEstimator</code></p> <p>Estimator of a margin, i.e. mean + factor * deviation.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain space.</p> </li> <li> <code>factor</code>               (<code>float</code>, default:                   <code>2.0</code> )           \u2013            <p>The factor related to the standard deviation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/control_variate/margin.py</code> <pre><code>def __init__(self, uncertain_space: ParameterSpace, factor: float = 2.0) -&gt; None:\n    \"\"\"\n    Args:\n        factor: The factor related to the standard deviation.\n    \"\"\"  # noqa: D205 D212 D415\n    super().__init__(uncertain_space)\n    self.__mean = Mean(uncertain_space)\n    self.__standard_deviation = StandardDeviation(uncertain_space)\n    self.__factor = factor\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/margin/#gemseo_umdo.formulations._statistics.control_variate.margin.Margin-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/margin/#gemseo_umdo.formulations._statistics.control_variate.margin.Margin.compute_jacobian","title":"compute_jacobian","text":"<pre><code>compute_jacobian(*args: Any, **kwargs: Any) -&gt; RealArray\n</code></pre> <p>Compute the Jacobian of the statistic estimation.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>               (<code>Any</code>, default:                   <code>()</code> )           \u2013            <p>The mandatory arguments.</p> </li> <li> <code>**kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The optional arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The Jacobian of the statistic estimation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/base_statistic_estimator.py</code> <pre><code>def compute_jacobian(self, *args: Any, **kwargs: Any) -&gt; RealArray:  # noqa: D102\n    \"\"\"Compute the Jacobian of the statistic estimation.\n\n    Args:\n        *args: The mandatory arguments.\n        **kwargs: The optional arguments.\n\n    Returns:\n        The Jacobian of the statistic estimation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/margin/#gemseo_umdo.formulations._statistics.control_variate.margin.Margin.estimate_statistic","title":"estimate_statistic","text":"<pre><code>estimate_statistic(\n    samples: RealArray,\n    u_samples: RealArray,\n    mean: RealArray,\n    jac: RealArray,\n) -&gt; RealArray\n</code></pre> <p>Estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>samples</code>               (<code>RealArray</code>)           \u2013            <p>The output evaluations arranged in rows.</p> </li> <li> <code>u_samples</code>               (<code>RealArray</code>)           \u2013            <p>The input evaluations arranged in rows.</p> </li> <li> <code>mean</code>               (<code>RealArray</code>)           \u2013            <p>The output value at the mean input one.</p> </li> <li> <code>jac</code>               (<code>RealArray</code>)           \u2013            <p>The Jacobian value at the mean input one.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/control_variate/margin.py</code> <pre><code>def estimate_statistic(  # noqa: D102\n    self,\n    samples: RealArray,\n    u_samples: RealArray,\n    mean: RealArray,\n    jac: RealArray,\n) -&gt; RealArray:\n    m = self.__mean.estimate_statistic(samples, u_samples, mean, jac)\n    s = self.__standard_deviation.estimate_statistic(samples, u_samples, mean, jac)\n    return m + self.__factor * s\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/mean/","title":"Mean","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/mean/#gemseo_umdo.formulations._statistics.control_variate.mean","title":"mean","text":"<p>Estimator of the expectation for U-MDO formulations based on control variates.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/mean/#gemseo_umdo.formulations._statistics.control_variate.mean-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/mean/#gemseo_umdo.formulations._statistics.control_variate.mean.Mean","title":"Mean","text":"<pre><code>Mean(uncertain_space: ParameterSpace)\n</code></pre> <p>               Bases: <code>BaseControlVariateEstimator</code></p> <p>Estimator of the expectation.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain space.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/control_variate/base_control_variate_estimator.py</code> <pre><code>def __init__(self, uncertain_space: ParameterSpace) -&gt; None:\n    \"\"\"\n    Args:\n        uncertain_space: The uncertain space.\n    \"\"\"  # noqa: D205 D212 D415\n    self._u_mean = uncertain_space.distribution.mean\n    self._u_standard_deviation = uncertain_space.distribution.standard_deviation\n    self._uncertain_space = uncertain_space\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/mean/#gemseo_umdo.formulations._statistics.control_variate.mean.Mean-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/mean/#gemseo_umdo.formulations._statistics.control_variate.mean.Mean.compute_jacobian","title":"compute_jacobian","text":"<pre><code>compute_jacobian(*args: Any, **kwargs: Any) -&gt; RealArray\n</code></pre> <p>Compute the Jacobian of the statistic estimation.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>               (<code>Any</code>, default:                   <code>()</code> )           \u2013            <p>The mandatory arguments.</p> </li> <li> <code>**kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The optional arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The Jacobian of the statistic estimation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/base_statistic_estimator.py</code> <pre><code>def compute_jacobian(self, *args: Any, **kwargs: Any) -&gt; RealArray:  # noqa: D102\n    \"\"\"Compute the Jacobian of the statistic estimation.\n\n    Args:\n        *args: The mandatory arguments.\n        **kwargs: The optional arguments.\n\n    Returns:\n        The Jacobian of the statistic estimation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/mean/#gemseo_umdo.formulations._statistics.control_variate.mean.Mean.estimate_statistic","title":"estimate_statistic","text":"<pre><code>estimate_statistic(\n    samples: RealArray,\n    u_samples: RealArray,\n    mean: RealArray,\n    jac: RealArray,\n) -&gt; RealArray\n</code></pre> <p>Estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>samples</code>               (<code>RealArray</code>)           \u2013            <p>The output evaluations arranged in rows.</p> </li> <li> <code>u_samples</code>               (<code>RealArray</code>)           \u2013            <p>The input evaluations arranged in rows.</p> </li> <li> <code>mean</code>               (<code>RealArray</code>)           \u2013            <p>The output value at the mean input one.</p> </li> <li> <code>jac</code>               (<code>RealArray</code>)           \u2013            <p>The Jacobian value at the mean input one.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/control_variate/mean.py</code> <pre><code>def estimate_statistic(  # noqa: D102\n    self,\n    samples: RealArray,\n    u_samples: RealArray,\n    mean: RealArray,\n    jac: RealArray,\n) -&gt; RealArray:\n    cv_samples = self._compute_control_variate_samples(u_samples, mean, jac)\n    alpha = self._compute_opposite_scaled_covariance(samples, cv_samples)\n    return samples.mean(0) + alpha * (cv_samples.mean(0) - mean)\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/probability/","title":"Probability","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/probability/#gemseo_umdo.formulations._statistics.control_variate.probability","title":"probability","text":"<p>Estimator of a probability for U-MDO formulations based on control variates.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/probability/#gemseo_umdo.formulations._statistics.control_variate.probability-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/probability/#gemseo_umdo.formulations._statistics.control_variate.probability.Probability","title":"Probability","text":"<pre><code>Probability(\n    uncertain_space: ParameterSpace,\n    threshold: float = 0.0,\n    greater: bool = True,\n    n_samples: int = 10000,\n)\n</code></pre> <p>               Bases: <code>BaseControlVariateEstimator</code></p> <p>Estimator of a probability.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain space.</p> </li> <li> <code>threshold</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>The threshold against which the probability is estimated.</p> </li> <li> <code>greater</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to compute the probability of exceeding the threshold.</p> </li> <li> <code>n_samples</code>               (<code>int</code>, default:                   <code>10000</code> )           \u2013            <p>A high number of samples to approximate the statistic with the control variates.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/control_variate/probability.py</code> <pre><code>def __init__(\n    self,\n    uncertain_space: ParameterSpace,\n    threshold: float = 0.0,\n    greater: bool = True,\n    n_samples: int = 10000,\n) -&gt; None:\n    \"\"\"\n    Args:\n        threshold: The threshold against which the probability is estimated.\n        greater: Whether to compute the probability of exceeding the threshold.\n        n_samples: A high number of samples to approximate the statistic\n            with the control variates.\n    \"\"\"  # noqa: D205 D212 D415\n    super().__init__(uncertain_space)\n    self.__threshold = threshold\n    self.__compare = ge if greater else le\n    self.__n_samples = n_samples\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/probability/#gemseo_umdo.formulations._statistics.control_variate.probability.Probability-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/probability/#gemseo_umdo.formulations._statistics.control_variate.probability.Probability.compute_jacobian","title":"compute_jacobian","text":"<pre><code>compute_jacobian(*args: Any, **kwargs: Any) -&gt; RealArray\n</code></pre> <p>Compute the Jacobian of the statistic estimation.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>               (<code>Any</code>, default:                   <code>()</code> )           \u2013            <p>The mandatory arguments.</p> </li> <li> <code>**kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The optional arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The Jacobian of the statistic estimation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/base_statistic_estimator.py</code> <pre><code>def compute_jacobian(self, *args: Any, **kwargs: Any) -&gt; RealArray:  # noqa: D102\n    \"\"\"Compute the Jacobian of the statistic estimation.\n\n    Args:\n        *args: The mandatory arguments.\n        **kwargs: The optional arguments.\n\n    Returns:\n        The Jacobian of the statistic estimation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/probability/#gemseo_umdo.formulations._statistics.control_variate.probability.Probability.estimate_statistic","title":"estimate_statistic","text":"<pre><code>estimate_statistic(\n    samples: RealArray,\n    u_samples: RealArray,\n    mean: RealArray,\n    jac: RealArray,\n) -&gt; RealArray\n</code></pre> <p>Estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>samples</code>               (<code>RealArray</code>)           \u2013            <p>The output evaluations arranged in rows.</p> </li> <li> <code>u_samples</code>               (<code>RealArray</code>)           \u2013            <p>The input evaluations arranged in rows.</p> </li> <li> <code>mean</code>               (<code>RealArray</code>)           \u2013            <p>The output value at the mean input one.</p> </li> <li> <code>jac</code>               (<code>RealArray</code>)           \u2013            <p>The Jacobian value at the mean input one.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/control_variate/probability.py</code> <pre><code>def estimate_statistic(  # noqa: D102\n    self,\n    samples: RealArray,\n    u_samples: RealArray,\n    mean: RealArray,\n    jac: RealArray,\n) -&gt; RealArray:\n    cv_samples = self._compute_control_variate_samples(u_samples, mean, jac)\n    ref_cv_samples = (\n        mean + self._uncertain_space.compute_samples(self.__n_samples) @ jac.T\n    )\n    samples = self.__compare(samples, self.__threshold)\n    cv_samples = self.__compare(cv_samples, self.__threshold)\n    ref_cv_samples = self.__compare(ref_cv_samples, self.__threshold)\n    alpha = self._compute_opposite_scaled_covariance(samples, cv_samples)\n    return samples.mean(0) + alpha * (cv_samples.mean(0) - ref_cv_samples.mean(0))\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/standard_deviation/","title":"Standard deviation","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/standard_deviation/#gemseo_umdo.formulations._statistics.control_variate.standard_deviation","title":"standard_deviation","text":"<p>Estimator of the standard deviation for control variate-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/standard_deviation/#gemseo_umdo.formulations._statistics.control_variate.standard_deviation-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/standard_deviation/#gemseo_umdo.formulations._statistics.control_variate.standard_deviation.StandardDeviation","title":"StandardDeviation","text":"<pre><code>StandardDeviation(uncertain_space: ParameterSpace)\n</code></pre> <p>               Bases: <code>Variance</code></p> <p>Estimator of the standard deviation.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain space.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/control_variate/base_control_variate_estimator.py</code> <pre><code>def __init__(self, uncertain_space: ParameterSpace) -&gt; None:\n    \"\"\"\n    Args:\n        uncertain_space: The uncertain space.\n    \"\"\"  # noqa: D205 D212 D415\n    self._u_mean = uncertain_space.distribution.mean\n    self._u_standard_deviation = uncertain_space.distribution.standard_deviation\n    self._uncertain_space = uncertain_space\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/standard_deviation/#gemseo_umdo.formulations._statistics.control_variate.standard_deviation.StandardDeviation-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/standard_deviation/#gemseo_umdo.formulations._statistics.control_variate.standard_deviation.StandardDeviation.compute_jacobian","title":"compute_jacobian","text":"<pre><code>compute_jacobian(*args: Any, **kwargs: Any) -&gt; RealArray\n</code></pre> <p>Compute the Jacobian of the statistic estimation.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>               (<code>Any</code>, default:                   <code>()</code> )           \u2013            <p>The mandatory arguments.</p> </li> <li> <code>**kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The optional arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The Jacobian of the statistic estimation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/base_statistic_estimator.py</code> <pre><code>def compute_jacobian(self, *args: Any, **kwargs: Any) -&gt; RealArray:  # noqa: D102\n    \"\"\"Compute the Jacobian of the statistic estimation.\n\n    Args:\n        *args: The mandatory arguments.\n        **kwargs: The optional arguments.\n\n    Returns:\n        The Jacobian of the statistic estimation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/standard_deviation/#gemseo_umdo.formulations._statistics.control_variate.standard_deviation.StandardDeviation.estimate_statistic","title":"estimate_statistic","text":"<pre><code>estimate_statistic(\n    samples: RealArray,\n    u_samples: RealArray,\n    mean: RealArray,\n    jac: RealArray,\n) -&gt; RealArray\n</code></pre> <p>Estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>samples</code>               (<code>RealArray</code>)           \u2013            <p>The output evaluations arranged in rows.</p> </li> <li> <code>u_samples</code>               (<code>RealArray</code>)           \u2013            <p>The input evaluations arranged in rows.</p> </li> <li> <code>mean</code>               (<code>RealArray</code>)           \u2013            <p>The output value at the mean input one.</p> </li> <li> <code>jac</code>               (<code>RealArray</code>)           \u2013            <p>The Jacobian value at the mean input one.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/control_variate/standard_deviation.py</code> <pre><code>def estimate_statistic(  # noqa: D102\n    self,\n    samples: RealArray,\n    u_samples: RealArray,\n    mean: RealArray,\n    jac: RealArray,\n) -&gt; RealArray:\n    return super().estimate_statistic(samples, u_samples, mean, jac) ** 0.5\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/variance/","title":"Variance","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/variance/#gemseo_umdo.formulations._statistics.control_variate.variance","title":"variance","text":"<p>Estimators of the variance for U-MDO formulation based on control variates.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/variance/#gemseo_umdo.formulations._statistics.control_variate.variance-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/variance/#gemseo_umdo.formulations._statistics.control_variate.variance.Variance","title":"Variance","text":"<pre><code>Variance(uncertain_space: ParameterSpace)\n</code></pre> <p>               Bases: <code>BaseControlVariateEstimator</code></p> <p>Estimator of the variance.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain space.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/control_variate/base_control_variate_estimator.py</code> <pre><code>def __init__(self, uncertain_space: ParameterSpace) -&gt; None:\n    \"\"\"\n    Args:\n        uncertain_space: The uncertain space.\n    \"\"\"  # noqa: D205 D212 D415\n    self._u_mean = uncertain_space.distribution.mean\n    self._u_standard_deviation = uncertain_space.distribution.standard_deviation\n    self._uncertain_space = uncertain_space\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/variance/#gemseo_umdo.formulations._statistics.control_variate.variance.Variance-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/variance/#gemseo_umdo.formulations._statistics.control_variate.variance.Variance.compute_jacobian","title":"compute_jacobian","text":"<pre><code>compute_jacobian(*args: Any, **kwargs: Any) -&gt; RealArray\n</code></pre> <p>Compute the Jacobian of the statistic estimation.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>               (<code>Any</code>, default:                   <code>()</code> )           \u2013            <p>The mandatory arguments.</p> </li> <li> <code>**kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The optional arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The Jacobian of the statistic estimation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/base_statistic_estimator.py</code> <pre><code>def compute_jacobian(self, *args: Any, **kwargs: Any) -&gt; RealArray:  # noqa: D102\n    \"\"\"Compute the Jacobian of the statistic estimation.\n\n    Args:\n        *args: The mandatory arguments.\n        **kwargs: The optional arguments.\n\n    Returns:\n        The Jacobian of the statistic estimation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/control_variate/variance/#gemseo_umdo.formulations._statistics.control_variate.variance.Variance.estimate_statistic","title":"estimate_statistic","text":"<pre><code>estimate_statistic(\n    samples: RealArray,\n    u_samples: RealArray,\n    mean: RealArray,\n    jac: RealArray,\n) -&gt; RealArray\n</code></pre> <p>Estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>samples</code>               (<code>RealArray</code>)           \u2013            <p>The output evaluations arranged in rows.</p> </li> <li> <code>u_samples</code>               (<code>RealArray</code>)           \u2013            <p>The input evaluations arranged in rows.</p> </li> <li> <code>mean</code>               (<code>RealArray</code>)           \u2013            <p>The output value at the mean input one.</p> </li> <li> <code>jac</code>               (<code>RealArray</code>)           \u2013            <p>The Jacobian value at the mean input one.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/control_variate/variance.py</code> <pre><code>def estimate_statistic(  # noqa: D102\n    self,\n    samples: RealArray,\n    u_samples: RealArray,\n    mean: RealArray,\n    jac: RealArray,\n) -&gt; RealArray:\n    cv_samples = self._compute_control_variate_samples(u_samples, mean, jac)\n    diff2 = (samples - samples.mean()) ** 2\n    cv_diff2 = (cv_samples - cv_samples.mean()) ** 2\n    cv_var = diagonal(multi_dot([jac, diag(self._u_standard_deviation**2), jac.T]))\n    alpha = self._compute_opposite_scaled_covariance(diff2, cv_diff2)\n    return (diff2.mean(0) + alpha * (cv_diff2.mean(0) - cv_var)).ravel()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/","title":"Iterative sampling","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/#gemseo_umdo.formulations._statistics.iterative_sampling","title":"iterative_sampling","text":"<p>Iterative estimators of statistics for sampling-based U-MDO formulations.</p> <p>These estimators iteratively estimate statistics from an increasing dataset without storing any data in memory.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_central_moment/","title":"Base central moment","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_central_moment/#gemseo_umdo.formulations._statistics.iterative_sampling.base_central_moment","title":"base_central_moment","text":"<p>Iterative estimator of a moment for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_central_moment/#gemseo_umdo.formulations._statistics.iterative_sampling.base_central_moment-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_central_moment/#gemseo_umdo.formulations._statistics.iterative_sampling.base_central_moment.BaseCentralMoment","title":"BaseCentralMoment","text":"<pre><code>BaseCentralMoment()\n</code></pre> <p>               Bases: <code>BaseSamplingEstimator</code></p> <p>Base iterative estimator of a central moment, e.g. expectation or variance.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator.py</code> <pre><code>def __init__(self) -&gt; None:  # noqa: D107\n    super().__init__()\n    self.shape = None\n    self.jac_shape = None\n    self._estimator = None\n    self._jac_estimator = None\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_central_moment/#gemseo_umdo.formulations._statistics.iterative_sampling.base_central_moment.BaseCentralMoment-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_central_moment/#gemseo_umdo.formulations._statistics.iterative_sampling.base_central_moment.BaseCentralMoment.jac_shape","title":"jac_shape  <code>instance-attribute</code>","text":"<pre><code>jac_shape: tuple[int, int] | None = None\n</code></pre> <p>The shape of the Jacobian, if known.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_central_moment/#gemseo_umdo.formulations._statistics.iterative_sampling.base_central_moment.BaseCentralMoment.shape","title":"shape  <code>instance-attribute</code>","text":"<pre><code>shape: tuple[int] | None = None\n</code></pre> <p>The shape of the output of interest, if known.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_central_moment/#gemseo_umdo.formulations._statistics.iterative_sampling.base_central_moment.BaseCentralMoment-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_central_moment/#gemseo_umdo.formulations._statistics.iterative_sampling.base_central_moment.BaseCentralMoment.compute_jacobian","title":"compute_jacobian","text":"<pre><code>compute_jacobian(\n    value: RealArray, jac_value: RealArray\n) -&gt; RealArray\n</code></pre> <p>Compute the Jacobian of the statistic estimation.</p> <p>Parameters:</p> <ul> <li> <code>value</code>               (<code>RealArray</code>)           \u2013            <p>The value of the function output.</p> </li> <li> <code>jac_value</code>               (<code>RealArray</code>)           \u2013            <p>The value of the Jacobian.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The Jacobian of the statistic estimation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator.py</code> <pre><code>def compute_jacobian(self, value: RealArray, jac_value: RealArray) -&gt; RealArray:\n    \"\"\"\n    Args:\n        value: The value of the function output.\n        jac_value: The value of the Jacobian.\n    \"\"\"  # noqa: D205 D212\n    if self.jac_shape is None:\n        self.jac_shape = jac_value.shape\n        self.reset(value.size)\n\n    self._jac_estimator.increment(jac_value.ravel())\n    return self._get_estimation_jacobian()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_central_moment/#gemseo_umdo.formulations._statistics.iterative_sampling.base_central_moment.BaseCentralMoment.estimate_statistic","title":"estimate_statistic","text":"<pre><code>estimate_statistic(value: RealArray) -&gt; RealArray\n</code></pre> <p>Estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>value</code>               (<code>RealArray</code>)           \u2013            <p>The value of the function output.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator.py</code> <pre><code>def estimate_statistic(self, value: RealArray) -&gt; RealArray:\n    \"\"\"\n    Args:\n        value: The value of the function output.\n    \"\"\"  # noqa: D205 D212\n    if self.shape is None:\n        self.shape = value.shape\n        self.reset(value.size)\n\n    self._estimator.increment(value.ravel())\n    return self._get_estimation()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_central_moment/#gemseo_umdo.formulations._statistics.iterative_sampling.base_central_moment.BaseCentralMoment.reset","title":"reset","text":"<pre><code>reset(size: int) -&gt; None\n</code></pre> <p>Reset the estimator of the statistic.</p> <p>Parameters:</p> <ul> <li> <code>size</code>               (<code>int</code>)           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/base_central_moment.py</code> <pre><code>def reset(self, size: int) -&gt; None:  # noqa: D102\n    super().reset(size)\n    self._estimator = IterativeMoments(self._ORDER, size)\n    if self.jac_shape is not None:\n        self._jac_estimator = IterativeMoments(\n            self._ORDER, self.jac_shape[0] * self.jac_shape[1]\n        )\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator/","title":"Base sampling estimator","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator/#gemseo_umdo.formulations._statistics.iterative_sampling.base_sampling_estimator","title":"base_sampling_estimator","text":"<p>Base statistic iterative estimator for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator/#gemseo_umdo.formulations._statistics.iterative_sampling.base_sampling_estimator-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator/#gemseo_umdo.formulations._statistics.iterative_sampling.base_sampling_estimator.BaseSamplingEstimator","title":"BaseSamplingEstimator","text":"<pre><code>BaseSamplingEstimator()\n</code></pre> <p>               Bases: <code>BaseStatisticEstimator</code></p> <p>Base statistic iterative estimator for a U-MDO formulation using sampling.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator.py</code> <pre><code>def __init__(self) -&gt; None:  # noqa: D107\n    super().__init__()\n    self.shape = None\n    self.jac_shape = None\n    self._estimator = None\n    self._jac_estimator = None\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator/#gemseo_umdo.formulations._statistics.iterative_sampling.base_sampling_estimator.BaseSamplingEstimator-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator/#gemseo_umdo.formulations._statistics.iterative_sampling.base_sampling_estimator.BaseSamplingEstimator.jac_shape","title":"jac_shape  <code>instance-attribute</code>","text":"<pre><code>jac_shape: tuple[int, int] | None = None\n</code></pre> <p>The shape of the Jacobian, if known.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator/#gemseo_umdo.formulations._statistics.iterative_sampling.base_sampling_estimator.BaseSamplingEstimator.shape","title":"shape  <code>instance-attribute</code>","text":"<pre><code>shape: tuple[int] | None = None\n</code></pre> <p>The shape of the output of interest, if known.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator/#gemseo_umdo.formulations._statistics.iterative_sampling.base_sampling_estimator.BaseSamplingEstimator-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator/#gemseo_umdo.formulations._statistics.iterative_sampling.base_sampling_estimator.BaseSamplingEstimator.compute_jacobian","title":"compute_jacobian","text":"<pre><code>compute_jacobian(\n    value: RealArray, jac_value: RealArray\n) -&gt; RealArray\n</code></pre> <p>Compute the Jacobian of the statistic estimation.</p> <p>Parameters:</p> <ul> <li> <code>value</code>               (<code>RealArray</code>)           \u2013            <p>The value of the function output.</p> </li> <li> <code>jac_value</code>               (<code>RealArray</code>)           \u2013            <p>The value of the Jacobian.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The Jacobian of the statistic estimation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator.py</code> <pre><code>def compute_jacobian(self, value: RealArray, jac_value: RealArray) -&gt; RealArray:\n    \"\"\"\n    Args:\n        value: The value of the function output.\n        jac_value: The value of the Jacobian.\n    \"\"\"  # noqa: D205 D212\n    if self.jac_shape is None:\n        self.jac_shape = jac_value.shape\n        self.reset(value.size)\n\n    self._jac_estimator.increment(jac_value.ravel())\n    return self._get_estimation_jacobian()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator/#gemseo_umdo.formulations._statistics.iterative_sampling.base_sampling_estimator.BaseSamplingEstimator.estimate_statistic","title":"estimate_statistic","text":"<pre><code>estimate_statistic(value: RealArray) -&gt; RealArray\n</code></pre> <p>Estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>value</code>               (<code>RealArray</code>)           \u2013            <p>The value of the function output.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator.py</code> <pre><code>def estimate_statistic(self, value: RealArray) -&gt; RealArray:\n    \"\"\"\n    Args:\n        value: The value of the function output.\n    \"\"\"  # noqa: D205 D212\n    if self.shape is None:\n        self.shape = value.shape\n        self.reset(value.size)\n\n    self._estimator.increment(value.ravel())\n    return self._get_estimation()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator/#gemseo_umdo.formulations._statistics.iterative_sampling.base_sampling_estimator.BaseSamplingEstimator.reset","title":"reset","text":"<pre><code>reset(size: int) -&gt; None\n</code></pre> <p>Reset the estimator of the statistic.</p> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator.py</code> <pre><code>def reset(self, size: int) -&gt; None:\n    \"\"\"Reset the estimator of the statistic.\"\"\"\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/factory/","title":"Factory","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/factory/#gemseo_umdo.formulations._statistics.iterative_sampling.factory","title":"factory","text":"<p>A factory of iterative statistic estimators for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/factory/#gemseo_umdo.formulations._statistics.iterative_sampling.factory-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/factory/#gemseo_umdo.formulations._statistics.iterative_sampling.factory.SamplingEstimatorFactory","title":"SamplingEstimatorFactory","text":"<p>               Bases: <code>BaseFactory</code></p> <p>The factory of iterative sampling estimators.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/margin/","title":"Margin","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/margin/#gemseo_umdo.formulations._statistics.iterative_sampling.margin","title":"margin","text":"<p>Iterative estimator of a margin for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/margin/#gemseo_umdo.formulations._statistics.iterative_sampling.margin-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/margin/#gemseo_umdo.formulations._statistics.iterative_sampling.margin.Margin","title":"Margin","text":"<pre><code>Margin(factor: float = 2.0)\n</code></pre> <p>               Bases: <code>BaseSamplingEstimator</code></p> <p>Iterative estimator of a margin, i.e. mean + factor * deviation.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>factor</code>               (<code>float</code>, default:                   <code>2.0</code> )           \u2013            <p>The factor related to the standard deviation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/margin.py</code> <pre><code>def __init__(self, factor: float = 2.0) -&gt; None:\n    \"\"\"\n    Args:\n        factor: The factor related to the standard deviation.\n    \"\"\"  # noqa: D205 D212 D415\n    super().__init__()\n    self.__mean = Mean()\n    self.__standard_deviation = StandardDeviation()\n    self.__factor = factor\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/margin/#gemseo_umdo.formulations._statistics.iterative_sampling.margin.Margin-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/margin/#gemseo_umdo.formulations._statistics.iterative_sampling.margin.Margin.jac_shape","title":"jac_shape  <code>instance-attribute</code>","text":"<pre><code>jac_shape: tuple[int, int] | None = None\n</code></pre> <p>The shape of the Jacobian, if known.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/margin/#gemseo_umdo.formulations._statistics.iterative_sampling.margin.Margin.shape","title":"shape  <code>instance-attribute</code>","text":"<pre><code>shape: tuple[int] | None = None\n</code></pre> <p>The shape of the output of interest, if known.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/margin/#gemseo_umdo.formulations._statistics.iterative_sampling.margin.Margin-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/margin/#gemseo_umdo.formulations._statistics.iterative_sampling.margin.Margin.compute_jacobian","title":"compute_jacobian","text":"<pre><code>compute_jacobian(\n    value: RealArray, jac_value: RealArray\n) -&gt; RealArray\n</code></pre> <p>Compute the Jacobian of the statistic estimation.</p> <p>Parameters:</p> <ul> <li> <code>value</code>               (<code>RealArray</code>)           \u2013            <p>The value of the function output.</p> </li> <li> <code>jac_value</code>               (<code>RealArray</code>)           \u2013            <p>The value of the Jacobian.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The Jacobian of the statistic estimation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/margin.py</code> <pre><code>def compute_jacobian(self, value: RealArray, jac_value: RealArray) -&gt; RealArray:\n    self.jac_shape = jac_value.shape\n    dmean_dx = self.__mean.compute_jacobian(value, jac_value)\n    dstd_dx = self.__standard_deviation.compute_jacobian(value, jac_value)\n    return dmean_dx + self.__factor * dstd_dx\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/margin/#gemseo_umdo.formulations._statistics.iterative_sampling.margin.Margin.estimate_statistic","title":"estimate_statistic","text":"<pre><code>estimate_statistic(value: RealArray) -&gt; RealArray\n</code></pre> <p>Estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>value</code>               (<code>RealArray</code>)           \u2013            <p>The value of the function output.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/margin.py</code> <pre><code>def estimate_statistic(self, value: RealArray) -&gt; RealArray:\n    self.shape = value.shape\n    return self.__mean.estimate_statistic(\n        value\n    ) + self.__factor * self.__standard_deviation.estimate_statistic(value)\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/margin/#gemseo_umdo.formulations._statistics.iterative_sampling.margin.Margin.reset","title":"reset","text":"<pre><code>reset(size: int) -&gt; None\n</code></pre> <p>Reset the estimator of the statistic.</p> <p>Parameters:</p> <ul> <li> <code>size</code>               (<code>int</code>)           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/margin.py</code> <pre><code>def reset(self, size: int) -&gt; None:  # noqa: D102\n    super().reset(size)\n    self.__mean.reset(size)\n    self.__standard_deviation.reset(size)\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/mean/","title":"Mean","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/mean/#gemseo_umdo.formulations._statistics.iterative_sampling.mean","title":"mean","text":"<p>Iterative estimator of the expectation for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/mean/#gemseo_umdo.formulations._statistics.iterative_sampling.mean-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/mean/#gemseo_umdo.formulations._statistics.iterative_sampling.mean.Mean","title":"Mean","text":"<pre><code>Mean()\n</code></pre> <p>               Bases: <code>BaseCentralMoment</code></p> <p>Iterative estimator of the expectation.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator.py</code> <pre><code>def __init__(self) -&gt; None:  # noqa: D107\n    super().__init__()\n    self.shape = None\n    self.jac_shape = None\n    self._estimator = None\n    self._jac_estimator = None\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/mean/#gemseo_umdo.formulations._statistics.iterative_sampling.mean.Mean-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/mean/#gemseo_umdo.formulations._statistics.iterative_sampling.mean.Mean.jac_shape","title":"jac_shape  <code>instance-attribute</code>","text":"<pre><code>jac_shape: tuple[int, int] | None = None\n</code></pre> <p>The shape of the Jacobian, if known.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/mean/#gemseo_umdo.formulations._statistics.iterative_sampling.mean.Mean.shape","title":"shape  <code>instance-attribute</code>","text":"<pre><code>shape: tuple[int] | None = None\n</code></pre> <p>The shape of the output of interest, if known.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/mean/#gemseo_umdo.formulations._statistics.iterative_sampling.mean.Mean-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/mean/#gemseo_umdo.formulations._statistics.iterative_sampling.mean.Mean.compute_jacobian","title":"compute_jacobian","text":"<pre><code>compute_jacobian(\n    value: RealArray, jac_value: RealArray\n) -&gt; RealArray\n</code></pre> <p>Compute the Jacobian of the statistic estimation.</p> <p>Parameters:</p> <ul> <li> <code>value</code>               (<code>RealArray</code>)           \u2013            <p>The value of the function output.</p> </li> <li> <code>jac_value</code>               (<code>RealArray</code>)           \u2013            <p>The value of the Jacobian.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The Jacobian of the statistic estimation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator.py</code> <pre><code>def compute_jacobian(self, value: RealArray, jac_value: RealArray) -&gt; RealArray:\n    \"\"\"\n    Args:\n        value: The value of the function output.\n        jac_value: The value of the Jacobian.\n    \"\"\"  # noqa: D205 D212\n    if self.jac_shape is None:\n        self.jac_shape = jac_value.shape\n        self.reset(value.size)\n\n    self._jac_estimator.increment(jac_value.ravel())\n    return self._get_estimation_jacobian()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/mean/#gemseo_umdo.formulations._statistics.iterative_sampling.mean.Mean.estimate_statistic","title":"estimate_statistic","text":"<pre><code>estimate_statistic(value: RealArray) -&gt; RealArray\n</code></pre> <p>Estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>value</code>               (<code>RealArray</code>)           \u2013            <p>The value of the function output.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator.py</code> <pre><code>def estimate_statistic(self, value: RealArray) -&gt; RealArray:\n    \"\"\"\n    Args:\n        value: The value of the function output.\n    \"\"\"  # noqa: D205 D212\n    if self.shape is None:\n        self.shape = value.shape\n        self.reset(value.size)\n\n    self._estimator.increment(value.ravel())\n    return self._get_estimation()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/mean/#gemseo_umdo.formulations._statistics.iterative_sampling.mean.Mean.reset","title":"reset","text":"<pre><code>reset(size: int) -&gt; None\n</code></pre> <p>Reset the estimator of the statistic.</p> <p>Parameters:</p> <ul> <li> <code>size</code>               (<code>int</code>)           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/base_central_moment.py</code> <pre><code>def reset(self, size: int) -&gt; None:  # noqa: D102\n    super().reset(size)\n    self._estimator = IterativeMoments(self._ORDER, size)\n    if self.jac_shape is not None:\n        self._jac_estimator = IterativeMoments(\n            self._ORDER, self.jac_shape[0] * self.jac_shape[1]\n        )\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/probability/","title":"Probability","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/probability/#gemseo_umdo.formulations._statistics.iterative_sampling.probability","title":"probability","text":"<p>Iterative estimator of a probability for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/probability/#gemseo_umdo.formulations._statistics.iterative_sampling.probability-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/probability/#gemseo_umdo.formulations._statistics.iterative_sampling.probability.Probability","title":"Probability","text":"<pre><code>Probability(threshold: float = 0.0, greater: bool = True)\n</code></pre> <p>               Bases: <code>BaseSamplingEstimator</code></p> <p>Iterative estimator of a probability.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>threshold</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>The threshold against which the probability is estimated.</p> </li> <li> <code>greater</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to compute the probability of exceeding the threshold.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/probability.py</code> <pre><code>def __init__(\n    self,\n    threshold: float = 0.0,\n    greater: bool = True,\n) -&gt; None:\n    \"\"\"\n    Args:\n        threshold: The threshold against which the probability is estimated.\n        greater: Whether to compute the probability of exceeding the threshold.\n    \"\"\"  # noqa: D205 D212 D415\n    super().__init__()\n    self.__threshold = threshold\n    self.__greater = greater\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/probability/#gemseo_umdo.formulations._statistics.iterative_sampling.probability.Probability-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/probability/#gemseo_umdo.formulations._statistics.iterative_sampling.probability.Probability.jac_shape","title":"jac_shape  <code>instance-attribute</code>","text":"<pre><code>jac_shape: tuple[int, int] | None = None\n</code></pre> <p>The shape of the Jacobian, if known.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/probability/#gemseo_umdo.formulations._statistics.iterative_sampling.probability.Probability.shape","title":"shape  <code>instance-attribute</code>","text":"<pre><code>shape: tuple[int] | None = None\n</code></pre> <p>The shape of the output of interest, if known.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/probability/#gemseo_umdo.formulations._statistics.iterative_sampling.probability.Probability-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/probability/#gemseo_umdo.formulations._statistics.iterative_sampling.probability.Probability.compute_jacobian","title":"compute_jacobian","text":"<pre><code>compute_jacobian(\n    value: RealArray, jac_value: RealArray\n) -&gt; RealArray\n</code></pre> <p>Compute the Jacobian of the statistic estimation.</p> <p>Parameters:</p> <ul> <li> <code>value</code>               (<code>RealArray</code>)           \u2013            <p>The value of the function output.</p> </li> <li> <code>jac_value</code>               (<code>RealArray</code>)           \u2013            <p>The value of the Jacobian.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The Jacobian of the statistic estimation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator.py</code> <pre><code>def compute_jacobian(self, value: RealArray, jac_value: RealArray) -&gt; RealArray:\n    \"\"\"\n    Args:\n        value: The value of the function output.\n        jac_value: The value of the Jacobian.\n    \"\"\"  # noqa: D205 D212\n    if self.jac_shape is None:\n        self.jac_shape = jac_value.shape\n        self.reset(value.size)\n\n    self._jac_estimator.increment(jac_value.ravel())\n    return self._get_estimation_jacobian()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/probability/#gemseo_umdo.formulations._statistics.iterative_sampling.probability.Probability.estimate_statistic","title":"estimate_statistic","text":"<pre><code>estimate_statistic(value: RealArray) -&gt; RealArray\n</code></pre> <p>Estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>value</code>               (<code>RealArray</code>)           \u2013            <p>The value of the function output.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator.py</code> <pre><code>def estimate_statistic(self, value: RealArray) -&gt; RealArray:\n    \"\"\"\n    Args:\n        value: The value of the function output.\n    \"\"\"  # noqa: D205 D212\n    if self.shape is None:\n        self.shape = value.shape\n        self.reset(value.size)\n\n    self._estimator.increment(value.ravel())\n    return self._get_estimation()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/probability/#gemseo_umdo.formulations._statistics.iterative_sampling.probability.Probability.reset","title":"reset","text":"<pre><code>reset(size: int) -&gt; None\n</code></pre> <p>Reset the estimator of the statistic.</p> <p>Parameters:</p> <ul> <li> <code>size</code>               (<code>int</code>)           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/probability.py</code> <pre><code>def reset(self, size: int) -&gt; None:  # noqa: D102\n    super().reset(size)\n    self._estimator = IterativeThresholdExceedance(size, self.__threshold)\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/standard_deviation/","title":"Standard deviation","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/standard_deviation/#gemseo_umdo.formulations._statistics.iterative_sampling.standard_deviation","title":"standard_deviation","text":"<p>Iterative estimator of a standard deviation for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/standard_deviation/#gemseo_umdo.formulations._statistics.iterative_sampling.standard_deviation-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/standard_deviation/#gemseo_umdo.formulations._statistics.iterative_sampling.standard_deviation.StandardDeviation","title":"StandardDeviation","text":"<pre><code>StandardDeviation()\n</code></pre> <p>               Bases: <code>Variance</code></p> <p>Iterative estimator of the standard deviation.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/standard_deviation.py</code> <pre><code>def __init__(self) -&gt; None:\n    super().__init__()\n    self.__var_jac = Variance()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/standard_deviation/#gemseo_umdo.formulations._statistics.iterative_sampling.standard_deviation.StandardDeviation-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/standard_deviation/#gemseo_umdo.formulations._statistics.iterative_sampling.standard_deviation.StandardDeviation.jac_shape","title":"jac_shape  <code>instance-attribute</code>","text":"<pre><code>jac_shape: tuple[int, int] | None = None\n</code></pre> <p>The shape of the Jacobian, if known.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/standard_deviation/#gemseo_umdo.formulations._statistics.iterative_sampling.standard_deviation.StandardDeviation.shape","title":"shape  <code>instance-attribute</code>","text":"<pre><code>shape: tuple[int] | None = None\n</code></pre> <p>The shape of the output of interest, if known.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/standard_deviation/#gemseo_umdo.formulations._statistics.iterative_sampling.standard_deviation.StandardDeviation-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/standard_deviation/#gemseo_umdo.formulations._statistics.iterative_sampling.standard_deviation.StandardDeviation.compute_jacobian","title":"compute_jacobian","text":"<pre><code>compute_jacobian(\n    value: RealArray, jac_value: RealArray\n) -&gt; RealArray\n</code></pre> <p>Compute the Jacobian of the statistic estimation.</p> <p>Parameters:</p> <ul> <li> <code>value</code>               (<code>RealArray</code>)           \u2013            <p>The value of the function output.</p> </li> <li> <code>jac_value</code>               (<code>RealArray</code>)           \u2013            <p>The value of the Jacobian.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The Jacobian of the statistic estimation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/standard_deviation.py</code> <pre><code>def compute_jacobian(self, value: RealArray, jac_value: RealArray) -&gt; RealArray:\n    self.jac_shape = jac_value.shape\n    return nan_to_num(\n        self.__var_jac.compute_jacobian(value, jac_value).reshape(self.jac_shape)\n        / self._get_estimation()[:, newaxis]\n        / 2\n    ).ravel()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/standard_deviation/#gemseo_umdo.formulations._statistics.iterative_sampling.standard_deviation.StandardDeviation.estimate_statistic","title":"estimate_statistic","text":"<pre><code>estimate_statistic(value: RealArray) -&gt; RealArray\n</code></pre> <p>Estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>value</code>               (<code>RealArray</code>)           \u2013            <p>The value of the function output.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator.py</code> <pre><code>def estimate_statistic(self, value: RealArray) -&gt; RealArray:\n    \"\"\"\n    Args:\n        value: The value of the function output.\n    \"\"\"  # noqa: D205 D212\n    if self.shape is None:\n        self.shape = value.shape\n        self.reset(value.size)\n\n    self._estimator.increment(value.ravel())\n    return self._get_estimation()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/standard_deviation/#gemseo_umdo.formulations._statistics.iterative_sampling.standard_deviation.StandardDeviation.reset","title":"reset","text":"<pre><code>reset(size: int) -&gt; None\n</code></pre> <p>Reset the estimator of the statistic.</p> <p>Parameters:</p> <ul> <li> <code>size</code>               (<code>int</code>)           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/standard_deviation.py</code> <pre><code>def reset(self, size: int) -&gt; None:\n    super().reset(size)\n    self.__var_jac.reset(size)\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/variance/","title":"Variance","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/variance/#gemseo_umdo.formulations._statistics.iterative_sampling.variance","title":"variance","text":"<p>Iterative estimator of the variance for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/variance/#gemseo_umdo.formulations._statistics.iterative_sampling.variance-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/variance/#gemseo_umdo.formulations._statistics.iterative_sampling.variance.Variance","title":"Variance","text":"<pre><code>Variance()\n</code></pre> <p>               Bases: <code>BaseCentralMoment</code></p> <p>Iterative estimator of the variance.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/variance.py</code> <pre><code>def __init__(self) -&gt; None:\n    super().__init__()\n    self.__mean_jac = Mean()\n    self.__mean = Mean()\n    self.__prod_mean = Mean()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/variance/#gemseo_umdo.formulations._statistics.iterative_sampling.variance.Variance-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/variance/#gemseo_umdo.formulations._statistics.iterative_sampling.variance.Variance.jac_shape","title":"jac_shape  <code>instance-attribute</code>","text":"<pre><code>jac_shape: tuple[int, int] | None = None\n</code></pre> <p>The shape of the Jacobian, if known.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/variance/#gemseo_umdo.formulations._statistics.iterative_sampling.variance.Variance.shape","title":"shape  <code>instance-attribute</code>","text":"<pre><code>shape: tuple[int] | None = None\n</code></pre> <p>The shape of the output of interest, if known.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/variance/#gemseo_umdo.formulations._statistics.iterative_sampling.variance.Variance-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/variance/#gemseo_umdo.formulations._statistics.iterative_sampling.variance.Variance.compute_jacobian","title":"compute_jacobian","text":"<pre><code>compute_jacobian(\n    value: RealArray, jac_value: RealArray\n) -&gt; RealArray\n</code></pre> <p>Compute the Jacobian of the statistic estimation.</p> <p>Parameters:</p> <ul> <li> <code>value</code>               (<code>RealArray</code>)           \u2013            <p>The value of the function output.</p> </li> <li> <code>jac_value</code>               (<code>RealArray</code>)           \u2013            <p>The value of the Jacobian.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The Jacobian of the statistic estimation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/variance.py</code> <pre><code>def compute_jacobian(self, value: RealArray, jac_value: RealArray) -&gt; RealArray:\n    self.jac_shape = jac_value.shape\n    n = self.__mean._estimator.getIterationNumber() + 1\n    alpha = n / (n - 1) if n &gt; 1 else 1\n    return (\n        2\n        * (\n            self.__prod_mean.estimate_statistic(value[:, newaxis] * jac_value)\n            - (\n                self.__mean.estimate_statistic(value)[:, newaxis]\n                * self.__mean_jac.estimate_statistic(jac_value).reshape(\n                    self.jac_shape\n                )\n            ).ravel()\n        )\n        * alpha\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/variance/#gemseo_umdo.formulations._statistics.iterative_sampling.variance.Variance.estimate_statistic","title":"estimate_statistic","text":"<pre><code>estimate_statistic(value: RealArray) -&gt; RealArray\n</code></pre> <p>Estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>value</code>               (<code>RealArray</code>)           \u2013            <p>The value of the function output.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/base_sampling_estimator.py</code> <pre><code>def estimate_statistic(self, value: RealArray) -&gt; RealArray:\n    \"\"\"\n    Args:\n        value: The value of the function output.\n    \"\"\"  # noqa: D205 D212\n    if self.shape is None:\n        self.shape = value.shape\n        self.reset(value.size)\n\n    self._estimator.increment(value.ravel())\n    return self._get_estimation()\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/iterative_sampling/variance/#gemseo_umdo.formulations._statistics.iterative_sampling.variance.Variance.reset","title":"reset","text":"<pre><code>reset(size: int) -&gt; None\n</code></pre> <p>Reset the estimator of the statistic.</p> <p>Parameters:</p> <ul> <li> <code>size</code>               (<code>int</code>)           \u2013            <p>The description is missing.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/iterative_sampling/variance.py</code> <pre><code>def reset(self, size: int) -&gt; None:  # noqa: D102\n    super().reset(size)\n    self.__mean_jac.reset(size)\n    self.__mean.reset(size)\n    self.__prod_mean.reset(size)\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/","title":"Pce","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/#gemseo_umdo.formulations._statistics.pce","title":"pce","text":"<p>Estimators of statistics for U-MDO formulations based on PCE.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/base_pce_estimator/","title":"Base pce estimator","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/base_pce_estimator/#gemseo_umdo.formulations._statistics.pce.base_pce_estimator","title":"base_pce_estimator","text":"<p>Base statistic estimator for a U-MDO formulations based on PCE.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/base_pce_estimator/#gemseo_umdo.formulations._statistics.pce.base_pce_estimator-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/base_pce_estimator/#gemseo_umdo.formulations._statistics.pce.base_pce_estimator.BasePCEEstimator","title":"BasePCEEstimator","text":"<p>               Bases: <code>BaseStatisticEstimator</code></p> <p>Base statistic estimator for a U-MDO formulation using PCE.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/base_pce_estimator/#gemseo_umdo.formulations._statistics.pce.base_pce_estimator.BasePCEEstimator-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/base_pce_estimator/#gemseo_umdo.formulations._statistics.pce.base_pce_estimator.BasePCEEstimator.ARG_NAMES","title":"ARG_NAMES  <code>class-attribute</code>","text":"<pre><code>ARG_NAMES: tuple[str] = ()\n</code></pre> <p>The names of the arguments to be used for the estimator.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/base_pce_estimator/#gemseo_umdo.formulations._statistics.pce.base_pce_estimator.BasePCEEstimator.MEAN_ARG_NAME","title":"MEAN_ARG_NAME  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MEAN_ARG_NAME: Final[str] = 'mean'\n</code></pre> <p>The name of the mean argument.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/base_pce_estimator/#gemseo_umdo.formulations._statistics.pce.base_pce_estimator.BasePCEEstimator.STD_ARG_NAME","title":"STD_ARG_NAME  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>STD_ARG_NAME: Final[str] = 'std'\n</code></pre> <p>The name of the standard deviation argument.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/base_pce_estimator/#gemseo_umdo.formulations._statistics.pce.base_pce_estimator.BasePCEEstimator.VAR_ARG_NAME","title":"VAR_ARG_NAME  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>VAR_ARG_NAME: Final[str] = 'var'\n</code></pre> <p>The name of the variance argument.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/base_pce_estimator/#gemseo_umdo.formulations._statistics.pce.base_pce_estimator.BasePCEEstimator-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/base_pce_estimator/#gemseo_umdo.formulations._statistics.pce.base_pce_estimator.BasePCEEstimator.compute_jacobian","title":"compute_jacobian","text":"<pre><code>compute_jacobian(*args: Any, **kwargs: Any) -&gt; RealArray\n</code></pre> <p>Compute the Jacobian of the statistic estimation.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>               (<code>Any</code>, default:                   <code>()</code> )           \u2013            <p>The mandatory arguments.</p> </li> <li> <code>**kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The optional arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The Jacobian of the statistic estimation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/base_statistic_estimator.py</code> <pre><code>def compute_jacobian(self, *args: Any, **kwargs: Any) -&gt; RealArray:  # noqa: D102\n    \"\"\"Compute the Jacobian of the statistic estimation.\n\n    Args:\n        *args: The mandatory arguments.\n        **kwargs: The optional arguments.\n\n    Returns:\n        The Jacobian of the statistic estimation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/base_pce_estimator/#gemseo_umdo.formulations._statistics.pce.base_pce_estimator.BasePCEEstimator.estimate_statistic","title":"estimate_statistic  <code>abstractmethod</code>","text":"<pre><code>estimate_statistic(*args: Any, **kwargs: Any) -&gt; RealArray\n</code></pre> <p>Estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>               (<code>Any</code>, default:                   <code>()</code> )           \u2013            <p>The mandatory arguments.</p> </li> <li> <code>**kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The optional arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/base_statistic_estimator.py</code> <pre><code>@abstractmethod\ndef estimate_statistic(self, *args: Any, **kwargs: Any) -&gt; RealArray:  # noqa: D102\n    \"\"\"Estimate the statistic.\n\n    Args:\n        *args: The mandatory arguments.\n        **kwargs: The optional arguments.\n\n    Returns:\n        The estimation of the statistic.\n    \"\"\"\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/factory/","title":"Factory","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/factory/#gemseo_umdo.formulations._statistics.pce.factory","title":"factory","text":"<p>A factory of statistic estimators for a U-MDO formulations using PCE.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/factory/#gemseo_umdo.formulations._statistics.pce.factory-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/factory/#gemseo_umdo.formulations._statistics.pce.factory.PCEEstimatorFactory","title":"PCEEstimatorFactory","text":"<p>               Bases: <code>BaseFactory</code></p> <p>The factory of statistic estimators based on PCE.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/margin/","title":"Margin","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/margin/#gemseo_umdo.formulations._statistics.pce.margin","title":"margin","text":"<p>Estimators of a margin for a U-MDO formulation based on PCE.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/margin/#gemseo_umdo.formulations._statistics.pce.margin-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/margin/#gemseo_umdo.formulations._statistics.pce.margin.Margin","title":"Margin","text":"<pre><code>Margin(factor: float = 2.0)\n</code></pre> <p>               Bases: <code>BasePCEEstimator</code></p> <p>Estimator of a margin, i.e. mean + factor * deviation.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>factor</code>               (<code>float</code>, default:                   <code>2.0</code> )           \u2013            <p>The factor related to the standard deviation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/pce/margin.py</code> <pre><code>def __init__(self, factor: float = 2.0) -&gt; None:\n    \"\"\"\n    Args:\n        factor: The factor related to the standard deviation.\n    \"\"\"  # noqa: D205 D212 D415\n    self.__factor = factor\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/margin/#gemseo_umdo.formulations._statistics.pce.margin.Margin-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/margin/#gemseo_umdo.formulations._statistics.pce.margin.Margin.ARG_NAMES","title":"ARG_NAMES  <code>class-attribute</code>","text":"<pre><code>ARG_NAMES: tuple[str] = (MEAN_ARG_NAME, STD_ARG_NAME)\n</code></pre> <p>The names of the arguments to be used for the estimator.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/margin/#gemseo_umdo.formulations._statistics.pce.margin.Margin.MEAN_ARG_NAME","title":"MEAN_ARG_NAME  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MEAN_ARG_NAME: Final[str] = 'mean'\n</code></pre> <p>The name of the mean argument.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/margin/#gemseo_umdo.formulations._statistics.pce.margin.Margin.STD_ARG_NAME","title":"STD_ARG_NAME  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>STD_ARG_NAME: Final[str] = 'std'\n</code></pre> <p>The name of the standard deviation argument.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/margin/#gemseo_umdo.formulations._statistics.pce.margin.Margin.VAR_ARG_NAME","title":"VAR_ARG_NAME  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>VAR_ARG_NAME: Final[str] = 'var'\n</code></pre> <p>The name of the variance argument.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/margin/#gemseo_umdo.formulations._statistics.pce.margin.Margin-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/margin/#gemseo_umdo.formulations._statistics.pce.margin.Margin.compute_jacobian","title":"compute_jacobian","text":"<pre><code>compute_jacobian(*args: Any, **kwargs: Any) -&gt; RealArray\n</code></pre> <p>Compute the Jacobian of the statistic estimation.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>               (<code>Any</code>, default:                   <code>()</code> )           \u2013            <p>The mandatory arguments.</p> </li> <li> <code>**kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The optional arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The Jacobian of the statistic estimation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/base_statistic_estimator.py</code> <pre><code>def compute_jacobian(self, *args: Any, **kwargs: Any) -&gt; RealArray:  # noqa: D102\n    \"\"\"Compute the Jacobian of the statistic estimation.\n\n    Args:\n        *args: The mandatory arguments.\n        **kwargs: The optional arguments.\n\n    Returns:\n        The Jacobian of the statistic estimation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/margin/#gemseo_umdo.formulations._statistics.pce.margin.Margin.estimate_statistic","title":"estimate_statistic","text":"<pre><code>estimate_statistic(\n    mean: RealArray, standard_deviation: RealArray\n) -&gt; RealArray\n</code></pre> <p>Estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>mean</code>               (<code>RealArray</code>)           \u2013            <p>The description is missing.</p> </li> <li> <code>standard_deviation</code>               (<code>RealArray</code>)           \u2013            <p>The description is missing.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/pce/margin.py</code> <pre><code>def estimate_statistic(\n    self, mean: RealArray, standard_deviation: RealArray\n) -&gt; RealArray:\n    return mean + self.__factor * standard_deviation\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/mean/","title":"Mean","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/mean/#gemseo_umdo.formulations._statistics.pce.mean","title":"mean","text":"<p>Estimator of the expectation for a U-MDO formulations based on PCE.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/mean/#gemseo_umdo.formulations._statistics.pce.mean-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/mean/#gemseo_umdo.formulations._statistics.pce.mean.Mean","title":"Mean","text":"<p>               Bases: <code>BasePCEEstimator</code></p> <p>Estimator of the expectation.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/mean/#gemseo_umdo.formulations._statistics.pce.mean.Mean-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/mean/#gemseo_umdo.formulations._statistics.pce.mean.Mean.ARG_NAMES","title":"ARG_NAMES  <code>class-attribute</code>","text":"<pre><code>ARG_NAMES: tuple[str] = (MEAN_ARG_NAME)\n</code></pre> <p>The names of the arguments to be used for the estimator.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/mean/#gemseo_umdo.formulations._statistics.pce.mean.Mean.MEAN_ARG_NAME","title":"MEAN_ARG_NAME  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MEAN_ARG_NAME: Final[str] = 'mean'\n</code></pre> <p>The name of the mean argument.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/mean/#gemseo_umdo.formulations._statistics.pce.mean.Mean.STD_ARG_NAME","title":"STD_ARG_NAME  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>STD_ARG_NAME: Final[str] = 'std'\n</code></pre> <p>The name of the standard deviation argument.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/mean/#gemseo_umdo.formulations._statistics.pce.mean.Mean.VAR_ARG_NAME","title":"VAR_ARG_NAME  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>VAR_ARG_NAME: Final[str] = 'var'\n</code></pre> <p>The name of the variance argument.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/mean/#gemseo_umdo.formulations._statistics.pce.mean.Mean-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/mean/#gemseo_umdo.formulations._statistics.pce.mean.Mean.compute_jacobian","title":"compute_jacobian","text":"<pre><code>compute_jacobian(*args: Any, **kwargs: Any) -&gt; RealArray\n</code></pre> <p>Compute the Jacobian of the statistic estimation.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>               (<code>Any</code>, default:                   <code>()</code> )           \u2013            <p>The mandatory arguments.</p> </li> <li> <code>**kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The optional arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The Jacobian of the statistic estimation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/base_statistic_estimator.py</code> <pre><code>def compute_jacobian(self, *args: Any, **kwargs: Any) -&gt; RealArray:  # noqa: D102\n    \"\"\"Compute the Jacobian of the statistic estimation.\n\n    Args:\n        *args: The mandatory arguments.\n        **kwargs: The optional arguments.\n\n    Returns:\n        The Jacobian of the statistic estimation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/mean/#gemseo_umdo.formulations._statistics.pce.mean.Mean.estimate_statistic","title":"estimate_statistic","text":"<pre><code>estimate_statistic(mean: RealArray) -&gt; RealArray\n</code></pre> <p>Estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>mean</code>               (<code>RealArray</code>)           \u2013            <p>The description is missing.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/pce/mean.py</code> <pre><code>def estimate_statistic(self, mean: RealArray) -&gt; RealArray:\n    return mean\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/standard_deviation/","title":"Standard deviation","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/standard_deviation/#gemseo_umdo.formulations._statistics.pce.standard_deviation","title":"standard_deviation","text":"<p>Estimator of the standard deviation for a U-MDO formulations based on PCE.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/standard_deviation/#gemseo_umdo.formulations._statistics.pce.standard_deviation-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/standard_deviation/#gemseo_umdo.formulations._statistics.pce.standard_deviation.StandardDeviation","title":"StandardDeviation","text":"<p>               Bases: <code>BasePCEEstimator</code></p> <p>Estimator of the standard deviation.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/standard_deviation/#gemseo_umdo.formulations._statistics.pce.standard_deviation.StandardDeviation-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/standard_deviation/#gemseo_umdo.formulations._statistics.pce.standard_deviation.StandardDeviation.ARG_NAMES","title":"ARG_NAMES  <code>class-attribute</code>","text":"<pre><code>ARG_NAMES: tuple[str] = (STD_ARG_NAME)\n</code></pre> <p>The names of the arguments to be used for the estimator.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/standard_deviation/#gemseo_umdo.formulations._statistics.pce.standard_deviation.StandardDeviation.MEAN_ARG_NAME","title":"MEAN_ARG_NAME  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MEAN_ARG_NAME: Final[str] = 'mean'\n</code></pre> <p>The name of the mean argument.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/standard_deviation/#gemseo_umdo.formulations._statistics.pce.standard_deviation.StandardDeviation.STD_ARG_NAME","title":"STD_ARG_NAME  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>STD_ARG_NAME: Final[str] = 'std'\n</code></pre> <p>The name of the standard deviation argument.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/standard_deviation/#gemseo_umdo.formulations._statistics.pce.standard_deviation.StandardDeviation.VAR_ARG_NAME","title":"VAR_ARG_NAME  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>VAR_ARG_NAME: Final[str] = 'var'\n</code></pre> <p>The name of the variance argument.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/standard_deviation/#gemseo_umdo.formulations._statistics.pce.standard_deviation.StandardDeviation-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/standard_deviation/#gemseo_umdo.formulations._statistics.pce.standard_deviation.StandardDeviation.compute_jacobian","title":"compute_jacobian","text":"<pre><code>compute_jacobian(*args: Any, **kwargs: Any) -&gt; RealArray\n</code></pre> <p>Compute the Jacobian of the statistic estimation.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>               (<code>Any</code>, default:                   <code>()</code> )           \u2013            <p>The mandatory arguments.</p> </li> <li> <code>**kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The optional arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The Jacobian of the statistic estimation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/base_statistic_estimator.py</code> <pre><code>def compute_jacobian(self, *args: Any, **kwargs: Any) -&gt; RealArray:  # noqa: D102\n    \"\"\"Compute the Jacobian of the statistic estimation.\n\n    Args:\n        *args: The mandatory arguments.\n        **kwargs: The optional arguments.\n\n    Returns:\n        The Jacobian of the statistic estimation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/standard_deviation/#gemseo_umdo.formulations._statistics.pce.standard_deviation.StandardDeviation.estimate_statistic","title":"estimate_statistic","text":"<pre><code>estimate_statistic(\n    standard_deviation: RealArray,\n) -&gt; RealArray\n</code></pre> <p>Estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>standard_deviation</code>               (<code>RealArray</code>)           \u2013            <p>The description is missing.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/pce/standard_deviation.py</code> <pre><code>def estimate_statistic(self, standard_deviation: RealArray) -&gt; RealArray:\n    return standard_deviation\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/variance/","title":"Variance","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/variance/#gemseo_umdo.formulations._statistics.pce.variance","title":"variance","text":"<p>Estimator of the variance for a U-MDO formulations based on PCE.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/variance/#gemseo_umdo.formulations._statistics.pce.variance-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/variance/#gemseo_umdo.formulations._statistics.pce.variance.Variance","title":"Variance","text":"<p>               Bases: <code>BasePCEEstimator</code></p> <p>Estimator of the variance.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/variance/#gemseo_umdo.formulations._statistics.pce.variance.Variance-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/variance/#gemseo_umdo.formulations._statistics.pce.variance.Variance.ARG_NAMES","title":"ARG_NAMES  <code>class-attribute</code>","text":"<pre><code>ARG_NAMES: tuple[str] = (VAR_ARG_NAME)\n</code></pre> <p>The names of the arguments to be used for the estimator.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/variance/#gemseo_umdo.formulations._statistics.pce.variance.Variance.MEAN_ARG_NAME","title":"MEAN_ARG_NAME  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MEAN_ARG_NAME: Final[str] = 'mean'\n</code></pre> <p>The name of the mean argument.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/variance/#gemseo_umdo.formulations._statistics.pce.variance.Variance.STD_ARG_NAME","title":"STD_ARG_NAME  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>STD_ARG_NAME: Final[str] = 'std'\n</code></pre> <p>The name of the standard deviation argument.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/variance/#gemseo_umdo.formulations._statistics.pce.variance.Variance.VAR_ARG_NAME","title":"VAR_ARG_NAME  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>VAR_ARG_NAME: Final[str] = 'var'\n</code></pre> <p>The name of the variance argument.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/variance/#gemseo_umdo.formulations._statistics.pce.variance.Variance-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/variance/#gemseo_umdo.formulations._statistics.pce.variance.Variance.compute_jacobian","title":"compute_jacobian","text":"<pre><code>compute_jacobian(*args: Any, **kwargs: Any) -&gt; RealArray\n</code></pre> <p>Compute the Jacobian of the statistic estimation.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>               (<code>Any</code>, default:                   <code>()</code> )           \u2013            <p>The mandatory arguments.</p> </li> <li> <code>**kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The optional arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The Jacobian of the statistic estimation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/base_statistic_estimator.py</code> <pre><code>def compute_jacobian(self, *args: Any, **kwargs: Any) -&gt; RealArray:  # noqa: D102\n    \"\"\"Compute the Jacobian of the statistic estimation.\n\n    Args:\n        *args: The mandatory arguments.\n        **kwargs: The optional arguments.\n\n    Returns:\n        The Jacobian of the statistic estimation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/pce/variance/#gemseo_umdo.formulations._statistics.pce.variance.Variance.estimate_statistic","title":"estimate_statistic","text":"<pre><code>estimate_statistic(variance: RealArray) -&gt; RealArray\n</code></pre> <p>Estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>variance</code>               (<code>RealArray</code>)           \u2013            <p>The description is missing.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/pce/variance.py</code> <pre><code>def estimate_statistic(self, variance: RealArray) -&gt; RealArray:\n    return variance\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/","title":"Sampling","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/#gemseo_umdo.formulations._statistics.sampling","title":"sampling","text":"<p>Estimators of statistics for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/base_sampling_estimator/","title":"Base sampling estimator","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/base_sampling_estimator/#gemseo_umdo.formulations._statistics.sampling.base_sampling_estimator","title":"base_sampling_estimator","text":"<p>Base statistic estimator for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/base_sampling_estimator/#gemseo_umdo.formulations._statistics.sampling.base_sampling_estimator-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/base_sampling_estimator/#gemseo_umdo.formulations._statistics.sampling.base_sampling_estimator.BaseSamplingEstimator","title":"BaseSamplingEstimator","text":"<p>               Bases: <code>BaseStatisticEstimator</code></p> <p>Base statistic estimator for a U-MDO formulation using sampling.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/base_sampling_estimator/#gemseo_umdo.formulations._statistics.sampling.base_sampling_estimator.BaseSamplingEstimator-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/base_sampling_estimator/#gemseo_umdo.formulations._statistics.sampling.base_sampling_estimator.BaseSamplingEstimator.compute_jacobian","title":"compute_jacobian","text":"<pre><code>compute_jacobian(\n    samples: RealArray, jac_samples: RealArray\n) -&gt; RealArray\n</code></pre> <p>Compute the Jacobian of the statistic estimation.</p> <p>Parameters:</p> <ul> <li> <code>samples</code>               (<code>RealArray</code>)           \u2013            <p>The samples to estimate the statistic.</p> </li> <li> <code>jac_samples</code>               (<code>RealArray</code>)           \u2013            <p>The samples to estimate the Jacobian of the statistic.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The Jacobian of the statistic estimation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/sampling/base_sampling_estimator.py</code> <pre><code>def compute_jacobian(self, samples: RealArray, jac_samples: RealArray) -&gt; RealArray:\n    \"\"\"\n    Args:\n        samples: The samples to estimate the statistic.\n        jac_samples: The samples to estimate the Jacobian of the statistic.\n    \"\"\"  # noqa: D205 D212\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/base_sampling_estimator/#gemseo_umdo.formulations._statistics.sampling.base_sampling_estimator.BaseSamplingEstimator.estimate_statistic","title":"estimate_statistic  <code>abstractmethod</code>","text":"<pre><code>estimate_statistic(samples: RealArray) -&gt; RealArray\n</code></pre> <p>Estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>samples</code>               (<code>RealArray</code>)           \u2013            <p>The samples to estimate the statistic.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/sampling/base_sampling_estimator.py</code> <pre><code>@abstractmethod\ndef estimate_statistic(self, samples: RealArray) -&gt; RealArray:\n    \"\"\"\n    Args:\n        samples: The samples to estimate the statistic.\n    \"\"\"  # noqa: D205 D212\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/factory/","title":"Factory","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/factory/#gemseo_umdo.formulations._statistics.sampling.factory","title":"factory","text":"<p>A factory of statistic estimators for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/factory/#gemseo_umdo.formulations._statistics.sampling.factory-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/factory/#gemseo_umdo.formulations._statistics.sampling.factory.SamplingEstimatorFactory","title":"SamplingEstimatorFactory","text":"<p>               Bases: <code>BaseFactory</code></p> <p>The factory of sampling-based statistic estimators.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/margin/","title":"Margin","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/margin/#gemseo_umdo.formulations._statistics.sampling.margin","title":"margin","text":"<p>Estimator of a margin for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/margin/#gemseo_umdo.formulations._statistics.sampling.margin-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/margin/#gemseo_umdo.formulations._statistics.sampling.margin.Margin","title":"Margin","text":"<pre><code>Margin(factor: float = 2.0)\n</code></pre> <p>               Bases: <code>BaseSamplingEstimator</code></p> <p>Estimator of a margin, i.e. mean + factor * deviation.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>factor</code>               (<code>float</code>, default:                   <code>2.0</code> )           \u2013            <p>The factor related to the standard deviation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/sampling/margin.py</code> <pre><code>def __init__(self, factor: float = 2.0) -&gt; None:\n    \"\"\"\n    Args:\n        factor: The factor related to the standard deviation.\n    \"\"\"  # noqa: D205 D212 D415\n    super().__init__()\n    self.__mean = Mean()\n    self.__standard_deviation = StandardDeviation()\n    self.__factor = factor\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/margin/#gemseo_umdo.formulations._statistics.sampling.margin.Margin-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/margin/#gemseo_umdo.formulations._statistics.sampling.margin.Margin.compute_jacobian","title":"compute_jacobian","text":"<pre><code>compute_jacobian(\n    samples: RealArray, jac_samples: RealArray\n) -&gt; RealArray\n</code></pre> <p>Compute the Jacobian of the statistic estimation.</p> <p>Parameters:</p> <ul> <li> <code>samples</code>               (<code>RealArray</code>)           \u2013            <p>The samples to estimate the statistic.</p> </li> <li> <code>jac_samples</code>               (<code>RealArray</code>)           \u2013            <p>The samples to estimate the Jacobian of the statistic.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The Jacobian of the statistic estimation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/sampling/margin.py</code> <pre><code>def compute_jacobian(self, samples: RealArray, jac_samples: RealArray) -&gt; RealArray:\n    mean = self.__mean.compute_jacobian(samples, jac_samples)\n    variance = self.__standard_deviation.compute_jacobian(samples, jac_samples)\n    return mean + self.__factor * variance\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/margin/#gemseo_umdo.formulations._statistics.sampling.margin.Margin.estimate_statistic","title":"estimate_statistic","text":"<pre><code>estimate_statistic(samples: RealArray) -&gt; RealArray\n</code></pre> <p>Estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>samples</code>               (<code>RealArray</code>)           \u2013            <p>The samples to estimate the statistic.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/sampling/margin.py</code> <pre><code>def estimate_statistic(self, samples: RealArray) -&gt; RealArray:\n    mean = self.__mean.estimate_statistic(samples)\n    variance = self.__standard_deviation.estimate_statistic(samples)\n    return mean + self.__factor * variance\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/mean/","title":"Mean","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/mean/#gemseo_umdo.formulations._statistics.sampling.mean","title":"mean","text":"<p>Estimator of the expectation for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/mean/#gemseo_umdo.formulations._statistics.sampling.mean-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/mean/#gemseo_umdo.formulations._statistics.sampling.mean.Mean","title":"Mean","text":"<p>               Bases: <code>BaseSamplingEstimator</code></p> <p>Estimator of the expectation.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/mean/#gemseo_umdo.formulations._statistics.sampling.mean.Mean-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/mean/#gemseo_umdo.formulations._statistics.sampling.mean.Mean.compute_jacobian","title":"compute_jacobian","text":"<pre><code>compute_jacobian(\n    samples: RealArray, jac_samples: RealArray\n) -&gt; RealArray\n</code></pre> <p>Compute the Jacobian of the statistic estimation.</p> <p>Parameters:</p> <ul> <li> <code>samples</code>               (<code>RealArray</code>)           \u2013            <p>The samples to estimate the statistic.</p> </li> <li> <code>jac_samples</code>               (<code>RealArray</code>)           \u2013            <p>The samples to estimate the Jacobian of the statistic.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The Jacobian of the statistic estimation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/sampling/mean.py</code> <pre><code>def compute_jacobian(self, samples: RealArray, jac_samples: RealArray) -&gt; RealArray:\n    return atleast_1d(jac_samples.mean(0))\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/mean/#gemseo_umdo.formulations._statistics.sampling.mean.Mean.estimate_statistic","title":"estimate_statistic","text":"<pre><code>estimate_statistic(samples: RealArray) -&gt; RealArray\n</code></pre> <p>Estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>samples</code>               (<code>RealArray</code>)           \u2013            <p>The samples to estimate the statistic.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/sampling/mean.py</code> <pre><code>def estimate_statistic(self, samples: RealArray) -&gt; RealArray:\n    return atleast_1d(samples.mean(0))\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/probability/","title":"Probability","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/probability/#gemseo_umdo.formulations._statistics.sampling.probability","title":"probability","text":"<p>Estimator of a probability for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/probability/#gemseo_umdo.formulations._statistics.sampling.probability-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/probability/#gemseo_umdo.formulations._statistics.sampling.probability.Probability","title":"Probability","text":"<pre><code>Probability(threshold: float = 0.0, greater: bool = True)\n</code></pre> <p>               Bases: <code>BaseSamplingEstimator</code></p> <p>Estimator of a probability.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>threshold</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>The threshold against which the probability is estimated.</p> </li> <li> <code>greater</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to compute the probability of exceeding the threshold.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/sampling/probability.py</code> <pre><code>def __init__(self, threshold: float = 0.0, greater: bool = True) -&gt; None:\n    \"\"\"\n    Args:\n        threshold: The threshold against which the probability is estimated.\n        greater: Whether to compute the probability of exceeding the threshold.\n    \"\"\"  # noqa: D205 D212 D415\n    super().__init__()\n    self.__threshold = threshold\n    self.__compare = ge if greater else le\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/probability/#gemseo_umdo.formulations._statistics.sampling.probability.Probability-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/probability/#gemseo_umdo.formulations._statistics.sampling.probability.Probability.compute_jacobian","title":"compute_jacobian","text":"<pre><code>compute_jacobian(\n    samples: RealArray, jac_samples: RealArray\n) -&gt; RealArray\n</code></pre> <p>Compute the Jacobian of the statistic estimation.</p> <p>Parameters:</p> <ul> <li> <code>samples</code>               (<code>RealArray</code>)           \u2013            <p>The samples to estimate the statistic.</p> </li> <li> <code>jac_samples</code>               (<code>RealArray</code>)           \u2013            <p>The samples to estimate the Jacobian of the statistic.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The Jacobian of the statistic estimation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/sampling/base_sampling_estimator.py</code> <pre><code>def compute_jacobian(self, samples: RealArray, jac_samples: RealArray) -&gt; RealArray:\n    \"\"\"\n    Args:\n        samples: The samples to estimate the statistic.\n        jac_samples: The samples to estimate the Jacobian of the statistic.\n    \"\"\"  # noqa: D205 D212\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/probability/#gemseo_umdo.formulations._statistics.sampling.probability.Probability.estimate_statistic","title":"estimate_statistic","text":"<pre><code>estimate_statistic(samples: RealArray) -&gt; RealArray\n</code></pre> <p>Estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>samples</code>               (<code>RealArray</code>)           \u2013            <p>The samples to estimate the statistic.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/sampling/probability.py</code> <pre><code>def estimate_statistic(self, samples: RealArray) -&gt; RealArray:\n    return atleast_1d(self.__compare(samples, self.__threshold).mean(0))\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/standard_deviation/","title":"Standard deviation","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/standard_deviation/#gemseo_umdo.formulations._statistics.sampling.standard_deviation","title":"standard_deviation","text":"<p>Estimator of the standard deviation for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/standard_deviation/#gemseo_umdo.formulations._statistics.sampling.standard_deviation-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/standard_deviation/#gemseo_umdo.formulations._statistics.sampling.standard_deviation.StandardDeviation","title":"StandardDeviation","text":"<p>               Bases: <code>Variance</code></p> <p>Estimator of the standard deviation.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/standard_deviation/#gemseo_umdo.formulations._statistics.sampling.standard_deviation.StandardDeviation-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/standard_deviation/#gemseo_umdo.formulations._statistics.sampling.standard_deviation.StandardDeviation.compute_jacobian","title":"compute_jacobian","text":"<pre><code>compute_jacobian(\n    samples: RealArray, jac_samples: RealArray\n) -&gt; RealArray\n</code></pre> <p>Compute the Jacobian of the statistic estimation.</p> <p>Parameters:</p> <ul> <li> <code>samples</code>               (<code>RealArray</code>)           \u2013            <p>The samples to estimate the statistic.</p> </li> <li> <code>jac_samples</code>               (<code>RealArray</code>)           \u2013            <p>The samples to estimate the Jacobian of the statistic.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The Jacobian of the statistic estimation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/sampling/standard_deviation.py</code> <pre><code>def compute_jacobian(self, samples: RealArray, jac_samples: RealArray) -&gt; RealArray:\n    std = self.estimate_statistic(samples)\n    return nan_to_num(\n        super().compute_jacobian(samples, jac_samples) / std[:, newaxis] / 2\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/standard_deviation/#gemseo_umdo.formulations._statistics.sampling.standard_deviation.StandardDeviation.estimate_statistic","title":"estimate_statistic","text":"<pre><code>estimate_statistic(samples: RealArray) -&gt; RealArray\n</code></pre> <p>Estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>samples</code>               (<code>RealArray</code>)           \u2013            <p>The samples to estimate the statistic.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/sampling/standard_deviation.py</code> <pre><code>def estimate_statistic(self, samples: RealArray) -&gt; RealArray:\n    return super().estimate_statistic(samples) ** 0.5\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/variance/","title":"Variance","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/variance/#gemseo_umdo.formulations._statistics.sampling.variance","title":"variance","text":"<p>Estimator of the variance for sampling-based U-MDO formulations.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/variance/#gemseo_umdo.formulations._statistics.sampling.variance-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/variance/#gemseo_umdo.formulations._statistics.sampling.variance.Variance","title":"Variance","text":"<p>               Bases: <code>BaseSamplingEstimator</code></p> <p>Estimator of the variance.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/variance/#gemseo_umdo.formulations._statistics.sampling.variance.Variance-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/variance/#gemseo_umdo.formulations._statistics.sampling.variance.Variance.compute_jacobian","title":"compute_jacobian","text":"<pre><code>compute_jacobian(\n    samples: RealArray, jac_samples: RealArray\n) -&gt; RealArray\n</code></pre> <p>Compute the Jacobian of the statistic estimation.</p> <p>Parameters:</p> <ul> <li> <code>samples</code>               (<code>RealArray</code>)           \u2013            <p>The samples to estimate the statistic.</p> </li> <li> <code>jac_samples</code>               (<code>RealArray</code>)           \u2013            <p>The samples to estimate the Jacobian of the statistic.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The Jacobian of the statistic estimation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/sampling/variance.py</code> <pre><code>def compute_jacobian(self, samples: RealArray, jac_samples: RealArray) -&gt; RealArray:\n    n = len(samples)\n    return (\n        2\n        * n\n        / (n - 1)\n        * (\n            (samples[:, :, newaxis] * jac_samples).mean(0)\n            - jac_samples.mean(0) * samples.mean(0)[:, newaxis]\n        )\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/sampling/variance/#gemseo_umdo.formulations._statistics.sampling.variance.Variance.estimate_statistic","title":"estimate_statistic","text":"<pre><code>estimate_statistic(samples: RealArray) -&gt; RealArray\n</code></pre> <p>Estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>samples</code>               (<code>RealArray</code>)           \u2013            <p>The samples to estimate the statistic.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/sampling/variance.py</code> <pre><code>def estimate_statistic(self, samples: RealArray) -&gt; RealArray:\n    return atleast_1d(samples.var(0, ddof=1))\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/","title":"Taylor polynomial","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/#gemseo_umdo.formulations._statistics.taylor_polynomial","title":"taylor_polynomial","text":"<p>Estimators of statistics for U-MDO formulations based on Taylor polynomials.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/base_taylor_polynomial_estimator/","title":"Base taylor polynomial estimator","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/base_taylor_polynomial_estimator/#gemseo_umdo.formulations._statistics.taylor_polynomial.base_taylor_polynomial_estimator","title":"base_taylor_polynomial_estimator","text":"<p>Base statistic estimator for U-MDO formulations based on Taylor polynomials.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/base_taylor_polynomial_estimator/#gemseo_umdo.formulations._statistics.taylor_polynomial.base_taylor_polynomial_estimator-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/base_taylor_polynomial_estimator/#gemseo_umdo.formulations._statistics.taylor_polynomial.base_taylor_polynomial_estimator.BaseTaylorPolynomialEstimator","title":"BaseTaylorPolynomialEstimator","text":"<pre><code>BaseTaylorPolynomialEstimator(\n    uncertain_space: ParameterSpace,\n)\n</code></pre> <p>               Bases: <code>BaseStatisticEstimator</code></p> <p>Base statistic estimator for a U-MDO formulation using Taylor polynomials.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain variables with their probability distributions.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/taylor_polynomial/base_taylor_polynomial_estimator.py</code> <pre><code>def __init__(self, uncertain_space: ParameterSpace) -&gt; None:\n    \"\"\"\n    Args:\n        uncertain_space: The uncertain variables\n            with their probability distributions.\n    \"\"\"  # noqa: D205 D212 D415\n    self._standard_deviations = uncertain_space.distribution.standard_deviation\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/base_taylor_polynomial_estimator/#gemseo_umdo.formulations._statistics.taylor_polynomial.base_taylor_polynomial_estimator.BaseTaylorPolynomialEstimator-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/base_taylor_polynomial_estimator/#gemseo_umdo.formulations._statistics.taylor_polynomial.base_taylor_polynomial_estimator.BaseTaylorPolynomialEstimator.compute_jacobian","title":"compute_jacobian","text":"<pre><code>compute_jacobian(*args: Any, **kwargs: Any) -&gt; RealArray\n</code></pre> <p>Compute the Jacobian of the statistic estimation.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>               (<code>Any</code>, default:                   <code>()</code> )           \u2013            <p>The mandatory arguments.</p> </li> <li> <code>**kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The optional arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The Jacobian of the statistic estimation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/base_statistic_estimator.py</code> <pre><code>def compute_jacobian(self, *args: Any, **kwargs: Any) -&gt; RealArray:  # noqa: D102\n    \"\"\"Compute the Jacobian of the statistic estimation.\n\n    Args:\n        *args: The mandatory arguments.\n        **kwargs: The optional arguments.\n\n    Returns:\n        The Jacobian of the statistic estimation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/base_taylor_polynomial_estimator/#gemseo_umdo.formulations._statistics.taylor_polynomial.base_taylor_polynomial_estimator.BaseTaylorPolynomialEstimator.estimate_statistic","title":"estimate_statistic  <code>abstractmethod</code>","text":"<pre><code>estimate_statistic(\n    func: RealArray, jac: RealArray, hess: RealArray | None\n) -&gt; RealArray\n</code></pre> <p>Estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>func</code>               (<code>RealArray</code>)           \u2013            <p>The output value at the mean value of the uncertain variables.</p> </li> <li> <code>jac</code>               (<code>RealArray</code>)           \u2013            <p>The Jacobian value at the mean value of the uncertain variables.</p> </li> <li> <code>hess</code>               (<code>RealArray | None</code>)           \u2013            <p>The Hessian value at the mean value of the uncertain variables.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/taylor_polynomial/base_taylor_polynomial_estimator.py</code> <pre><code>@abstractmethod\ndef estimate_statistic(\n    self, func: RealArray, jac: RealArray, hess: RealArray | None\n) -&gt; RealArray:\n    \"\"\"\n    Args:\n        func: The output value at the mean value of the uncertain variables.\n        jac: The Jacobian value at the mean value of the uncertain variables.\n        hess: The Hessian value at the mean value of the uncertain variables.\n    \"\"\"  # noqa: D205 D212 D415 E112\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/factory/","title":"Factory","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/factory/#gemseo_umdo.formulations._statistics.taylor_polynomial.factory","title":"factory","text":"<p>A factory of statistic estimators for U-MDO formulations using Taylor polynomials.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/factory/#gemseo_umdo.formulations._statistics.taylor_polynomial.factory-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/factory/#gemseo_umdo.formulations._statistics.taylor_polynomial.factory.TaylorPolynomialEstimatorFactory","title":"TaylorPolynomialEstimatorFactory","text":"<p>               Bases: <code>BaseFactory</code></p> <p>The factory of statistic estimators based on Taylor polynomials.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/margin/","title":"Margin","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/margin/#gemseo_umdo.formulations._statistics.taylor_polynomial.margin","title":"margin","text":"<p>Estimators of a margin for U-MDO formulation based on Taylor polynomials.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/margin/#gemseo_umdo.formulations._statistics.taylor_polynomial.margin-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/margin/#gemseo_umdo.formulations._statistics.taylor_polynomial.margin.Margin","title":"Margin","text":"<pre><code>Margin(\n    uncertain_space: ParameterSpace, factor: float = 2.0\n)\n</code></pre> <p>               Bases: <code>BaseTaylorPolynomialEstimator</code></p> <p>Estimator of a margin, i.e. mean + factor * deviation.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain variables with their probability distributions.</p> </li> <li> <code>factor</code>               (<code>float</code>, default:                   <code>2.0</code> )           \u2013            <p>The factor related to the standard deviation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/taylor_polynomial/margin.py</code> <pre><code>def __init__(self, uncertain_space: ParameterSpace, factor: float = 2.0) -&gt; None:\n    \"\"\"\n    Args:\n        factor: The factor related to the standard deviation.\n    \"\"\"  # noqa: D205 D212 D415\n    super().__init__(uncertain_space)\n    self.__mean = Mean(uncertain_space)\n    self.__standard_deviation = StandardDeviation(uncertain_space)\n    self.__factor = factor\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/margin/#gemseo_umdo.formulations._statistics.taylor_polynomial.margin.Margin-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/margin/#gemseo_umdo.formulations._statistics.taylor_polynomial.margin.Margin.compute_jacobian","title":"compute_jacobian","text":"<pre><code>compute_jacobian(*args: Any, **kwargs: Any) -&gt; RealArray\n</code></pre> <p>Compute the Jacobian of the statistic estimation.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>               (<code>Any</code>, default:                   <code>()</code> )           \u2013            <p>The mandatory arguments.</p> </li> <li> <code>**kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The optional arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The Jacobian of the statistic estimation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/base_statistic_estimator.py</code> <pre><code>def compute_jacobian(self, *args: Any, **kwargs: Any) -&gt; RealArray:  # noqa: D102\n    \"\"\"Compute the Jacobian of the statistic estimation.\n\n    Args:\n        *args: The mandatory arguments.\n        **kwargs: The optional arguments.\n\n    Returns:\n        The Jacobian of the statistic estimation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/margin/#gemseo_umdo.formulations._statistics.taylor_polynomial.margin.Margin.estimate_statistic","title":"estimate_statistic","text":"<pre><code>estimate_statistic(\n    func: RealArray, jac: RealArray, hess: RealArray\n) -&gt; RealArray\n</code></pre> <p>Estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>func</code>               (<code>RealArray</code>)           \u2013            <p>The output value at the mean value of the uncertain variables.</p> </li> <li> <code>jac</code>               (<code>RealArray</code>)           \u2013            <p>The Jacobian value at the mean value of the uncertain variables.</p> </li> <li> <code>hess</code>               (<code>RealArray</code>)           \u2013            <p>The Hessian value at the mean value of the uncertain variables.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/taylor_polynomial/margin.py</code> <pre><code>def estimate_statistic(  # noqa: D102\n    self, func: RealArray, jac: RealArray, hess: RealArray\n) -&gt; RealArray:\n    mean = self.__mean.estimate_statistic(func, jac, hess)\n    std = self.__standard_deviation.estimate_statistic(func, jac, hess)\n    return mean + self.__factor * std\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/mean/","title":"Mean","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/mean/#gemseo_umdo.formulations._statistics.taylor_polynomial.mean","title":"mean","text":"<p>Estimator of the expectation for U-MDO formulations based on Taylor polynomials.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/mean/#gemseo_umdo.formulations._statistics.taylor_polynomial.mean-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/mean/#gemseo_umdo.formulations._statistics.taylor_polynomial.mean.Mean","title":"Mean","text":"<pre><code>Mean(uncertain_space: ParameterSpace)\n</code></pre> <p>               Bases: <code>BaseTaylorPolynomialEstimator</code></p> <p>Estimator of the expectation.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain variables with their probability distributions.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/taylor_polynomial/base_taylor_polynomial_estimator.py</code> <pre><code>def __init__(self, uncertain_space: ParameterSpace) -&gt; None:\n    \"\"\"\n    Args:\n        uncertain_space: The uncertain variables\n            with their probability distributions.\n    \"\"\"  # noqa: D205 D212 D415\n    self._standard_deviations = uncertain_space.distribution.standard_deviation\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/mean/#gemseo_umdo.formulations._statistics.taylor_polynomial.mean.Mean-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/mean/#gemseo_umdo.formulations._statistics.taylor_polynomial.mean.Mean.compute_jacobian","title":"compute_jacobian","text":"<pre><code>compute_jacobian(*args: Any, **kwargs: Any) -&gt; RealArray\n</code></pre> <p>Compute the Jacobian of the statistic estimation.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>               (<code>Any</code>, default:                   <code>()</code> )           \u2013            <p>The mandatory arguments.</p> </li> <li> <code>**kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The optional arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The Jacobian of the statistic estimation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/base_statistic_estimator.py</code> <pre><code>def compute_jacobian(self, *args: Any, **kwargs: Any) -&gt; RealArray:  # noqa: D102\n    \"\"\"Compute the Jacobian of the statistic estimation.\n\n    Args:\n        *args: The mandatory arguments.\n        **kwargs: The optional arguments.\n\n    Returns:\n        The Jacobian of the statistic estimation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/mean/#gemseo_umdo.formulations._statistics.taylor_polynomial.mean.Mean.estimate_statistic","title":"estimate_statistic","text":"<pre><code>estimate_statistic(\n    func: RealArray, jac: RealArray, hess: RealArray | None\n) -&gt; RealArray\n</code></pre> <p>Estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>func</code>               (<code>RealArray</code>)           \u2013            <p>The output value at the mean value of the uncertain variables.</p> </li> <li> <code>jac</code>               (<code>RealArray</code>)           \u2013            <p>The Jacobian value at the mean value of the uncertain variables.</p> </li> <li> <code>hess</code>               (<code>RealArray | None</code>)           \u2013            <p>The Hessian value at the mean value of the uncertain variables.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/taylor_polynomial/mean.py</code> <pre><code>def estimate_statistic(  # noqa: D102\n    self, func: RealArray, jac: RealArray, hess: RealArray | None\n) -&gt; RealArray:\n    if hess is None:\n        return func\n\n    std = self._standard_deviations\n    return func + 0.5 * array([\n        multi_dot([std, sub_hess, std]) for sub_hess in hess\n    ])\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/standard_deviation/","title":"Standard deviation","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/standard_deviation/#gemseo_umdo.formulations._statistics.taylor_polynomial.standard_deviation","title":"standard_deviation","text":"<p>Estimator of the standard deviation for U-MDO formulations based on Taylor.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/standard_deviation/#gemseo_umdo.formulations._statistics.taylor_polynomial.standard_deviation-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/standard_deviation/#gemseo_umdo.formulations._statistics.taylor_polynomial.standard_deviation.StandardDeviation","title":"StandardDeviation","text":"<pre><code>StandardDeviation(uncertain_space: ParameterSpace)\n</code></pre> <p>               Bases: <code>Variance</code></p> <p>Estimator of the standard deviation.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain variables with their probability distributions.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/taylor_polynomial/base_taylor_polynomial_estimator.py</code> <pre><code>def __init__(self, uncertain_space: ParameterSpace) -&gt; None:\n    \"\"\"\n    Args:\n        uncertain_space: The uncertain variables\n            with their probability distributions.\n    \"\"\"  # noqa: D205 D212 D415\n    self._standard_deviations = uncertain_space.distribution.standard_deviation\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/standard_deviation/#gemseo_umdo.formulations._statistics.taylor_polynomial.standard_deviation.StandardDeviation-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/standard_deviation/#gemseo_umdo.formulations._statistics.taylor_polynomial.standard_deviation.StandardDeviation.compute_jacobian","title":"compute_jacobian","text":"<pre><code>compute_jacobian(*args: Any, **kwargs: Any) -&gt; RealArray\n</code></pre> <p>Compute the Jacobian of the statistic estimation.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>               (<code>Any</code>, default:                   <code>()</code> )           \u2013            <p>The mandatory arguments.</p> </li> <li> <code>**kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The optional arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The Jacobian of the statistic estimation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/base_statistic_estimator.py</code> <pre><code>def compute_jacobian(self, *args: Any, **kwargs: Any) -&gt; RealArray:  # noqa: D102\n    \"\"\"Compute the Jacobian of the statistic estimation.\n\n    Args:\n        *args: The mandatory arguments.\n        **kwargs: The optional arguments.\n\n    Returns:\n        The Jacobian of the statistic estimation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/standard_deviation/#gemseo_umdo.formulations._statistics.taylor_polynomial.standard_deviation.StandardDeviation.estimate_statistic","title":"estimate_statistic","text":"<pre><code>estimate_statistic(\n    func: RealArray, jac: RealArray, hess: RealArray\n) -&gt; RealArray\n</code></pre> <p>Estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>func</code>               (<code>RealArray</code>)           \u2013            <p>The output value at the mean value of the uncertain variables.</p> </li> <li> <code>jac</code>               (<code>RealArray</code>)           \u2013            <p>The Jacobian value at the mean value of the uncertain variables.</p> </li> <li> <code>hess</code>               (<code>RealArray</code>)           \u2013            <p>The Hessian value at the mean value of the uncertain variables.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/taylor_polynomial/standard_deviation.py</code> <pre><code>def estimate_statistic(\n    self, func: RealArray, jac: RealArray, hess: RealArray\n) -&gt; RealArray:\n    \"\"\"\n    Args:\n        func: The output value at the mean value of the uncertain variables.\n        jac: The Jacobian value at the mean value of the uncertain variables.\n        hess: The Hessian value at the mean value of the uncertain variables.\n    \"\"\"  # noqa: D205 D212 D415\n    return super().estimate_statistic(func, jac, hess) ** 0.5\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/variance/","title":"Variance","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/variance/#gemseo_umdo.formulations._statistics.taylor_polynomial.variance","title":"variance","text":"<p>Estimator of the variance for U-MDO formulations based on Taylor polynomials.</p>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/variance/#gemseo_umdo.formulations._statistics.taylor_polynomial.variance-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/variance/#gemseo_umdo.formulations._statistics.taylor_polynomial.variance.Variance","title":"Variance","text":"<pre><code>Variance(uncertain_space: ParameterSpace)\n</code></pre> <p>               Bases: <code>BaseTaylorPolynomialEstimator</code></p> <p>Estimator of the variance.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain variables with their probability distributions.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/taylor_polynomial/base_taylor_polynomial_estimator.py</code> <pre><code>def __init__(self, uncertain_space: ParameterSpace) -&gt; None:\n    \"\"\"\n    Args:\n        uncertain_space: The uncertain variables\n            with their probability distributions.\n    \"\"\"  # noqa: D205 D212 D415\n    self._standard_deviations = uncertain_space.distribution.standard_deviation\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/variance/#gemseo_umdo.formulations._statistics.taylor_polynomial.variance.Variance-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/variance/#gemseo_umdo.formulations._statistics.taylor_polynomial.variance.Variance.compute_jacobian","title":"compute_jacobian","text":"<pre><code>compute_jacobian(*args: Any, **kwargs: Any) -&gt; RealArray\n</code></pre> <p>Compute the Jacobian of the statistic estimation.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>               (<code>Any</code>, default:                   <code>()</code> )           \u2013            <p>The mandatory arguments.</p> </li> <li> <code>**kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The optional arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The Jacobian of the statistic estimation.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/base_statistic_estimator.py</code> <pre><code>def compute_jacobian(self, *args: Any, **kwargs: Any) -&gt; RealArray:  # noqa: D102\n    \"\"\"Compute the Jacobian of the statistic estimation.\n\n    Args:\n        *args: The mandatory arguments.\n        **kwargs: The optional arguments.\n\n    Returns:\n        The Jacobian of the statistic estimation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/gemseo_umdo/formulations/_statistics/taylor_polynomial/variance/#gemseo_umdo.formulations._statistics.taylor_polynomial.variance.Variance.estimate_statistic","title":"estimate_statistic","text":"<pre><code>estimate_statistic(\n    func: RealArray, jac: RealArray, hess: RealArray\n) -&gt; RealArray\n</code></pre> <p>Estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>func</code>               (<code>RealArray</code>)           \u2013            <p>The output value at the mean value of the uncertain variables.</p> </li> <li> <code>jac</code>               (<code>RealArray</code>)           \u2013            <p>The Jacobian value at the mean value of the uncertain variables.</p> </li> <li> <code>hess</code>               (<code>RealArray</code>)           \u2013            <p>The Hessian value at the mean value of the uncertain variables.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RealArray</code>           \u2013            <p>The estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/formulations/_statistics/taylor_polynomial/variance.py</code> <pre><code>def estimate_statistic(\n    self, func: RealArray, jac: RealArray, hess: RealArray\n) -&gt; RealArray:\n    \"\"\"\n    Args:\n        func: The output value at the mean value of the uncertain variables.\n        jac: The Jacobian value at the mean value of the uncertain variables.\n        hess: The Hessian value at the mean value of the uncertain variables.\n    \"\"\"  # noqa: D205 D212 D415\n    return diagonal(multi_dot([jac, diag(self._standard_deviations**2), jac.T]))\n</code></pre>"},{"location":"reference/gemseo_umdo/scenarios/","title":"Scenarios","text":""},{"location":"reference/gemseo_umdo/scenarios/#gemseo_umdo.scenarios","title":"scenarios","text":"<p>Scenarios to address multidisciplinary design problems under uncertainty.</p>"},{"location":"reference/gemseo_umdo/scenarios/base_u_scenario/","title":"Base u scenario","text":""},{"location":"reference/gemseo_umdo/scenarios/base_u_scenario/#gemseo_umdo.scenarios.base_u_scenario","title":"base_u_scenario","text":"<p>Scenarios to address multidisciplinary design problems under uncertainty.</p>"},{"location":"reference/gemseo_umdo/scenarios/base_u_scenario/#gemseo_umdo.scenarios.base_u_scenario-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/scenarios/base_u_scenario/#gemseo_umdo.scenarios.base_u_scenario.BaseUScenario","title":"BaseUScenario","text":"<pre><code>BaseUScenario(\n    disciplines: Sequence[Discipline],\n    objective_name: str,\n    design_space: DesignSpace,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    objective_statistic_parameters: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    statistic_estimation: str = \"Sampling\",\n    statistic_estimation_parameters: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    uncertain_design_variables: Mapping[\n        str, str | tuple[str, str]\n    ] = READ_ONLY_EMPTY_DICT,\n    name: str = \"\",\n    formulation_settings_model: (\n        BaseFormulationSettings | None\n    ) = None,\n    maximize_objective: bool = False,\n    **formulation_settings: Any\n)\n</code></pre> <p>Base scenario for multidisciplinary design problems under uncertainty.</p> <p>Parameters:</p> <ul> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain variables with their probability distributions.</p> </li> <li> <code>objective_statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the objective, e.g. \"margin\".</p> </li> <li> <code>objective_statistic_parameters</code>               (<code>StrKeyMapping</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The parameters of the statistics to be applied to the objective, e.g. <code>{\"factor\": 2.}</code> when <code>objective_statistic=\"margin\"</code>.</p> </li> <li> <code>statistic_estimation</code>               (<code>str</code>, default:                   <code>'Sampling'</code> )           \u2013            <p>The name of the method to estimate the statistic.</p> </li> <li> <code>statistic_estimation_parameters</code>               (<code>StrKeyMapping</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The options of <code>statistic_estimation</code>.</p> </li> <li> <code>uncertain_design_variables</code>               (<code>Mapping[str, str | tuple[str, str]]</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>This argument facilitates the definition of uncertain design variables in two ways. The first way consists of passing a dictionary of the form <code>{\"x1\": (\"+\", \"u1\"), \"x2\": (\"*\", \"u2\"), ...}</code> which defines the uncertain design variables as <code>x1 = dv_x1 + u1</code> and <code>x2 = dv_x2 * (1 + u2)</code>. Here <code>\"x1\"</code> and <code>\"x2\"</code> are the names of the design variables made uncertain by the random variables <code>\"u_1\"</code> and <code>\"u_2\"</code> which typically have zero mean. <code>\"x1\"</code> and <code>\"x2\"</code> are the names of the design variables actually used in <code>disciplines</code> while the names <code>\"dv_x1\"</code> and <code>dv_x2</code> are generated by the scenario. More generally, the first element of the tuple is assumed to be either the class name or the SHORT_NAME of a BaseNoiser (feel free to create new noising disciplines). The second way of defining these uncertain design variables consists of passing a set of more complex expressions of the form <code>{\"x\": \"{} + u\", ...}</code> where <code>\"x\"</code> is the name of the design variable actually used in the equations, <code>\"u\"</code> is the name of the uncertain variable defined in the <code>uncertain_space</code> and <code>\"{}\"</code> is the optimization variable. Leave <code>\"{}\"</code> as is; it will be automatically replaced by <code>\"dv_x\"</code>. This more complex format assumes variables of dimension 1. If <code>None</code>, do not consider other variable relations than those defined by <code>disciplines</code>.</p> </li> <li> <code>maximize_objective</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to maximize the statistic of the objective.</p> </li> </ul> Source code in <code>src/gemseo_umdo/scenarios/base_u_scenario.py</code> <pre><code>def __init__(\n    self,\n    disciplines: Sequence[Discipline],\n    objective_name: str,\n    design_space: DesignSpace,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    objective_statistic_parameters: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    statistic_estimation: str = \"Sampling\",\n    statistic_estimation_parameters: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    uncertain_design_variables: Mapping[\n        str, str | tuple[str, str]\n    ] = READ_ONLY_EMPTY_DICT,\n    name: str = \"\",\n    formulation_settings_model: BaseFormulationSettings | None = None,\n    maximize_objective: bool = False,\n    **formulation_settings: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        uncertain_space: The uncertain variables\n            with their probability distributions.\n        objective_statistic_name: The name of the statistic\n            to be applied to the objective, e.g. \"margin\".\n        objective_statistic_parameters: The parameters of the statistics\n            to be applied to the objective,\n            e.g. `{\"factor\": 2.}` when `objective_statistic=\"margin\"`.\n        statistic_estimation: The name of the method to estimate the statistic.\n        statistic_estimation_parameters: The options of `statistic_estimation`.\n        uncertain_design_variables: This argument facilitates\n            the definition of uncertain design variables in two ways.\n            The first way consists of passing a dictionary\n            of the form `{\"x1\": (\"+\", \"u1\"), \"x2\": (\"*\", \"u2\"), ...}`\n            which defines the uncertain design variables as\n            `x1 = dv_x1 + u1` and `x2 = dv_x2 * (1 + u2)`.\n            Here `\"x1\"` and `\"x2\"` are the names of the design variables\n            made uncertain by the random variables `\"u_1\"` and `\"u_2\"`\n            which typically have zero mean.\n            `\"x1\"` and `\"x2\"` are the names of the design variables\n            actually used in `disciplines`\n            while the names `\"dv_x1\"` and `dv_x2` are generated by the scenario.\n            More generally,\n            the first element of the tuple is assumed\n            to be either the class name or the\n            [SHORT_NAME][gemseo_umdo.disciplines.base_noiser.BaseNoiser.SHORT_NAME]\n            of a\n            [BaseNoiser][gemseo_umdo.disciplines.base_noiser.BaseNoiser]\n            (feel free to create new noising disciplines).\n            The second way of defining these uncertain design variables\n            consists of passing a set of more complex expressions\n            of the form `{\"x\": \"{} + u\", ...}`\n            where `\"x\"` is the name of the design variable\n            actually used in the equations,\n            `\"u\"` is the name of the uncertain variable\n            defined in the `uncertain_space`\n            and `\"{}\"` is the optimization variable.\n            Leave `\"{}\"` as is; it will be automatically replaced by `\"dv_x\"`.\n            This more complex format assumes variables of dimension 1.\n            If `None`,\n            do not consider other variable relations\n            than those defined by `disciplines`.\n        maximize_objective: Whether to maximize the statistic of the objective.\n    \"\"\"  # noqa: D205 D212 D415\n    disciplines = list(disciplines)\n    if uncertain_design_variables:\n        self.__add_noising_discipline_chain(\n            disciplines, design_space, uncertain_design_variables\n        )\n\n    formulation_name = formulation_settings.pop(\"formulation_name\")\n    mdo_formulation_class = MDOFormulationFactory().get_class(formulation_name)\n\n    # Create the design space associated with the optimization problem\n    # generated by the MDO formulation\n    mdo_formulation_design_space = mdo_formulation_class(\n        disciplines,\n        objective_name,\n        design_space,\n        settings_model=formulation_settings_model,\n        **formulation_settings,\n    ).design_space\n\n    # Create the MDO formulation\n    # whose functions are evaluable over the uncertain space\n    # and differentiable with respect to the design variables.\n    mdo_formulation = mdo_formulation_class(\n        disciplines,\n        objective_name,\n        uncertain_space,\n        differentiated_input_names_substitute=mdo_formulation_design_space.variable_names,  # noqa:E501\n        **formulation_settings,\n    )\n\n    super().__init__(\n        disciplines,\n        objective_name,\n        mdo_formulation_design_space,\n        name=name,\n        formulation_name=statistic_estimation,\n        mdo_formulation=mdo_formulation,\n        objective_statistic_name=objective_statistic_name,\n        objective_statistic_parameters=objective_statistic_parameters,\n        uncertain_space=uncertain_space,\n        maximize_objective=maximize_objective,\n        mdo_formulation_settings=formulation_settings,\n        **statistic_estimation_parameters,\n    )\n\n    self.formulation_name = self.formulation.name\n</code></pre>"},{"location":"reference/gemseo_umdo/scenarios/base_u_scenario/#gemseo_umdo.scenarios.base_u_scenario.BaseUScenario-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/scenarios/base_u_scenario/#gemseo_umdo.scenarios.base_u_scenario.BaseUScenario.available_statistics","title":"available_statistics  <code>property</code>","text":"<pre><code>available_statistics: list[str]\n</code></pre> <p>The names of the available statistics.</p>"},{"location":"reference/gemseo_umdo/scenarios/base_u_scenario/#gemseo_umdo.scenarios.base_u_scenario.BaseUScenario.mdo_formulation","title":"mdo_formulation  <code>property</code>","text":"<pre><code>mdo_formulation: BaseMDOFormulation\n</code></pre> <p>The MDO formulation over the uncertain space.</p>"},{"location":"reference/gemseo_umdo/scenarios/base_u_scenario/#gemseo_umdo.scenarios.base_u_scenario.BaseUScenario.uncertain_space","title":"uncertain_space  <code>property</code>","text":"<pre><code>uncertain_space: ParameterSpace\n</code></pre> <p>The uncertain variable space.</p>"},{"location":"reference/gemseo_umdo/scenarios/base_u_scenario/#gemseo_umdo.scenarios.base_u_scenario.BaseUScenario-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/scenarios/base_u_scenario/#gemseo_umdo.scenarios.base_u_scenario.BaseUScenario.add_constraint","title":"add_constraint","text":"<pre><code>add_constraint(\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: ConstraintType = INEQ,\n    constraint_name: str = \"\",\n    value: float = 0,\n    positive: bool = False,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Parameters:</p> <ul> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the constraint, e.g. \"margin\".</p> </li> <li> <code>statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The parameters of the statistics to be applied to the constraint, <code>{\"factor\": 2.}</code> when <code>objective_statistic=\"margin\"</code>.</p> </li> </ul> Source code in <code>src/gemseo_umdo/scenarios/base_u_scenario.py</code> <pre><code>def add_constraint(\n    self,\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: MDOFunction.ConstraintType = MDOFunction.ConstraintType.INEQ,\n    constraint_name: str = \"\",\n    value: float = 0,\n    positive: bool = False,\n    **statistic_parameters: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        statistic_name: The name of the statistic\n            to be applied to the constraint, e.g. \"margin\".\n        statistic_parameters: The parameters of the statistics\n            to be applied to the constraint,\n            `{\"factor\": 2.}` when `objective_statistic=\"margin\"`.\n    \"\"\"  # noqa: D205 D212 D415\n    self.formulation.add_constraint(\n        output_name,\n        statistic_name,\n        constraint_type=constraint_type,\n        constraint_name=constraint_name,\n        value=value,\n        positive=positive,\n        **statistic_parameters,\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/scenarios/base_u_scenario/#gemseo_umdo.scenarios.base_u_scenario.BaseUScenario.add_observable","title":"add_observable","text":"<pre><code>add_observable(\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: str = \"\",\n    discipline: Discipline | None = None,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Parameters:</p> <ul> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the constraint, e.g. \"margin\".</p> </li> <li> <code>statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The parameters of the statistics to be applied to the constraint, <code>{\"factor\": 2.}</code> when <code>objective_statistic=\"margin\"</code>.</p> </li> </ul> Source code in <code>src/gemseo_umdo/scenarios/base_u_scenario.py</code> <pre><code>def add_observable(\n    self,\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: str = \"\",\n    discipline: Discipline | None = None,\n    **statistic_parameters: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        statistic_name: The name of the statistic\n            to be applied to the constraint, e.g. \"margin\".\n        statistic_parameters: The parameters of the statistics\n            to be applied to the constraint,\n            `{\"factor\": 2.}` when `objective_statistic=\"margin\"`.\n    \"\"\"  # noqa: D205 D212 D415\n    self.formulation.add_observable(\n        output_names,\n        statistic_name,\n        observable_name=observable_name,\n        discipline=discipline,\n        **statistic_parameters,\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/scenarios/udoe_scenario/","title":"Udoe scenario","text":""},{"location":"reference/gemseo_umdo/scenarios/udoe_scenario/#gemseo_umdo.scenarios.udoe_scenario","title":"udoe_scenario","text":"<p>Scenario for multidisciplinary design sampling problems under uncertainty.</p>"},{"location":"reference/gemseo_umdo/scenarios/udoe_scenario/#gemseo_umdo.scenarios.udoe_scenario-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/scenarios/udoe_scenario/#gemseo_umdo.scenarios.udoe_scenario.UDOEScenario","title":"UDOEScenario","text":"<pre><code>UDOEScenario(\n    disciplines: Sequence[Discipline],\n    objective_name: str,\n    design_space: DesignSpace,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    objective_statistic_parameters: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    statistic_estimation: str = \"Sampling\",\n    statistic_estimation_parameters: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    uncertain_design_variables: Mapping[\n        str, str | tuple[str, str]\n    ] = READ_ONLY_EMPTY_DICT,\n    name: str = \"\",\n    formulation_settings_model: (\n        BaseFormulationSettings | None\n    ) = None,\n    maximize_objective: bool = False,\n    **formulation_settings: Any\n)\n</code></pre> <p>               Bases: <code>BaseUScenario</code>, <code>DOEScenario</code></p> <p>A DOE-based scenario for multidisciplinary design under uncertainty.</p> <p>Parameters:</p> <ul> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain variables with their probability distributions.</p> </li> <li> <code>objective_statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the objective, e.g. \"margin\".</p> </li> <li> <code>objective_statistic_parameters</code>               (<code>StrKeyMapping</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The parameters of the statistics to be applied to the objective, e.g. <code>{\"factor\": 2.}</code> when <code>objective_statistic=\"margin\"</code>.</p> </li> <li> <code>statistic_estimation</code>               (<code>str</code>, default:                   <code>'Sampling'</code> )           \u2013            <p>The name of the method to estimate the statistic.</p> </li> <li> <code>statistic_estimation_parameters</code>               (<code>StrKeyMapping</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The options of <code>statistic_estimation</code>.</p> </li> <li> <code>uncertain_design_variables</code>               (<code>Mapping[str, str | tuple[str, str]]</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>This argument facilitates the definition of uncertain design variables in two ways. The first way consists of passing a dictionary of the form <code>{\"x1\": (\"+\", \"u1\"), \"x2\": (\"*\", \"u2\"), ...}</code> which defines the uncertain design variables as <code>x1 = dv_x1 + u1</code> and <code>x2 = dv_x2 * (1 + u2)</code>. Here <code>\"x1\"</code> and <code>\"x2\"</code> are the names of the design variables made uncertain by the random variables <code>\"u_1\"</code> and <code>\"u_2\"</code> which typically have zero mean. <code>\"x1\"</code> and <code>\"x2\"</code> are the names of the design variables actually used in <code>disciplines</code> while the names <code>\"dv_x1\"</code> and <code>dv_x2</code> are generated by the scenario. More generally, the first element of the tuple is assumed to be either the class name or the SHORT_NAME of a BaseNoiser (feel free to create new noising disciplines). The second way of defining these uncertain design variables consists of passing a set of more complex expressions of the form <code>{\"x\": \"{} + u\", ...}</code> where <code>\"x\"</code> is the name of the design variable actually used in the equations, <code>\"u\"</code> is the name of the uncertain variable defined in the <code>uncertain_space</code> and <code>\"{}\"</code> is the optimization variable. Leave <code>\"{}\"</code> as is; it will be automatically replaced by <code>\"dv_x\"</code>. This more complex format assumes variables of dimension 1. If <code>None</code>, do not consider other variable relations than those defined by <code>disciplines</code>.</p> </li> <li> <code>maximize_objective</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to maximize the statistic of the objective.</p> </li> </ul> Source code in <code>src/gemseo_umdo/scenarios/base_u_scenario.py</code> <pre><code>def __init__(\n    self,\n    disciplines: Sequence[Discipline],\n    objective_name: str,\n    design_space: DesignSpace,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    objective_statistic_parameters: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    statistic_estimation: str = \"Sampling\",\n    statistic_estimation_parameters: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    uncertain_design_variables: Mapping[\n        str, str | tuple[str, str]\n    ] = READ_ONLY_EMPTY_DICT,\n    name: str = \"\",\n    formulation_settings_model: BaseFormulationSettings | None = None,\n    maximize_objective: bool = False,\n    **formulation_settings: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        uncertain_space: The uncertain variables\n            with their probability distributions.\n        objective_statistic_name: The name of the statistic\n            to be applied to the objective, e.g. \"margin\".\n        objective_statistic_parameters: The parameters of the statistics\n            to be applied to the objective,\n            e.g. `{\"factor\": 2.}` when `objective_statistic=\"margin\"`.\n        statistic_estimation: The name of the method to estimate the statistic.\n        statistic_estimation_parameters: The options of `statistic_estimation`.\n        uncertain_design_variables: This argument facilitates\n            the definition of uncertain design variables in two ways.\n            The first way consists of passing a dictionary\n            of the form `{\"x1\": (\"+\", \"u1\"), \"x2\": (\"*\", \"u2\"), ...}`\n            which defines the uncertain design variables as\n            `x1 = dv_x1 + u1` and `x2 = dv_x2 * (1 + u2)`.\n            Here `\"x1\"` and `\"x2\"` are the names of the design variables\n            made uncertain by the random variables `\"u_1\"` and `\"u_2\"`\n            which typically have zero mean.\n            `\"x1\"` and `\"x2\"` are the names of the design variables\n            actually used in `disciplines`\n            while the names `\"dv_x1\"` and `dv_x2` are generated by the scenario.\n            More generally,\n            the first element of the tuple is assumed\n            to be either the class name or the\n            [SHORT_NAME][gemseo_umdo.disciplines.base_noiser.BaseNoiser.SHORT_NAME]\n            of a\n            [BaseNoiser][gemseo_umdo.disciplines.base_noiser.BaseNoiser]\n            (feel free to create new noising disciplines).\n            The second way of defining these uncertain design variables\n            consists of passing a set of more complex expressions\n            of the form `{\"x\": \"{} + u\", ...}`\n            where `\"x\"` is the name of the design variable\n            actually used in the equations,\n            `\"u\"` is the name of the uncertain variable\n            defined in the `uncertain_space`\n            and `\"{}\"` is the optimization variable.\n            Leave `\"{}\"` as is; it will be automatically replaced by `\"dv_x\"`.\n            This more complex format assumes variables of dimension 1.\n            If `None`,\n            do not consider other variable relations\n            than those defined by `disciplines`.\n        maximize_objective: Whether to maximize the statistic of the objective.\n    \"\"\"  # noqa: D205 D212 D415\n    disciplines = list(disciplines)\n    if uncertain_design_variables:\n        self.__add_noising_discipline_chain(\n            disciplines, design_space, uncertain_design_variables\n        )\n\n    formulation_name = formulation_settings.pop(\"formulation_name\")\n    mdo_formulation_class = MDOFormulationFactory().get_class(formulation_name)\n\n    # Create the design space associated with the optimization problem\n    # generated by the MDO formulation\n    mdo_formulation_design_space = mdo_formulation_class(\n        disciplines,\n        objective_name,\n        design_space,\n        settings_model=formulation_settings_model,\n        **formulation_settings,\n    ).design_space\n\n    # Create the MDO formulation\n    # whose functions are evaluable over the uncertain space\n    # and differentiable with respect to the design variables.\n    mdo_formulation = mdo_formulation_class(\n        disciplines,\n        objective_name,\n        uncertain_space,\n        differentiated_input_names_substitute=mdo_formulation_design_space.variable_names,  # noqa:E501\n        **formulation_settings,\n    )\n\n    super().__init__(\n        disciplines,\n        objective_name,\n        mdo_formulation_design_space,\n        name=name,\n        formulation_name=statistic_estimation,\n        mdo_formulation=mdo_formulation,\n        objective_statistic_name=objective_statistic_name,\n        objective_statistic_parameters=objective_statistic_parameters,\n        uncertain_space=uncertain_space,\n        maximize_objective=maximize_objective,\n        mdo_formulation_settings=formulation_settings,\n        **statistic_estimation_parameters,\n    )\n\n    self.formulation_name = self.formulation.name\n</code></pre>"},{"location":"reference/gemseo_umdo/scenarios/udoe_scenario/#gemseo_umdo.scenarios.udoe_scenario.UDOEScenario-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/scenarios/udoe_scenario/#gemseo_umdo.scenarios.udoe_scenario.UDOEScenario.available_statistics","title":"available_statistics  <code>property</code>","text":"<pre><code>available_statistics: list[str]\n</code></pre> <p>The names of the available statistics.</p>"},{"location":"reference/gemseo_umdo/scenarios/udoe_scenario/#gemseo_umdo.scenarios.udoe_scenario.UDOEScenario.mdo_formulation","title":"mdo_formulation  <code>property</code>","text":"<pre><code>mdo_formulation: BaseMDOFormulation\n</code></pre> <p>The MDO formulation over the uncertain space.</p>"},{"location":"reference/gemseo_umdo/scenarios/udoe_scenario/#gemseo_umdo.scenarios.udoe_scenario.UDOEScenario.uncertain_space","title":"uncertain_space  <code>property</code>","text":"<pre><code>uncertain_space: ParameterSpace\n</code></pre> <p>The uncertain variable space.</p>"},{"location":"reference/gemseo_umdo/scenarios/udoe_scenario/#gemseo_umdo.scenarios.udoe_scenario.UDOEScenario-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/scenarios/udoe_scenario/#gemseo_umdo.scenarios.udoe_scenario.UDOEScenario.add_constraint","title":"add_constraint","text":"<pre><code>add_constraint(\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: ConstraintType = INEQ,\n    constraint_name: str = \"\",\n    value: float = 0,\n    positive: bool = False,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Parameters:</p> <ul> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the constraint, e.g. \"margin\".</p> </li> <li> <code>statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The parameters of the statistics to be applied to the constraint, <code>{\"factor\": 2.}</code> when <code>objective_statistic=\"margin\"</code>.</p> </li> </ul> Source code in <code>src/gemseo_umdo/scenarios/base_u_scenario.py</code> <pre><code>def add_constraint(\n    self,\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: MDOFunction.ConstraintType = MDOFunction.ConstraintType.INEQ,\n    constraint_name: str = \"\",\n    value: float = 0,\n    positive: bool = False,\n    **statistic_parameters: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        statistic_name: The name of the statistic\n            to be applied to the constraint, e.g. \"margin\".\n        statistic_parameters: The parameters of the statistics\n            to be applied to the constraint,\n            `{\"factor\": 2.}` when `objective_statistic=\"margin\"`.\n    \"\"\"  # noqa: D205 D212 D415\n    self.formulation.add_constraint(\n        output_name,\n        statistic_name,\n        constraint_type=constraint_type,\n        constraint_name=constraint_name,\n        value=value,\n        positive=positive,\n        **statistic_parameters,\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/scenarios/udoe_scenario/#gemseo_umdo.scenarios.udoe_scenario.UDOEScenario.add_observable","title":"add_observable","text":"<pre><code>add_observable(\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: str = \"\",\n    discipline: Discipline | None = None,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Parameters:</p> <ul> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the constraint, e.g. \"margin\".</p> </li> <li> <code>statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The parameters of the statistics to be applied to the constraint, <code>{\"factor\": 2.}</code> when <code>objective_statistic=\"margin\"</code>.</p> </li> </ul> Source code in <code>src/gemseo_umdo/scenarios/base_u_scenario.py</code> <pre><code>def add_observable(\n    self,\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: str = \"\",\n    discipline: Discipline | None = None,\n    **statistic_parameters: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        statistic_name: The name of the statistic\n            to be applied to the constraint, e.g. \"margin\".\n        statistic_parameters: The parameters of the statistics\n            to be applied to the constraint,\n            `{\"factor\": 2.}` when `objective_statistic=\"margin\"`.\n    \"\"\"  # noqa: D205 D212 D415\n    self.formulation.add_observable(\n        output_names,\n        statistic_name,\n        observable_name=observable_name,\n        discipline=discipline,\n        **statistic_parameters,\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/scenarios/umdo_scenario/","title":"Umdo scenario","text":""},{"location":"reference/gemseo_umdo/scenarios/umdo_scenario/#gemseo_umdo.scenarios.umdo_scenario","title":"umdo_scenario","text":"<p>Scenario for multidisciplinary design optimization problems under uncertainty.</p>"},{"location":"reference/gemseo_umdo/scenarios/umdo_scenario/#gemseo_umdo.scenarios.umdo_scenario-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/scenarios/umdo_scenario/#gemseo_umdo.scenarios.umdo_scenario.UMDOScenario","title":"UMDOScenario","text":"<pre><code>UMDOScenario(\n    disciplines: Sequence[Discipline],\n    objective_name: str,\n    design_space: DesignSpace,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    objective_statistic_parameters: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    statistic_estimation: str = \"Sampling\",\n    statistic_estimation_parameters: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    uncertain_design_variables: Mapping[\n        str, str | tuple[str, str]\n    ] = READ_ONLY_EMPTY_DICT,\n    name: str = \"\",\n    formulation_settings_model: (\n        BaseFormulationSettings | None\n    ) = None,\n    maximize_objective: bool = False,\n    **formulation_settings: Any\n)\n</code></pre> <p>               Bases: <code>BaseUScenario</code>, <code>MDOScenario</code></p> <p>An optimizer-based scenario for multidisciplinary design under uncertainty.</p> <p>Parameters:</p> <ul> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain variables with their probability distributions.</p> </li> <li> <code>objective_statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the objective, e.g. \"margin\".</p> </li> <li> <code>objective_statistic_parameters</code>               (<code>StrKeyMapping</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The parameters of the statistics to be applied to the objective, e.g. <code>{\"factor\": 2.}</code> when <code>objective_statistic=\"margin\"</code>.</p> </li> <li> <code>statistic_estimation</code>               (<code>str</code>, default:                   <code>'Sampling'</code> )           \u2013            <p>The name of the method to estimate the statistic.</p> </li> <li> <code>statistic_estimation_parameters</code>               (<code>StrKeyMapping</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>The options of <code>statistic_estimation</code>.</p> </li> <li> <code>uncertain_design_variables</code>               (<code>Mapping[str, str | tuple[str, str]]</code>, default:                   <code>READ_ONLY_EMPTY_DICT</code> )           \u2013            <p>This argument facilitates the definition of uncertain design variables in two ways. The first way consists of passing a dictionary of the form <code>{\"x1\": (\"+\", \"u1\"), \"x2\": (\"*\", \"u2\"), ...}</code> which defines the uncertain design variables as <code>x1 = dv_x1 + u1</code> and <code>x2 = dv_x2 * (1 + u2)</code>. Here <code>\"x1\"</code> and <code>\"x2\"</code> are the names of the design variables made uncertain by the random variables <code>\"u_1\"</code> and <code>\"u_2\"</code> which typically have zero mean. <code>\"x1\"</code> and <code>\"x2\"</code> are the names of the design variables actually used in <code>disciplines</code> while the names <code>\"dv_x1\"</code> and <code>dv_x2</code> are generated by the scenario. More generally, the first element of the tuple is assumed to be either the class name or the SHORT_NAME of a BaseNoiser (feel free to create new noising disciplines). The second way of defining these uncertain design variables consists of passing a set of more complex expressions of the form <code>{\"x\": \"{} + u\", ...}</code> where <code>\"x\"</code> is the name of the design variable actually used in the equations, <code>\"u\"</code> is the name of the uncertain variable defined in the <code>uncertain_space</code> and <code>\"{}\"</code> is the optimization variable. Leave <code>\"{}\"</code> as is; it will be automatically replaced by <code>\"dv_x\"</code>. This more complex format assumes variables of dimension 1. If <code>None</code>, do not consider other variable relations than those defined by <code>disciplines</code>.</p> </li> <li> <code>maximize_objective</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to maximize the statistic of the objective.</p> </li> </ul> Source code in <code>src/gemseo_umdo/scenarios/base_u_scenario.py</code> <pre><code>def __init__(\n    self,\n    disciplines: Sequence[Discipline],\n    objective_name: str,\n    design_space: DesignSpace,\n    uncertain_space: ParameterSpace,\n    objective_statistic_name: str,\n    objective_statistic_parameters: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    statistic_estimation: str = \"Sampling\",\n    statistic_estimation_parameters: StrKeyMapping = READ_ONLY_EMPTY_DICT,\n    uncertain_design_variables: Mapping[\n        str, str | tuple[str, str]\n    ] = READ_ONLY_EMPTY_DICT,\n    name: str = \"\",\n    formulation_settings_model: BaseFormulationSettings | None = None,\n    maximize_objective: bool = False,\n    **formulation_settings: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        uncertain_space: The uncertain variables\n            with their probability distributions.\n        objective_statistic_name: The name of the statistic\n            to be applied to the objective, e.g. \"margin\".\n        objective_statistic_parameters: The parameters of the statistics\n            to be applied to the objective,\n            e.g. `{\"factor\": 2.}` when `objective_statistic=\"margin\"`.\n        statistic_estimation: The name of the method to estimate the statistic.\n        statistic_estimation_parameters: The options of `statistic_estimation`.\n        uncertain_design_variables: This argument facilitates\n            the definition of uncertain design variables in two ways.\n            The first way consists of passing a dictionary\n            of the form `{\"x1\": (\"+\", \"u1\"), \"x2\": (\"*\", \"u2\"), ...}`\n            which defines the uncertain design variables as\n            `x1 = dv_x1 + u1` and `x2 = dv_x2 * (1 + u2)`.\n            Here `\"x1\"` and `\"x2\"` are the names of the design variables\n            made uncertain by the random variables `\"u_1\"` and `\"u_2\"`\n            which typically have zero mean.\n            `\"x1\"` and `\"x2\"` are the names of the design variables\n            actually used in `disciplines`\n            while the names `\"dv_x1\"` and `dv_x2` are generated by the scenario.\n            More generally,\n            the first element of the tuple is assumed\n            to be either the class name or the\n            [SHORT_NAME][gemseo_umdo.disciplines.base_noiser.BaseNoiser.SHORT_NAME]\n            of a\n            [BaseNoiser][gemseo_umdo.disciplines.base_noiser.BaseNoiser]\n            (feel free to create new noising disciplines).\n            The second way of defining these uncertain design variables\n            consists of passing a set of more complex expressions\n            of the form `{\"x\": \"{} + u\", ...}`\n            where `\"x\"` is the name of the design variable\n            actually used in the equations,\n            `\"u\"` is the name of the uncertain variable\n            defined in the `uncertain_space`\n            and `\"{}\"` is the optimization variable.\n            Leave `\"{}\"` as is; it will be automatically replaced by `\"dv_x\"`.\n            This more complex format assumes variables of dimension 1.\n            If `None`,\n            do not consider other variable relations\n            than those defined by `disciplines`.\n        maximize_objective: Whether to maximize the statistic of the objective.\n    \"\"\"  # noqa: D205 D212 D415\n    disciplines = list(disciplines)\n    if uncertain_design_variables:\n        self.__add_noising_discipline_chain(\n            disciplines, design_space, uncertain_design_variables\n        )\n\n    formulation_name = formulation_settings.pop(\"formulation_name\")\n    mdo_formulation_class = MDOFormulationFactory().get_class(formulation_name)\n\n    # Create the design space associated with the optimization problem\n    # generated by the MDO formulation\n    mdo_formulation_design_space = mdo_formulation_class(\n        disciplines,\n        objective_name,\n        design_space,\n        settings_model=formulation_settings_model,\n        **formulation_settings,\n    ).design_space\n\n    # Create the MDO formulation\n    # whose functions are evaluable over the uncertain space\n    # and differentiable with respect to the design variables.\n    mdo_formulation = mdo_formulation_class(\n        disciplines,\n        objective_name,\n        uncertain_space,\n        differentiated_input_names_substitute=mdo_formulation_design_space.variable_names,  # noqa:E501\n        **formulation_settings,\n    )\n\n    super().__init__(\n        disciplines,\n        objective_name,\n        mdo_formulation_design_space,\n        name=name,\n        formulation_name=statistic_estimation,\n        mdo_formulation=mdo_formulation,\n        objective_statistic_name=objective_statistic_name,\n        objective_statistic_parameters=objective_statistic_parameters,\n        uncertain_space=uncertain_space,\n        maximize_objective=maximize_objective,\n        mdo_formulation_settings=formulation_settings,\n        **statistic_estimation_parameters,\n    )\n\n    self.formulation_name = self.formulation.name\n</code></pre>"},{"location":"reference/gemseo_umdo/scenarios/umdo_scenario/#gemseo_umdo.scenarios.umdo_scenario.UMDOScenario-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/scenarios/umdo_scenario/#gemseo_umdo.scenarios.umdo_scenario.UMDOScenario.available_statistics","title":"available_statistics  <code>property</code>","text":"<pre><code>available_statistics: list[str]\n</code></pre> <p>The names of the available statistics.</p>"},{"location":"reference/gemseo_umdo/scenarios/umdo_scenario/#gemseo_umdo.scenarios.umdo_scenario.UMDOScenario.mdo_formulation","title":"mdo_formulation  <code>property</code>","text":"<pre><code>mdo_formulation: BaseMDOFormulation\n</code></pre> <p>The MDO formulation over the uncertain space.</p>"},{"location":"reference/gemseo_umdo/scenarios/umdo_scenario/#gemseo_umdo.scenarios.umdo_scenario.UMDOScenario.uncertain_space","title":"uncertain_space  <code>property</code>","text":"<pre><code>uncertain_space: ParameterSpace\n</code></pre> <p>The uncertain variable space.</p>"},{"location":"reference/gemseo_umdo/scenarios/umdo_scenario/#gemseo_umdo.scenarios.umdo_scenario.UMDOScenario-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/scenarios/umdo_scenario/#gemseo_umdo.scenarios.umdo_scenario.UMDOScenario.add_constraint","title":"add_constraint","text":"<pre><code>add_constraint(\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: ConstraintType = INEQ,\n    constraint_name: str = \"\",\n    value: float = 0,\n    positive: bool = False,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Parameters:</p> <ul> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the constraint, e.g. \"margin\".</p> </li> <li> <code>statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The parameters of the statistics to be applied to the constraint, <code>{\"factor\": 2.}</code> when <code>objective_statistic=\"margin\"</code>.</p> </li> </ul> Source code in <code>src/gemseo_umdo/scenarios/base_u_scenario.py</code> <pre><code>def add_constraint(\n    self,\n    output_name: str | Sequence[str],\n    statistic_name: str,\n    constraint_type: MDOFunction.ConstraintType = MDOFunction.ConstraintType.INEQ,\n    constraint_name: str = \"\",\n    value: float = 0,\n    positive: bool = False,\n    **statistic_parameters: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        statistic_name: The name of the statistic\n            to be applied to the constraint, e.g. \"margin\".\n        statistic_parameters: The parameters of the statistics\n            to be applied to the constraint,\n            `{\"factor\": 2.}` when `objective_statistic=\"margin\"`.\n    \"\"\"  # noqa: D205 D212 D415\n    self.formulation.add_constraint(\n        output_name,\n        statistic_name,\n        constraint_type=constraint_type,\n        constraint_name=constraint_name,\n        value=value,\n        positive=positive,\n        **statistic_parameters,\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/scenarios/umdo_scenario/#gemseo_umdo.scenarios.umdo_scenario.UMDOScenario.add_observable","title":"add_observable","text":"<pre><code>add_observable(\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: str = \"\",\n    discipline: Discipline | None = None,\n    **statistic_parameters: Any\n) -&gt; None\n</code></pre> <p>Parameters:</p> <ul> <li> <code>statistic_name</code>               (<code>str</code>)           \u2013            <p>The name of the statistic to be applied to the constraint, e.g. \"margin\".</p> </li> <li> <code>statistic_parameters</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The parameters of the statistics to be applied to the constraint, <code>{\"factor\": 2.}</code> when <code>objective_statistic=\"margin\"</code>.</p> </li> </ul> Source code in <code>src/gemseo_umdo/scenarios/base_u_scenario.py</code> <pre><code>def add_observable(\n    self,\n    output_names: Sequence[str],\n    statistic_name: str,\n    observable_name: str = \"\",\n    discipline: Discipline | None = None,\n    **statistic_parameters: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        statistic_name: The name of the statistic\n            to be applied to the constraint, e.g. \"margin\".\n        statistic_parameters: The parameters of the statistics\n            to be applied to the constraint,\n            `{\"factor\": 2.}` when `objective_statistic=\"margin\"`.\n    \"\"\"  # noqa: D205 D212 D415\n    self.formulation.add_observable(\n        output_names,\n        statistic_name,\n        observable_name=observable_name,\n        discipline=discipline,\n        **statistic_parameters,\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/","title":"Statistics","text":""},{"location":"reference/gemseo_umdo/statistics/#gemseo_umdo.statistics","title":"statistics","text":"<p>Tools for the estimation of statistics.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/","title":"Multilevel","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/#gemseo_umdo.statistics.multilevel","title":"multilevel","text":"<p>Multilevel Monte Carlo (MLMC) algorithms.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/base_pilot/","title":"Base pilot","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/base_pilot/#gemseo_umdo.statistics.multilevel.base_pilot","title":"base_pilot","text":"<p>The base pilot for multilevel algorithms.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/base_pilot/#gemseo_umdo.statistics.multilevel.base_pilot-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/base_pilot/#gemseo_umdo.statistics.multilevel.base_pilot.BasePilot","title":"BasePilot","text":"<pre><code>BasePilot(\n    sampling_ratios: NDArray[float], costs: NDArray[float]\n)\n</code></pre> <p>The base pilot for multilevel algorithms.</p> <p>A pilot is associated with a statistic, e.g. mean. The method compute_next_level_and_statistic() returns a multilevel estimation of the statistic based on the current samples and the next level \\(\\ell^*\\) of the telescopic sum to sample in order to improve this estimation.</p> <p>This level \\(\\ell^*\\) maximizes the criterion</p> \\[\\frac{\\mathcal{V}_\\ell} {r_\\ell n_\\ell^2(\\mathcal{C}_\\ell+\\mathcal{C}_{\\ell-1})}\\] <p>where \\(\\mathcal{C}_{\\ell}\\) is the unit evaluation cost of the model \\(f_\\ell\\) (with \\(\\mathcal{C}_{-1}=0\\)), \\(n_\\ell\\) is the current number of evaluations of \\(f_\\ell\\) and \\(r_\\ell\\) is the factor by which \\(n_\\ell\\) would be increased by choosing the level \\(\\ell\\). Regarding \\(\\mathcal{V}_\\ell\\), it represents the variance of the \\(\\ell\\)-th term of the telescopic sum characteristic of the MLMC techniques. For instance, \\(\\mathcal{V}_\\ell=\\mathbb{E}[Y_\\ell-Y_{\\ell}]\\) in the case of the expectation.</p> See Also <p>El Amri et al., Algo. 1, Multilevel Surrogate-based Control Variates, 2023.</p> <p>Parameters:</p> <ul> <li> <code>sampling_ratios</code>               (<code>NDArray[float]</code>)           \u2013            <p>The sampling ratios \\(r_0,\\ldots,r_L\\); the sampling ratio \\(r_\\ell\\) is the factor by which \\(n_\\ell\\) is increased between two sampling steps on the level \\(ell\\).</p> </li> <li> <code>costs</code>               (<code>NDArray[float]</code>)           \u2013            <p>The unit sampling costs of each level of the telescopic sum. Namely, \\((\\mathcal{C}_{\\ell-1}+\\mathcal{C}_\\ell)_{\\ell\\in\\{0,\\ldots,L\\}}\\) with \\(\\mathcal{C}_{-1}=0\\).</p> </li> </ul> Source code in <code>src/gemseo_umdo/statistics/multilevel/base_pilot.py</code> <pre><code>def __init__(self, sampling_ratios: NDArray[float], costs: NDArray[float]) -&gt; None:\n    r\"\"\"\n    Args:\n        sampling_ratios: The sampling ratios $r_0,\\ldots,r_L$;\n            the sampling ratio $r_\\ell$ is\n            the factor by which $n_\\ell$ is increased\n            between two sampling steps on the level $ell$.\n        costs: The unit sampling costs of each level of the telescopic sum.\n            Namely,\n            $(\\mathcal{C}_{\\ell-1}+\\mathcal{C}_\\ell)_{\\ell\\in\\{0,\\ldots,L\\}}$\n            with $\\mathcal{C}_{-1}=0$.\n    \"\"\"  # noqa: D205 D212 D415\n    self.__costs = costs\n    self.__r_l = sampling_ratios\n    self.V_l = array([nan] * len(self.__r_l))\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/base_pilot/#gemseo_umdo.statistics.multilevel.base_pilot.BasePilot-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/base_pilot/#gemseo_umdo.statistics.multilevel.base_pilot.BasePilot.V_l","title":"V_l  <code>instance-attribute</code>","text":"<pre><code>V_l: NDArray[float] = array([nan] * len(__r_l))\n</code></pre> <p>The terms variances \\(\\mathcal{V}_0,\\ldots,\\mathcal{V}_L\\).</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/base_pilot/#gemseo_umdo.statistics.multilevel.base_pilot.BasePilot-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/base_pilot/#gemseo_umdo.statistics.multilevel.base_pilot.BasePilot.compute_next_level_and_statistic","title":"compute_next_level_and_statistic","text":"<pre><code>compute_next_level_and_statistic(\n    levels: Iterable[int],\n    total_n_samples: NDArray[int],\n    samples: Sequence[NDArray[float]],\n    *pilot_parameters: Any\n) -&gt; tuple[int, NDArray[float]]\n</code></pre> <p>Compute the next level \\(\\ell^*\\) to sample and estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>levels</code>               (<code>Iterable[int]</code>)           \u2013            <p>The levels that have just been sampled.</p> </li> <li> <code>total_n_samples</code>               (<code>NDArray[int]</code>)           \u2013            <p>The total number of samples of each level.</p> </li> <li> <code>samples</code>               (<code>Sequence[NDArray[float]]</code>)           \u2013            <p>The samples of the different quantities of each level.</p> </li> <li> <code>*pilot_parameters</code>               (<code>Any</code>, default:                   <code>()</code> )           \u2013            <p>The parameters of the pilot.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[int, NDArray[float]]</code>           \u2013            <p>The next level \\(\\ell^*\\) to sample and an estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/statistics/multilevel/base_pilot.py</code> <pre><code>def compute_next_level_and_statistic(\n    self,\n    levels: Iterable[int],\n    total_n_samples: NDArray[int],\n    samples: Sequence[NDArray[float]],\n    *pilot_parameters: Any,\n) -&gt; tuple[int, NDArray[float]]:\n    r\"\"\"Compute the next level $\\ell^*$ to sample and estimate the statistic.\n\n    Args:\n        levels: The levels that have just been sampled.\n        total_n_samples: The total number of samples of each level.\n        samples: The samples of the different quantities of each level.\n        *pilot_parameters: The parameters of the pilot.\n\n    Returns:\n        The next level $\\ell^*$ to sample and an estimation of the statistic.\n    \"\"\"\n    self.V_l = self._compute_V_l(levels, samples, *pilot_parameters)\n    # WARNING: do not replace \"/ total_n_samples / total_n_samples\"\n    #          by \"/ total_n_samples**2\"\n    #          to avoid numerical division issue due to an excessively big number.\n    return (\n        argmax(\n            self.V_l / self.__r_l / total_n_samples / total_n_samples / self.__costs\n        ),\n        self._compute_statistic(),\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/","title":"Mlmc","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/#gemseo_umdo.statistics.multilevel.mlmc","title":"mlmc","text":"<p>Multilevel Monte Carlo (MLMC) algorithm.</p> <p>The goal of the MLMC algorithm is to estimate a statistic \\(\\theta\\) (ex: mean, variance) of the output of a simulator \\(f\\) whose input \\(\\mathbf{X}\\) is random: that is, a statistic \\(\\theta\\) of \\(Y=f(\\mathbf{X})\\).</p> <p>Let \\((f_\\ell)_{\\ell = 0}^L\\) be a sequence of model levels with increasing accuracy and computational cost, such that \\(f_L = f\\). The MLMC algorithm uses all these models to estimate the statistic \\(\\theta_L\\) (a.k.a. \\(\\theta\\)) of the random output variable \\(f_L(\\mathbf{X})\\) where \\(\\mathbf{X}\\) is a random input vector.</p> <p>We denote by \\(Y_\\ell=f_\\ell(\\mathbf{X})\\) the random output variable associated with the model level \\(f_\\ell\\) and by \\((\\theta_\\ell)_{\\ell = 0}^L\\) the sequence of statistics increasingly close to \\(\\theta_L\\) where \\(\\theta_\\ell\\) is the statistic of \\(Y_\\ell\\).</p> <p>The statistical measure \\(\\theta_L\\) can be expressed as a telescoping sum \\(\\theta_L = \\sum \\limits_{\\ell = 0}^{L} T_\\ell\\), where \\(T_\\ell = \\theta_\\ell - \\theta_{\\ell-1}\\), and by convention \\(\\theta_{-1} = 0\\).</p> <p>Let \\(\\hat{\\theta}_{\\ell,n_\\ell}^{\\mathrm{MC},(\\ell)}\\) and \\(\\hat{\\theta}_{\\ell-1,n_\\ell}^{\\mathrm{MC},(\\ell)}\\) be respectively the Monte Carlo (MC) estimators of \\(\\theta_\\ell\\) and \\(\\theta_{\\ell-1}\\) using the same \\(n_{\\ell}\\)-sample.</p> <p>Then, the MLMC estimator \\(\\hat{\\theta}_L^{\\mathrm{ML}}\\) of \\(\\theta_L\\) may be expressed as:</p> \\[\\hat{\\theta}_L^{\\mathrm{MLMC}} = \\sum \\limits_{\\ell = 0}^{L} \\hat{T}_{\\ell,n_\\ell}^{\\mathrm{MC}} = \\sum \\limits_{\\ell = 0}^{L} \\hat{\\theta}_{\\ell,n_\\ell}^{\\mathrm{MC},(\\ell)} - \\hat{\\theta}_{\\ell-1,n_\\ell}^{\\mathrm{MC},(\\ell)}. \\]"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/level/","title":"Level","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/level/#gemseo_umdo.statistics.multilevel.mlmc.level","title":"level","text":"<p>A level \\(\\ell\\) for the MLMC algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/level/#gemseo_umdo.statistics.multilevel.mlmc.level-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/level/#gemseo_umdo.statistics.multilevel.mlmc.level.Level","title":"Level  <code>dataclass</code>","text":"<pre><code>Level(\n    model: MDOFunction,\n    cost: float | None = None,\n    n_cost_estimation_samples: int = 1,\n    n_initial_samples: int = 10,\n    sampling_ratio: float = 2.0,\n)\n</code></pre> <p>A level \\(\\ell\\) for the MLMC algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/level/#gemseo_umdo.statistics.multilevel.mlmc.level.Level-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/level/#gemseo_umdo.statistics.multilevel.mlmc.level.Level.cost","title":"cost  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cost: float | None = None\n</code></pre> <p>The cost \\(\\mathcal{C}_\\ell\\) to evaluate \\(f_\\ell\\), if known.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/level/#gemseo_umdo.statistics.multilevel.mlmc.level.Level.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model: MDOFunction\n</code></pre> <p>The model \\(f_\\ell\\) to sample.</p> <p>This model can be set from any callable taking a NumPy array of float numbers as input and outputting either a float number or a NumPy array of float numbers.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/level/#gemseo_umdo.statistics.multilevel.mlmc.level.Level.n_cost_estimation_samples","title":"n_cost_estimation_samples  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>n_cost_estimation_samples: int = 1\n</code></pre> <p>The number of \\(f_\\ell\\) calls to estimate \\(\\mathcal{C}_\\ell\\).</p> <p>It will be used only if <code>cost</code> is <code>None</code>.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/level/#gemseo_umdo.statistics.multilevel.mlmc.level.Level.n_initial_samples","title":"n_initial_samples  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>n_initial_samples: int = 10\n</code></pre> <p>The number of samples \\(n_\\ell\\) at the first iteration of the algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/level/#gemseo_umdo.statistics.multilevel.mlmc.level.Level.sampling_ratio","title":"sampling_ratio  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>sampling_ratio: float = 2.0\n</code></pre> <p>The number \\(r_\\ell\\) by which \\(n_\\ell\\) is increased.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/mlmc/","title":"Mlmc","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/mlmc/#gemseo_umdo.statistics.multilevel.mlmc.mlmc","title":"mlmc","text":"<p>A generic algorithm for multilevel Monte Carlo (MLMC) sampling.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/mlmc/#gemseo_umdo.statistics.multilevel.mlmc.mlmc-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/mlmc/#gemseo_umdo.statistics.multilevel.mlmc.mlmc.MLMC","title":"MLMC","text":"<pre><code>MLMC(\n    levels: Iterable[Level],\n    uncertain_space: ParameterSpace,\n    n_samples: float,\n    pilot_statistic_name: str = \"Mean\",\n    seed: int = SEED,\n)\n</code></pre> <p>Multilevel Monte Carlo (MLMC) algorithm.</p> <p>This algorithm aims at sampling the different model levels in an adaptive way, with many evaluations for the coarsest model and a few evaluations for the finest one.</p> <p>This adaptive sampling is guided by a BasePilot.</p> <p>This algorithm depends on the execution cost ratio between two consecutive levels, that can be estimated from the models, and on the sampling size ratio between two sampling steps on the same level.</p> <p>At a given iteration, the algorithm</p> <ol> <li>considers a level \\(\\ell^*\\) and a sample size \\(n_{\\ell^*}\\)</li> <li>samples the models involved in the statistic \\(T_{\\ell^*}\\)    of the telescoping sum (TS) \\(\\theta_L = \\sum_{\\ell=0}^L T_\\ell\\),</li> <li>computes the new level \\(\\ell^*\\) to sample    and the corresponding sample size \\(n_{\\ell^*}\\).</li> </ol> <p>Parameters:</p> <ul> <li> <code>levels</code>               (<code>Iterable[Level]</code>)           \u2013            <p>The levels defined in terms of model, evaluation cost and initial number of calls.</p> </li> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain space on which to sample the functions.</p> </li> <li> <code>n_samples</code>               (<code>float</code>)           \u2013            <p>The sampling budget expressed as the number of model evaluations equivalent to evaluations of the finest model. This number is not necessarily an integer; for instance, if \\(f_L\\) is twice as expensive as \\(f_{L-1}\\), then <code>n_samples=1.5</code> can correspond to 1 evaluation of \\(f_L\\) and 1 evaluation of \\(f_{L-1}\\).</p> </li> <li> <code>pilot_statistic_name</code>               (<code>str</code>, default:                   <code>'Mean'</code> )           \u2013            <p>The name of the statistic used to drive the algorithm.</p> </li> <li> <code>seed</code>               (<code>int</code>, default:                   <code>SEED</code> )           \u2013            <p>The initial random seed for reproducibility. Then, the seed is incremented at each level of the telescopic sum and at each algorithm iteration.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>When the minimum cost is greater than the maximum cost.</p> </li> </ul> Source code in <code>src/gemseo_umdo/statistics/multilevel/mlmc/mlmc.py</code> <pre><code>def __init__(\n    self,\n    levels: Iterable[Level],\n    uncertain_space: ParameterSpace,\n    n_samples: float,\n    pilot_statistic_name: str = \"Mean\",\n    seed: int = SEED,\n) -&gt; None:\n    r\"\"\"\n    Args:\n        levels: The levels\n            defined in terms of model, evaluation cost and initial number of calls.\n        uncertain_space: The uncertain space on which to sample the functions.\n        n_samples: The sampling budget expressed as\n            the number of model evaluations\n            equivalent to evaluations of the finest model.\n            This number is not necessarily an integer;\n            for instance,\n            if $f_L$ is twice as expensive as $f_{L-1}$,\n            then `n_samples=1.5` can correspond to\n            1 evaluation of $f_L$ and 1 evaluation of $f_{L-1}$.\n        pilot_statistic_name: The name of the statistic used to drive the algorithm.\n        seed: The initial random seed for reproducibility.\n            Then,\n            the seed is incremented at each level of the telescopic sum\n            and at each algorithm iteration.\n\n    Raises:\n        ValueError: When the minimum cost is greater than the maximum cost.\n    \"\"\"  # noqa: D205 D212 D415\n    self._algorithm_name = \"MLMC\"\n\n    # Initialize the seed.\n    self.__seed = seed\n\n    # Set the models f_0, f_1, ..., f_L.\n    self.__f_l = [level.model for level in levels]\n    for l, f_l in enumerate(self.__f_l):  # noqa: E741\n        f_l.name = f\"f[{l}]\"\n\n    # Set the number of levels.\n    self._n_levels = len(self.__f_l)\n\n    # Set the unit sampling costs of each level of the telescopic sum (TS).\n    C_l = array(  # noqa: N806\n        [level.cost if level.cost is not None else nan for level in levels]\n    )\n    self.__C_l = C_l = C_l / C_l[-1]  # noqa: N806\n    self.__total_execution_times = array([0] * self._n_levels)\n    self.__costs = array([C_l[0], *(C_l[1:] + C_l[:-1]).tolist()])\n\n    # Set the sampling ratios r_l of each level of the TS.\n    self.__r_l = array([level.sampling_ratio for level in levels])\n\n    # Set the Monte Carlo samplers of each level of the TS.\n    self._samplers = tuple(\n        MonteCarloSampler(uncertain_space) for _ in range(self._n_levels)\n    )\n    self._add_functions_to_samplers()\n\n    # Set the numbers of samples to be added at each level of the TS.\n    self.__delta_n_l = [level.n_initial_samples for level in levels]\n\n    # Initialize the history of numbers of samples added at each level of the TS.\n    self.__n_samples_history = [self.__delta_n_l.copy()]\n\n    # Initialize the numbers of samples of each level of the TS.\n    self.__n_l = array(self.__n_samples_history[0], dtype=\"int64\")\n\n    self.__minimum_budget = sum(\n        nl * cost for nl, cost in zip(self.__n_samples_history[0], self.__costs)\n    )\n    self.__total_budget = n_samples\n    self.__current_budget = self.__total_budget\n    self.__budget_history = []\n    self.__use_empirical_C_l = isnan(self.__minimum_budget)\n    if not self.__use_empirical_C_l and self.__minimum_budget &gt; n_samples:\n        msg = (\n            f\"The minimum budget {self.__minimum_budget} is greater \"\n            f\"than the total budget {n_samples}.\"\n        )\n        raise ValueError(msg)\n\n    # Set the estimator of the pilot statistic and initialize its estimation.\n    self.__pilot_statistic_estimation = array([])\n    self.__pilot_statistic_estimator = self._PILOT_FACTORY().create(\n        pilot_statistic_name,\n        sampling_ratios=self.__r_l,\n        costs=self.__costs,\n    )\n    self._pilot_statistic_estimator_parameters = []\n    self.__V_l = 0\n    LOGGER.info(\"%s\", self)\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/mlmc/#gemseo_umdo.statistics.multilevel.mlmc.mlmc.MLMC-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/mlmc/#gemseo_umdo.statistics.multilevel.mlmc.mlmc.MLMC.budget_history","title":"budget_history  <code>property</code>","text":"<pre><code>budget_history: NDArray[float]\n</code></pre> <p>The history of the budget.</p> <p><code>algo.budget_history[i]</code> is the budget at iteration <code>i+1</code>.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/mlmc/#gemseo_umdo.statistics.multilevel.mlmc.mlmc.MLMC.level_costs","title":"level_costs  <code>property</code>","text":"<pre><code>level_costs: NDArray[float]\n</code></pre> <p>The evaluation costs of the different levels.</p> <p><code>algo.level_costs[l]</code> is the cost of one evaluation of the <code>l</code>-th level.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/mlmc/#gemseo_umdo.statistics.multilevel.mlmc.mlmc.MLMC.model_costs","title":"model_costs  <code>property</code>","text":"<pre><code>model_costs: NDArray[float]\n</code></pre> <p>The evaluation costs of the different models.</p> <p><code>algo.model_costs[l]</code> is the cost of one evaluation of the <code>l</code>-th model.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/mlmc/#gemseo_umdo.statistics.multilevel.mlmc.mlmc.MLMC.n_total_samples","title":"n_total_samples  <code>property</code>","text":"<pre><code>n_total_samples: NDArray[int]\n</code></pre> <p>The total numbers of samples per level.</p> <p><code>algo.n_total_samples[l]</code> is the total number of samples at level <code>l</code>.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/mlmc/#gemseo_umdo.statistics.multilevel.mlmc.mlmc.MLMC.pilot_statistic_estimation","title":"pilot_statistic_estimation  <code>property</code>","text":"<pre><code>pilot_statistic_estimation: NDArray[float]\n</code></pre> <p>The estimation of the pilot statistic.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/mlmc/#gemseo_umdo.statistics.multilevel.mlmc.mlmc.MLMC.sampling_history","title":"sampling_history  <code>property</code>","text":"<pre><code>sampling_history: NDArray[int]\n</code></pre> <p>The history of the numbers of samples of each level of the telescopic sum.</p> <p><code>algo.sampling_size_history[i, l]</code> is the number of samples at iteration <code>i+1</code> and level <code>l</code>.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/mlmc/#gemseo_umdo.statistics.multilevel.mlmc.mlmc.MLMC-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/mlmc/#gemseo_umdo.statistics.multilevel.mlmc.mlmc.MLMC.execute","title":"execute","text":"<pre><code>execute() -&gt; None\n</code></pre> <p>Execute the algorithm.</p> Source code in <code>src/gemseo_umdo/statistics/multilevel/mlmc/mlmc.py</code> <pre><code>def execute(self) -&gt; None:\n    \"\"\"Execute the algorithm.\"\"\"\n    # The current version of the algorithm samples only one level at a time,\n    # except at the first iteration where it samples them all.\n    levels_to_be_sampled = list(range(self._n_levels))\n\n    # Initialize the iteration of the algorithm.\n    is_last_iteration = False\n    iteration = 0\n\n    # As long as there is budget left\n    LOGGER.info(\"Start sampling with a total budget of %s\", self.__total_budget)\n    while self.__current_budget &gt;= 0:\n        iteration += 1\n        if is_last_iteration:\n            LOGGER.info(\"   Iteration #%s (last iteration)\", iteration)\n        else:\n            LOGGER.info(\"   Iteration #%s\", iteration)\n\n        # Append the budget to the budget history.\n        self.__budget_history.append(self.__current_budget)\n\n        # Sample the selected levels of the TS.\n        levels_to_samples = self.__compute_samples(*levels_to_be_sampled)\n\n        # Select the next level l_star of the TS to be sampled\n        # and estimate the statistic.\n        (\n            l_star,\n            self.__pilot_statistic_estimation,\n        ) = self.__pilot_statistic_estimator.compute_next_level_and_statistic(\n            levels_to_be_sampled,\n            self.__n_l,\n            levels_to_samples,\n            *self._pilot_statistic_estimator_parameters,\n        )\n\n        # Stop the algorithm if it is the last iteration.\n        if is_last_iteration:\n            break\n\n        # The current version of the algorithm samples only one level at a time.\n        levels_to_be_sampled = [l_star]\n\n        # Define the corresponding sample size.\n        delta_n_l_star = int(\n            math.floor((self.__r_l[l_star] - 1) * self.__n_l[l_star])\n        )\n        n_l_star = self.__n_l[l_star] + delta_n_l_star\n        LOGGER.info(\"      Find the next level to sample\")\n        LOGGER.info(\"         l_star = %s\", l_star)\n        LOGGER.info(\"         d_n_l_star = %s\", delta_n_l_star)\n        LOGGER.info(\"         n_l_star = %s\", n_l_star)\n\n        # If the new sampling stage is too expensive, reduce the number of samples.\n        posterior_budget = (\n            self.__current_budget - delta_n_l_star * self.__costs[l_star]\n        )\n        if posterior_budget &lt; 0:\n            LOGGER.info(\"         Maximum budget exceeded by %s\", -posterior_budget)\n            LOGGER.info(\n                \"         Decrease d_n_l_star to respect the maximum budget\"\n            )\n\n            # There is a budget to do at most one iteration.\n            is_last_iteration = True\n\n            # Update the numbers of additional samples at level l_star\n            # to achieve a positive or zero budget.\n            delta_n_l_star = int(\n                delta_n_l_star + posterior_budget / self.__costs[l_star]\n            )\n            n_l_star = self.__n_l[l_star] + delta_n_l_star\n            LOGGER.info(\"         d_n_l_star = %s\", delta_n_l_star)\n            LOGGER.info(\"         n_l_star = %s\", n_l_star)\n            # Stop the algorithm if one can no longer sample l_star.\n            if delta_n_l_star == 0:\n                LOGGER.info(\n                    \"Stop the algorithm as sampling l_star is too expensive.\"\n                )\n                break\n\n        # Update the history of number of samples of each level\n        # (0 for all the levels, but l_star).\n        self.__delta_n_l = zeros(self._n_levels)\n        self.__delta_n_l[l_star] = delta_n_l_star\n        self.__n_l[l_star] += delta_n_l_star\n        self.__n_samples_history.extend([self.__delta_n_l.copy()])\n\n    LOGGER.info(\"Sampling completed\")\n    LOGGER.info(\"Results\")\n    LOGGER.info(\"   Pilot statistic = %s\", self.pilot_statistic_estimation)\n    LOGGER.info(\"   Total cost = %s\", sum(self.__n_l * self.__costs))\n    LOGGER.info(\"   Cost allocation\")\n    levels_to_total_costs = self.__n_l * self.__costs\n    levels_to_total_costs = levels_to_total_costs / sum(levels_to_total_costs)\n    for level, total_cost in enumerate(levels_to_total_costs):\n        LOGGER.info(\"      Level %s: %s\", level, f\"{total_cost:.1%}\")\n\n    LOGGER.info(\"   n_l\")\n    for level in range(self._n_levels):\n        LOGGER.info(\"       n_%s = %s\", level, self.__n_l[level])\n\n    LOGGER.info(\"   V_l\")\n    self.__V_l = self.__pilot_statistic_estimator.V_l\n    for level in range(self._n_levels):\n        LOGGER.info(\"       V_%s = %s\", level, f\"{self.__V_l[level]:.2e}\")\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/mlmc/#gemseo_umdo.statistics.multilevel.mlmc.mlmc.MLMC.plot_evaluation_history","title":"plot_evaluation_history","text":"<pre><code>plot_evaluation_history(\n    show: bool = True,\n    file_path: str | Path | None = None,\n    log_n_evaluations: bool = True,\n    log_budget: bool = False,\n) -&gt; None\n</code></pre> <p>Plot the history of the model evaluations in terms of sample size and budget.</p> <p>Parameters:</p> <ul> <li> <code>show</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to display the graph.</p> </li> <li> <code>file_path</code>               (<code>str | Path | None</code>, default:                   <code>None</code> )           \u2013            <p>The file path to save the graph.</p> </li> <li> <code>log_n_evaluations</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to use a log-scale for the number of evaluations.</p> </li> <li> <code>log_budget</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to use a log-scale for the budget.</p> </li> </ul> Source code in <code>src/gemseo_umdo/statistics/multilevel/mlmc/mlmc.py</code> <pre><code>def plot_evaluation_history(\n    self,\n    show: bool = True,\n    file_path: str | Path | None = None,\n    log_n_evaluations: bool = True,\n    log_budget: bool = False,\n) -&gt; None:\n    \"\"\"Plot the history of the model evaluations in terms of sample size and budget.\n\n    Args:\n        show: Whether to display the graph.\n        file_path: The file path to save the graph.\n        log_n_evaluations: Whether to use a log-scale for the number of evaluations.\n        log_budget: Whether to use a log-scale for the budget.\n    \"\"\"\n    fig, (ax1, ax2) = plt.subplots(ncols=2)\n    iterations = [i + 1 for i, _ in enumerate(self.__n_samples_history)]\n    ax1.plot(\n        iterations,\n        cumsum(array(self.__n_samples_history), axis=0),\n        label=[rf\"$f_{level}$\" for level in range(self._n_levels)],\n        marker=\".\",\n    )\n    if log_n_evaluations:\n        ax1.set_yscale(\"log\")\n\n    ax1.set_xlabel(\"Iteration\")\n    ax1.set_ylabel(\"Cumulated number of evaluations\")\n    ax1.legend(title=\"Simulators\")\n    ax1.grid(which=\"both\")\n    data = (array(self.__n_samples_history) * self.__costs).T\n    ax2.bar(iterations, data[0], label=r\"$f_0$\")\n    for index, row in enumerate(data[1:]):\n        ax2.bar(\n            iterations,\n            row,\n            bottom=data[0 : index + 1].sum(0),\n            label=rf\"$f_{index + 1}$\",\n        )\n\n    if log_budget:\n        ax2.set_yscale(\"log\")\n\n    ax2.set_xlabel(\"Iteration\")\n    ax2.set_ylabel(\"Cost\")\n    ax2.legend(title=\"Simulators\")\n    ax2.grid(which=\"both\")\n    ax2.set_axisbelow(True)\n    save_show_figure(fig, show, file_path, fig_size=(10, 3))\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/","title":"Pilots","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/#gemseo_umdo.statistics.multilevel.mlmc.pilots","title":"pilots","text":"<p>A set of pilots for the MLMC algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/base_mlmc_pilot/","title":"Base mlmc pilot","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/base_mlmc_pilot/#gemseo_umdo.statistics.multilevel.mlmc.pilots.base_mlmc_pilot","title":"base_mlmc_pilot","text":"<p>The base pilot class for the MLMC algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/base_mlmc_pilot/#gemseo_umdo.statistics.multilevel.mlmc.pilots.base_mlmc_pilot-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/base_mlmc_pilot/#gemseo_umdo.statistics.multilevel.mlmc.pilots.base_mlmc_pilot.BaseMLMCPilot","title":"BaseMLMCPilot","text":"<pre><code>BaseMLMCPilot(\n    sampling_ratios: NDArray[float], costs: NDArray[float]\n)\n</code></pre> <p>               Bases: <code>BasePilot</code></p> <p>The base pilot class for the MLMC algorithm.</p> See Also <p>El Amri et al., Algo. 1, Multilevel Surrogate-based Control Variates, 2023.</p> <p>Parameters:</p> <ul> <li> <code>sampling_ratios</code>               (<code>NDArray[float]</code>)           \u2013            <p>The sampling ratios \\(r_0,\\ldots,r_L\\); the sampling ratio \\(r_\\ell\\) is the factor by which \\(n_\\ell\\) is increased between two sampling steps on the level \\(ell\\).</p> </li> <li> <code>costs</code>               (<code>NDArray[float]</code>)           \u2013            <p>The unit sampling costs of each level of the telescopic sum. Namely, \\((\\mathcal{C}_{\\ell-1}+\\mathcal{C}_\\ell)_{\\ell\\in\\{0,\\ldots,L\\}}\\) with \\(\\mathcal{C}_{-1}=0\\).</p> </li> </ul> Source code in <code>src/gemseo_umdo/statistics/multilevel/base_pilot.py</code> <pre><code>def __init__(self, sampling_ratios: NDArray[float], costs: NDArray[float]) -&gt; None:\n    r\"\"\"\n    Args:\n        sampling_ratios: The sampling ratios $r_0,\\ldots,r_L$;\n            the sampling ratio $r_\\ell$ is\n            the factor by which $n_\\ell$ is increased\n            between two sampling steps on the level $ell$.\n        costs: The unit sampling costs of each level of the telescopic sum.\n            Namely,\n            $(\\mathcal{C}_{\\ell-1}+\\mathcal{C}_\\ell)_{\\ell\\in\\{0,\\ldots,L\\}}$\n            with $\\mathcal{C}_{-1}=0$.\n    \"\"\"  # noqa: D205 D212 D415\n    self.__costs = costs\n    self.__r_l = sampling_ratios\n    self.V_l = array([nan] * len(self.__r_l))\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/base_mlmc_pilot/#gemseo_umdo.statistics.multilevel.mlmc.pilots.base_mlmc_pilot.BaseMLMCPilot-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/base_mlmc_pilot/#gemseo_umdo.statistics.multilevel.mlmc.pilots.base_mlmc_pilot.BaseMLMCPilot.V_l","title":"V_l  <code>instance-attribute</code>","text":"<pre><code>V_l: NDArray[float] = array([nan] * len(__r_l))\n</code></pre> <p>The terms variances \\(\\mathcal{V}_0,\\ldots,\\mathcal{V}_L\\).</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/base_mlmc_pilot/#gemseo_umdo.statistics.multilevel.mlmc.pilots.base_mlmc_pilot.BaseMLMCPilot-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/base_mlmc_pilot/#gemseo_umdo.statistics.multilevel.mlmc.pilots.base_mlmc_pilot.BaseMLMCPilot.compute_next_level_and_statistic","title":"compute_next_level_and_statistic","text":"<pre><code>compute_next_level_and_statistic(\n    levels: Iterable[int],\n    total_n_samples: NDArray[int],\n    samples: Sequence[NDArray[float]],\n    *pilot_parameters: Any\n) -&gt; tuple[int, NDArray[float]]\n</code></pre> <p>Compute the next level \\(\\ell^*\\) to sample and estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>levels</code>               (<code>Iterable[int]</code>)           \u2013            <p>The levels that have just been sampled.</p> </li> <li> <code>total_n_samples</code>               (<code>NDArray[int]</code>)           \u2013            <p>The total number of samples of each level.</p> </li> <li> <code>samples</code>               (<code>Sequence[NDArray[float]]</code>)           \u2013            <p>The samples of the different quantities of each level.</p> </li> <li> <code>*pilot_parameters</code>               (<code>Any</code>, default:                   <code>()</code> )           \u2013            <p>The parameters of the pilot.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[int, NDArray[float]]</code>           \u2013            <p>The next level \\(\\ell^*\\) to sample and an estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/statistics/multilevel/base_pilot.py</code> <pre><code>def compute_next_level_and_statistic(\n    self,\n    levels: Iterable[int],\n    total_n_samples: NDArray[int],\n    samples: Sequence[NDArray[float]],\n    *pilot_parameters: Any,\n) -&gt; tuple[int, NDArray[float]]:\n    r\"\"\"Compute the next level $\\ell^*$ to sample and estimate the statistic.\n\n    Args:\n        levels: The levels that have just been sampled.\n        total_n_samples: The total number of samples of each level.\n        samples: The samples of the different quantities of each level.\n        *pilot_parameters: The parameters of the pilot.\n\n    Returns:\n        The next level $\\ell^*$ to sample and an estimation of the statistic.\n    \"\"\"\n    self.V_l = self._compute_V_l(levels, samples, *pilot_parameters)\n    # WARNING: do not replace \"/ total_n_samples / total_n_samples\"\n    #          by \"/ total_n_samples**2\"\n    #          to avoid numerical division issue due to an excessively big number.\n    return (\n        argmax(\n            self.V_l / self.__r_l / total_n_samples / total_n_samples / self.__costs\n        ),\n        self._compute_statistic(),\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/factory/","title":"Factory","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/factory/#gemseo_umdo.statistics.multilevel.mlmc.pilots.factory","title":"factory","text":"<p>A factory of pilots for the MLMC algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/factory/#gemseo_umdo.statistics.multilevel.mlmc.pilots.factory-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/factory/#gemseo_umdo.statistics.multilevel.mlmc.pilots.factory.MLMCPilotFactory","title":"MLMCPilotFactory","text":"<p>               Bases: <code>BaseFactory</code></p> <p>A factory of pilots for the MLMC algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/mean/","title":"Mean","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/mean/#gemseo_umdo.statistics.multilevel.mlmc.pilots.mean","title":"mean","text":"<p>The mean-based pilot for the MLMC algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/mean/#gemseo_umdo.statistics.multilevel.mlmc.pilots.mean-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/mean/#gemseo_umdo.statistics.multilevel.mlmc.pilots.mean.Mean","title":"Mean","text":"<pre><code>Mean(\n    sampling_ratios: NDArray[float], costs: NDArray[float]\n)\n</code></pre> <p>               Bases: <code>BaseMLMCPilot</code></p> <p>The mean-based pilot for the MLMC algorithm.</p> See Also <p>El Amri et al., Algo. 1, Multilevel Surrogate-based Control Variates, 2023.</p> <p>Parameters:</p> <ul> <li> <code>sampling_ratios</code>               (<code>NDArray[float]</code>)           \u2013            <p>The sampling ratios \\(r_0,\\ldots,r_L\\); the sampling ratio \\(r_\\ell\\) is the factor by which \\(n_\\ell\\) is increased between two sampling steps on the level \\(ell\\).</p> </li> <li> <code>costs</code>               (<code>NDArray[float]</code>)           \u2013            <p>The unit sampling costs of each level of the telescopic sum. Namely, \\((\\mathcal{C}_{\\ell-1}+\\mathcal{C}_\\ell)_{\\ell\\in\\{0,\\ldots,L\\}}\\) with \\(\\mathcal{C}_{-1}=0\\).</p> </li> </ul> Source code in <code>src/gemseo_umdo/statistics/multilevel/mlmc/pilots/mean.py</code> <pre><code>def __init__(  # noqa: D107\n    self, sampling_ratios: NDArray[float], costs: NDArray[float]\n) -&gt; None:\n    super().__init__(sampling_ratios, costs)\n    self.__delta = [array([]) for _ in range(len(sampling_ratios))]\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/mean/#gemseo_umdo.statistics.multilevel.mlmc.pilots.mean.Mean-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/mean/#gemseo_umdo.statistics.multilevel.mlmc.pilots.mean.Mean.V_l","title":"V_l  <code>instance-attribute</code>","text":"<pre><code>V_l: NDArray[float] = array([nan] * len(__r_l))\n</code></pre> <p>The terms variances \\(\\mathcal{V}_0,\\ldots,\\mathcal{V}_L\\).</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/mean/#gemseo_umdo.statistics.multilevel.mlmc.pilots.mean.Mean-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/mean/#gemseo_umdo.statistics.multilevel.mlmc.pilots.mean.Mean.compute_next_level_and_statistic","title":"compute_next_level_and_statistic","text":"<pre><code>compute_next_level_and_statistic(\n    levels: Iterable[int],\n    total_n_samples: NDArray[int],\n    samples: Sequence[NDArray[float]],\n    *pilot_parameters: Any\n) -&gt; tuple[int, NDArray[float]]\n</code></pre> <p>Compute the next level \\(\\ell^*\\) to sample and estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>levels</code>               (<code>Iterable[int]</code>)           \u2013            <p>The levels that have just been sampled.</p> </li> <li> <code>total_n_samples</code>               (<code>NDArray[int]</code>)           \u2013            <p>The total number of samples of each level.</p> </li> <li> <code>samples</code>               (<code>Sequence[NDArray[float]]</code>)           \u2013            <p>The samples of the different quantities of each level.</p> </li> <li> <code>*pilot_parameters</code>               (<code>Any</code>, default:                   <code>()</code> )           \u2013            <p>The parameters of the pilot.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[int, NDArray[float]]</code>           \u2013            <p>The next level \\(\\ell^*\\) to sample and an estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/statistics/multilevel/base_pilot.py</code> <pre><code>def compute_next_level_and_statistic(\n    self,\n    levels: Iterable[int],\n    total_n_samples: NDArray[int],\n    samples: Sequence[NDArray[float]],\n    *pilot_parameters: Any,\n) -&gt; tuple[int, NDArray[float]]:\n    r\"\"\"Compute the next level $\\ell^*$ to sample and estimate the statistic.\n\n    Args:\n        levels: The levels that have just been sampled.\n        total_n_samples: The total number of samples of each level.\n        samples: The samples of the different quantities of each level.\n        *pilot_parameters: The parameters of the pilot.\n\n    Returns:\n        The next level $\\ell^*$ to sample and an estimation of the statistic.\n    \"\"\"\n    self.V_l = self._compute_V_l(levels, samples, *pilot_parameters)\n    # WARNING: do not replace \"/ total_n_samples / total_n_samples\"\n    #          by \"/ total_n_samples**2\"\n    #          to avoid numerical division issue due to an excessively big number.\n    return (\n        argmax(\n            self.V_l / self.__r_l / total_n_samples / total_n_samples / self.__costs\n        ),\n        self._compute_statistic(),\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/variance/","title":"Variance","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/variance/#gemseo_umdo.statistics.multilevel.mlmc.pilots.variance","title":"variance","text":"<p>The variance-based pilot for the MLMC algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/variance/#gemseo_umdo.statistics.multilevel.mlmc.pilots.variance-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/variance/#gemseo_umdo.statistics.multilevel.mlmc.pilots.variance.Variance","title":"Variance","text":"<pre><code>Variance(\n    sampling_ratios: NDArray[float], costs: NDArray[float]\n)\n</code></pre> <p>               Bases: <code>BaseMLMCPilot</code></p> <p>The variance-based pilot for the MLMC algorithm.</p> See Also <p>El Amri et al., Algo. 1, Multilevel Surrogate-based Control Variates, 2023.</p> <p>Parameters:</p> <ul> <li> <code>sampling_ratios</code>               (<code>NDArray[float]</code>)           \u2013            <p>The sampling ratios \\(r_0,\\ldots,r_L\\); the sampling ratio \\(r_\\ell\\) is the factor by which \\(n_\\ell\\) is increased between two sampling steps on the level \\(ell\\).</p> </li> <li> <code>costs</code>               (<code>NDArray[float]</code>)           \u2013            <p>The unit sampling costs of each level of the telescopic sum. Namely, \\((\\mathcal{C}_{\\ell-1}+\\mathcal{C}_\\ell)_{\\ell\\in\\{0,\\ldots,L\\}}\\) with \\(\\mathcal{C}_{-1}=0\\).</p> </li> </ul> Source code in <code>src/gemseo_umdo/statistics/multilevel/mlmc/pilots/variance.py</code> <pre><code>def __init__(  # noqa: D107\n    self, sampling_ratios: NDArray[float], costs: NDArray[float]\n) -&gt; None:\n    super().__init__(sampling_ratios, costs)\n    n_levels = len(sampling_ratios)\n    self.__delta = [array([]) for _ in range(n_levels)]\n    self.__sigma = [array([]) for _ in range(n_levels)]\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/variance/#gemseo_umdo.statistics.multilevel.mlmc.pilots.variance.Variance-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/variance/#gemseo_umdo.statistics.multilevel.mlmc.pilots.variance.Variance.V_l","title":"V_l  <code>instance-attribute</code>","text":"<pre><code>V_l: NDArray[float] = array([nan] * len(__r_l))\n</code></pre> <p>The terms variances \\(\\mathcal{V}_0,\\ldots,\\mathcal{V}_L\\).</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/variance/#gemseo_umdo.statistics.multilevel.mlmc.pilots.variance.Variance-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc/pilots/variance/#gemseo_umdo.statistics.multilevel.mlmc.pilots.variance.Variance.compute_next_level_and_statistic","title":"compute_next_level_and_statistic","text":"<pre><code>compute_next_level_and_statistic(\n    levels: Iterable[int],\n    total_n_samples: NDArray[int],\n    samples: Sequence[NDArray[float]],\n    *pilot_parameters: Any\n) -&gt; tuple[int, NDArray[float]]\n</code></pre> <p>Compute the next level \\(\\ell^*\\) to sample and estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>levels</code>               (<code>Iterable[int]</code>)           \u2013            <p>The levels that have just been sampled.</p> </li> <li> <code>total_n_samples</code>               (<code>NDArray[int]</code>)           \u2013            <p>The total number of samples of each level.</p> </li> <li> <code>samples</code>               (<code>Sequence[NDArray[float]]</code>)           \u2013            <p>The samples of the different quantities of each level.</p> </li> <li> <code>*pilot_parameters</code>               (<code>Any</code>, default:                   <code>()</code> )           \u2013            <p>The parameters of the pilot.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[int, NDArray[float]]</code>           \u2013            <p>The next level \\(\\ell^*\\) to sample and an estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/statistics/multilevel/base_pilot.py</code> <pre><code>def compute_next_level_and_statistic(\n    self,\n    levels: Iterable[int],\n    total_n_samples: NDArray[int],\n    samples: Sequence[NDArray[float]],\n    *pilot_parameters: Any,\n) -&gt; tuple[int, NDArray[float]]:\n    r\"\"\"Compute the next level $\\ell^*$ to sample and estimate the statistic.\n\n    Args:\n        levels: The levels that have just been sampled.\n        total_n_samples: The total number of samples of each level.\n        samples: The samples of the different quantities of each level.\n        *pilot_parameters: The parameters of the pilot.\n\n    Returns:\n        The next level $\\ell^*$ to sample and an estimation of the statistic.\n    \"\"\"\n    self.V_l = self._compute_V_l(levels, samples, *pilot_parameters)\n    # WARNING: do not replace \"/ total_n_samples / total_n_samples\"\n    #          by \"/ total_n_samples**2\"\n    #          to avoid numerical division issue due to an excessively big number.\n    return (\n        argmax(\n            self.V_l / self.__r_l / total_n_samples / total_n_samples / self.__costs\n        ),\n        self._compute_statistic(),\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/","title":"Mlmc mlcv","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv","title":"mlmc_mlcv","text":"<p>Multilevel Monte Carlo with multilevel control variate (MLMC-MLCV) algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/level/","title":"Level","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/level/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.level","title":"level","text":"<p>A level \\(\\ell\\) for the MLMC-MLCV algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/level/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.level-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/level/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.level.Level","title":"Level  <code>dataclass</code>","text":"<pre><code>Level(\n    model: MDOFunction,\n    surrogate_model: tuple[MDOFunction, float],\n    difference_surrogate_model: tuple[\n        MDOFunction, float\n    ] = (),\n    cost: float | None = None,\n    n_cost_estimation_samples: int = 1,\n    n_initial_samples: int = 10,\n    sampling_ratio: float = 2.0,\n)\n</code></pre> <p>A level \\(\\ell\\) for the MLMC-MLCV algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/level/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.level.Level-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/level/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.level.Level.cost","title":"cost  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cost: float | None = None\n</code></pre> <p>The cost \\(\\mathcal{C}_\\ell\\) to evaluate \\(f_\\ell\\), if known.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/level/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.level.Level.difference_surrogate_model","title":"difference_surrogate_model  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>difference_surrogate_model: tuple[MDOFunction, float] = ()\n</code></pre> <p>The surrogate model \\(h_\\ell\\) approximating \\(f_\\ell-f_{\\ell-1}\\).</p> <p>More precisely, \\(h_\\ell\\) and its statistic for the MLMCMLCV algorithm.</p> <p>Empty at level \\(\\ell=0\\).</p> <p>The surrogate model can be set from any callable taking a NumPy array of float numbers as input and outputting either a float number or a NumPy array of float numbers.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/level/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.level.Level.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model: MDOFunction\n</code></pre> <p>The model \\(f_\\ell\\) to sample.</p> <p>This model can be set from any callable taking a NumPy array of float numbers as input and outputting either a float number or a NumPy array of float numbers.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/level/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.level.Level.n_cost_estimation_samples","title":"n_cost_estimation_samples  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>n_cost_estimation_samples: int = 1\n</code></pre> <p>The number of \\(f_\\ell\\) calls to estimate \\(\\mathcal{C}_\\ell\\).</p> <p>It will be used only if <code>cost</code> is <code>None</code>.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/level/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.level.Level.n_initial_samples","title":"n_initial_samples  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>n_initial_samples: int = 10\n</code></pre> <p>The number of samples \\(n_\\ell\\) at the first iteration of the algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/level/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.level.Level.sampling_ratio","title":"sampling_ratio  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>sampling_ratio: float = 2.0\n</code></pre> <p>The factor \\(r_\\ell\\) by which \\(n_\\ell\\) is increased.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/level/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.level.Level.surrogate_model","title":"surrogate_model  <code>instance-attribute</code>","text":"<pre><code>surrogate_model: tuple[MDOFunction, float]\n</code></pre> <p>The surrogate model \\(g_\\ell\\) approximating \\(f_\\ell\\).</p> <p>More precisely, \\(g_\\ell\\) and its statistic for the MLMCMLCV algorithm.</p> <p>The surrogate model can be set from any callable taking a NumPy array of float numbers as input and outputting either a float number or a NumPy array of float numbers.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/","title":"Mlmc mlcv","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.mlmc_mlcv","title":"mlmc_mlcv","text":"<p>Multilevel Monte Carlo with multilevel control variates (MLMC-MLCV).</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.mlmc_mlcv-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.mlmc_mlcv.MLMCMLCV","title":"MLMCMLCV","text":"<pre><code>MLMCMLCV(\n    levels: Sequence[Level],\n    uncertain_space: ParameterSpace,\n    n_samples: float,\n    pilot: str = \"Mean\",\n    variant: Variant = MLMC_MLCV,\n    seed: int = SEED,\n)\n</code></pre> <p>               Bases: <code>MLMC</code></p> <p>Multilevel Monte Carlo with multilevel control variates (MLMC-MLCV).</p> <p>Parameters:</p> <ul> <li> <code>levels</code>               (<code>Iterable[Level]</code>)           \u2013            <p>The levels defined in terms of model, evaluation cost and initial number of calls.</p> </li> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The uncertain space on which to sample the functions.</p> </li> <li> <code>n_samples</code>               (<code>float</code>)           \u2013            <p>The sampling budget expressed as the number of model evaluations equivalent to evaluations of the finest model. This number is not necessarily an integer; for instance, if \\(f_L\\) is twice as expensive as \\(f_{L-1}\\), then <code>n_samples=1.5</code> can correspond to 1 evaluation of \\(f_L\\) and 1 evaluation of \\(f_{L-1}\\).</p> </li> <li> <code>pilot_statistic_name</code>               (<code>str</code>, default:                   <code>'Mean'</code> )           \u2013            <p>The name of the statistic used to drive the algorithm.</p> </li> <li> <code>seed</code>               (<code>int</code>, default:                   <code>SEED</code> )           \u2013            <p>The initial random seed for reproducibility. Then, the seed is incremented at each level of the telescopic sum and at each algorithm iteration.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>When the minimum cost is greater than the maximum cost.</p> </li> </ul> Source code in <code>src/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv.py</code> <pre><code>def __init__(  # noqa: D107\n    self,\n    levels: Sequence[Level],\n    uncertain_space: ParameterSpace,\n    n_samples: float,\n    pilot: str = \"Mean\",\n    variant: Variant = Variant.MLMC_MLCV,\n    seed: int = SEED,\n) -&gt; None:\n    self.__g_l = tuple(level.surrogate_model[0] for level in levels)\n    for l, g_l in enumerate(self.__g_l):  # noqa: E741\n        g_l.name = f\"g[{l}]\"\n\n    self.__h_l = tuple(\n        level.difference_surrogate_model[0]\n        for l, level in enumerate(levels)  # noqa: E741\n        if l != 0\n    )\n    for l, h_l in enumerate(self.__h_l):  # noqa: E741\n        h_l.name = f\"h[{l + 1}]\"\n    self.__variant = variant\n    super().__init__(\n        levels,\n        uncertain_space,\n        n_samples,\n        pilot_statistic_name=pilot,\n        seed=seed,\n    )\n\n    self._algorithm_name = variant.value\n    self._pilot_statistic_estimator_parameters = [\n        array([level.surrogate_model[1] for level in levels]),\n        array([\n            level.difference_surrogate_model[1]\n            for l, level in enumerate(levels)  # noqa: E741\n            if l != 0\n        ]),\n        variant,\n    ]\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.mlmc_mlcv.MLMCMLCV-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.mlmc_mlcv.MLMCMLCV.budget_history","title":"budget_history  <code>property</code>","text":"<pre><code>budget_history: NDArray[float]\n</code></pre> <p>The history of the budget.</p> <p><code>algo.budget_history[i]</code> is the budget at iteration <code>i+1</code>.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.mlmc_mlcv.MLMCMLCV.level_costs","title":"level_costs  <code>property</code>","text":"<pre><code>level_costs: NDArray[float]\n</code></pre> <p>The evaluation costs of the different levels.</p> <p><code>algo.level_costs[l]</code> is the cost of one evaluation of the <code>l</code>-th level.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.mlmc_mlcv.MLMCMLCV.model_costs","title":"model_costs  <code>property</code>","text":"<pre><code>model_costs: NDArray[float]\n</code></pre> <p>The evaluation costs of the different models.</p> <p><code>algo.model_costs[l]</code> is the cost of one evaluation of the <code>l</code>-th model.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.mlmc_mlcv.MLMCMLCV.n_total_samples","title":"n_total_samples  <code>property</code>","text":"<pre><code>n_total_samples: NDArray[int]\n</code></pre> <p>The total numbers of samples per level.</p> <p><code>algo.n_total_samples[l]</code> is the total number of samples at level <code>l</code>.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.mlmc_mlcv.MLMCMLCV.pilot_statistic_estimation","title":"pilot_statistic_estimation  <code>property</code>","text":"<pre><code>pilot_statistic_estimation: NDArray[float]\n</code></pre> <p>The estimation of the pilot statistic.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.mlmc_mlcv.MLMCMLCV.sampling_history","title":"sampling_history  <code>property</code>","text":"<pre><code>sampling_history: NDArray[int]\n</code></pre> <p>The history of the numbers of samples of each level of the telescopic sum.</p> <p><code>algo.sampling_size_history[i, l]</code> is the number of samples at iteration <code>i+1</code> and level <code>l</code>.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.mlmc_mlcv.MLMCMLCV-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.mlmc_mlcv.MLMCMLCV.Variant","title":"Variant","text":"<p>               Bases: <code>StrEnum</code></p> <p>A variant of the MLMC-MLCV algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.mlmc_mlcv.MLMCMLCV-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.mlmc_mlcv.MLMCMLCV.execute","title":"execute","text":"<pre><code>execute() -&gt; None\n</code></pre> <p>Execute the algorithm.</p> Source code in <code>src/gemseo_umdo/statistics/multilevel/mlmc/mlmc.py</code> <pre><code>def execute(self) -&gt; None:\n    \"\"\"Execute the algorithm.\"\"\"\n    # The current version of the algorithm samples only one level at a time,\n    # except at the first iteration where it samples them all.\n    levels_to_be_sampled = list(range(self._n_levels))\n\n    # Initialize the iteration of the algorithm.\n    is_last_iteration = False\n    iteration = 0\n\n    # As long as there is budget left\n    LOGGER.info(\"Start sampling with a total budget of %s\", self.__total_budget)\n    while self.__current_budget &gt;= 0:\n        iteration += 1\n        if is_last_iteration:\n            LOGGER.info(\"   Iteration #%s (last iteration)\", iteration)\n        else:\n            LOGGER.info(\"   Iteration #%s\", iteration)\n\n        # Append the budget to the budget history.\n        self.__budget_history.append(self.__current_budget)\n\n        # Sample the selected levels of the TS.\n        levels_to_samples = self.__compute_samples(*levels_to_be_sampled)\n\n        # Select the next level l_star of the TS to be sampled\n        # and estimate the statistic.\n        (\n            l_star,\n            self.__pilot_statistic_estimation,\n        ) = self.__pilot_statistic_estimator.compute_next_level_and_statistic(\n            levels_to_be_sampled,\n            self.__n_l,\n            levels_to_samples,\n            *self._pilot_statistic_estimator_parameters,\n        )\n\n        # Stop the algorithm if it is the last iteration.\n        if is_last_iteration:\n            break\n\n        # The current version of the algorithm samples only one level at a time.\n        levels_to_be_sampled = [l_star]\n\n        # Define the corresponding sample size.\n        delta_n_l_star = int(\n            math.floor((self.__r_l[l_star] - 1) * self.__n_l[l_star])\n        )\n        n_l_star = self.__n_l[l_star] + delta_n_l_star\n        LOGGER.info(\"      Find the next level to sample\")\n        LOGGER.info(\"         l_star = %s\", l_star)\n        LOGGER.info(\"         d_n_l_star = %s\", delta_n_l_star)\n        LOGGER.info(\"         n_l_star = %s\", n_l_star)\n\n        # If the new sampling stage is too expensive, reduce the number of samples.\n        posterior_budget = (\n            self.__current_budget - delta_n_l_star * self.__costs[l_star]\n        )\n        if posterior_budget &lt; 0:\n            LOGGER.info(\"         Maximum budget exceeded by %s\", -posterior_budget)\n            LOGGER.info(\n                \"         Decrease d_n_l_star to respect the maximum budget\"\n            )\n\n            # There is a budget to do at most one iteration.\n            is_last_iteration = True\n\n            # Update the numbers of additional samples at level l_star\n            # to achieve a positive or zero budget.\n            delta_n_l_star = int(\n                delta_n_l_star + posterior_budget / self.__costs[l_star]\n            )\n            n_l_star = self.__n_l[l_star] + delta_n_l_star\n            LOGGER.info(\"         d_n_l_star = %s\", delta_n_l_star)\n            LOGGER.info(\"         n_l_star = %s\", n_l_star)\n            # Stop the algorithm if one can no longer sample l_star.\n            if delta_n_l_star == 0:\n                LOGGER.info(\n                    \"Stop the algorithm as sampling l_star is too expensive.\"\n                )\n                break\n\n        # Update the history of number of samples of each level\n        # (0 for all the levels, but l_star).\n        self.__delta_n_l = zeros(self._n_levels)\n        self.__delta_n_l[l_star] = delta_n_l_star\n        self.__n_l[l_star] += delta_n_l_star\n        self.__n_samples_history.extend([self.__delta_n_l.copy()])\n\n    LOGGER.info(\"Sampling completed\")\n    LOGGER.info(\"Results\")\n    LOGGER.info(\"   Pilot statistic = %s\", self.pilot_statistic_estimation)\n    LOGGER.info(\"   Total cost = %s\", sum(self.__n_l * self.__costs))\n    LOGGER.info(\"   Cost allocation\")\n    levels_to_total_costs = self.__n_l * self.__costs\n    levels_to_total_costs = levels_to_total_costs / sum(levels_to_total_costs)\n    for level, total_cost in enumerate(levels_to_total_costs):\n        LOGGER.info(\"      Level %s: %s\", level, f\"{total_cost:.1%}\")\n\n    LOGGER.info(\"   n_l\")\n    for level in range(self._n_levels):\n        LOGGER.info(\"       n_%s = %s\", level, self.__n_l[level])\n\n    LOGGER.info(\"   V_l\")\n    self.__V_l = self.__pilot_statistic_estimator.V_l\n    for level in range(self._n_levels):\n        LOGGER.info(\"       V_%s = %s\", level, f\"{self.__V_l[level]:.2e}\")\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.mlmc_mlcv.MLMCMLCV.get_surrogate_positions","title":"get_surrogate_positions  <code>classmethod</code>","text":"<pre><code>get_surrogate_positions(\n    level: int, n_levels: int, variant: Variant\n) -&gt; slice\n</code></pre> <p>Return the positions of the surrogate models for given level and variant.</p> <p>These are their positions in a sequence starting to count at 0. So, the position of \\(g_\\ell\\) is \\(\\ell\\) for \\(\\ell\\in\\{0,\\ldots,L\\}\\) while the position of \\(h_\\ell\\) is \\(\\ell-1\\) for \\(\\ell\\in\\{1,\\ldots,L\\}\\).</p> <p>Parameters:</p> <ul> <li> <code>level</code>               (<code>int</code>)           \u2013            <p>The level of the telescopic sum.</p> </li> <li> <code>n_levels</code>               (<code>int</code>)           \u2013            <p>The number of levels.</p> </li> <li> <code>variant</code>               (<code>Variant</code>)           \u2013            <p>The variant of the algorithm.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>slice</code>           \u2013            <p>The positions of the surrogate models.</p> </li> </ul> See Also <p>El Amri et al., Table 1, Multilevel Surrogate-based Control Variates, 2023.</p> Source code in <code>src/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv.py</code> <pre><code>@classmethod\ndef get_surrogate_positions(\n    cls, level: int, n_levels: int, variant: Variant\n) -&gt; slice:\n    r\"\"\"Return the positions of the surrogate models for given level and variant.\n\n    These are their positions in a sequence starting to count at 0.\n    So,\n    the position of $g_\\ell$ is $\\ell$\n    for $\\ell\\in\\{0,\\ldots,L\\}$\n    while\n    the position of $h_\\ell$ is $\\ell-1$\n    for $\\ell\\in\\{1,\\ldots,L\\}$.\n\n    Args:\n        level: The level of the telescopic sum.\n        n_levels: The number of levels.\n        variant: The variant of the algorithm.\n\n    Returns:\n        The positions of the surrogate models.\n\n    See Also:\n        El Amri et al., Table 1, Multilevel Surrogate-based Control Variates, 2023.\n    \"\"\"\n    if level == 0:\n        if variant == cls.Variant.MLMC_MLCV:\n            return slice(0, n_levels)\n\n        if variant == cls.Variant.MLMC_CV:\n            return slice(0, 1)\n\n        if variant == cls.Variant.MLMC_MLCV_0:\n            return slice(0, 2)\n\n        return slice(0, 1)\n\n    if variant == cls.Variant.MLMC_MLCV:\n        return slice(0, n_levels - 1)\n\n    if variant == cls.Variant.MLMC_CV:\n        return slice(level - 1, level)\n\n    if variant == cls.Variant.MLMC_MLCV_0:\n        return slice(0, 1)\n\n    return slice(0, 0)\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/mlmc_mlcv/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.mlmc_mlcv.MLMCMLCV.plot_evaluation_history","title":"plot_evaluation_history","text":"<pre><code>plot_evaluation_history(\n    show: bool = True,\n    file_path: str | Path | None = None,\n    log_n_evaluations: bool = True,\n    log_budget: bool = False,\n) -&gt; None\n</code></pre> <p>Plot the history of the model evaluations in terms of sample size and budget.</p> <p>Parameters:</p> <ul> <li> <code>show</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to display the graph.</p> </li> <li> <code>file_path</code>               (<code>str | Path | None</code>, default:                   <code>None</code> )           \u2013            <p>The file path to save the graph.</p> </li> <li> <code>log_n_evaluations</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to use a log-scale for the number of evaluations.</p> </li> <li> <code>log_budget</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to use a log-scale for the budget.</p> </li> </ul> Source code in <code>src/gemseo_umdo/statistics/multilevel/mlmc/mlmc.py</code> <pre><code>def plot_evaluation_history(\n    self,\n    show: bool = True,\n    file_path: str | Path | None = None,\n    log_n_evaluations: bool = True,\n    log_budget: bool = False,\n) -&gt; None:\n    \"\"\"Plot the history of the model evaluations in terms of sample size and budget.\n\n    Args:\n        show: Whether to display the graph.\n        file_path: The file path to save the graph.\n        log_n_evaluations: Whether to use a log-scale for the number of evaluations.\n        log_budget: Whether to use a log-scale for the budget.\n    \"\"\"\n    fig, (ax1, ax2) = plt.subplots(ncols=2)\n    iterations = [i + 1 for i, _ in enumerate(self.__n_samples_history)]\n    ax1.plot(\n        iterations,\n        cumsum(array(self.__n_samples_history), axis=0),\n        label=[rf\"$f_{level}$\" for level in range(self._n_levels)],\n        marker=\".\",\n    )\n    if log_n_evaluations:\n        ax1.set_yscale(\"log\")\n\n    ax1.set_xlabel(\"Iteration\")\n    ax1.set_ylabel(\"Cumulated number of evaluations\")\n    ax1.legend(title=\"Simulators\")\n    ax1.grid(which=\"both\")\n    data = (array(self.__n_samples_history) * self.__costs).T\n    ax2.bar(iterations, data[0], label=r\"$f_0$\")\n    for index, row in enumerate(data[1:]):\n        ax2.bar(\n            iterations,\n            row,\n            bottom=data[0 : index + 1].sum(0),\n            label=rf\"$f_{index + 1}$\",\n        )\n\n    if log_budget:\n        ax2.set_yscale(\"log\")\n\n    ax2.set_xlabel(\"Iteration\")\n    ax2.set_ylabel(\"Cost\")\n    ax2.legend(title=\"Simulators\")\n    ax2.grid(which=\"both\")\n    ax2.set_axisbelow(True)\n    save_show_figure(fig, show, file_path, fig_size=(10, 3))\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/","title":"Pilots","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.pilots","title":"pilots","text":"<p>A set of pilots for the MLMC-MLCV algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/base_mlmc_mlcv_pilot/","title":"Base mlmc mlcv pilot","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/base_mlmc_mlcv_pilot/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.pilots.base_mlmc_mlcv_pilot","title":"base_mlmc_mlcv_pilot","text":"<p>The base pilot class for the MLMC-MLCV algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/base_mlmc_mlcv_pilot/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.pilots.base_mlmc_mlcv_pilot-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/base_mlmc_mlcv_pilot/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.pilots.base_mlmc_mlcv_pilot.BaseMLMCMLCVPilot","title":"BaseMLMCMLCVPilot","text":"<pre><code>BaseMLMCMLCVPilot(\n    sampling_ratios: NDArray[float], costs: NDArray[float]\n)\n</code></pre> <p>               Bases: <code>BasePilot</code></p> <p>The base pilot class for the MLMC-MLCV algorithm.</p> See Also <p>El Amri et al., Algo. 1, Multilevel Surrogate-based Control Variates, 2023.</p> <p>Parameters:</p> <ul> <li> <code>sampling_ratios</code>               (<code>NDArray[float]</code>)           \u2013            <p>The sampling ratios \\(r_0,\\ldots,r_L\\); the sampling ratio \\(r_\\ell\\) is the factor by which \\(n_\\ell\\) is increased between two sampling steps on the level \\(ell\\).</p> </li> <li> <code>costs</code>               (<code>NDArray[float]</code>)           \u2013            <p>The unit sampling costs of each level of the telescopic sum. Namely, \\((\\mathcal{C}_{\\ell-1}+\\mathcal{C}_\\ell)_{\\ell\\in\\{0,\\ldots,L\\}}\\) with \\(\\mathcal{C}_{-1}=0\\).</p> </li> </ul> Source code in <code>src/gemseo_umdo/statistics/multilevel/base_pilot.py</code> <pre><code>def __init__(self, sampling_ratios: NDArray[float], costs: NDArray[float]) -&gt; None:\n    r\"\"\"\n    Args:\n        sampling_ratios: The sampling ratios $r_0,\\ldots,r_L$;\n            the sampling ratio $r_\\ell$ is\n            the factor by which $n_\\ell$ is increased\n            between two sampling steps on the level $ell$.\n        costs: The unit sampling costs of each level of the telescopic sum.\n            Namely,\n            $(\\mathcal{C}_{\\ell-1}+\\mathcal{C}_\\ell)_{\\ell\\in\\{0,\\ldots,L\\}}$\n            with $\\mathcal{C}_{-1}=0$.\n    \"\"\"  # noqa: D205 D212 D415\n    self.__costs = costs\n    self.__r_l = sampling_ratios\n    self.V_l = array([nan] * len(self.__r_l))\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/base_mlmc_mlcv_pilot/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.pilots.base_mlmc_mlcv_pilot.BaseMLMCMLCVPilot-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/base_mlmc_mlcv_pilot/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.pilots.base_mlmc_mlcv_pilot.BaseMLMCMLCVPilot.V_l","title":"V_l  <code>instance-attribute</code>","text":"<pre><code>V_l: NDArray[float] = array([nan] * len(__r_l))\n</code></pre> <p>The terms variances \\(\\mathcal{V}_0,\\ldots,\\mathcal{V}_L\\).</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/base_mlmc_mlcv_pilot/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.pilots.base_mlmc_mlcv_pilot.BaseMLMCMLCVPilot-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/base_mlmc_mlcv_pilot/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.pilots.base_mlmc_mlcv_pilot.BaseMLMCMLCVPilot.compute_next_level_and_statistic","title":"compute_next_level_and_statistic","text":"<pre><code>compute_next_level_and_statistic(\n    levels: Iterable[int],\n    total_n_samples: NDArray[int],\n    samples: Sequence[NDArray[float]],\n    *pilot_parameters: Any\n) -&gt; tuple[int, NDArray[float]]\n</code></pre> <p>Compute the next level \\(\\ell^*\\) to sample and estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>levels</code>               (<code>Iterable[int]</code>)           \u2013            <p>The levels that have just been sampled.</p> </li> <li> <code>total_n_samples</code>               (<code>NDArray[int]</code>)           \u2013            <p>The total number of samples of each level.</p> </li> <li> <code>samples</code>               (<code>Sequence[NDArray[float]]</code>)           \u2013            <p>The samples of the different quantities of each level.</p> </li> <li> <code>*pilot_parameters</code>               (<code>Any</code>, default:                   <code>()</code> )           \u2013            <p>The parameters of the pilot.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[int, NDArray[float]]</code>           \u2013            <p>The next level \\(\\ell^*\\) to sample and an estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/statistics/multilevel/base_pilot.py</code> <pre><code>def compute_next_level_and_statistic(\n    self,\n    levels: Iterable[int],\n    total_n_samples: NDArray[int],\n    samples: Sequence[NDArray[float]],\n    *pilot_parameters: Any,\n) -&gt; tuple[int, NDArray[float]]:\n    r\"\"\"Compute the next level $\\ell^*$ to sample and estimate the statistic.\n\n    Args:\n        levels: The levels that have just been sampled.\n        total_n_samples: The total number of samples of each level.\n        samples: The samples of the different quantities of each level.\n        *pilot_parameters: The parameters of the pilot.\n\n    Returns:\n        The next level $\\ell^*$ to sample and an estimation of the statistic.\n    \"\"\"\n    self.V_l = self._compute_V_l(levels, samples, *pilot_parameters)\n    # WARNING: do not replace \"/ total_n_samples / total_n_samples\"\n    #          by \"/ total_n_samples**2\"\n    #          to avoid numerical division issue due to an excessively big number.\n    return (\n        argmax(\n            self.V_l / self.__r_l / total_n_samples / total_n_samples / self.__costs\n        ),\n        self._compute_statistic(),\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/factory/","title":"Factory","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/factory/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.pilots.factory","title":"factory","text":"<p>A factory of pilots for the MLMC-MLCV algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/factory/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.pilots.factory-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/factory/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.pilots.factory.MLMCMLCVPilotFactory","title":"MLMCMLCVPilotFactory","text":"<p>               Bases: <code>BaseFactory</code></p> <p>A factory of pilots for the MLMC-MLCV algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/mean/","title":"Mean","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/mean/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.pilots.mean","title":"mean","text":"<p>The mean-based pilot for the MLMC-MLCV algorithm.</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/mean/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.pilots.mean-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/mean/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.pilots.mean.Mean","title":"Mean","text":"<pre><code>Mean(\n    sampling_ratios: NDArray[float], costs: NDArray[float]\n)\n</code></pre> <p>               Bases: <code>BaseMLMCMLCVPilot</code></p> <p>The mean-based pilot for the MLMC-MLCV algorithm.</p> See Also <p>El Amri et al., Algo. 1, Multilevel Surrogate-based Control Variates, 2023.</p> <p>Parameters:</p> <ul> <li> <code>sampling_ratios</code>               (<code>NDArray[float]</code>)           \u2013            <p>The sampling ratios \\(r_0,\\ldots,r_L\\); the sampling ratio \\(r_\\ell\\) is the factor by which \\(n_\\ell\\) is increased between two sampling steps on the level \\(ell\\).</p> </li> <li> <code>costs</code>               (<code>NDArray[float]</code>)           \u2013            <p>The unit sampling costs of each level of the telescopic sum. Namely, \\((\\mathcal{C}_{\\ell-1}+\\mathcal{C}_\\ell)_{\\ell\\in\\{0,\\ldots,L\\}}\\) with \\(\\mathcal{C}_{-1}=0\\).</p> </li> </ul> Source code in <code>src/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/mean.py</code> <pre><code>def __init__(  # noqa: D107\n    self, sampling_ratios: NDArray[float], costs: NDArray[float]\n) -&gt; None:\n    super().__init__(sampling_ratios, costs)\n    self.__delta = [array([]) for _ in range(len(sampling_ratios))]\n</code></pre>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/mean/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.pilots.mean.Mean-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/mean/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.pilots.mean.Mean.V_l","title":"V_l  <code>instance-attribute</code>","text":"<pre><code>V_l: NDArray[float] = array([nan] * len(__r_l))\n</code></pre> <p>The terms variances \\(\\mathcal{V}_0,\\ldots,\\mathcal{V}_L\\).</p>"},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/mean/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.pilots.mean.Mean-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/statistics/multilevel/mlmc_mlcv/pilots/mean/#gemseo_umdo.statistics.multilevel.mlmc_mlcv.pilots.mean.Mean.compute_next_level_and_statistic","title":"compute_next_level_and_statistic","text":"<pre><code>compute_next_level_and_statistic(\n    levels: Iterable[int],\n    total_n_samples: NDArray[int],\n    samples: Sequence[NDArray[float]],\n    *pilot_parameters: Any\n) -&gt; tuple[int, NDArray[float]]\n</code></pre> <p>Compute the next level \\(\\ell^*\\) to sample and estimate the statistic.</p> <p>Parameters:</p> <ul> <li> <code>levels</code>               (<code>Iterable[int]</code>)           \u2013            <p>The levels that have just been sampled.</p> </li> <li> <code>total_n_samples</code>               (<code>NDArray[int]</code>)           \u2013            <p>The total number of samples of each level.</p> </li> <li> <code>samples</code>               (<code>Sequence[NDArray[float]]</code>)           \u2013            <p>The samples of the different quantities of each level.</p> </li> <li> <code>*pilot_parameters</code>               (<code>Any</code>, default:                   <code>()</code> )           \u2013            <p>The parameters of the pilot.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[int, NDArray[float]]</code>           \u2013            <p>The next level \\(\\ell^*\\) to sample and an estimation of the statistic.</p> </li> </ul> Source code in <code>src/gemseo_umdo/statistics/multilevel/base_pilot.py</code> <pre><code>def compute_next_level_and_statistic(\n    self,\n    levels: Iterable[int],\n    total_n_samples: NDArray[int],\n    samples: Sequence[NDArray[float]],\n    *pilot_parameters: Any,\n) -&gt; tuple[int, NDArray[float]]:\n    r\"\"\"Compute the next level $\\ell^*$ to sample and estimate the statistic.\n\n    Args:\n        levels: The levels that have just been sampled.\n        total_n_samples: The total number of samples of each level.\n        samples: The samples of the different quantities of each level.\n        *pilot_parameters: The parameters of the pilot.\n\n    Returns:\n        The next level $\\ell^*$ to sample and an estimation of the statistic.\n    \"\"\"\n    self.V_l = self._compute_V_l(levels, samples, *pilot_parameters)\n    # WARNING: do not replace \"/ total_n_samples / total_n_samples\"\n    #          by \"/ total_n_samples**2\"\n    #          to avoid numerical division issue due to an excessively big number.\n    return (\n        argmax(\n            self.V_l / self.__r_l / total_n_samples / total_n_samples / self.__costs\n        ),\n        self._compute_statistic(),\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/use_cases/","title":"Use cases","text":""},{"location":"reference/gemseo_umdo/use_cases/#gemseo_umdo.use_cases","title":"use_cases","text":"<p>Some use cases for uncertainty quantification and robust optimization.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/","title":"Beam model","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/#gemseo_umdo.use_cases.beam_model","title":"beam_model","text":"<p>The beam model.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/advanced_uncertain_space/","title":"Advanced uncertain space","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/advanced_uncertain_space/#gemseo_umdo.use_cases.beam_model.advanced_uncertain_space","title":"advanced_uncertain_space","text":"<p>The advanced uncertain space for the beam use case.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/advanced_uncertain_space/#gemseo_umdo.use_cases.beam_model.advanced_uncertain_space-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/advanced_uncertain_space/#gemseo_umdo.use_cases.beam_model.advanced_uncertain_space-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/advanced_uncertain_space/#gemseo_umdo.use_cases.beam_model.advanced_uncertain_space.AdvancedBeamUncertainSpace","title":"AdvancedBeamUncertainSpace","text":"<pre><code>AdvancedBeamUncertainSpace(\n    nominal_values: Mapping[str, float] | None = None,\n    **dispersions: float\n)\n</code></pre> <p>               Bases: <code>ParameterSpace</code></p> <p>The advanced uncertain space for the beam use case.</p> <p>Parameters:</p> <ul> <li> <code>nominal_values</code>               (<code>Mapping[str, float] | None</code>, default:                   <code>None</code> )           \u2013            <p>The nominal values of some uncertain variables. For missing ones, use the default values of the variables available in <code>gemseo_umdo.use_cases.beam_model.core.variables</code>.</p> </li> <li> <code>**dispersions</code>               (<code>float</code>, default:                   <code>{}</code> )           \u2013            <p>The dispersions around the nominal values.</p> </li> </ul> Source code in <code>src/gemseo_umdo/use_cases/beam_model/advanced_uncertain_space.py</code> <pre><code>def __init__(\n    self, nominal_values: Mapping[str, float] | None = None, **dispersions: float\n) -&gt; None:\n    \"\"\"\n    Args:\n        nominal_values: The nominal values of some uncertain variables.\n            For missing ones,\n            use the default values of the variables available in\n            `gemseo_umdo.use_cases.beam_model.core.variables`.\n        **dispersions: The dispersions around the nominal values.\n    \"\"\"  # noqa: D205 D212 D415\n    super().__init__()\n    variables = [\n        b,\n        h,\n        t,\n        L,\n        alpha,\n        beta,\n        dy,\n        dz,\n        E,\n        Variable(\"Rd\", 180.0),\n        Variable(\"Ry\", 600.0),\n    ]\n    self.__nominal_values = {\n        variable.name: variable.value for variable in variables\n    }\n    if nominal_values is not None:\n        self.__nominal_values.update(nominal_values)\n\n    for variable in variables[:4]:\n        name = variable.name\n        nominal_value = variable.value\n        delta = dispersions.get(name, self.__DEFAULT_DISPERSION)\n        self.add_random_variable(\n            name,\n            \"OTUniformDistribution\",\n            minimum=nominal_value - delta,\n            maximum=nominal_value + delta,\n        )\n\n    for variable in variables[4:]:\n        self.__add_truncated_normal(variable.name, **dispersions)\n</code></pre>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/constraints/","title":"Constraints","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/constraints/#gemseo_umdo.use_cases.beam_model.constraints","title":"constraints","text":"<p>The discipline computing the constraints for the beam use case.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/constraints/#gemseo_umdo.use_cases.beam_model.constraints-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/constraints/#gemseo_umdo.use_cases.beam_model.constraints-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/constraints/#gemseo_umdo.use_cases.beam_model.constraints.BeamConstraints","title":"BeamConstraints","text":"<pre><code>BeamConstraints()\n</code></pre> <p>               Bases: <code>Discipline</code></p> <p>The discipline computing the constraints of the beam problem.</p> <p>More particularly, the left-hand sides of</p> <ul> <li>the stress constraints \\(\\sigma_{\\mathrm{VM}}/\\sigma_{\\mathrm{all}} \\leq 1\\),</li> <li>the displacements constraints \\(\\Delta/\\Delta_{\\mathrm{min}} \\geq 1\\).</li> </ul> <p>Initialize self.  See help(type(self)) for accurate signature.</p> Source code in <code>src/gemseo_umdo/use_cases/beam_model/constraints.py</code> <pre><code>def __init__(self) -&gt; None:  # noqa: D107\n    super().__init__()\n    self.input_grammar.update_from_names([\n        self.__DISPL,\n        self.__SIGMA_VM,\n        sigma_all.name,\n    ])\n    self.output_grammar.update_from_names([self.__C_DISPL, self.__C_STRESS])\n    self.default_input_data = {\n        sigma_all.name: array([sigma_all.value]),\n        self.__SIGMA_VM: array([300.0]),\n        self.__DISPL: array([100.0]),\n    }\n</code></pre>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/design_space/","title":"Design space","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/design_space/#gemseo_umdo.use_cases.beam_model.design_space","title":"design_space","text":"<p>The design space for the beam use case.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/design_space/#gemseo_umdo.use_cases.beam_model.design_space-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/design_space/#gemseo_umdo.use_cases.beam_model.design_space.BeamDesignSpace","title":"BeamDesignSpace","text":"<pre><code>BeamDesignSpace()\n</code></pre> <p>               Bases: <code>DesignSpace</code></p> <p>The design space for the beam use case.</p> Source code in <code>src/gemseo_umdo/use_cases/beam_model/design_space.py</code> <pre><code>def __init__(self) -&gt; None:  # noqa: D107\n    super().__init__()\n    for variable in BeamDesignVariables:\n        self.add_variable(\n            variable.value.name,\n            lower_bound=variable.value.l_b,\n            upper_bound=variable.value.u_b,\n            value=variable.value.value,\n        )\n</code></pre>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/discipline/","title":"Discipline","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/discipline/#gemseo_umdo.use_cases.beam_model.discipline","title":"discipline","text":"<p>The discipline for the beam use case.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/discipline/#gemseo_umdo.use_cases.beam_model.discipline-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/discipline/#gemseo_umdo.use_cases.beam_model.discipline-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/discipline/#gemseo_umdo.use_cases.beam_model.discipline.Beam","title":"Beam","text":"<pre><code>Beam(n_y: int = 3, n_z: int = 3)\n</code></pre> <p>               Bases: <code>Discipline</code></p> <p>The beam discipline.</p> See Also <p>BeamModel for more information about the beam model.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>n_y</code>               (<code>int</code>, default:                   <code>3</code> )           \u2013            <p>The number of discretization points in the y-direction.</p> </li> <li> <code>n_z</code>               (<code>int</code>, default:                   <code>3</code> )           \u2013            <p>The number of discretization points in the z-direction.</p> </li> </ul> Source code in <code>src/gemseo_umdo/use_cases/beam_model/discipline.py</code> <pre><code>def __init__(self, n_y: int = 3, n_z: int = 3) -&gt; None:\n    \"\"\"\n    Args:\n        n_y: The number of discretization points in the y-direction.\n        n_z: The number of discretization points in the z-direction.\n    \"\"\"  # noqa: D205 D212 D415\n    super().__init__()\n    input_variables = [b, h, t, L, E, alpha, beta, dy, dz, rho, F, nu]\n    self.input_grammar.update_from_names([\n        variable.name for variable in input_variables\n    ])\n    self.output_grammar.update_from_names([\n        f.name for f in fields(BeamModelOutputData)\n    ])\n    self.default_input_data = {\n        variable.name: array([variable.value]) for variable in input_variables\n    }\n    self.__beam_model = BeamModel(n_y, n_z)\n</code></pre>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/uncertain_space/","title":"Uncertain space","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/uncertain_space/#gemseo_umdo.use_cases.beam_model.uncertain_space","title":"uncertain_space","text":"<p>The uncertain space for the beam use case.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/uncertain_space/#gemseo_umdo.use_cases.beam_model.uncertain_space-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/uncertain_space/#gemseo_umdo.use_cases.beam_model.uncertain_space-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/uncertain_space/#gemseo_umdo.use_cases.beam_model.uncertain_space.BeamUncertainSpace","title":"BeamUncertainSpace","text":"<pre><code>BeamUncertainSpace(uniform: bool = True, **deltas: float)\n</code></pre> <p>               Bases: <code>ParameterSpace</code></p> <p>The advanced uncertain space for the beam use case.</p> <p>\\(F\\), \\(E\\) and \\(\\sigma_{\\text{all}}\\) are random variables with nominal values -200000, 73500 and 300 and deviation values 10%, 5% and 5%.</p> <p>Their probability distribution are centered in these values denoted \\(\\mu_F\\), \\(\\mu_E\\) and \\(\\mu_{\\sigma_{\\text{all}}}\\).</p> <p>Precisely, a uniform distribution is defined by the minimum \\(\\mu (1 - \\delta)\\) and the maximum \\(\\mu (1 + \\delta)\\) and a Gaussian distribution is defined by the mean \\(\\mu\\) and the standard deviation \\(|\\mu|\\delta/3\\), where \\(\\delta\\) is an aforementioned deviation value.</p> <p>Parameters:</p> <ul> <li> <code>uniform</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If <code>True</code>, use uniform distributions; otherwise, use Gaussian ones.</p> </li> <li> <code>**deltas</code>               (<code>float</code>, default:                   <code>{}</code> )           \u2013            <p>The percentage variations \\(\\delta\\) around the nominal values of the random variables.</p> </li> </ul> Source code in <code>src/gemseo_umdo/use_cases/beam_model/uncertain_space.py</code> <pre><code>def __init__(self, uniform: bool = True, **deltas: float) -&gt; None:\n    r\"\"\"\n    Args:\n        uniform: If `True`, use uniform distributions;\n            otherwise, use Gaussian ones.\n        **deltas: The percentage variations $\\delta$ around the nominal values\n            of the random variables.\n    \"\"\"  # noqa: D205 D212 D415\n    super().__init__()\n    for variable in [F, E, sigma_all]:\n        nominal = variable.value\n        name = variable.name\n        delta = deltas.pop(name, self.__DEFAULT_DELTA[name]) / 100\n        if uniform:\n            minimum, maximum = sorted([\n                nominal * (1 - delta),\n                nominal * (1 + delta),\n            ])\n            self.add_random_variable(\n                name,\n                \"OTUniformDistribution\",\n                minimum=minimum,\n                maximum=maximum,\n            )\n        else:\n            self.add_random_variable(\n                name,\n                \"OTNormalDistribution\",\n                mu=nominal,\n                sigma=abs(nominal) * delta / 3,\n            )\n</code></pre>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/","title":"Core","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/#gemseo_umdo.use_cases.beam_model.core","title":"core","text":"<p>The GEMSEO-free version of the beam use case.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/design_space/","title":"Design space","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/design_space/#gemseo_umdo.use_cases.beam_model.core.design_space","title":"design_space","text":"<p>The GEMSEO-free version of the design space for the beam use case.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/design_space/#gemseo_umdo.use_cases.beam_model.core.design_space-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/design_space/#gemseo_umdo.use_cases.beam_model.core.design_space-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/design_space/#gemseo_umdo.use_cases.beam_model.core.design_space.BeamDesignVariables","title":"BeamDesignVariables","text":"<p>               Bases: <code>Enum</code></p> <p>The design variables for the beam use case.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/design_space/#gemseo_umdo.use_cases.beam_model.core.design_space.BeamDesignVariables-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/design_space/#gemseo_umdo.use_cases.beam_model.core.design_space.BeamDesignVariables.h","title":"h  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>h = DesignVariable(name, 500, 800, value)\n</code></pre> <p>The height of the beam.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/design_space/#gemseo_umdo.use_cases.beam_model.core.design_space.BeamDesignVariables.t","title":"t  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>t = DesignVariable(name, 2, 10, value)\n</code></pre> <p>The thickness of the beam.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/design_space/#gemseo_umdo.use_cases.beam_model.core.design_space.DesignVariable","title":"DesignVariable","text":"<p>               Bases: <code>NamedTuple</code></p> <p>A design variable.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/design_space/#gemseo_umdo.use_cases.beam_model.core.design_space.DesignVariable-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/design_space/#gemseo_umdo.use_cases.beam_model.core.design_space.DesignVariable.l_b","title":"l_b  <code>instance-attribute</code>","text":"<pre><code>l_b: float\n</code></pre> <p>The lower bound of the design variable.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/design_space/#gemseo_umdo.use_cases.beam_model.core.design_space.DesignVariable.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre> <p>The name of the design variable.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/design_space/#gemseo_umdo.use_cases.beam_model.core.design_space.DesignVariable.u_b","title":"u_b  <code>instance-attribute</code>","text":"<pre><code>u_b: float\n</code></pre> <p>The upper bound of the design variable.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/design_space/#gemseo_umdo.use_cases.beam_model.core.design_space.DesignVariable.value","title":"value  <code>instance-attribute</code>","text":"<pre><code>value: float\n</code></pre> <p>The current value of the design variable.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/model/","title":"Model","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/model/#gemseo_umdo.use_cases.beam_model.core.model","title":"model","text":"<p>The GEMSEO-free version of the model for the beam use case.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/model/#gemseo_umdo.use_cases.beam_model.core.model-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/model/#gemseo_umdo.use_cases.beam_model.core.model-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/model/#gemseo_umdo.use_cases.beam_model.core.model.BeamModel","title":"BeamModel","text":"<pre><code>BeamModel(n_y: int = 3, n_z: int = 3)\n</code></pre> <p>The beam model.</p> <p>We consider an horizontal beam with length \\(L\\), width \\(b\\) and height \\(h\\). This beam is hollow and made of a material with a Young's modulus \\(E\\), a Poisson's ratio \\(\\nu\\) and a thickness \\(t\\). One of its ends is fixed at \\(x=0\\) (the \"root\") while the other  at \\(x=L\\) (the \"tip\") is free. The \\(y\\)-axis is horizontal and perpendicular to the beam, the \\(z\\) is vertical and the center of the root is at the origin \\((0, 0, 0)\\).</p> <p>A force \\(\\vec{F}\\) of amplitude \\(F\\) is applied to the beam at \\((L, dy, dz)\\) with an angle \\(\\alpha\\) w.r.t. \\(-\\vec{e}_y\\) in the xz-plane and an angle \\(\\beta\\) w.r.t. \\(-\\vec{e}_y\\) in the yz-plane, where \\(\\vec{e}_y\\) is the unit vector along the \\(y\\)-axis.</p> <p>From these settings, the model computes the weight of the beam \\(w=2 \\rho L (b + h -2t)\\) and several quantities on a regular \\(yz\\)-grid:</p> <ul> <li>the strain energy vector \\(\\vec{U}=(U_x,U_y,U_z)\\) at the tip,</li> <li>the normal stress \\(\\sigma\\) at the root,</li> <li>the torsional stress \\(\\tau\\) at the root,</li> <li>the displacement \\(\\delta\\) at the tip,</li> <li>the von Mises stress \\(\\sigma_{\\text{VM}}\\) at the root.</li> </ul> <p>The equations are:</p> <ul> <li>Force components<ul> <li>\\(F_x=F\\sin(\\alpha)\\)</li> <li>\\(F_y=F\\cos(\\alpha)\\sin(\\beta)\\)</li> <li>\\(F_z=F\\cos(\\alpha)\\cos(\\beta)\\)</li> </ul> </li> <li>Inertia<ul> <li>\\(I_x=(2tb^2h^2)/(b + h)\\)</li> <li>\\(I_y=(bh^3-(b-2t)(h-2t)^3)/12\\)</li> <li>\\(I_z=(hb^3-(h-2t)(b-2t)^3)/12\\)</li> </ul> </li> <li>Strain energy<ul> <li>\\(U_x = E^{-1} \\{ \\frac{ F_x L }{ 2t (b+h-2t) } +   zL (F_x dZ - F_z L/2) I_y^{-1} - yL (F_y L/2 - F_x dY) I_z^{-1} \\}\\)</li> <li>\\(U_y = E^{-1} \\{ (F_y L^3/3 - F_x dY L^2/2)I_z^{-1} -   zL \\frac{ F_zdY-F_ydZ }{ 2 (1+\\nu) I_x } \\}\\)</li> <li>\\(U_z = E^{-1} \\{ (F_z L^3/3 - F_xdZ L^2/2) I_y^{-1} +   yL \\frac{ F_zdY-F_ydZ }{ 2 (1+\\nu) I_x } \\}\\)</li> </ul> </li> <li>Displacements<ul> <li>\\(\\delta=\\sqrt{U_x^2+U_y^2+U_z^2}\\)</li> </ul> </li> <li>Torsional stress<ul> <li>\\(\\tau_x=(F_zdY-F_ydZ)/(2bht)\\)</li> <li>\\(\\tau_y= - (0.5|z|(b-t)+(b-t)^2(1-4y^2/(b-t)^2))F_y\\text{sign}(z)/(8I_z)\\)</li> <li>\\(\\tau_z=(0.5|y|(h-t)+(h-t)^2(1-4z^2/(h-t)^2))F_z\\text{sign}(y)/(8I_y)\\)</li> <li>\\(\\tau = \\tau_x + \\tau_y + \\tau_z\\)</li> </ul> </li> <li>Stress<ul> <li>\\(\\sigma = F_x/(2t(b+h-2t)) + y (F_xdY-F_yL)/I_z + z (F_xdZ-F_zL)/I_y\\)</li> </ul> </li> <li>von Mises stress<ul> <li>\\(\\sigma_{\\text{VM}} = \\sqrt{\\sigma^2 + 3\\tau^2}\\)</li> </ul> </li> </ul> <p>Parameters:</p> <ul> <li> <code>n_y</code>               (<code>int</code>, default:                   <code>3</code> )           \u2013            <p>The number of discretization points in the y-direction.</p> </li> <li> <code>n_z</code>               (<code>int</code>, default:                   <code>3</code> )           \u2013            <p>The number of discretization points in the z-direction.</p> </li> </ul> Source code in <code>src/gemseo_umdo/use_cases/beam_model/core/model.py</code> <pre><code>def __init__(self, n_y: int = 3, n_z: int = 3) -&gt; None:\n    \"\"\"\n    Args:\n        n_y: The number of discretization points in the y-direction.\n        n_z: The number of discretization points in the z-direction.\n    \"\"\"  # noqa: D205 D212 D415\n    self.__n_y = n_y\n    self.__n_z = n_z\n</code></pre>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/output_data/","title":"Output data","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/output_data/#gemseo_umdo.use_cases.beam_model.core.output_data","title":"output_data","text":"<p>The GEMSEO-free version of the output data for the beam use case.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/output_data/#gemseo_umdo.use_cases.beam_model.core.output_data-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/output_data/#gemseo_umdo.use_cases.beam_model.core.output_data.BeamModelOutputData","title":"BeamModelOutputData  <code>dataclass</code>","text":"<pre><code>BeamModelOutputData(\n    Ux: NDArray[float],\n    Uy: NDArray[float],\n    Uz: NDArray[float],\n    sigma: NDArray[float],\n    tau: NDArray[float],\n    displ: NDArray[float],\n    sigma_vm: NDArray[float],\n    w: float,\n    yz_grid: NDArray[float],\n)\n</code></pre> <p>Output data of the beam model.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/output_data/#gemseo_umdo.use_cases.beam_model.core.output_data.BeamModelOutputData-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/output_data/#gemseo_umdo.use_cases.beam_model.core.output_data.BeamModelOutputData.Ux","title":"Ux  <code>instance-attribute</code>","text":"<pre><code>Ux: NDArray[float]\n</code></pre> <p>The strain energy along the \\(x\\)-axis.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/output_data/#gemseo_umdo.use_cases.beam_model.core.output_data.BeamModelOutputData.Uy","title":"Uy  <code>instance-attribute</code>","text":"<pre><code>Uy: NDArray[float]\n</code></pre> <p>The strain energy along the \\(y\\)-axis.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/output_data/#gemseo_umdo.use_cases.beam_model.core.output_data.BeamModelOutputData.Uz","title":"Uz  <code>instance-attribute</code>","text":"<pre><code>Uz: NDArray[float]\n</code></pre> <p>The strain energy along the \\(z\\)-axis.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/output_data/#gemseo_umdo.use_cases.beam_model.core.output_data.BeamModelOutputData.displ","title":"displ  <code>instance-attribute</code>","text":"<pre><code>displ: NDArray[float]\n</code></pre> <p>The displacements at the tip section points.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/output_data/#gemseo_umdo.use_cases.beam_model.core.output_data.BeamModelOutputData.sigma","title":"sigma  <code>instance-attribute</code>","text":"<pre><code>sigma: NDArray[float]\n</code></pre> <p>The normal stress at the root section points.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/output_data/#gemseo_umdo.use_cases.beam_model.core.output_data.BeamModelOutputData.sigma_vm","title":"sigma_vm  <code>instance-attribute</code>","text":"<pre><code>sigma_vm: NDArray[float]\n</code></pre> <p>The von Mises stress at the root section points.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/output_data/#gemseo_umdo.use_cases.beam_model.core.output_data.BeamModelOutputData.tau","title":"tau  <code>instance-attribute</code>","text":"<pre><code>tau: NDArray[float]\n</code></pre> <p>The torsional stress at the root section points.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/output_data/#gemseo_umdo.use_cases.beam_model.core.output_data.BeamModelOutputData.w","title":"w  <code>instance-attribute</code>","text":"<pre><code>w: float\n</code></pre> <p>The weight of the beam.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/output_data/#gemseo_umdo.use_cases.beam_model.core.output_data.BeamModelOutputData.yz_grid","title":"yz_grid  <code>instance-attribute</code>","text":"<pre><code>yz_grid: NDArray[float]\n</code></pre> <p>The \\(yz\\)-grid coordinates.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/","title":"Variables","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables","title":"variables","text":"<p>Some variables of the GEMSEO-free version of the beam use case.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.E","title":"E  <code>module-attribute</code>","text":"<pre><code>E = Variable('E', 73500.0)\n</code></pre> <p>The Young's modulus of the material.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.F","title":"F  <code>module-attribute</code>","text":"<pre><code>F = Variable('F', -200000.0)\n</code></pre> <p>The load applied to a point at the tip of the beam.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.L","title":"L  <code>module-attribute</code>","text":"<pre><code>L = Variable('L', 5000.0)\n</code></pre> <p>The length of the beam.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.alpha","title":"alpha  <code>module-attribute</code>","text":"<pre><code>alpha = Variable('alpha', 0.0)\n</code></pre> <p>The angle between \\(-\\vec{e}_z\\) and \\(\\vec{F}\\) in \\(xy\\)-plane.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.b","title":"b  <code>module-attribute</code>","text":"<pre><code>b = Variable('b', 500.0)\n</code></pre> <p>The width of the beam.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.beta","title":"beta  <code>module-attribute</code>","text":"<pre><code>beta = Variable('beta', 0.0)\n</code></pre> <p>The angle between \\(-\\vec{e}_z\\) and \\(\\vec{F}\\) in \\(yz\\)-plane.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.dy","title":"dy  <code>module-attribute</code>","text":"<pre><code>dy = Variable('dy', 0.0)\n</code></pre> <p>The \\(y\\)-coordinate of the point where the force is applied.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.dz","title":"dz  <code>module-attribute</code>","text":"<pre><code>dz = Variable('dz', 0.0)\n</code></pre> <p>The \\(z\\)-coordinate of the point where the force is applied.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.h","title":"h  <code>module-attribute</code>","text":"<pre><code>h = Variable('h', 800.0)\n</code></pre> <p>The height of the beam.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.nu","title":"nu  <code>module-attribute</code>","text":"<pre><code>nu = Variable('nu', 0.33)\n</code></pre> <p>The Poisson's ratio.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.rho","title":"rho  <code>module-attribute</code>","text":"<pre><code>rho = Variable('rho', 2.8e-06)\n</code></pre> <p>The density of the material.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.sigma_all","title":"sigma_all  <code>module-attribute</code>","text":"<pre><code>sigma_all = Variable('sigma_all', 300.0)\n</code></pre> <p>A constant used by the stress constraints.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.t","title":"t  <code>module-attribute</code>","text":"<pre><code>t = Variable('t', 2.5)\n</code></pre> <p>The thickness of the beam.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.Variable","title":"Variable","text":"<p>               Bases: <code>NamedTuple</code></p> <p>A variable of the beam use case.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.Variable-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.Variable.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre> <p>The name of the variable.</p>"},{"location":"reference/gemseo_umdo/use_cases/beam_model/core/variables/#gemseo_umdo.use_cases.beam_model.core.variables.Variable.value","title":"value  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>value: float | None = None\n</code></pre> <p>The default value of the variable.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/","title":"Heat equation","text":""},{"location":"reference/gemseo_umdo/use_cases/heat_equation/#gemseo_umdo.use_cases.heat_equation","title":"heat_equation","text":"<p>The heat equation use case.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/configuration/","title":"Configuration","text":""},{"location":"reference/gemseo_umdo/use_cases/heat_equation/configuration/#gemseo_umdo.use_cases.heat_equation.configuration","title":"configuration","text":"<p>A configuration for the heat equation model.</p> <p>HeatEquationConfiguration is used by HeatEquationModel; read its docstring for more details.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/configuration/#gemseo_umdo.use_cases.heat_equation.configuration-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/use_cases/heat_equation/configuration/#gemseo_umdo.use_cases.heat_equation.configuration.HeatEquationConfiguration","title":"HeatEquationConfiguration  <code>dataclass</code>","text":"<pre><code>HeatEquationConfiguration(\n    mesh_size: int = 100,\n    n_modes: int = 21,\n    final_time: float = 0.5,\n    nu_bounds: tuple[float, float] = (0.001, 0.009),\n    rod_length: float = 1.0,\n)\n</code></pre> <p>A configuration for the heat equation model.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/configuration/#gemseo_umdo.use_cases.heat_equation.configuration.HeatEquationConfiguration-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/use_cases/heat_equation/configuration/#gemseo_umdo.use_cases.heat_equation.configuration.HeatEquationConfiguration.cost","title":"cost  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cost: int = field(init=False)\n</code></pre> <p>The evaluation cost of the HeatEquationModel.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/configuration/#gemseo_umdo.use_cases.heat_equation.configuration.HeatEquationConfiguration.expectation","title":"expectation  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>expectation: float = field(init=False)\n</code></pre> <p>The theoretical expectation of the integral of the temperature along the rod.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/configuration/#gemseo_umdo.use_cases.heat_equation.configuration.HeatEquationConfiguration.final_time","title":"final_time  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>final_time: float = 0.5\n</code></pre> <p>The time of interest, denoted \\(t_f\\).</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/configuration/#gemseo_umdo.use_cases.heat_equation.configuration.HeatEquationConfiguration.mesh","title":"mesh  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>mesh: NDArray[float] = field(init=False)\n</code></pre> <p>The mesh for the HeatEquationModel.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/configuration/#gemseo_umdo.use_cases.heat_equation.configuration.HeatEquationConfiguration.mesh_size","title":"mesh_size  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>mesh_size: int = 100\n</code></pre> <p>The number of equispaced spatial nodes.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/configuration/#gemseo_umdo.use_cases.heat_equation.configuration.HeatEquationConfiguration.n_modes","title":"n_modes  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>n_modes: int = 21\n</code></pre> <p>The number of modes of the truncated Fourier expansion.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/configuration/#gemseo_umdo.use_cases.heat_equation.configuration.HeatEquationConfiguration.nu_bounds","title":"nu_bounds  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>nu_bounds: tuple[float, float] = (0.001, 0.009)\n</code></pre> <p>The bounds of the thermal diffusivity.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/configuration/#gemseo_umdo.use_cases.heat_equation.configuration.HeatEquationConfiguration.rod_length","title":"rod_length  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>rod_length: float = 1.0\n</code></pre> <p>The length of the rod.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/discipline/","title":"Discipline","text":""},{"location":"reference/gemseo_umdo/use_cases/heat_equation/discipline/#gemseo_umdo.use_cases.heat_equation.discipline","title":"discipline","text":"<p>The heat equation discipline.</p> <p>This discipline wraps the HeatEquationModel; read its docstring for more details.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/discipline/#gemseo_umdo.use_cases.heat_equation.discipline-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/use_cases/heat_equation/discipline/#gemseo_umdo.use_cases.heat_equation.discipline.HeatEquation","title":"HeatEquation","text":"<pre><code>HeatEquation(\n    mesh_size: int = 100,\n    n_modes: int = 21,\n    final_time: float = 0.5,\n    nu_bounds: tuple[float, float] = (0.001, 0.009),\n    rod_length: float = 1.0,\n)\n</code></pre> <p>               Bases: <code>Discipline</code></p> <p>The discipline computing the temperature averaged over the rod at final time.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>mesh_size</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>The number of equispaced spatial nodes.</p> </li> <li> <code>n_modes</code>               (<code>int</code>, default:                   <code>21</code> )           \u2013            <p>The number of modes of the truncated Fourier expansion.</p> </li> <li> <code>final_time</code>               (<code>float</code>, default:                   <code>0.5</code> )           \u2013            <p>The time of interest.</p> </li> <li> <code>nu_bounds</code>               (<code>tuple[float, float]</code>, default:                   <code>(0.001, 0.009)</code> )           \u2013            <p>The bounds of the thermal diffusivity.</p> </li> <li> <code>rod_length</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>The length of the rod.</p> </li> </ul> Source code in <code>src/gemseo_umdo/use_cases/heat_equation/discipline.py</code> <pre><code>def __init__(\n    self,\n    mesh_size: int = 100,\n    n_modes: int = 21,\n    final_time: float = 0.5,\n    nu_bounds: tuple[float, float] = (0.001, 0.009),\n    rod_length: float = 1.0,\n) -&gt; None:\n    \"\"\"\n    Args:\n        mesh_size: The number of equispaced spatial nodes.\n        n_modes: The number of modes of the truncated Fourier expansion.\n        final_time: The time of interest.\n        nu_bounds: The bounds of the thermal diffusivity.\n        rod_length: The length of the rod.\n    \"\"\"  # noqa: D205 D212 D415\n    super().__init__(name=f\"{self.__class__.__name__}({mesh_size})\")\n    self.input_grammar.update_from_names([f\"X_{i}\" for i in range(1, 8)])\n    self.output_grammar.update_from_names([\"u\", \"u_mesh\"])\n    self.__heat_equation_model = HeatEquationModel(\n        mesh_size=mesh_size,\n        n_modes=n_modes,\n        final_time=final_time,\n        nu_bounds=nu_bounds,\n        rod_length=rod_length,\n    )\n    self.default_input_data = {\n        \"X_1\": array([0.0]),\n        \"X_2\": array([0.0]),\n        \"X_3\": array([0.0]),\n        \"X_4\": array([0.005]),\n        \"X_5\": array([0.0]),\n        \"X_6\": array([0.0]),\n        \"X_7\": array([0.0]),\n    }\n</code></pre>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/discipline/#gemseo_umdo.use_cases.heat_equation.discipline.HeatEquation-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/use_cases/heat_equation/discipline/#gemseo_umdo.use_cases.heat_equation.discipline.HeatEquation.configuration","title":"configuration  <code>property</code>","text":"<pre><code>configuration: HeatEquationConfiguration\n</code></pre> <p>The configuration.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/model/","title":"Model","text":""},{"location":"reference/gemseo_umdo/use_cases/heat_equation/model/#gemseo_umdo.use_cases.heat_equation.model","title":"model","text":"<p>The heat equation model.</p> <p>This model solves the 1D transient equation, a.k.a. heat equation. It describes the temperature evolution \\(u\\) in a \\(L\\)-length rod from the initial time 0 to the final time \\(T\\) with a thermal diffusivity \\(\\nu(\\mathbf{X})\\) depending on a random vector \\(\\mathbf{X}\\). The heat equation is</p> \\[\\frac{\\partial u(x,t;\\mathbf{X})}{\\partial t}    - \\nu(\\mathbf{X})\\frac{\\partial^2 u(x,t;\\mathbf{X})}{\\partial x^2} = 0\\] <p>with the boundary condition \\(u(0,t;\\mathbf{X})=u(L,t;\\mathbf{X})=0\\) where \\(x\\in\\mathcal{D}=[0,L]\\) and \\(t\\in[0,T]\\).</p> <p>To obtain an analytical solution, Geraci et al. (2015) chose \\(L=1\\) and the uncertain initial condition:</p> \\[u(x,0;\\mathbf{X}) =    \\mathcal{G}(\\mathbf{X})\\mathcal{F}_1(x)    +\\mathcal{I}(\\mathbf{X})\\mathcal{F}_2(x) \\] <p>where</p> <ul> <li>\\(\\mathcal{F}_1(x)=\\sin(\\pi x)\\),</li> <li>\\(\\mathcal{F}_2(x)=\\sin(2\\pi x)+\\sin(3\\pi x)           +50\\left(\\sin(9\\pi x)+\\sin(21\\pi x)\\right)\\),</li> <li>\\(\\mathcal{I}(\\mathbf{X})=3.5          \\left(\\sin(X_1)+7\\sin^2(X_2)+0.1X_3^4\\sin(X_1)\\right)\\),</li> <li>\\(\\mathcal{G}(\\mathbf{X})=50\\prod_{i=5}^7(4|X_i|-1)\\).</li> </ul> <p>This uncertainty on the initial condition is modelled by the random variables \\(X_1,\\ldots X_7\\) that are independent and distributed as:</p> <ul> <li>\\(X_i\\sim\\mathcal{U}(-\\pi,\\pi)\\), for \\(i\\in\\{1,2,3\\}\\),</li> <li>\\(\\nu(\\mathbf{X})=X_4\\sim\\mathcal{U}(\\nu_{\\min},\\nu_{\\max})\\),</li> <li>\\(X_i\\sim\\mathcal{U}(-1,1)\\), for \\(i\\in\\{5,6,7\\}\\).</li> </ul> <p>Then, Geraci et al. (2015) consider the integral of the temperature along the rod</p> \\[\\mathcal{M}(\\mathbf{X}) = \\int_{\\mathcal{D}}u(x,T;\\mathbf{X})dx\\] <p>and are interested in the estimation of its HeatEquationConfiguration:</p> \\[\\mathbb{E}[\\mathcal{M}(\\mathbf{X})] = 50H_1+\\frac{49}{4}(H_3+50H_9+50H_{21})\\] <p>where \\(H_k=\\frac{2}{k^3\\pi^3T} \\frac{\\exp(-\\nu_{\\min}k^2\\pi^2T)-\\exp(-\\nu_{\\max}k^2\\pi^2T)}{\\nu_{\\max}-\\nu_{\\min}}\\).</p> <p>The HeatEquationModel computes the temperature at final time from instances of the random variables <code>\"X_1\"</code>, ..., <code>\"X_7\"</code> defined over the HeatEquationUncertainSpace. The temperature <code>\"u_mesh\"</code> is computed at each mesh node while the temperature <code>\"u\"</code> is an integral over the rod.</p> See Also <p>Geraci et al., A multifidelity control variate approach for the multilevel Monte Carlo technique, Center for Turbulence Research, Annual Research Briefs, 2015.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/model/#gemseo_umdo.use_cases.heat_equation.model-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/use_cases/heat_equation/model/#gemseo_umdo.use_cases.heat_equation.model.HeatEquationModel","title":"HeatEquationModel","text":"<pre><code>HeatEquationModel(\n    mesh_size: int = 100,\n    n_modes: int = 21,\n    final_time: float = 0.5,\n    nu_bounds: tuple[float, float] = (0.001, 0.009),\n    rod_length: float = 1.0,\n)\n</code></pre> <p>The discipline computing the temperature averaged over the rod at final time.</p> <p>This discipline can also compute a first-order polynomial centered at the mean input value.</p> <p>Parameters:</p> <ul> <li> <code>mesh_size</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>The number of equispaced spatial nodes.</p> </li> <li> <code>n_modes</code>               (<code>int</code>, default:                   <code>21</code> )           \u2013            <p>The number of modes of the truncated Fourier expansion.</p> </li> <li> <code>final_time</code>               (<code>float</code>, default:                   <code>0.5</code> )           \u2013            <p>The time of interest.</p> </li> <li> <code>nu_bounds</code>               (<code>tuple[float, float]</code>, default:                   <code>(0.001, 0.009)</code> )           \u2013            <p>The bounds of the thermal diffusivity.</p> </li> <li> <code>rod_length</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>The length of the rod.</p> </li> </ul> Source code in <code>src/gemseo_umdo/use_cases/heat_equation/model.py</code> <pre><code>def __init__(\n    self,\n    mesh_size: int = 100,\n    n_modes: int = 21,\n    final_time: float = 0.5,\n    nu_bounds: tuple[float, float] = (0.001, 0.009),\n    rod_length: float = 1.0,\n) -&gt; None:\n    \"\"\"\n    Args:\n        mesh_size: The number of equispaced spatial nodes.\n        n_modes: The number of modes of the truncated Fourier expansion.\n        final_time: The time of interest.\n        nu_bounds: The bounds of the thermal diffusivity.\n        rod_length: The length of the rod.\n    \"\"\"  # noqa: D205 D212 D415\n    self.configuration = HeatEquationConfiguration(\n        mesh_size, n_modes, final_time, nu_bounds, rod_length\n    )\n    self.__nu_delta = nu_bounds[1] - nu_bounds[0]\n    self.__modes = linspace(1, n_modes, n_modes)\n    xx, nn = meshgrid(self.configuration.mesh, self.__modes, copy=False)\n    self.__sinus = sin(xx * nn * pi)[:, :, newaxis]\n    self.__default_input_value = array([0.0, 0.0, 0.0, 0.005, 0.0, 0.0, 0.0])\n    pi_mesh = pi * self.configuration.mesh\n    self.__F1 = sin(pi_mesh)  # noqa: N806\n    self.__F2 = (  # noqa: N806\n        sin(2 * pi_mesh)\n        + sin(3 * pi_mesh)\n        + 50 * (sin(9 * pi_mesh) + sin(21 * pi_mesh))\n    )\n    self.__term1 = self.__term2 = self.__term3 = self.__f_at_mu_X = 0\n    self.__compute_taylor_materials()\n    self.taylor_mean = self.__f_at_mu_X + 600 * self.__term1\n</code></pre>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/model/#gemseo_umdo.use_cases.heat_equation.model.HeatEquationModel-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/use_cases/heat_equation/model/#gemseo_umdo.use_cases.heat_equation.model.HeatEquationModel.configuration","title":"configuration  <code>instance-attribute</code>","text":"<pre><code>configuration: HeatEquationConfiguration = (\n    HeatEquationConfiguration(\n        mesh_size,\n        n_modes,\n        final_time,\n        nu_bounds,\n        rod_length,\n    )\n)\n</code></pre> <p>The configuration of the heat equation problem.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/model/#gemseo_umdo.use_cases.heat_equation.model.HeatEquationModel.taylor_mean","title":"taylor_mean  <code>instance-attribute</code>","text":"<pre><code>taylor_mean: float = __f_at_mu_X + 600 * __term1\n</code></pre> <p>The expectation of the output of the first-order Taylor polynomial.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/model/#gemseo_umdo.use_cases.heat_equation.model.HeatEquationModel-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/use_cases/heat_equation/model/#gemseo_umdo.use_cases.heat_equation.model.HeatEquationModel.compute_taylor","title":"compute_taylor","text":"<pre><code>compute_taylor(\n    input_samples: NDArray[float],\n) -&gt; NDArray[float]\n</code></pre> <p>Evaluate the first-order Taylor polynomial.</p> <p>Parameters:</p> <ul> <li> <code>input_samples</code>               (<code>NDArray[float]</code>)           \u2013            <p>The input samples shaped as <code>(sample_size, input_dimension)</code> or <code>(input_dimension, )</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray[float]</code>           \u2013            <p>The output samples of the first-order Taylor polynomial shaped as <code>(sample_size, n_nodes)</code> or <code>(n_nodes, )</code>.</p> </li> </ul> Source code in <code>src/gemseo_umdo/use_cases/heat_equation/model.py</code> <pre><code>def compute_taylor(self, input_samples: NDArray[float]) -&gt; NDArray[float]:\n    \"\"\"Evaluate the first-order Taylor polynomial.\n\n    Args:\n        input_samples: The input samples\n            shaped as `(sample_size, input_dimension)` or `(input_dimension, )`.\n\n    Returns:\n        The output samples of the first-order Taylor polynomial\n        shaped as `(sample_size, n_nodes)` or `(n_nodes, )`.\n    \"\"\"\n    X = input_samples  # noqa: N806\n    mu_X = self.__default_input_value  # noqa: N806\n    return self.__f_at_mu_X + (\n        7 * X[..., [0]] * self.__term2\n        - (X[..., [3]] - mu_X[3]) * pi**2 * 0.5 * self.__term3\n        + 400\n        * self.__term1\n        * (np_abs(X[..., [4]]) + np_abs(X[..., [5]]) + np_abs(X[..., [6]]))\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/uncertain_space/","title":"Uncertain space","text":""},{"location":"reference/gemseo_umdo/use_cases/heat_equation/uncertain_space/#gemseo_umdo.use_cases.heat_equation.uncertain_space","title":"uncertain_space","text":"<p>The uncertain space to be used with the heat equation discipline.</p>"},{"location":"reference/gemseo_umdo/use_cases/heat_equation/uncertain_space/#gemseo_umdo.use_cases.heat_equation.uncertain_space-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/use_cases/heat_equation/uncertain_space/#gemseo_umdo.use_cases.heat_equation.uncertain_space.HeatEquationUncertainSpace","title":"HeatEquationUncertainSpace","text":"<pre><code>HeatEquationUncertainSpace(\n    nu_bounds: tuple[float, float] = (0.001, 0.009)\n)\n</code></pre> <p>               Bases: <code>ParameterSpace</code></p> <p>The uncertain space to be used with the heat equation discipline.</p> <p>Parameters:</p> <ul> <li> <code>nu_bounds</code>               (<code>tuple[float, float]</code>, default:                   <code>(0.001, 0.009)</code> )           \u2013            <p>The lower and upper bounds of the thermal diffusivity \\(\\nu\\).</p> </li> </ul> Source code in <code>src/gemseo_umdo/use_cases/heat_equation/uncertain_space.py</code> <pre><code>def __init__(self, nu_bounds: tuple[float, float] = (0.001, 0.009)) -&gt; None:\n    r\"\"\"\n    Args:\n        nu_bounds: The lower and upper bounds\n            of the thermal diffusivity $\\nu$.\n    \"\"\"  # noqa: D205 D212 D415\n    distribution_name = \"OTUniformDistribution\"\n    super().__init__()\n    self.add_random_variable(\"X_1\", distribution_name, minimum=-pi, maximum=pi)\n    self.add_random_variable(\"X_2\", distribution_name, minimum=-pi, maximum=pi)\n    self.add_random_variable(\"X_3\", distribution_name, minimum=-pi, maximum=pi)\n    self.add_random_variable(\n        \"X_4\", distribution_name, minimum=nu_bounds[0], maximum=nu_bounds[1]\n    )\n    self.add_random_variable(\"X_5\", distribution_name, minimum=-1.0, maximum=1.0)\n    self.add_random_variable(\"X_6\", distribution_name, minimum=-1.0, maximum=1.0)\n    self.add_random_variable(\"X_7\", distribution_name, minimum=-1.0, maximum=1.0)\n</code></pre>"},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/","title":"Spring mass model","text":""},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/#gemseo_umdo.use_cases.spring_mass_model","title":"spring_mass_model","text":"<p>The spring-mass system under uncertainty.</p>"},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/discipline/","title":"Discipline","text":""},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/discipline/#gemseo_umdo.use_cases.spring_mass_model.discipline","title":"discipline","text":"<p>The spring-mass model use case.</p>"},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/discipline/#gemseo_umdo.use_cases.spring_mass_model.discipline-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/discipline/#gemseo_umdo.use_cases.spring_mass_model.discipline.SpringMassDiscipline","title":"SpringMassDiscipline","text":"<pre><code>SpringMassDiscipline(\n    mass: float = 1.5,\n    initial_state: tuple[float, float] = (0, 0),\n    initial_time: float = 0.0,\n    final_time: float = 10.0,\n    time_step: float = 0.1,\n    gravity: float = 9.8,\n)\n</code></pre> <p>               Bases: <code>Discipline</code></p> <p>The GEMSEO-based spring-mass model \\(m\\frac{d^2z(t)}{dt^2} = -kz(t) + mg\\).</p> <p>This model computes the time displacement of an object attached to a spring in function of the stiffness of the spring.</p> <p>It computes also its maximum displacement.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>mass</code>               (<code>float</code>, default:                   <code>1.5</code> )           \u2013            <p>The mass of the object.</p> </li> <li> <code>initial_state</code>               (<code>tuple[float, float]</code>, default:                   <code>(0, 0)</code> )           \u2013            <p>The initial position and velocity of the object.</p> </li> <li> <code>initial_time</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>The initial time.</p> </li> <li> <code>final_time</code>               (<code>float</code>, default:                   <code>10.0</code> )           \u2013            <p>The final time.</p> </li> <li> <code>time_step</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>The time step.</p> </li> <li> <code>gravity</code>               (<code>float</code>, default:                   <code>9.8</code> )           \u2013            <p>The gravity acceleration.</p> </li> </ul> Source code in <code>src/gemseo_umdo/use_cases/spring_mass_model/discipline.py</code> <pre><code>def __init__(\n    self,\n    mass: float = 1.5,\n    initial_state: tuple[float, float] = (0, 0),\n    initial_time: float = 0.0,\n    final_time: float = 10.0,\n    time_step: float = 0.1,\n    gravity: float = 9.8,\n) -&gt; None:\n    \"\"\"\n    Args:\n        mass: The mass of the object.\n        initial_state: The initial position and velocity of the object.\n        initial_time: The initial time.\n        final_time: The final time.\n        time_step: The time step.\n        gravity: The gravity acceleration.\n    \"\"\"  # noqa: D205 D212 D415\n    super().__init__(name=f\"{self.__class__.__name__}({time_step})\")\n    self.input_grammar.update_from_names([self.__STIFFNESS])\n    self.output_grammar.update_from_names([\n        self.__MAX_DISPLACEMENT,\n        self.__DISPLACEMENT,\n    ])\n    self.__model = SpringMassModel(\n        mass=mass,\n        initial_state=initial_state,\n        initial_time=initial_time,\n        final_time=final_time,\n        time_step=time_step,\n        gravity=gravity,\n    )\n    self.default_input_data = {self.__STIFFNESS: array([2.25])}\n</code></pre>"},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/discipline/#gemseo_umdo.use_cases.spring_mass_model.discipline.SpringMassDiscipline-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/discipline/#gemseo_umdo.use_cases.spring_mass_model.discipline.SpringMassDiscipline.cost","title":"cost  <code>property</code>","text":"<pre><code>cost: float\n</code></pre> <p>The evaluation cost.</p>"},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/model/","title":"Model","text":""},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/model/#gemseo_umdo.use_cases.spring_mass_model.model","title":"model","text":"<p>The GEMSEO-free spring-mass model.</p>"},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/model/#gemseo_umdo.use_cases.spring_mass_model.model-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/model/#gemseo_umdo.use_cases.spring_mass_model.model.SpringMassModel","title":"SpringMassModel","text":"<pre><code>SpringMassModel(\n    mass: float = 1.5,\n    initial_state: tuple[float, float] = (0, 0),\n    initial_time: float = 0.0,\n    final_time: float = 10.0,\n    time_step: float = 0.1,\n    gravity: float = 9.8,\n)\n</code></pre> <p>The GEMSEO-free spring-mass model.</p> <p>This model computes the time displacement of an object attached to a spring in function of the stiffness of the spring.</p> <p>It computes also its maximum displacement.</p> <p>The ordinary differential equation is</p> \\[m\\frac{d^2z(t)}{dt^2} = -kz(t) + mg\\] <p>with \\(\\left.\\frac{dz(t)}{dt}\\right|_{t=0}=z(0)=z_0\\).</p> <p>Parameters:</p> <ul> <li> <code>mass</code>               (<code>float</code>, default:                   <code>1.5</code> )           \u2013            <p>The mass of the object.</p> </li> <li> <code>initial_state</code>               (<code>tuple[float, float]</code>, default:                   <code>(0, 0)</code> )           \u2013            <p>The initial position and velocity of the object.</p> </li> <li> <code>initial_time</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>The initial time.</p> </li> <li> <code>final_time</code>               (<code>float</code>, default:                   <code>10.0</code> )           \u2013            <p>The final time.</p> </li> <li> <code>time_step</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>The time step.</p> </li> <li> <code>gravity</code>               (<code>float</code>, default:                   <code>9.8</code> )           \u2013            <p>The gravity acceleration.</p> </li> </ul> Source code in <code>src/gemseo_umdo/use_cases/spring_mass_model/model.py</code> <pre><code>def __init__(\n    self,\n    mass: float = 1.5,\n    initial_state: tuple[float, float] = (0, 0),\n    initial_time: float = 0.0,\n    final_time: float = 10.0,\n    time_step: float = 0.1,\n    gravity: float = 9.8,\n) -&gt; None:\n    \"\"\"\n    Args:\n        mass: The mass of the object.\n        initial_state: The initial position and velocity of the object.\n        initial_time: The initial time.\n        final_time: The final time.\n        time_step: The time step.\n        gravity: The gravity acceleration.\n    \"\"\"  # noqa: D205 D212 D415\n    self.__mass = mass\n    self.__gravity = gravity\n    self.__initial_state = initial_state\n    self.__time = arange(initial_time, final_time, time_step)\n    self.__cost = 1.0 / time_step\n</code></pre>"},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/model/#gemseo_umdo.use_cases.spring_mass_model.model.SpringMassModel-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/model/#gemseo_umdo.use_cases.spring_mass_model.model.SpringMassModel.cost","title":"cost  <code>property</code>","text":"<pre><code>cost: float\n</code></pre> <p>The evaluation cost.</p>"},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/uncertain_space/","title":"Uncertain space","text":""},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/uncertain_space/#gemseo_umdo.use_cases.spring_mass_model.uncertain_space","title":"uncertain_space","text":"<p>The space of the uncertain variables of the spring-mass system.</p>"},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/uncertain_space/#gemseo_umdo.use_cases.spring_mass_model.uncertain_space-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/use_cases/spring_mass_model/uncertain_space/#gemseo_umdo.use_cases.spring_mass_model.uncertain_space.SpringMassUncertainSpace","title":"SpringMassUncertainSpace","text":"<pre><code>SpringMassUncertainSpace()\n</code></pre> <p>               Bases: <code>ParameterSpace</code></p> <p>The space of the uncertain variables of the spring-mass system.</p> Source code in <code>src/gemseo_umdo/use_cases/spring_mass_model/uncertain_space.py</code> <pre><code>def __init__(self) -&gt; None:  # noqa: D107\n    super().__init__()\n    self.add_random_variable(\n        \"stiffness\",\n        \"OTDistribution\",\n        interfaced_distribution=\"Beta\",\n        interfaced_distribution_parameters=(3.0, 2.0, 1.0, 3.5),\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/visualizations/","title":"Visualizations","text":""},{"location":"reference/gemseo_umdo/visualizations/#gemseo_umdo.visualizations","title":"visualizations","text":"<p>Data visualization.</p>"},{"location":"reference/gemseo_umdo/visualizations/sobol_graph/","title":"Sobol graph","text":""},{"location":"reference/gemseo_umdo/visualizations/sobol_graph/#gemseo_umdo.visualizations.sobol_graph","title":"sobol_graph","text":"<p>A network of uncertain variables representing their Sobol' indices.</p>"},{"location":"reference/gemseo_umdo/visualizations/sobol_graph/#gemseo_umdo.visualizations.sobol_graph-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/visualizations/sobol_graph/#gemseo_umdo.visualizations.sobol_graph.SobolGraph","title":"SobolGraph","text":"<pre><code>SobolGraph(\n    first_order_indices: Mapping[str, float],\n    total_order_indices: Mapping[str, float],\n    second_order_indices: Mapping[tuple[str, str], float],\n    threshold: float = 0.1,\n    maximum_thickness: float = 10.0,\n)\n</code></pre> <p>               Bases: <code>GraphView</code></p> <p>A network of uncertain variables representing their Sobol' indices.</p> <p>A node represents an uncertain variable whose name is written inside, followed by its first-order and total-order Sobol' indices.</p> <p>The thickness of a node is proportional to the total-order Sobol' index of the variable while the thickness of an edge is proportional to the second-order Sobol' index of the corresponding pair of variables.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>first_order_indices</code>               (<code>Mapping[str, float]</code>)           \u2013            <p>The first-order Sobol' indices of the scalar inputs, shaped as <code>{name: index}</code>.</p> </li> <li> <code>total_order_indices</code>               (<code>Mapping[str, float]</code>)           \u2013            <p>The total-order Sobol' indices of the scalar inputs, shaped as <code>{name: index}</code>.</p> </li> <li> <code>second_order_indices</code>               (<code>Mapping[tuple[str, str], float]</code>)           \u2013            <p>The second-order Sobol' indices of the scalar inputs, shaped as <code>{(name, other_name): index}</code>.</p> </li> <li> <code>threshold</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>The sensitivity threshold above which a second-order index is significant and the corresponding edge plotted.</p> </li> <li> <code>maximum_thickness</code>               (<code>float</code>, default:                   <code>10.0</code> )           \u2013            <p>The maximum thickness of a line.</p> </li> </ul> Source code in <code>src/gemseo_umdo/visualizations/sobol_graph.py</code> <pre><code>def __init__(\n    self,\n    first_order_indices: Mapping[str, float],\n    total_order_indices: Mapping[str, float],\n    second_order_indices: Mapping[tuple[str, str], float],\n    threshold: float = 0.1,\n    maximum_thickness: float = 10.0,\n) -&gt; None:\n    \"\"\"\n    Args:\n        first_order_indices: The first-order Sobol' indices of the scalar inputs,\n            shaped as `{name: index}`.\n        second_order_indices:  The second-order Sobol' indices of the scalar inputs,\n            shaped as `{(name, other_name): index}`.\n        total_order_indices: The total-order Sobol' indices of the scalar inputs,\n            shaped as `{name: index}`.\n        threshold: The sensitivity threshold\n            above which a second-order index is significant\n            and the corresponding edge plotted.\n        maximum_thickness: The maximum thickness of a line.\n    \"\"\"  # noqa: D205 D212 D415\n    super().__init__(False)\n    variables_to_nodes = {}\n\n    # Add the nodes representing both first- and total-order indices.\n    for name, total_order_index in total_order_indices.items():\n        first_order_index = first_order_indices[name]\n        node_name = (\n            f\"{name}\\n\"\n            f\"({round(total_order_index * 100)}, {round(first_order_index * 100)})\"\n        )\n        variables_to_nodes[name] = node_name\n        self.node(\n            node_name,\n            penwidth=str(total_order_index * maximum_thickness),\n        )\n\n    # Add the edges representing the second-order indices.\n    for (name, other_name), index in second_order_indices.items():\n        if index &gt;= threshold:\n            self.edge(\n                variables_to_nodes[name],\n                variables_to_nodes[other_name],\n                penwidth=str(index * maximum_thickness),\n            )\n</code></pre>"},{"location":"reference/gemseo_umdo/visualizations/sobol_graph/#gemseo_umdo.visualizations.sobol_graph.SobolGraph-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_umdo/visualizations/sobol_graph/#gemseo_umdo.visualizations.sobol_graph.SobolGraph.DEFAULT_FILE_PATH","title":"DEFAULT_FILE_PATH  <code>class-attribute</code>","text":"<pre><code>DEFAULT_FILE_PATH: str | Path = 'sobol_graph.png'\n</code></pre> <p>The default file path to save the graph.</p>"},{"location":"reference/gemseo_umdo/visualizations/sobol_graph/#gemseo_umdo.visualizations.sobol_graph.SobolGraph.threshold","title":"threshold  <code>instance-attribute</code>","text":"<pre><code>threshold: float\n</code></pre> <p>The threshold above which an edge is significant.</p>"},{"location":"reference/gemseo_umdo/visualizations/sobol_graph/#gemseo_umdo.visualizations.sobol_graph.SobolGraph-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/visualizations/sobol_graph/#gemseo_umdo.visualizations.sobol_graph.SobolGraph.from_analysis","title":"from_analysis  <code>classmethod</code>","text":"<pre><code>from_analysis(\n    analysis: SobolAnalysis,\n    output_name: str,\n    output_component: int = 0,\n) -&gt; SobolGraph\n</code></pre> <p>Create the Sobol' graph from a Sobol' analysis.</p> <p>Parameters:</p> <ul> <li> <code>analysis</code>               (<code>SobolAnalysis</code>)           \u2013            <p>A Sobol' analysis.</p> </li> <li> <code>output_name</code>               (<code>str</code>)           \u2013            <p>The name of the output.</p> </li> <li> <code>output_component</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The component of the output.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>SobolGraph</code>           \u2013            <p>The Sobol' graph associated with this Sobol' analysis.</p> </li> </ul> Source code in <code>src/gemseo_umdo/visualizations/sobol_graph.py</code> <pre><code>@classmethod\ndef from_analysis(\n    cls, analysis: SobolAnalysis, output_name: str, output_component: int = 0\n) -&gt; SobolGraph:\n    \"\"\"Create the Sobol' graph from a Sobol' analysis.\n\n    Args:\n        analysis: A Sobol' analysis.\n        output_name: The name of the output.\n        output_component: The component of the output.\n\n    Returns:\n        The Sobol' graph associated with this Sobol' analysis.\n    \"\"\"\n    return cls(\n        cls.__preprocess(analysis.indices.first[output_name][output_component]),\n        second_order_indices=cls.__preprocess_second_order(\n            analysis.indices.second[output_name][output_component]\n        ),\n        total_order_indices=cls.__preprocess(\n            analysis.indices.total[output_name][output_component]\n        ),\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/visualizations/uncertain_coupling_graph/","title":"Uncertain coupling graph","text":""},{"location":"reference/gemseo_umdo/visualizations/uncertain_coupling_graph/#gemseo_umdo.visualizations.uncertain_coupling_graph","title":"uncertain_coupling_graph","text":"<p>An uncertain coupling graph.</p>"},{"location":"reference/gemseo_umdo/visualizations/uncertain_coupling_graph/#gemseo_umdo.visualizations.uncertain_coupling_graph-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/visualizations/uncertain_coupling_graph/#gemseo_umdo.visualizations.uncertain_coupling_graph.UncertainCouplingGraph","title":"UncertainCouplingGraph","text":"<pre><code>UncertainCouplingGraph(\n    disciplines: Sequence[Discipline],\n    uncertain_space: ParameterSpace,\n    variable_names: Iterable[str] | None = None,\n)\n</code></pre> <p>An uncertain coupling graph.</p> <p>A coupling graph whose disciplines are represented by nodes and coupling variables by edges whose thickness is proportional to its dispersion.</p> <p>The dispersion is computed using a DispersionMeasure such as the coefficient of variation (CV) or the quartile coefficient of dispersion (QCD).</p> <p>To be used as:</p> <ol> <li>Instantiate an    UncertainCouplingGraph.</li> <li>Sample the multidisciplinary system, using    sample().</li> <li>Generate the coupling graph for a given dispersion measure, using    visualize().</li> </ol> <p>If you want to change the dispersion measure or filter the variables, repeat Step 3 with another dispersion measure or a list of variable names.</p> <p>If you want to improve the estimations of the statistics, repeat Step 2 with additional evaluations and Step 3.</p> <p>Parameters:</p> <ul> <li> <code>disciplines</code>               (<code>Sequence[Discipline]</code>)           \u2013            <p>The coupled disciplines.</p> </li> <li> <code>uncertain_space</code>               (<code>ParameterSpace</code>)           \u2013            <p>The space of the uncertain variables.</p> </li> <li> <code>variable_names</code>               (<code>Iterable[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>The names of the coupling variables of interest. If <code>None</code>, use all the coupling variables.</p> </li> </ul> Source code in <code>src/gemseo_umdo/visualizations/uncertain_coupling_graph.py</code> <pre><code>def __init__(\n    self,\n    disciplines: Sequence[Discipline],\n    uncertain_space: ParameterSpace,\n    variable_names: Iterable[str] | None = None,\n) -&gt; None:\n    \"\"\"\n    Args:\n        disciplines: The coupled disciplines.\n        uncertain_space: The space of the uncertain variables.\n        variable_names: The names of the coupling variables of interest.\n            If `None`, use all the coupling variables.\n    \"\"\"  # noqa: D205 D212 D415\n    if variable_names is None:\n        self.__output_names = get_all_outputs(disciplines)\n    else:\n        self.__output_names = variable_names\n\n    self.__scenario = DOEScenario(\n        disciplines, self.__output_names[0], uncertain_space, formulation_name=\"MDF\"\n    )\n    for output_name in self.__output_names:\n        self.__scenario.add_observable(output_name)\n</code></pre>"},{"location":"reference/gemseo_umdo/visualizations/uncertain_coupling_graph/#gemseo_umdo.visualizations.uncertain_coupling_graph.UncertainCouplingGraph-classes","title":"Classes","text":""},{"location":"reference/gemseo_umdo/visualizations/uncertain_coupling_graph/#gemseo_umdo.visualizations.uncertain_coupling_graph.UncertainCouplingGraph.DispersionMeasure","title":"DispersionMeasure","text":"<p>               Bases: <code>StrEnum</code></p> <p>A dispersion measure.</p>"},{"location":"reference/gemseo_umdo/visualizations/uncertain_coupling_graph/#gemseo_umdo.visualizations.uncertain_coupling_graph.UncertainCouplingGraph-functions","title":"Functions","text":""},{"location":"reference/gemseo_umdo/visualizations/uncertain_coupling_graph/#gemseo_umdo.visualizations.uncertain_coupling_graph.UncertainCouplingGraph.sample","title":"sample","text":"<pre><code>sample(\n    n_samples: int,\n    algo_name: str = \"OT_OPT_LHS\",\n    **algo_options: Any\n) -&gt; None\n</code></pre> <p>Sample the multidisciplinary system.</p> <p>Parameters:</p> <ul> <li> <code>n_samples</code>               (<code>int</code>)           \u2013            <p>The number of evaluations of the multidisciplinary system.</p> </li> <li> <code>algo_name</code>               (<code>str</code>, default:                   <code>'OT_OPT_LHS'</code> )           \u2013            <p>The name of the DOE algorithm.</p> </li> <li> <code>**algo_options</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The options of the DOE algorithm.</p> </li> </ul> Source code in <code>src/gemseo_umdo/visualizations/uncertain_coupling_graph.py</code> <pre><code>def sample(\n    self, n_samples: int, algo_name: str = \"OT_OPT_LHS\", **algo_options: Any\n) -&gt; None:\n    \"\"\"Sample the multidisciplinary system.\n\n    Args:\n        n_samples: The number of evaluations of the multidisciplinary system.\n        algo_name: The name of the DOE algorithm.\n        **algo_options: The options of the DOE algorithm.\n    \"\"\"\n    self.__scenario.execute(\n        algo_name=algo_name, n_samples=n_samples, **algo_options\n    )\n</code></pre>"},{"location":"reference/gemseo_umdo/visualizations/uncertain_coupling_graph/#gemseo_umdo.visualizations.uncertain_coupling_graph.UncertainCouplingGraph.visualize","title":"visualize","text":"<pre><code>visualize(\n    maximum_thickness: int = 30,\n    dispersion_measure: DispersionMeasure = QCD,\n    variable_names: Iterable[str] | None = None,\n    show: bool = True,\n    save: bool = True,\n    file_path: str | Path = \"\",\n    clean_up: bool = True,\n) -&gt; GraphView\n</code></pre> <p>Generate the uncertain coupling graph.</p> <p>Parameters:</p> <ul> <li> <code>maximum_thickness</code>               (<code>int</code>, default:                   <code>30</code> )           \u2013            <p>The maximum thickness of a line.</p> </li> <li> <code>dispersion_measure</code>               (<code>DispersionMeasure</code>, default:                   <code>QCD</code> )           \u2013            <p>A standardized measure of dispersion.</p> </li> <li> <code>variable_names</code>               (<code>Iterable[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>The names of the coupling variables of interest. If <code>None</code>, use all the coupling variables of interest defined at instantiation.</p> </li> <li> <code>show</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to display the graph with the default application associated to the file extension.</p> </li> <li> <code>save</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to save the graph on the disk.</p> </li> <li> <code>file_path</code>               (<code>str | Path</code>, default:                   <code>''</code> )           \u2013            <p>The file path with extension to save the graph. If <code>\"\"</code>, use the class name with PNG format.</p> </li> <li> <code>clean_up</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to remove the source files.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>GraphView</code>           \u2013            <p>The view of the uncertain coupling graph.</p> </li> </ul> Source code in <code>src/gemseo_umdo/visualizations/uncertain_coupling_graph.py</code> <pre><code>def visualize(\n    self,\n    maximum_thickness: int = 30,\n    dispersion_measure: DispersionMeasure = DispersionMeasure.QCD,\n    variable_names: Iterable[str] | None = None,\n    show: bool = True,\n    save: bool = True,\n    file_path: str | Path = \"\",\n    clean_up: bool = True,\n) -&gt; GraphView:\n    \"\"\"Generate the uncertain coupling graph.\n\n    Args:\n        maximum_thickness: The maximum thickness of a line.\n        dispersion_measure: A standardized measure of dispersion.\n        variable_names: The names of the coupling variables of interest.\n            If `None`,\n            use all the coupling variables of interest defined at instantiation.\n        show: Whether to display the graph\n            with the default application associated to the file extension.\n        save: Whether to save the graph on the disk.\n        file_path: The file path with extension to save the graph.\n            If `\"\"`, use the class name with PNG format.\n        clean_up: Whether to remove the source files.\n\n    Returns:\n        The view of the uncertain coupling graph.\n    \"\"\"\n    if variable_names is None:\n        all_output_names = self.__output_names\n    else:\n        all_output_names = variable_names\n\n    database = self.__scenario.formulation.optimization_problem.database\n    output_names_to_measures = {\n        output_name: self.__DISP_MEAS_TO_FUNCTION[dispersion_measure](\n            database.get_function_history(output_name)\n        )\n        for output_name in self.__output_names\n    }\n    dependency_graph = DependencyGraph(self.__scenario.disciplines).graph\n    graph_view = GraphView()\n    for discipline in self.__scenario.disciplines:\n        graph_view.node(discipline.name)\n\n    for head_disc, tail_disc, coupling_names in dependency_graph.edges(data=\"io\"):\n        variable_names = set(coupling_names).intersection(set(all_output_names))\n        for coupling_name in variable_names:\n            disp_meas = atleast_1d(output_names_to_measures[coupling_name])\n            coupling_size = disp_meas.size\n            for i in range(coupling_size):\n                graph_view.edge(\n                    head_disc.name,\n                    tail_disc.name,\n                    label=repr_variable(coupling_name, i, coupling_size),\n                    penwidth=str(round(abs(disp_meas[i] * maximum_thickness), 2)),\n                )\n\n    for discipline in dependency_graph.nodes:\n        coupling_names = set(discipline.io.input_grammar.names).intersection(\n            discipline.io.output_grammar.names\n        )\n        discipline_name = discipline.name\n        variable_names = set(coupling_names).intersection(set(all_output_names))\n        for coupling_name in variable_names:\n            disp_meas = atleast_1d(output_names_to_measures[coupling_name])\n            coupling_size = disp_meas.size\n            for i in range(coupling_size):\n                graph_view.edge(\n                    discipline_name,\n                    discipline_name,\n                    label=repr_variable(coupling_name, i, coupling_size),\n                    penwidth=str(round(abs(disp_meas[i] * maximum_thickness), 2)),\n                )\n\n    if save:\n        graph_view.visualize(show=show, file_path=file_path, clean_up=clean_up)\n\n    return graph_view\n</code></pre>"},{"location":"user_guide/","title":"User guide","text":""},{"location":"user_guide/#user-guide","title":"User guide","text":""},{"location":"user_guide/statistics/","title":"Statistics","text":""},{"location":"user_guide/statistics/#statistics","title":"Statistics","text":""},{"location":"user_guide/statistics/multilevel/","title":"Multilevel Monte Carlo","text":""},{"location":"user_guide/statistics/multilevel/#multilevel-monte-carlo","title":"Multilevel Monte Carlo","text":"<p>A classical problem consists of estimating a statistic \\(\\theta\\) of the output of a simulator \\(f\\) whose input \\(\\mathbf{X}\\) is random: that is, a statistic \\(\\theta\\) of \\(Y=f(\\mathbf{X})\\).</p>"},{"location":"user_guide/statistics/multilevel/#multilevel-monte-carlo-methods","title":"Multilevel Monte Carlo methods","text":"<p>Crude Monte Carlo (MC) is the most standard method to estimate it. For instance, given a sample \\(\\left(\\mathbf{X}^{(1)},\\ldots,\\mathbf{X}^{(N)}\\right)\\) made of independent random variables distributed as \\(\\mathbf{X}\\), \\(\\frac{1}{N}\\sum_{i=1}^Nf(\\mathbf{X}^{(i)})\\) is an unbiased MC estimator of the expectation of \\(Y\\) whose variance is \\(\\mathcal{O}(N^{-1})\\). (N.B. by unbiasedness, the variance of the MC estimator equals its mean squared error.)</p> <p>In presence of a sequence of simulators \\((f_\\ell)_{\\ell = 0}^L\\) with increasing accuracy and computational cost, such that \\(f_L = f\\), multilevel Monte Carlo (MLMC) methods<sup>1</sup> can be relevant to reduce the variance of the MC estimator. The MLMC methods use all these models to estimate the statistic \\(\\theta_L\\) (a.k.a. \\(\\theta\\)) of the random output variable \\(f_L(\\mathbf{X})\\).</p> <p>We denote by \\(Y_\\ell=f_\\ell(\\mathbf{X})\\) the random output variable associated with the model level \\(f_\\ell\\) and by \\((\\theta_1,\\ldots,\\theta_L)\\) the sequence of statistics increasingly close to \\(\\theta_L\\), where \\(\\theta_\\ell\\) is the statistic of \\(Y_\\ell\\). Then, the statistical measure \\(\\theta_L\\) can be expressed as a telescoping sum \\(\\theta_L = \\sum \\limits_{\\ell = 0}^{L} T_\\ell\\), where \\(T_\\ell = \\theta_\\ell - \\theta_{\\ell-1}\\), and by convention \\(\\theta_{-1} = 0\\). Let \\(\\hat{\\theta}_{\\ell,n_\\ell}^{\\mathrm{MC},(\\ell)}\\) and \\(\\hat{\\theta}_{\\ell-1,n_\\ell}^{\\mathrm{MC},(\\ell)}\\) be respectively the Monte Carlo (MC) estimators of \\(\\theta_\\ell\\) and \\(\\theta_{\\ell-1}\\) using the same \\(n_{\\ell}\\)-sample.</p> <p>Then, the MLMC estimator \\(\\hat{\\theta}_L^{\\mathrm{ML}}\\) of \\(\\theta_L\\) may be expressed as:</p> \\[ \\hat{\\theta}_L^{\\mathrm{MLMC}} = \\sum \\limits_{\\ell = 0}^{L} \\hat{T}_{\\ell,n_\\ell}^{\\mathrm{MC}} = \\sum \\limits_{\\ell = 0}^{L} \\hat{\\theta}_{\\ell,n_\\ell}^{\\mathrm{MC},(\\ell)}- \\hat{\\theta}_{\\ell-1,n_\\ell}^{\\mathrm{MC},(\\ell)}. \\] <p>Many algorithms distributing the sampling budget between the different levels can be found in the literature. Their goal is often to get an MLMC estimator with an accuracy target set by the user. Recently, an allocation algorithm<sup>2</sup> has been proposed to get the best accuracy for a given sampling budget.</p>"},{"location":"user_guide/statistics/multilevel/#multilevel-monte-carlo-with-control-variates","title":"Multilevel Monte Carlo with control variates","text":"<p>When surrogate models are available as functions of the random input \\(\\mathbf{X}\\), their random outputs can be used as control variates (CVs) to reduce the variance of the MC estimators.</p> <p>In 2023, El Amri et al<sup>3</sup> have investigated the combination of CVs and MLMC in different ways and called the resulting algorithm MLMC-MLCV, standing for multilevel Monte Carlo with multilevel control variates. Their idea was to estimate each \\(T_\\ell\\) of the telescoping sum with a control variate approach based on surrogate models. They showed that even with surrogate models that are moderately correlated to the original models, the reduction in variance could be significant.</p> <ol> <li> <p>Michael B Giles. Multilevel Monte Carlo methods. Acta numerica, 24:259\u2013328, 2015.\u00a0\u21a9</p> </li> <li> <p>Paul Mycek and Matthias De Lozzo. Multilevel Monte Carlo covariance estimation for the computation of Sobol'indices. SIAM/ASA Journal on Uncertainty Quantification, 7(4):1323\u20131348, 2019.\u00a0\u21a9</p> </li> <li> <p>Mohamed Reda El Amri, Paul Mycek, Sophie Ricci, and Matthias De Lozzo. Multilevel surrogate-based control variates. 2023. arXiv:2306.10800.\u00a0\u21a9</p> </li> </ol>"},{"location":"user_guide/umdo/","title":"MDO under uncertainty","text":""},{"location":"user_guide/umdo/#mdo-under-uncertainty","title":"MDO under uncertainty","text":""},{"location":"user_guide/umdo/#introduction","title":"Introduction","text":""},{"location":"user_guide/umdo/#optimization-problem","title":"Optimization problem","text":"<p>A standard optimization problem aims to find a vector \\(x^*\\) minimizing an objective function \\(f\\) over a search space \\(\\mathcal{X}\\subset\\mathbb{R}^d\\) while satisfying inequality constraints \\(g(x)\\leq 0\\) and equality constraints \\(h(x)=0\\):</p> \\[ \\begin{align} &amp;\\underset{x\\in\\mathcal{X}}{\\operatorname{minimize}}&amp; &amp; f(x) \\\\ &amp;\\operatorname{subject\\;to} &amp; &amp;g(x) \\leq 0 \\\\ &amp;&amp;&amp;h(x) = 0 \\end{align} \\] <p>where \\(f:\\mathcal{X}\\mapsto\\mathbb{R}\\), \\(g:\\mathcal{X}\\mapsto\\mathbb{R}^{p_g}\\) and \\(h:\\mathcal{X}\\mapsto\\mathbb{R}^{p_h}\\).</p> <p>Any optimization problem of the form</p> \\[ \\begin{align} &amp;\\underset{x\\in\\mathcal{X}}{\\operatorname{minimize}}&amp; &amp; f_{\\textrm{cost}}(x) \\\\ &amp;\\underset{x\\in\\mathcal{X}}{\\operatorname{maximize}}&amp; &amp; f_{\\textrm{performance}}(x) \\\\ &amp;\\operatorname{subject\\;to} &amp; &amp;g_n(x) \\leq t_{g_n} \\\\ &amp;&amp;&amp;g_p(x) \\geq t_{g_p} \\\\ &amp;&amp;&amp;\\tilde{h}(x) = t_h \\end{align} \\] <p>can be reduced to this standard optimization problem:</p> <ul> <li>an objective to minimize,</li> <li>upper inequality constraints with bounds equal to 0,</li> <li>equality constraints with right-hand sides equal to 0.</li> </ul> <p>API</p> <p>In GEMSEO, the user instantiates an OptimizationProblem from a DesignSpace, defines its objective functions and constraints with MDOFunction objects and solves it with an algorithm from a DriverLibrary. This algorithm can be either an optimizer or a design of experiments (DOE).</p> Example <p>The optimization problem</p> \\[ \\begin{align} &amp;\\underset{x\\in[-1,1]}{\\operatorname{minimize}}&amp; &amp; x^2 \\\\ &amp;\\operatorname{subject\\;to} &amp; &amp; x^3 \\ge 0.1 \\end{align} \\] <p>can be solved with the Python lines</p> <pre><code>from gemseo import execute_algo\nfrom gemseo.algos.optimization_problem import Optimization\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.core.mdofunctions.mdo_function import MDOFunction\n\ndesign_space = DesignSpace()\ndesign_space.add_variable(\"x\", lower_bound=-1., upper_bound=1.)\n\nproblem = OptimizationProblem(design_space)\nproblem.objective = MDOFunction(lambda x: x**2, \"f\")\nproblem.add_constraint(MDOFunction(lambda x: x**3, \"g\"), positive=True, value=0.1)\n\nexecute_algo(problem, algo_name=\"PYDOE_FULLFACT\", n_samples=10, algo_type=\"doe\")\n</code></pre>"},{"location":"user_guide/umdo/#multidisciplinary-optimization-mdo-problem","title":"Multidisciplinary optimization (MDO) problem","text":"<p>In complex systems, the quantities \\(f(x)\\), \\(g(x)\\) and \\(h(x)\\) are often computed by \\(D\\) models, called disciplines, which can be weakly or strongly coupled. The vector \\(x\\) can be split into</p> <ul> <li>a sub-vector \\(x_0\\) shared by at least two disciplines,</li> <li>sub-vectors \\(x_i\\), each specific to a discipline \\(i\\).</li> </ul> <p>The problem is then called a multidisciplinary optimization (MDO) problem</p> \\[ \\begin{align} &amp;\\underset{x\\in\\mathcal{X},y\\in\\mathcal{Y}}{\\operatorname{minimize}}&amp;&amp;f(x,y)\\\\ &amp;\\operatorname{subject\\;to} &amp; &amp;g(x,y) \\leq 0 \\\\ &amp;&amp;&amp;h(x,y) = 0 \\\\ &amp;&amp;&amp;y=c(x,y) \\end{align} \\] <p>where \\(c_i:x_0,x_i,y_{-i}\\mapsto y_i\\) represents the \\(i\\)-th discipline with \\(y_{-i}=\\{y_j, 1\\leq j\\neq i \\leq D\\}\\).</p> <p>This MDO problem implies that the optimum \\((x^*,y^*)\\) must be multidisciplinary feasible, i.e. satisfying the coupling equations \\(y^*=c(x^*,y^*)\\). Solving these equations is called a multidisciplinary analysis (MDA).</p> Example: MDA with linear disciplines <p>Let us consider a simple MDO problem with two linear disciplines given by \\(c_1: x_0,x_1,y_2 \\mapsto x_0 + x_1 + y_2\\) and \\(c_2: x_0,x_2,y_1 \\mapsto x_0 + x_2 + 2y_1\\). Let us define the objective function as \\(f(x_0,x_1,x_2,y_1,y_2)=c_1(x_0,x_1,y_2)^2+c_2(x_0,x_2,y_1)^2\\). The coupling equations are \\(c_1(x_0,x_1,y_2)=y_1\\) and \\(c_2(x_0,x_2,y_1)=y_2\\). In this linear case, they can be solved analytically: \\(y_1(x) = -2x_0-x_1-x_2\\) and \\(y_2(x) = -3x_0-2x_1-x_2\\). Then, the objective function output can be rewritten as a function of \\(x\\) only: \\(f(x,y(x))=y_1(x)^2+y_2(x)^2\\), and the MDO problem becomes a simple optimization problem.</p> <p>In the case of non-linear disciplines, the MDA can be solved with Newton's method or a fixed-point technique.</p> <p>Last but not least, the efficient resolution of an MDO problem involves finding a suitable rewriting of the problem, called MDO formulation or architecture<sup>1</sup>.</p> <ul> <li> <p>The MDF (multidisciplinary feasible) formulation is certainly the best-known.   This architecture performs an MDA at each iteration of the optimization loop   and is thus qualified as coupled.</p> \\[ \\begin{align} &amp;\\underset{x\\in\\mathcal{X}}{\\operatorname{minimize}}&amp;&amp;f(x,y(x))\\\\ &amp;\\operatorname{subject\\;to} &amp; &amp;g(x,y(x)) \\leq 0 \\\\ &amp;&amp;&amp;h(x,y(x)) = 0 \\\\ &amp;&amp;&amp;y(x)=c(x,y(x)). \\end{align} \\] </li> <li> <p>The IDF (individual disciplinary feasible) formulation is also popular.   This architecture evaluates the disciplines independently   at each iteration of the optimization loop   and is thus qualified as uncoupled.   The multidisciplinary feasibility is ensured   at convergence of the optimization algorithm   by means of consistency constraints.</p> \\[ \\begin{align} &amp;\\underset{x\\in\\mathcal{X},\\tilde{y}\\in\\mathcal{Y}}{\\operatorname{minimize}}&amp;&amp;f(x,\\tilde{y})\\\\ &amp;\\operatorname{subject\\;to} &amp; &amp;g(x,\\tilde{y}) \\leq 0 \\\\ &amp;&amp;&amp;h(x,\\tilde{y}) = 0 \\\\ &amp;&amp;&amp;\\tilde{y} = c(x,\\tilde{y}). \\end{align} \\] </li> <li> <p>Bi-level formulations<sup>2</sup> split the optimization problem   into a top-level optimization problem controlling the shared variable \\(x_0\\)   and a collection of sub-optimization problems   whose \\(i\\)-th controls the local variable \\(x_i\\).</p> </li> </ul> <p>API</p> <p>GEMSEO offers implementations for the MDF, IDF and BiLevel formulations.</p> Example: MDF applied to the Sellar problem <pre><code>  from gemseo import create_scenario\n  from gemseo.algos.design_space import DesignSpace\n  from gemseo.disciplines.analytic import AnalyticDiscipline\n\n  disciplines = [\n      AnalyticDiscipline({\"y_1\": \"(z1**2+z2+x-0.2*y2)**0.5\"}, \"Sellar1\"),\n      AnalyticDiscipline({\"y_2\": \"abs(y1)+z1+z2\"}, \"Sellar2\"),\n      AnalyticDiscipline(\n          {\n              \"f\": \"x**2+z2+y**2+exp(-y_2)\",\n              \"c1\": \"3.16-y1**2\",\n              \"c2\": \"y2-24\"\n          },\n          \"SellarSystem\"\n      )\n  ]\n\n  design_space = DesignSpace()\n  design_space.add_variable(\"x\", lower_bound=0.0, upper_bound=10.0, value=1)\n  design_space.add_variable(\"z1\", lower_bound=-10, upper_bound=10.0, value=4.0)\n  design_space.add_variable(\"z2\", lower_bound=0.0, upper_bound=10.0, value=3.0)\n\n  scenario = create_scenario(disciplines, \"MDF\", \"f\", design_space)\n  scenario.add_constraint(\"c1\", \"ineq\")\n  scenario.add_constraint(\"c2\", \"ineq\")\n  scenario.execute(algo_name=\"SLSQP\", max_iter=100)\n</code></pre>"},{"location":"user_guide/umdo/#optimization-problem-under-uncertainty","title":"Optimization problem under uncertainty","text":"<p>The models are often subject to uncertainties There are different ways of classifying uncertainties and different ways of modeling them. However, GEMSEO-UMDO is limited to the probability theory for the sake of simplicity and because this framework is the most popular and has proved its worth. And so, the uncertainties are modelled by random variables.</p> <p>Then, the objective \\(f(x,U)\\) and the constraints \\(g(x,U)\\) and \\(h(x,U)\\), where \\(U\\) denotes random inputs, are in turn random variables and the standard optimization problem is replaced by</p> \\[ \\begin{align} &amp;\\underset{x\\in\\mathcal{X}}{\\operatorname{minimize}}&amp; &amp; \\mathbb{K}_f[f(x,U)] \\\\ &amp;\\operatorname{subject\\;to} &amp; &amp;\\mathbb{K}_g[g(x,U)] \\leq 0 \\\\ &amp;&amp;&amp;\\mathbb{K}_h[h(x,U)] = 0 \\end{align} \\] <p>where \\(\\mathbb{K}_f\\), \\(\\mathbb{K}_g\\) and \\(\\mathbb{K}_h\\) are statistics.</p> <p>The statistic of a function \\(\\phi\\) can be the expectation \\(\\mathbb{E}[\\phi(x,U)]\\), the standard deviation \\(\\mathbb{S}[\\phi(x,U)]\\), the variance \\(\\mathbb{V}[\\phi(x,U)]\\), a margin \\(\\mathbb{E}[\\phi(x,U)]+\\kappa\\times\\mathbb{S}[\\phi(x,U)]\\) or a probability \\(\\mathbb{P}[m \\leq \\phi(x,U)\\leq M]\\). For the inequality constraints, \\(\\mathbb{K}_g[g(x,U)]\\) could be \\(\\mathbb{P}[g(x,U)\\geq\\epsilon]\\) or \\(\\mathbb{P}[g(x,U)\\geq 0]-\\varepsilon\\). For the equality constraints, \\(\\mathbb{K}_h[h(x,U)]\\) could be \\(\\mathbb{P}[|h(x,U)|\\geq\\epsilon]\\).</p> <p>Note</p> <p>When \\(\\phi(x,U)\\) is normally distributed, the margin \\(\\mathbb{E}[\\phi(x,U)]+q_\\alpha\\times\\mathbb{S}[\\phi(x,U)]\\) corresponds to the \\(\\alpha\\)-quantile of \\(\\phi(x,U)\\) where \\(q_\\alpha\\) is the \\(\\alpha\\)-quantile of the standard Gaussian distribution. For that reason, 2 or 3 are common candidates for \\(\\kappa\\) as in this case, the margins correspond to the 0.975- and 0.999- quantiles of \\(\\phi(x,U)\\) respectively.</p> <p>Typically, a margin is applied to the objective to ensure a robust optimum \\(x^*\\):</p> <ul> <li>a small value of \\(f(x^*,u)\\) by minimizing \\(\\mathbb{E}[f(x,U)]\\),</li> <li>whatever the realization \\(u\\) of \\(U\\) by minimizing \\(\\mathbb{S}[f(x,U)]\\).</li> </ul>"},{"location":"user_guide/umdo/#api","title":"API","text":"<p>Here is an outline of the API. Go to the examples for more information.</p>"},{"location":"user_guide/umdo/#disciplines","title":"Disciplines","text":"<p>When defining disciplines, do not forget to declare the uncertain variables as input variables so that the UMDOScenario and UDOEScenario can change their values.</p> <p>Example</p> <p>Let us implement an Discipline outputting \\(f(x,U)=(x_1+U)^2+(x_2+U)^2\\): <pre><code>from numpy import array\nfrom gemseo.core.discipline.discipline import Discipline\n\n\nclass MyDiscipline(Discipline):\n\n    def __init__(self):\n        super().__init__()\n        self.input_grammar.update_from_names([\"x1\", \"x2\", \"U\"])\n        self.default_input_data = {\"x1\": array([0.]), \"x2\": array([0.]), \"U\": array([0.5])}\n\n    def _run(self, input_data):\n        x1 = self.io.data[\"x1\"]\n        x2 = self.io.data[\"x2\"]\n        U = self.io.data[\"U\"]\n        y = (x1+U)**2 + (x2+U)**2\n        self.io.update_output_data({\"y\": y})\n</code></pre></p> <p>This discipline can be executed with different values of the uncertain variable \\(U\\): <pre><code>discipline.execute()  # default value, i.e. U=0.5\ndiscipline.execute({\"U\": array([0.2])})  # custom value: U=0.2\n</code></pre></p>"},{"location":"user_guide/umdo/#uncertain-space","title":"Uncertain space","text":"<p>The uncertain variables have to be defined in a ParameterSpace with the method add_random_variable.</p> <p>Example</p> <p>In the previous example, we could model the uncertain variable \\(U\\) as a random variable distributed according to a triangular distribution between 0.2 and 0.7 with a mode of 0.4:</p> <pre><code>from gemseo.algos.parameter_space import ParameterSpace\n\nuncertain_space = ParameterSpace()\nuncertan_space.add_random_variable(\n    \"U\", \"OTTriangularDistribution\", minimum=0.2, maximum=0.7, mode=0.4\n)\n</code></pre>"},{"location":"user_guide/umdo/#scenario","title":"Scenario","text":"<p>Given these disciplines and uncertain space and also a design space of course, the MDO problem can be set up.</p> <p>In the case of MDO without uncertainty, there are two scenarios to set up the MDO problem:</p> <ul> <li>DOEScenario   to solve it with a DOE,</li> <li>MDOScenario   to solve it with an optimizer.</li> </ul> <p>Both need knowledge of objective and constraint functions in addition to the disciplines and design space to solve the MDO problem.</p> <p>In the case of MDO with uncertainty, there are two similar scenarios to set up the MDO problem:</p> <ul> <li>UDOEScenario   to solve it with a DOE,</li> <li>UMDOScenario   to solve it with an optimizer.</li> </ul> <p>Both need knowledge of the statistics and their estimators in addition to the disciplines, design space, objective and constraints to solve the MDO problem under uncertainty.</p> <p>API</p> <p>The API of UDOEScenario is deliberately similar to the API of DOEScenario. And the same for UMDOScenario and MDOScenario. This choice was made not only to simplify the user's life, but also because an MDO problem under uncertainty is first and foremost an MDO problem.</p> <p>Example</p> <p>Continuing the previous example, we seek to minimize \\(\\mathbf{E}[(x_1+U)^2+(x_2+U)^2]\\) over the domain \\([-1,1]^2\\) with the gradient-free optimization algorithm COBYLA and a Monte Carlo estimator of the expectation.</p> <pre><code>from gemseo.algos.design_space import DesignSpace\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\ndesign_space = DesignSpace()\ndesign_space.add_variable(\"x1\", lower_bound=-1., upper_bound=1.)\ndesign_space.add_variable(\"x2\", lower_bound=-1, upper_bound=1.)\n\nscenario = UMDOScenario(\n    [discipline],\n    \"DisciplinaryOpt\",\n    \"y\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    statistic_estimation_parameters={\"n_samples\": 100},\n)\nscenario.execute(algo_name=\"NLOPT_COBYLA\", max_iter=50)\n</code></pre>"},{"location":"user_guide/umdo/#u-mdo-formulations","title":"U-MDO formulations","text":"<p>By default, UDOEScenario and UMDOScenario estimate the statistics associated with \\(f(x,U)\\), \\(g(x,U)\\) and \\(h(x,U)\\) by sampling these random variables:</p> \\[(f(x,U^{(i)}),g(x,U^{(i)}),h(x,U^{(i)}))_{1\\leq i \\leq N}.\\] <p>However, as sampling can be expensive, GEMSEO-UMDO offers other techniques to reduce the cost of statistics estimation, such as control variates, Taylor polynomials and polynomial chaos expansions. The choice of an estimation technique is made via the string argument <code>estimation_technique</code> of UDOEScenario (or UMDOScenario), representing the class name of an BaseUMDOFormulation, e.g. <code>\"ControlVariate\"</code>, <code>\"TaylorPolynomial\"</code> or <code>\"PCE\"</code>.</p> <p>As of now, only the <code>Sampling</code> U-MDO formulation provides analytical derivatives of the statistics when the disciplines and the multidisciplinary process generated by the MDO formulation are differentiable. Therefore, the other U-MDO formulations require gradient approximation to use gradient-based optimizers, what can be expensive according to the dimension of the design space.</p> <p>The rest of the MDO under uncertainty section of the user guide presents the different U-MDO formulations.</p> Implementation <p>Given a DesignSpace and a collection of Disciplines, a DOEScenario generates and solves an OptimizationProblem that corresponds to an MDOFormulation. The resolution consists in sampling the objective and constraints over the DesignSpace, i.e. \\((x^{(i)},f(x^{(i)},U),g(x^{(i)},U),h(x^{(i)},U))_{1\\leq i \\leq N}\\), and returning either the \\(x^*\\) minimizing \\(f\\) while satisying \\(g\\) and \\(h\\) or the \\(x^*\\) that violates the least \\(g\\) and \\(h\\).</p> <p>GEMSEO-UMDO uses this sampling mechanism a first time with a ParameterSpace instead of the DesignSpace to estimate the statistics \\(\\mathbb{K}_f[f(x,U)]\\), \\(\\mathbb{K}_g[g(x,U)]\\) and \\(\\mathbb{K}_h[h(x,U)]\\) based on the samples \\((U^{(i)},f(x,U^{(i)}),g(x,U^{(i)}),h(x,U^{(i)}))_{1\\leq i \\leq M}\\). In the case of Monte Carlo sampling, \\(M\\) is the number of samples while in the case of Taylor expansion, \\(M\\in\\{1,1+q\\}\\) where \\(q\\) is the dimension of the uncertain space depending on whether the derivatives are known or to be estimated by finite differences. These statistics estimators \\(\\hat{\\mathbb{K}}_f[f(x,U)]\\), \\(\\hat{\\mathbb{K}}_g[g(x,U)]\\) and \\(\\hat{\\mathbb{K}}_h[h(x,U)]\\) are then used to build a new OptimizationProblem over the DesignSpace:</p> \\[ \\begin{align} &amp;\\underset{x\\in\\mathcal{X}}{\\operatorname{minimize}} &amp; &amp; \\hat{\\mathbb{K}}_f[f(x,U)] \\\\ &amp;\\operatorname{subject\\;to} &amp; &amp;\\hat{\\mathbb{K}}_g[g(x,U)] \\leq 0 \\\\ &amp;&amp;&amp;\\hat{\\mathbb{K}}_h[h(x,U)] = 0. \\end{align} \\] <p>Thus implemented, GEMSEO-UMDO should be able to set up any MDO problem under uncertainty from any MDOFormulation and any statistic estimation technique. This vision may be theoretical at the moment, but the ambition of GEMSEO-UMDO is to be an engine generating U-MDO formulations based on any MDO formulation and any statistic estimators.</p> <ol> <li> <p>Joaquim R. R. A. Martins and Andrew B. Lambe. Multidisciplinary design optimization: a survey of architectures. AIAA Journal, 51:2049\u20132075, 2013. doi:10.2514/1.J051895.\u00a0\u21a9</p> </li> <li> <p>Anne Gazaix, Francois Gallard, Vincent Ambert, Damien Gu\u00e9not, Maxime Hamadi, Patrick Sarouille, St\u00e9phane Grihon, Thierry Druot, Joel Brezillon, Thierry Lefebvre, Nathalie Bartoli, Remi Lafage, Vincent Gachelin, Justin Plakoo, Nicolas Desfachelles, Selime Gurol, Benoit Pauwels, and Charlie Vanaret. Industrial application of an advanced bi-level MDO formulation to an aircraft engine pylon optimization. In AIAA AVIATION Forum. American Institute of Aeronautics and Astronautics, 2019.\u00a0\u21a9</p> </li> </ol>"},{"location":"user_guide/umdo/control_variate/","title":"Control variate","text":""},{"location":"user_guide/umdo/control_variate/#control-variate","title":"Control variate","text":"<p>ControlVariate is a U-MDO formulation that estimates the statistics using control variates based on first-order Taylor polynomials.</p> <p>Control variates (CVs) method</p> <p>The control variates method is a variance reduction technique used in Monte Carlo sampling. Read more</p> <p>The Taylor polynomials are centered at \\(\\mu=\\mathbb{E}[U]\\) where \\(U\\) is the random input vector.</p> <p>This U-MDO formulation has one mandatory parameter, namely <code>n_samples</code>.</p> <p>Here is a typical scenario template:</p> <pre><code>scenario = UMDOScenario(\n    disciplines,\n    mdo_formulation_name,\n    objective_name,\n    design_space,\n    uncertain_space,\n    statistic_name,\n    statistic_estimation=\"ControlVariate\",\n)\n</code></pre>"},{"location":"user_guide/umdo/control_variate/#options","title":"Options","text":"<p>By default, the formulation uses the DOE algorithm <code>OT_OPT_LHS</code>: the Latin hypercube sampling (LHS) enhanced by simulated annealing of OpenTURNS. Simulated annealing is a global optimization technique that starts from an initial LHS and improves it to maximize its discrepancy and so to get a better space-filling LHS.</p> <p>The DOE algorithm name can be set with the string parameter <code>algo</code> and its options with the dictionary parameter <code>algo_options</code>.</p> <p>API</p> <p>Use <code>statistic_estimation_parameters</code> to set the algorithm name and parameters, e.g.</p> <pre><code>scenario = UMDOScenario(\n    disciplines,\n    mdo_formulation_name,\n    objective_name,\n    design_space,\n    uncertain_space,\n    statistic_name,\n    statistic_estimation=\"ControlVariate\",\n    statistic_estimation_parameters={\n        \"algo\": \"OT_MONTE_CARLO\",\n        \"n_samples\": 20,\n        \"algo_options\": {\"n_processes\": 2}\n    }\n)\n</code></pre>"},{"location":"user_guide/umdo/control_variate/#statistics","title":"Statistics","text":"<p>This U-MDO formulation has been implemented for the expectation, the standard deviation, the variance and the margin.</p> <p>Only the average formula is noted here, for simplicity's sake</p> \\[\\mathbb{E}[\\varphi(x,U)] \\approx \\frac{1}{N}\\sum_{i=1}^N f\\left(x,U^{(i)}\\right) +\\alpha_N\\left(\\frac{1}{N}\\sum_{j=1}^N \\tilde{f}\\left(x,U^{(j)}\\right)-f(x,\\mu)\\right)\\] <p>where \\(\\tilde{f}(x)\\) is the first-order Taylor polynomial of \\(f(x)\\) at \\(\\mu\\), \\(\\alpha_N\\) is the empirical estimator of \\(\\frac{\\text{cov}\\left[f(x,U),\\tilde{f}(x,u)\\right]} {\\mathbb{V}\\left[f(x,U)\\right]}\\) and \\(U^{(1)},\\ldots,U^{(N)}\\) are \\(N\\) independent realizations of \\(U\\).</p>"},{"location":"user_guide/umdo/pce/","title":"Polynomial chaos expansion","text":""},{"location":"user_guide/umdo/pce/#polynomial-chaos-expansion","title":"Polynomial chaos expansion","text":"<p>PCE is a U-MDO formulation that estimates the statistics using polynomial chaos expansions (PCEs).</p> <p>At each iteration of the optimization loop, a PCE is built over the uncertain space and its coefficients are used to estimate specific statistics, namely mean, standard deviation, variance and margin.</p> <p>The number of samples to build the PCE is mandatory and must be set with the parameter <code>doe_n_samples</code>.</p> <p>Here is a typical scenario template:</p> <pre><code>scenario = UMDOScenario(\n    disciplines,\n    mdo_formulation_name,\n    objective_name,\n    design_space,\n    uncertain_space,\n    statistic_name,\n    statistic_estimation=\"PCE\",\n    statistic_estimation_parameters={\"doe_n_samples\": 20}\n)\n</code></pre>"},{"location":"user_guide/umdo/pce/#options","title":"Options","text":""},{"location":"user_guide/umdo/pce/#doe-algorithm","title":"DOE algorithm","text":"<p>By default, the formulation uses the OpenTURNS' DOE algorithm <code>OT_OPT_LHS</code>, which is a Latin hypercube sampling (LHS) technique enhanced by simulated annealing, a global optimization technique that starts from an initial LHS and improves it to maximize its discrepancy and so to get a better space-filling LHS.</p> <p>The DOE algorithm name can be set with the string option <code>doe_algo</code> and its options with the dictionary parameter <code>doe_algo_options</code>. When the DOE algorithm uses a random number generator, the integer option <code>doe_seed</code> can be used for reproducibility purposes.</p>"},{"location":"user_guide/umdo/pce/#pces-options","title":"PCE's options","text":"<p>This U-MDO formulation is based on the PCERegressor available in GEMSEO, which wraps the OpenTURNS' PCE algorithm. Use the <code>pce_options</code> argument to set the options of the PCERegressor. For example, set <code>use_lars</code> to <code>True</code> to obtain a more sparse PCE and avoid overfitting (more details) and <code>degree</code> to <code>3</code> for a maximum degree of 3.</p> <p>API</p> <p>Use <code>statistic_estimation_parameters</code> to set the DOE algorithm and the PCE's options, e.g.</p> <pre><code>scenario = UMDOScenario(\n    disciplines,\n    mdo_formulation_name,\n    objective_name,\n    design_space,\n    uncertain_space,\n    statistic_name,\n    statistic_estimation_parameters={\n        \"doe_algo\": \"OT_MONTE_CARLO\",\n        \"doe_n_samples\": 20,\n        \"doe_algo_options\": {\"n_processes\": 2},\n        \"pce_options\": {\"use_lars\": True, \"degree\": 3}\n    }\n)\n</code></pre>"},{"location":"user_guide/umdo/pce/#quality-options","title":"Quality options","text":"<p>Finally, many options can be used to adjust the log verbosity providing information on the PCEs built at each optimization iteration:</p> Name Description quality_threshold The learning quality threshold below which a warning is logged. quality_name The name of the measure to assess the quality of the PCE regressor. quality_cv_compute Whether to estimate the quality by cross-validation (CV). quality_n_folds The number of folds in the case of the CV technique. quality_cv_randomize Whether to shuffle the samples before dividing them in folds in the case of the CV technique. quality_cv_seed The seed of the pseudo-random number generator. quality_cv_threshold The CV quality threshold below which a warning is logged."},{"location":"user_guide/umdo/pce/#statistics","title":"Statistics","text":"<p>This U-MDO formulation has been implemented for the expectation, the standard deviation, the variance and the margin, from the coefficients \\((\\alpha_i)_{0\\leq i \\leq N}\\) of the PCE</p> \\[\\hat{f}_x(U)=\\alpha_0 + \\sum_{1\\leq i\\leq P}\\alpha_i\\Phi_i(U).\\] Statistic Notation Estimator Mean \\(\\mathbb{E}[\\varphi(x,U)]\\) \\(E_{\\textrm{PCE}}[\\varphi(x,U)]=\\alpha_0\\) Variance \\(\\mathbb{V}[\\varphi(x,U)]\\) \\(V_{\\textrm{PCE}}[\\varphi(x,U)]=\\sum_{1\\leq i\\leq P}\\alpha_i^2\\) Standard deviation \\(\\mathbb{S}[\\varphi(x,U)]\\) \\(S_{\\textrm{PCE}}[\\varphi(x,U)]=\\sqrt{V_{\\textrm{PCE}}[\\varphi(x,U)]}\\) Margin \\(\\textrm{Margin}[\\varphi(x,U)]\\) \\(\\textrm{Margin}_{\\textrm{PCE}}[\\varphi(x,U)]=E_{\\textrm{PCE}}[\\varphi(x,U)] + \\kappa \\times S_{\\textrm{PCE}}[\\varphi(x,U)]\\)"},{"location":"user_guide/umdo/sampling/","title":"Sampling","text":""},{"location":"user_guide/umdo/sampling/#sampling","title":"Sampling","text":"<p>Sampling is a U-MDO formulation that estimates the statistics unbiasedly using Monte Carlo sampling.</p> <p>This is the default U-MDO formulation. So, the argument <code>statistic_estimation</code> does not have to be set to use it. However, the number of samples is mandatory and must be set with the parameter <code>n_samples</code>.</p> <p>Here is a typical scenario template:</p> <pre><code>scenario = UMDOScenario(\n    disciplines,\n    mdo_formulation_name,\n    objective_name,\n    design_space,\n    uncertain_space,\n    statistic_name,\n    statistic_estimation_parameters={\"n_samples\": n_samples}\n)\n</code></pre>"},{"location":"user_guide/umdo/sampling/#options","title":"Options","text":"<p>By default, the formulation uses the DOE algorithm <code>OT_OPT_LHS</code>: the Latin hypercube sampling (LHS) enhanced by simulated annealing of OpenTURNS. Simulated annealing is a global optimization technique that starts from an initial LHS and improves it to maximize its discrepancy and so to get a better space-filling LHS.</p> <p>The DOE algorithm name can be set with the string parameter <code>algo</code> and its options with the dictionary parameter <code>algo_options</code>.</p> <p>API</p> <p>Use <code>statistic_estimation_parameters</code> to set the algorithm name and parameters, e.g.</p> <pre><code>scenario = UMDOScenario(\n    disciplines,\n    mdo_formulation_name,\n    objective_name,\n    design_space,\n    uncertain_space,\n    statistic_name,\n    statistic_estimation_parameters={\n        \"algo\": \"OT_MONTE_CARLO\",\n        \"n_samples\": 20,\n        \"algo_options\": {\"n_processes\": 2}\n    }\n)\n</code></pre>"},{"location":"user_guide/umdo/sampling/#statistics","title":"Statistics","text":"<p>This U-MDO formulation has been implemented for the expectation, the standard deviation, the variance, the margin and the probability.</p> Statistic Notation Estimator Mean \\(\\mathbb{E}[\\varphi(x,U)]\\) \\(E_N[\\varphi(x,U)]=\\frac{1}{N}\\sum_{i=1}^N\\varphi(x,U^{(i)})\\) Variance \\(\\mathbb{V}[\\varphi(x,U)]\\) \\(V_N[\\varphi(x,U)]=\\frac{1}{N-1}\\sum_{i=1}^N\\left(\\varphi(x,U^{(i)})-E_N[\\varphi(x,U)]\\right)^2\\) Standard deviation \\(\\mathbb{S}[\\varphi(x,U)]\\) \\(S_N[\\varphi(x,U)]=\\sqrt{V_N[\\varphi(x,U)]}\\) Margin \\(\\textrm{Margin}[\\varphi(x,U)]\\) \\(\\textrm{Margin}_N[\\varphi(x,U)]=E_N[\\varphi(x,U)]+\\kappa\\times S_N[\\varphi(x,U)]\\) Probability \\(\\mathbb{P}[\\varphi(x,U)\\leq 0]\\) \\(P_N[\\varphi(x,U)\\leq 0]=E_N[\\mathbb{1}_{\\varphi(x,U)\\leq 0}]\\)"},{"location":"user_guide/umdo/sampling/#gradient-based-optimization","title":"Gradient-based optimization","text":"<p>When the multidisciplinary process is differentiable, and a gradient-based optimizer is used, analytical derivatives are implemented with the following statistics: mean, standard deviation, variance and margin. For probability statistics, only derivatives approximated by finite differences are currently available.</p>"},{"location":"user_guide/umdo/sequential_sampling/","title":"Sequential sampling","text":""},{"location":"user_guide/umdo/sequential_sampling/#sequential-sampling","title":"Sequential sampling","text":"<p>SequentialSampling is a U-MDO formulation that estimates the statistics unbiasedly by using Monte Carlo sampling. Contrary to Sampling, this U-MDO formulation does not use a constant sample size but a sample size that increases with the iterations of the optimization loop.</p> <p>The number of samples is mandatory and must be set with the parameter <code>n_samples</code>. It corresponds to the maximum number of samples for a given iteration of the optimization loop.</p> <p>Here is a typical scenario template:</p> <pre><code>scenario = UMDOScenario(\n    disciplines,\n    mdo_formulation_name,\n    objective_name,\n    design_space,\n    uncertain_space,\n    statistic_name,\n    statistic_estimation=\"SequentialSampling\",\n    statistic_estimation_parameters={\"n_samples\": n_samples}\n)\n</code></pre>"},{"location":"user_guide/umdo/sequential_sampling/#options","title":"Options","text":""},{"location":"user_guide/umdo/sequential_sampling/#algorithm","title":"Algorithm","text":"<p>By default, the formulation uses the algorithm <code>OT_OPT_LHS</code> to get a good space-filling design of experiments (DOE).</p> <p>DOE algorithms</p> <p>Read the GEMSEO documentation for more information about the available DOE algorithms.</p> <p>The DOE algorithm name can be set with the string parameter <code>algo</code> and its options with the dictionary parameter <code>algo_options</code>.</p> <p>API</p> <p>Use <code>statistic_estimation_parameters</code> to set the algorithm name and parameters, e.g.</p> <pre><code>scenario = UMDOScenario(\n    disciplines,\n    mdo_formulation_name,\n    objective_name,\n    design_space,\n    uncertain_space,\n    statistic_name,\n    statistic_estimation_parameters={\n        \"algo\": \"OT_MONTE_CARLO\",\n        \"n_samples\": 20,\n        \"algo_options\": {\"n_processes\": 2}\n    }\n)\n</code></pre>"},{"location":"user_guide/umdo/sequential_sampling/#sampling-size-profile","title":"Sampling size profile","text":"<p>By default, the number of samples is equal to 1 at the first iteration and is incremented by 1 at each iteration of the optimization loop.</p> <p>These values can be changed with the statistic estimation parameters <code>initial_n_samples</code> and <code>n_samples_increment</code>.</p>"},{"location":"user_guide/umdo/sequential_sampling/#statistics","title":"Statistics","text":"<p>This U-MDO formulation has been implemented for the expectation, the standard deviation, the variance, the margin and the probability, The estimators are given below at the \\(k\\)-th iteration of the optimization loop.</p> Statistic Notation Estimator Mean \\(\\mathbb{E}[\\varphi(x,U)]\\) \\(E_{N_k}[\\varphi(x,U)]=\\frac{1}{N_k}\\sum_{i=1}^{N_k}\\varphi(x,U^{(i)})\\) Variance \\(\\mathbb{V}[\\varphi(x,U)]\\) \\(V_{N_k}[\\varphi(x,U)]=\\frac{1}{N_k-1}\\sum_{i=1}^{N_k}\\left(\\varphi(x,U^{(i)})-E_{N_k}[\\varphi(x,U)]\\right)^2\\) Standard deviation \\(\\mathbb{S}[\\varphi(x,U)]\\) \\(S_{N_k}[\\varphi(x,U)]=\\sqrt{V_{N_k}[\\varphi(x,U)]}\\) Margin \\(\\textrm{Margin}[\\varphi(x,U)]\\) \\(\\textrm{Margin}_{N_k}[\\varphi(x,U)]=E_{N_k}[\\varphi(x,U)]+\\kappa\\times S_{N_k}[\\varphi(x,U)]\\) Probability \\(\\mathbb{P}[\\varphi(x,U)\\leq 0]\\) \\(P_{N_k}[\\varphi(x,U)\\leq 0]=E_{N_k}[\\mathbb{1}_{\\varphi(x,U)\\leq 0}]\\)"},{"location":"user_guide/umdo/surrogate/","title":"Surrogate model","text":""},{"location":"user_guide/umdo/surrogate/#surrogate","title":"Surrogate","text":"<p>Surrogate is a U-MDO formulation that estimates the statistics using surrogate models.</p> <p>At each iteration of the optimization loop, a surrogate model is built over the uncertain space and Monte Carlo sampling is used to estimate specific statistics, namely mean, standard deviation, variance, probability and margin.</p> <p>The number of samples to build the surrogate model is mandatory and must be set with the parameter <code>doe_n_samples</code>.</p> <p>Here is a typical scenario template:</p> <pre><code>scenario = UMDOScenario(\n    disciplines,\n    mdo_formulation_name,\n    objective_name,\n    design_space,\n    uncertain_space,\n    statistic_name,\n    statistic_estimation=\"Surrogate\",\n    statistic_estimation_parameters={\"doe_n_samples\": 20}\n)\n</code></pre>"},{"location":"user_guide/umdo/surrogate/#options","title":"Options","text":""},{"location":"user_guide/umdo/surrogate/#doe-algorithm","title":"DOE algorithm","text":"<p>By default, the formulation uses the OpenTURNS' DOE algorithm <code>OT_OPT_LHS</code>, which is a Latin hypercube sampling (LHS) technique enhanced by simulated annealing, a global optimization technique that starts from an initial LHS and improves it to maximize its discrepancy and so to get a better space-filling LHS.</p> <p>The DOE algorithm name can be set with the string option <code>doe_algo</code> and its options with the dictionary parameter <code>doe_algo_options</code>. When the DOE algorithm uses a random number generator, the integer option <code>doe_seed</code> can be used for reproducibility purposes.</p>"},{"location":"user_guide/umdo/surrogate/#surrogates-options","title":"Surrogate's options","text":"<p>This U-MDO formulation is based on a BaseRegressor. By default, this surrogate model is the RBFRegressor available in GEMSEO, which wraps the SciPy's RBF algorithm. Use the <code>regressor_name</code> to change the kind of regressor (use the name of a subclass of BaseRegressor) and the <code>regressor_options</code> argument to set the options of the BaseRegressor. For example, set <code>regressor_name</code> to <code>\"LinearRegressor\"</code> to use a linear regressor, <code>regressor_options</code> to <code>{\"function\": \"cubic\"}</code> for a RBFRegressor based on a cubic function and <code>regressor_n_samples</code> to <code>100</code> to estimate the statistics with 100 Monte Carlo simulations instead of 10000.</p> <p>API</p> <p>Use <code>statistic_estimation_parameters</code> to set the DOE algorithm and the surrogate's options, e.g.</p> <pre><code>scenario = UMDOScenario(\n    disciplines,\n    mdo_formulation_name,\n    objective_name,\n    design_space,\n    uncertain_space,\n    statistic_name,\n    statistic_estimation_parameters={\n        \"doe_algo\": \"OT_MONTE_CARLO\",\n        \"doe_n_samples\": 20,\n        \"doe_algo_options\": {\"n_processes\": 2},\n        \"regressor_name\": \"PolynomialRegressor\",\n        \"regressor_n_samples\": 100,\n        \"regressor_options\": {\"degree\": 3}\n    }\n)\n</code></pre>"},{"location":"user_guide/umdo/surrogate/#quality-options","title":"Quality options","text":"<p>Finally, many options can be used to adjust the log verbosity providing information on the PCEs built at each optimization iteration:</p> Name Description quality_threshold The learning quality threshold below which a warning is logged. quality_name The name of the measure to assess the quality of the PCE regressor. quality_cv_compute Whether to estimate the quality by cross-validation (CV). quality_n_folds The number of folds in the case of the CV technique. quality_cv_randomize Whether to shuffle the samples before dividing them in folds in the case of the CV technique. quality_cv_seed The seed of the pseudo-random number generator. quality_cv_threshold The CV quality threshold below which a warning is logged."},{"location":"user_guide/umdo/surrogate/#statistics","title":"Statistics","text":"<p>This U-MDO formulation has been implemented for the expectation, the standard deviation, the variance, the margin and the probability, by sampling the surrogate model \\(\\widehat{\\varphi}\\) of \\(\\varphi\\).</p> Statistic Notation Estimator Mean \\(\\mathbb{E}[\\varphi(x,U)]\\) \\(E_{\\textrm{Surrogate}}[\\varphi(x,U)]=\\frac{1}{N}\\sum_{i=1}^N\\widehat{\\varphi}(x,U^{(i)})\\) Variance \\(\\mathbb{V}[\\varphi(x,U)]\\) \\(V_{\\textrm{Surrogate}}[\\varphi(x,U)]=\\frac{1}{N-1}\\sum_{i=1}^N\\left(\\widehat{\\varphi}(x,U^{(i)})-E_{\\textrm{Surrogate}}[\\varphi(x,U)]\\right)^2\\) Standard deviation \\(\\mathbb{S}[\\varphi(x,U)]\\) \\(S_{\\textrm{PCE}}[\\varphi(x,U)]=\\sqrt{V_{\\textrm{Surrogate}}[\\varphi(x,U)]}\\) Margin \\(\\textrm{Margin}[\\varphi(x,U)]\\) \\(\\textrm{Margin}_{\\textrm{Surrogate}}[\\varphi(x,U)]=E_{\\textrm{Surrogate}}[\\varphi(x,U)] + \\kappa \\times S_{\\textrm{Surrogate}}[\\varphi(x,U)]\\) Probability \\(\\mathbb{P}[\\varphi(x,U)\\leq 0]\\) \\(P_{\\textrm{PCE}}[\\varphi(x,U)\\leq 0]=E_N[\\mathbb{1}_{\\widehat{\\varphi}(x,U)\\leq 0}]\\)"},{"location":"user_guide/umdo/taylor_polynomial/","title":"Taylor polynomial","text":""},{"location":"user_guide/umdo/taylor_polynomial/#taylor-polynomial","title":"Taylor polynomial","text":"<p>TaylorPolynomial is a U-MDO formulation that estimates the statistics using Taylor polynomials.</p> <p>The Taylor polynomials are centered at \\(\\mu=\\mathbb{E}[U]\\) where \\(U\\) is the random input vector.</p> <p>When the derivatives with respect to the uncertain variables are available, this U-MDO formulation introduces no additional calculation cost associated with taking the uncertainties into account. Otherwise, finite differences are computed and so the additional cost is \\(d+1\\) evaluations of the process associated with the MDOFormulation where \\(d\\) is the dimension of the uncertain space.</p> <p>This U-MDO formulation has no mandatory parameters.</p> <p>Here is a typical scenario template:</p> <pre><code>scenario = UMDOScenario(\n    disciplines,\n    mdo_formulation_name,\n    objective_name,\n    design_space,\n    uncertain_space,\n    statistic_name,\n    statistic_estimation=\"TaylorPolynomial\",\n)\n</code></pre>"},{"location":"user_guide/umdo/taylor_polynomial/#options","title":"Options","text":""},{"location":"user_guide/umdo/taylor_polynomial/#derivatives-calculation","title":"Derivatives calculation","text":"<p>When the derivatives with respect to the uncertain variables are missing or when the process resulting from the MDOFormulation cannot be differentiated with respect to these variables, this U-MDO formulation uses finite difference approximations. One can also force the use of finite difference approximations by setting the statistic estimation parameter <code>differentiation_method</code> to <code>\"finite_differences\"</code>.</p> <p>API</p> <p>Use <code>statistic_estimation_parameters</code> to set the options, e.g.</p> <pre><code>scenario = UMDOScenario(\n    disciplines,\n    mdo_formulation_name,\n    objective_name,\n    design_space,\n    uncertain_space,\n    statistic_name,\n    statistic_estimation=\"TaylorPolynomial\",\n    statistic_estimation_parameters={\"differentiation_method\": \"finite_differences\"}\n)\n</code></pre>"},{"location":"user_guide/umdo/taylor_polynomial/#second-order","title":"Second-order","text":"<p>By default, this U-MDO formulation uses first-order Taylor polynomials. Second-order Taylor polynomials can also be used by setting the statistic estimation parameter <code>second_order</code> to <code>True</code>.</p> <p>Computational cost</p> <p>As GEMSEO does not support second-order derivatives, the second-order derivatives are estimated by finite-differences from the first-order derivatives. When the dimension of the uncertain space is large or when the first-order derivatives are already finite difference approximations, using second-order Taylor polynomials can be very costly.</p>"},{"location":"user_guide/umdo/taylor_polynomial/#statistics","title":"Statistics","text":"<p>This U-MDO formulation has been implemented for the expectation, the standard deviation, the variance and the margin.</p> <p>Here are the expressions when using first-order Taylor polynomials.</p> Statistic Notation Estimator Mean \\(\\mathbb{E}[\\varphi(x,U)]\\) \\(E_{\\textrm{TP}_1}[\\varphi(x,U)]=\\varphi(x,\\mu)\\) Variance \\(\\mathbb{V}[\\varphi(x,U)]\\) \\(V_{\\textrm{TP}_1}[\\varphi(x,U)]=\\nabla\\varphi(x,\\mu)^T\\Sigma \\nabla\\varphi(x,\\mu)\\) Standard deviation \\(\\mathbb{S}[\\varphi(x,U)]\\) \\(S_{\\textrm{TP}_1}[\\varphi(x,U)]=\\sqrt{V_{\\textrm{TP}_1}[\\varphi(x,U)]}\\) Margin \\(\\textrm{Margin}[\\varphi(x,U)]\\) \\(\\textrm{Margin}_{\\textrm{TP}_1}[\\varphi(x,U)]=E_{\\textrm{TP}_1}[\\varphi(x,U)]+\\kappa\\times S_{\\textrm{TP}_1}[\\varphi(x,U)]\\) <p>where \\(\\Sigma=\\left(\\textrm{cov}(U_i,U_j)\\right)_{1\\leq i,j\\leq d}\\) is the covariance matrix of \\(U\\) and \\(\\nabla\\varphi(x,\\mu)= \\left(\\frac{\\partial\\varphi(x,\\mu)}{\\partial u_i}\\right)_{1\\leq i \\leq d}\\) is the column-vector of the partial derivatives of \\(\\varphi\\) with respect to the uncertain variables.</p>"},{"location":"user_guide/visualization/","title":"Visualization","text":""},{"location":"user_guide/visualization/#visualization","title":"Visualization","text":""},{"location":"user_guide/visualization/sobol_graph/","title":"Sobol graph","text":""},{"location":"user_guide/visualization/sobol_graph/#sobol-sensitivity-graph","title":"Sobol' sensitivity graph","text":"<p>The Sobol' indices<sup>1</sup> are widely used in sensitivity analysis <sup>2</sup><sup>3</sup>.</p> <p>Sobol' index</p> <p>A Sobol' index represent the proportion of the variance of a quantity of interest explained by one or more uncertain inputs.</p> <p>The proportion explained by a single uncertain input is called a first-order index, the proportion explained by the interaction of two uncertain inputs is called a second-order index, ... and the proportion explained by an uncertain input separately or in interaction with other uncertain inputs is called a total-order index.</p>"},{"location":"user_guide/visualization/sobol_graph/#visualize-sobol-indices","title":"Visualize Sobol' indices","text":"<p>These sensitivity indices are often represented with pie charts and bar charts. These charts display the first-order and total-order Sobol' indices associated with the different uncertain inputs.</p> <p>The pie charts represent the first- and second-order indices as pie slices while the bar charts represent the first- and total-order indices with confidence intervals.</p> <p>Bar charts can help to determine whether the indices are well estimated or whether the variance of the quantity of interest is explained by the interaction between some uncertain inputs.</p> <p></p> <p>Bar chart generated by GEMSEO from the Ishigami function.</p> <p>Pie charts can help to determine whether interactions of order greater than 2 explain the variance of the quantity of interest.</p> <p></p> <p>Pie chart generated from synthetic data.</p> <p>Info</p> <p>Most of the UQ libraries propose only first-order indices and total-order indices; some of them propose also the second-order indices.</p>"},{"location":"user_guide/visualization/sobol_graph/#fanova-graph","title":"FANOVA graph","text":""},{"location":"user_guide/visualization/sobol_graph/#introduction","title":"Introduction","text":"<p>In the case of second-order Sobol' indices, a FANOVA graph<sup>4</sup> can be used to display the interactions between the uncertain variables. This graph is a network of uncertain variables representing their Sobol' indices:</p> <ul> <li>A node represents an uncertain variable whose name is written inside,   followed by its first-order and total-order Sobol' indices,</li> <li>The thickness of a node   is proportional to the total-order Sobol' index   of the variable   while the thickness of an edge   is proportional to the second-order Sobol' index   of the corresponding pair of variables.</li> </ul>"},{"location":"user_guide/visualization/sobol_graph/#api","title":"API","text":"<p>The SobolGraph can be built from three dictionaries:</p> <ul> <li>the first-order indices defined as <code>{name: sobol_index}</code>,</li> <li>the second-order indices defined as <code>{(name, other_name): sobol_index}</code>,</li> <li>the total-order indices defined as <code>{name: sobol_index}</code>.</li> </ul> <p>Then, this graph can be both displayed in a window and saved on the disk:</p> <pre><code>sobol_graph = SobolGraph(first_sobol, second_sobol, total_sobol)\nsobol_graph.visualize()\n</code></pre> <p></p> <p>Sobol' graph for the Ishigami function.</p> <p>Note</p> <p>Several examples of Sobol' graphs, including this one, can be found in a dedicated gallery.</p> <p>Lastly, given one or more disciplines and an uncertain space, the SobolAnalysis proposed by GEMSEO computes the Sobol' indices for several discipline outputs. Then, the SobolGraph associated with a specific discipline output can be generated from this analysis:</p> <pre><code>sobol_graph = SobolGraph.from_analysis(sobol_analysis, output_name)\nsobol_graph.visualize()\n</code></pre>"},{"location":"user_guide/visualization/sobol_graph/#options","title":"Options","text":"<p>At instantiation, the float argument <code>threshold</code> allows to set the sensitivity threshold above which a second-order index is declared as significant and the corresponding edge plotted.</p> <p>One can also change the maximum thickness of a line with the argument <code>maximum_thickness</code>.</p> <ol> <li> <p>I.M Sobol\u2032. Global sensitivity indices for nonlinear mathematical models and their Monte Carlo estimates. Mathematics and Computers in Simulation, 55(1):271\u2013280, 2001.\u00a0\u21a9</p> </li> <li> <p>Andrea Saltelli, Marco Ratto, Terry Andres, Francesca Campolongo, Jessica Cariboni, Debora Gatelli, Michaela Saisana, and Stefano Tarantola. Global sensitivity analysis: the primer. John Wiley &amp; Sons, 2008.\u00a0\u21a9</p> </li> <li> <p>Bertrand Iooss and Paul Lema\u00eetre. A review on global sensitivity analysis methods. Uncertainty management in simulation-optimization of complex systems: algorithms and applications, pages 101\u2013122, 2015.\u00a0\u21a9</p> </li> <li> <p>Thomas Muehlenstaedt, Olivier Roustant, Laurent Carraro, and Sonja Kuhnt. Data-driven Kriging models based on FANOVA-decomposition. Statistics and Computing, 22:723\u2013738, 2012.\u00a0\u21a9</p> </li> </ol>"},{"location":"user_guide/visualization/uncertain_coupling_graph/","title":"Uncertain coupling graph","text":""},{"location":"user_guide/visualization/uncertain_coupling_graph/#uncertain-coupling-graph","title":"Uncertain coupling graph","text":""},{"location":"user_guide/visualization/uncertain_coupling_graph/#introduction","title":"Introduction","text":"<p>Standard sensitivity analysis<sup>1</sup><sup>2</sup> seeks to identify the uncertain inputs that have an impact on a model output. Similarly, in the case of a multidisciplinary system, some uncertain inputs can have a more significant impact on certain disciplines.</p>"},{"location":"user_guide/visualization/uncertain_coupling_graph/#graph","title":"Graph","text":"<p>Then, the goal of the UncertainCouplingGraph proposed by GEMSEO-UMDO is to identify:</p> <ul> <li>the coupling variables that are not impacted by the uncertain inputs,</li> <li>the disciplines that are not impacted by the uncertain inputs.</li> </ul> <p>The nodes of this graph represent the disciplines while the edges represent the coupling variables.</p> <p>The thickness of an edge is proportional to the absolute value of the dispersion of the corresponding coupling variable.</p> <p>A node connected only by ultra-thin edges will therefore be judged to be very insensitive to uncertain inputs.</p>"},{"location":"user_guide/visualization/uncertain_coupling_graph/#dispersion-measures","title":"Dispersion measures","text":"<p>The dispersion of a coupling variable is computed using a DispersionMeasure. GEMSEO-UMDO proposes two dispersion measures.</p> <p>The coefficient of variation (COV) represents the standard deviation normalized by the mean value:</p> \\[\\textrm{COV}[Y]=\\frac{\\mathbb{S}[Y]}{\\mathbb{E}[Y]}\\] <p>where \\(\\mathbb{E}[Y]\\) and \\(\\mathbb{S}[Y]\\) are the expectation and standard deviation of the random variable \\(Y\\). \\(\\textrm{COV}[Y]\\) tends to infinity as \\(\\textrm{E}[Y]\\) tends to 0, which makes it sensitive to small changes in \\(\\textrm{E}[Y]\\) for values near zero.</p> <p>The quartile coefficient of dispersion (QCD) represents the interquartile range (IQR) normalized by the sum of the first and third quartile:</p> \\[\\textrm{QCD}[Y]=\\frac{\\mathbb{q}_{75\\%}[Y]-\\mathbb{q}_{25\\%}[Y]}{\\mathbb{q}_{25\\%}[Y]+\\mathbb{q}_{75\\%}[Y]}\\] <p>where \\(\\mathbb{q}_{\\alpha}[Y]\\) is the \\(\\alpha\\)-quantile of \\(Y\\).</p>"},{"location":"user_guide/visualization/uncertain_coupling_graph/#api","title":"API","text":"<p>Firstly, the UncertainCouplingGraph is built from a collection of disciplines, an uncertain space and possibly a subset of coupling variable names.</p> <pre><code>graph = UncertainCouplingGraph(disciplines, uncertain_space)\n</code></pre> <p>Then, the disciplines are sampled using an optimized Latin hypercube sampling technique:</p> <pre><code>graph.sample(100)\n</code></pre> <p>Warning</p> <p>Setting the number of samples is mandatory. In the previous example, we used 100 samples.</p> <p>Lastly, this graph can be both displayed in a window and saved on the disk:</p> <pre><code>graph.visualize()\n</code></pre> <p></p> <p>Uncertainty coupling graph from the Sobieski's SSBJ problem.</p> <p>Note</p> <p>Several examples of uncertain coupling graphs, including this one, can be found in a dedicated gallery.</p>"},{"location":"user_guide/visualization/uncertain_coupling_graph/#options","title":"Options","text":"<p>At the sampling stage, the algorithm can be modified by setting the arguments <code>algo_name</code> and <code>algo_options</code> of the method sample().</p> <p>At the visualization stage, the string argument <code>dispersion_measure</code> allows to change the dispersion measure (QCD by default).</p> <p>It is also possible to filter some coupling variables with the argument <code>variable_names</code> (all coupling variables are displayed by default).</p> <p>Lastly, the float argument <code>maximum_thickness</code> can be used to set the maximum edge thickness.</p> <ol> <li> <p>Andrea Saltelli, Marco Ratto, Terry Andres, Francesca Campolongo, Jessica Cariboni, Debora Gatelli, Michaela Saisana, and Stefano Tarantola. Global sensitivity analysis: the primer. John Wiley &amp; Sons, 2008.\u00a0\u21a9</p> </li> <li> <p>Bertrand Iooss and Paul Lema\u00eetre. A review on global sensitivity analysis methods. Uncertainty management in simulation-optimization of complex systems: algorithms and applications, pages 101\u2013122, 2015.\u00a0\u21a9</p> </li> </ol>"}]}