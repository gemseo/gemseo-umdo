{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Take advantage of vectorized disciplines\n\nGEMSEO v6.2 opened the door to batch sampling\nby making the MDO formulations support vectorized disciplines\nand adding the ``vectorize`` option to the DOE algorithms.\nIn other words,\nGEMSEO can evaluate a multidisciplinary system at several points at the same time,\nwithout the need for multiple processes (see the DOE option ``n_processes`` for more information).\nThis can be particularly useful when evaluating such a system\nin parallel is more expensive than evaluating it serially because\nthe disciplines are so inexpensive.\nIn this case, the batch sampling can be sequential.\n\nTo illustrate this new feature,\nGEMSEO v6.2 vectorizes the disciplines of the Sellar problem\n([Sellar1][gemseo.problems.mdo.sellar.sellar_1.Sellar1],\n[Sellar2][gemseo.problems.mdo.sellar.sellar_2.Sellar2] and\n[SellarSystem][gemseo.problems.mdo.sellar.sellar_system.SellarSystem]).\nThis example uses them to demonstrate the interest of vectorization\nwhen solving an MDO problem under uncertainty\nwhose statistics are estimated by Monte Carlo sampling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n\nfrom typing import TYPE_CHECKING\n\nfrom gemseo.algos.doe.scipy.settings.mc import MC_Settings\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.formulations.mdf_settings import MDF_Settings\nfrom gemseo.mda.gauss_seidel_settings import MDAGaussSeidel_Settings\nfrom gemseo.problems.mdo.sellar.sellar_1 import Sellar1\nfrom gemseo.problems.mdo.sellar.sellar_2 import Sellar2\nfrom gemseo.problems.mdo.sellar.sellar_design_space import SellarDesignSpace\nfrom gemseo.problems.mdo.sellar.sellar_system import SellarSystem\nfrom gemseo.uncertainty.distributions.openturns.triangular_settings import (\n    OTTriangularDistribution_Settings,\n)\nfrom gemseo.utils.timer import Timer\n\nfrom gemseo_umdo.formulations.sampling_settings import Sampling_Settings\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario\n\nif TYPE_CHECKING:\n    from gemseo.datasets.optimization_dataset import OptimizationDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First,\nwe create a function to solve the MDO problem under uncertainty\ndepending on a boolean argument `vectorize`.\nThe Monte Carlo sampling to estimate the statistics can be performed\neither sequentially when `vectorize` is `True`\nor all at once when `vectorize` is `False`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def solve_problem(vectorize: bool) -> tuple[float, OptimizationDataset]:\n    \"\"\"Solve the MDO problem under uncertainty.\n\n    Args:\n        vectorize: Whether to enable vectorization.\n\n    Returns:\n        The elapsed time and the dataset\n        including the value of the design variables, the objective and the constraints\n        at each iteration of the algorithm in charge to solve the problem.\n    \"\"\"\n\n    disciplines = [Sellar1(), Sellar2(), SellarSystem()]\n\n    design_space = SellarDesignSpace(dtype=\"float\")\n\n    uncertain_space = ParameterSpace()\n    uncertain_space.add_random_variable(\n        \"gamma\", OTTriangularDistribution_Settings(minimum=0.1, mode=0.2, maximum=0.3)\n    )\n\n    scenario = UMDOScenario(\n        disciplines,\n        \"obj\",\n        design_space,\n        uncertain_space,\n        \"Mean\",\n        Sampling_Settings(\n            # Note: The default value of vectorize is False, whatever the DOE algorithm.\n            doe_algo_settings=MC_Settings(n_samples=100, vectorize=vectorize)\n        ),\n        formulation_settings_model=MDF_Settings(\n            main_mda_settings=MDAGaussSeidel_Settings()\n        ),\n    )\n    scenario.add_constraint(\"c_1\", \"Margin\")\n    scenario.add_constraint(\"c_2\", \"Margin\")\n    with Timer() as timer:\n        scenario.execute(MC_Settings(n_samples=20))\n\n    return timer.elapsed_time, scenario.to_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are ready to solve the MDO problem under uncertainty sequentially,\nin order to get a reference:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "time_no_vect, dataset_no_vect = solve_problem(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now,\nwe can solve this problem using batch sampling:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "time_vect, dataset_vect = solve_problem(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that both executions produce similar logs.\nIn particular,\nthe objective value is the same at each iteration... which is reassuring!\nThis is confirmed by checking that all results are equal:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset_vect.equals(dataset_vect)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That's reassuring, isn't it?\n\nLast but not least,\nwe can look at the execution time\nwhen sampling the process in batch mode (`vectorize=True`):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "round(time_vect, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and see that it is much lower than in sequential mode (`vectorize=False`):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "round(time_no_vect, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "More precisely,\nthe time execution is reduced by\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(round((time_no_vect - time_vect) / time_no_vect * 100), \"%\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}