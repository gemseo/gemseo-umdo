{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# A quadratic mono-disciplinary problem\n\nIn this example, we consider the quadratic mono-disciplinary optimization problem\n\n$$\\min_{x\\in[-1,1]} \\mathbb{E}[(x+U)^2]$$\n\nwhere $U\\sim\\mathcal{N}(0,1)$ is a standard Gaussian variable and $\\mathbb{E}$ is the\nexpectation operator.\n\nThe objective can be rewritten as $x^2+1$ and then the solution is obvious, namely\n\n$$(x^*,\\mathbb{E}[(x^*+U)^2])=(0,1).$$\n\nIn the following, we will call $f$ the function computing $(x+U)^2$ given $x$ and $U$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\n\nfrom gemseo_umdo.formulations.pce_settings import PCE_Settings\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Firstly,\nwe define an [AnalyticDiscipline][gemseo.disciplines.analytic.AnalyticDiscipline]\nimplementing the function $f$:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "discipline = AnalyticDiscipline({\"y\": \"(x+u)**2\"}, name=\"f\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "as well as the design space:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "design_space = DesignSpace()\ndesign_space.add_variable(\"x\", lower_bound=-1, upper_bound=1.0, value=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and the uncertain space:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "uncertain_space = ParameterSpace()\nuncertain_space.add_random_variable(\"u\", \"OTNormalDistribution\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then,\nwe define a [UMDOScenario][gemseo_umdo.scenarios.umdo_scenario.UMDOScenario]\nto minimize the statistic $\\mathbb{E}[(x+U)^2]$\nestimated using a polynomial chaos expansion (PCE)\ntrained from 20 samples at each iteration of the optimization loop:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scenario = UMDOScenario(\n    [discipline],\n    \"y\",\n    design_space,\n    uncertain_space,\n    \"Mean\",\n    formulation_name=\"DisciplinaryOpt\",\n    statistic_estimation_settings=PCE_Settings(n_samples=20),\n    # Note that we can change the settings of the OpenTURNS-based PCE regressor:\n    # statistic_estimation_settings=PCE_Settings(\n    #     n_samples=20, regressor_settings=PCERegressor_Settings(use_lars=True)\n    # ),\n    #\n    # or even change the type of FCE regressor:\n    # statistic_estimation_settings=PCE_Settings(\n    #     n_samples=20, regressor_settings=FCERegressor_Settings()\n    # ),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "!!! note\n    The mean, standard deviation and variance\n    of the PCE built over the uncertain space\n    are differentiable with respect to the design variables\n    if both the disciplines and the MDO formulation are differentiable,\n    which is the case in this example.\n    This implies that a gradient-based optimization algorithm can be used\n    without approximating the derivatives of the objective.\n\nWe execute this scenario using the gradient-based optimizer SLSQP:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scenario.execute(algo_name=\"NLOPT_SLSQP\", max_iter=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and plot the optimization history:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scenario.post_process(post_name=\"OptHistoryView\", save=False, show=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice that the numerical solution\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "(scenario.optimization_result.x_opt[0], scenario.optimization_result.f_opt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "is close to the theoretical solution $(x^*,\\mathbb{E}[(x^*+U)^2])=(0,1)$.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}