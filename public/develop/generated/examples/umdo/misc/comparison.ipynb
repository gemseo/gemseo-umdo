{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Control variate vs Sampling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n\nimport numpy as np\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\nfrom gemseo.utils.string_tools import MultiLineString\nfrom matplotlib import pyplot as plt\nfrom numpy import array\nfrom numpy import ndarray\nfrom numpy import quantile\nfrom scipy.spatial.distance import cdist\n\nfrom gemseo_umdo.scenarios.umdo_scenario import UMDOScenario"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Firstly,\nwe define an [AnalyticDiscipline][gemseo.disciplines.analytic.AnalyticDiscipline]\nimplementing a random version of the Rosenbrock function\n$f(x,y,U)=(U-x)^2+100(y-x^2)^2$:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "discipline = AnalyticDiscipline({\"z\": \"(a-x)**2+100*(y-x**2)**2\"}, name=\"Rosenbrock\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "where $x,y$ belongs to the interval $[-2,2]$:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "design_space = DesignSpace()\ndesign_space.add_variable(\"x\", l_b=-2, u_b=2.0, value=-2.0)\ndesign_space.add_variable(\"y\", l_b=-2, u_b=2.0, value=-2.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and $U$ is a Gaussian variable with unit mean\nand standard deviation equal to 0.05:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "uncertain_space = ParameterSpace()\nuncertain_space.add_random_variable(\"a\", \"OTNormalDistribution\", mu=1.0, sigma=0.05)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then,\nwe want to build a [UMDOScenario][gemseo_umdo.scenarios.umdo_scenario.UMDOScenario]\nto minimize a sampling-based estimation\nof the expectation $\\mathbb{E}[Y]$ where $Y=f(x,y,U)$:\nFor that,\nwe compare an approach based on crude Monte Carlo\nand an approach based on a linearized model as control variate\nand repeat it 20 times to get statistics on the results:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "method_to_x_opt = {\"Sampling\": [], \"ControlVariate\": []}\nfor i in range(20):\n    for method in [\"Sampling\", \"ControlVariate\"]:\n        scenario = UMDOScenario(\n            [discipline],\n            \"DisciplinaryOpt\",\n            \"z\",\n            design_space,\n            uncertain_space,\n            \"Mean\",\n            statistic_estimation=method,\n            statistic_estimation_parameters={\n                \"algo\": \"OT_MONTE_CARLO\",\n                \"n_samples\": 10,\n                \"seed\": i + 1,\n            },\n        )\n        scenario.set_differentiation_method(\"finite_differences\")\n        scenario.execute({\"algo\": \"NLOPT_SLSQP\", \"max_iter\": 100})\n        method_to_x_opt[method].append(scenario.optimization_result.x_opt.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lastly,\nwe print and plot the comparison\nin terms of distance to the theoretical solution $x^*=(1,1)$:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def ecdf(data: ndarray) -> tuple[ndarray, ndarray]:\n    \"\"\"Empirical cumulative distribution function.\n\n    Args:\n        data: The data.\n\n    Returns:\n        The quantiles and the cumulative probabilities.\n    \"\"\"\n    quantiles, counts = np.unique(data, return_counts=True)\n    return quantiles, np.cumsum(counts).astype(np.double) / data.size\n\n\ncomparison = MultiLineString()\nfor index, method in enumerate([\"Sampling\", \"ControlVariate\"]):\n    distances_to_one = cdist(array(method_to_x_opt[method]), array([[1.0, 1.0]]))\n    x, y = ecdf(abs(distances_to_one))\n    plt.plot(x, y, \"-\" * index, label=method)\n    comparison.add(method)\n    comparison.indent()\n    comparison.add(f\"Mean: {distances_to_one.mean():.2e}\")\n    comparison.add(f\"Standard deviation: {distances_to_one.std():.2e}\")\n    comparison.add(f\"0.05-quantile: {quantile(distances_to_one, 0.05):.2e}\")\n    comparison.add(f\"0.95-quantile: {quantile(distances_to_one, 0.95):.2e}\")\n    comparison.dedent()\n\nprint(comparison)\n\nplt.xlabel(\"Distance to the theoretical solution x=(1,1)\")\nplt.ylabel(\"Cumulative distribution function\")\nplt.legend()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}